Natural Language Processing for Analyzing Electronic
Health Records and Clinical Notes in Cancer Research:
A Review
Muhammad Bilala,∗, Ameer Hamzab, Nadia Malikc
aDepartment of Pharmaceutical Outcomes and Policy, University of
Florida, Gainesville, 32611, Florida, USA
bDepartment of Computer Science, Faculty of Computing and IT, University of
Sargodha, Sargodha, 40100, Punjab, Pakistan
cDepartment of Software Engineering, Faculty of Computing and IT, University of
Sargodha, Sargodha, 40100, Punjab, Pakistan
Abstract
Objective: This review aims to analyze the application of natural lan-
guage processing (NLP) techniques in cancer research using electronic health
records (EHRs) and clinical notes. This review addresses gaps in the existing
literature by providing a broader perspective than previous studies focused
on specific cancer types or applications.
Methods: A comprehensive literature search was conducted using the Sco-
pus database, identifying 94 relevant studies published between 2019 and
2024.
Data extraction included study characteristics, cancer types, NLP
methodologies, dataset information, performance metrics, challenges, and
future directions. Studies were categorized based on cancer types and NLP
applications.
Results: The results showed a growing trend in NLP applications for cancer
research, with breast, lung, and colorectal cancers being the most studied.
Information extraction and text classification emerged as predominant NLP
tasks. A shift from rule-based to advanced machine learning techniques, par-
ticularly transformer-based models, was observed. The Dataset sizes used
in existing studies varied widely. Key challenges included the limited gener-
alizability of proposed solutions and the need for improved integration into
clinical workflows.
∗muhammad.bilal@ufl.edu; mbilal.csit@gmail.com (Muhammad Bilal)
Preprint submitted to Elsevier
October 30, 2024
arXiv:2410.22180v1  [cs.CL]  29 Oct 2024
Conclusion: NLP techniques show significant potential in analyzing EHRs
and clinical notes for cancer research. However, future work should focus on
improving model generalizability, enhancing robustness in handling complex
clinical language, and expanding applications to understudied cancer types.
Integration of NLP tools into clinical practice and addressing ethical consid-
erations remain crucial for utilizing the full potential of NLP in enhancing
cancer diagnosis, treatment, and patient outcomes.
Keywords:
Natural Language Processing, Electronic Health Records,
Clinical Notes, Cancer, Information Extraction, Text Classification
1. Introduction
Cancer remains one of the most significant global health challenges, with
recent projections indicating 1,958,310 new cancer cases and 611,720 cancer
deaths in the United States for 2024 [1]. Despite significant advancements
in cancer research and treatment, there is an urgent need for innovative ap-
proaches to improve patient outcomes and address persistent disparities in
cancer care [2, 3]. Traditionally, cancer research has heavily relied on struc-
tured data and imaging techniques, such as histopathology and radiology
[4, 5]. Advanced image processing and computer vision techniques have been
applied to analyze medical imaging data to assist in early detection and accu-
rate diagnosis of various cancers [6, 7]. While these techniques have produced
useful results, they frequently fail to capture the rich, complex information
contained in unstructured clinical text. Electronic health records (EHRs)
and clinical notes contain extensive information about patient’s medical his-
tories, diagnoses, treatments, and outcomes, providing a unique opportunity
to gain a better understanding of cancer progression, treatment effectiveness,
and patient experiences [8, 9].
In recent years, the application of natural language processing (NLP)
to analyze EHRs and clinical notes has emerged as a promising field for
advancing cancer research [10]. NLP techniques can automatically analyze
large volumes of clinical text, identify relevant information, and generate
structured data for further analysis [11]. This capability has the potential
to revolutionize cancer research by enabling the extraction of valuable in-
sights from enormous amounts of previously unexplored clinical data [12].
Moreover, by automating the analysis of unstructured clinical data, NLP
can substantially reduce the costs and time associated with manual data re-
2
view. This efficiency can expedite the review of extensive medical records
and potentially identify early warning signs leading to earlier and more accu-
rate diagnoses. Furthermore, by improving the accuracy of data extraction
and analysis, NLP can enhance clinical decision-making and improve patient
health outcomes.
In recent years, the application of NLP to analyze EHRs and clinical notes
in cancer research has gained significant attention. However, compared to
reviews on image processing and computer vision techniques for cancer re-
search, very few reviews exist on NLP applications in cancer research. While
recent studies have attempted to address this gap by exploring various aspects
of NLP in cancer research they have primarily concentrated on specific areas
or cancer types. For instance, Datta et al. [12] provided a frame semantic
overview of NLP-based information extraction for cancer-related EHR notes,
while Aggarwal and Pallavi [13] examined advancements and challenges in
NLP for oral cancer research. Wang et al. [14] assessed EHRs for cancer
research and patient care through a scoping review, and Gholipour et al. [15]
systematically reviewed studies that applied NLP methods to identify cancer
concepts from clinical notes. Additionally, Bitterman et al. [16] presented a
review of clinical NLP for radiation oncology, and Sangariyavanich et al. [17]
conducted a systematic review of NLP for recurrent cancer detection from
electronic medical records.
The limitations attached to existing reviews highlight the need for a more
comprehensive review that can provide valuable insights into various cancer
types, NLP applications, techniques, datasets, and challenges. This review
aims to address this gap by analyzing NLP applications in cancer research
using EHRs and clinical notes, classifying studies based on different can-
cer types, discussing NLP techniques and applications, examining available
datasets, and exploring open research challenges and future directions. This
will give researchers and clinicians a broader understanding of the current
state and potential future developments.
The remainder of this paper is structured as follows: Section 2 details
the methodology used in conducting this review. Section 3 provides a tax-
onomy and categorizes the studies by cancer type and research objective.
Section 4 discusses the overall distribution of studies across different cate-
gories and journals highlighting trends in the number of publications, and
identifying top-cited papers. Section 5 discusses the various NLP techniques
and methodologies identified in the literature. Section 6 examines NLP-based
datasets in cancer research, discussing their characteristics, availability, and
3
potential for future research. Section 7 outlines open research challenges and
future directions for NLP in cancer research. Lastly, Section 8 concludes this
review with a summary of key findings and implications for future research.
2. Materials and Methods
This study conducted a systematic literature review to investigate the
use of NLP techniques in analyzing EHRs for cancer research. The review
focused on peer-reviewed articles published since 2019. The literature search
was conducted using the “Scopus” database. The search query was care-
fully created to capture relevant studies addressing the intersection of EHRs,
cancer, and NLP. The search query included key terms such as “Electronic
Health Records”. “EHRs”, “Clinical Notes”, “Cancer”, “Natural Language
Processing”, and “NLP”. The query was structured to focus on these concepts
within the title, abstract, and keywords of articles. The selection of stud-
ies for this review was guided by a set of predefined inclusion and exclusion
criteria. To be included, studies had to be published in peer-reviewed jour-
nals since 2019, focusing specifically on the application of NLP techniques
to EHRs or clinical notes in the context of cancer. Only articles written
in English were considered. The review excluded conference papers, book
chapters, reviews, and editorials to maintain a focus on primary research ar-
ticles. Studies that did not directly address the use of NLP on EHR data for
cancer research were also excluded. Additionally, articles published outside
the specified time frame were not considered. These criteria were strictly ap-
plied throughout the screening process to ensure the inclusion of articles that
specifically addressed the application of NLP techniques to EHRs or clini-
cal notes in the context of cancer, published in reputable academic journals
within the specified time frame.
The flow diagram in Figure 1 illustrates the selection process, clearly in-
dicating the number of studies at each stage of screening and the reasons for
exclusions. Initially, the Scopus database search identified 272 potentially
relevant studies. After removing duplicate studies 255 articles underwent a
preliminary screening based on titles and abstracts, resulting in 130 stud-
ies being considered for further review. Subsequently, 130 articles were at-
tempted to be retrieved for full-text review, and 117 studies were successfully
received for full-text evaluation. Finally, 94 studies were selected to be in-
cluded in this review. This rigorous selection process ensured that only the
4
most relevant and high-quality studies addressing the application of NLP to
EHRs in cancer care were included in the final analysis.
This review was guided by key research questions focusing on the cat-
egorization of studies by cancer types, distribution of research across can-
cer categories, predominant NLP applications and techniques, NLP-based
datasets, and current research challenges and future directions.
For each
selected study, we extracted a comprehensive set of data including study
identifiers, characteristics, cancer-specific information, NLP-related details,
dataset information, outcomes and performance metrics, reported challenges
and limitations, and suggested future directions. This systematic extraction
Figure 1: Prisma flow diagram for selection of studies.
5
process enabled us to develop a detailed taxonomy based on cancer types
and facilitated in-depth analysis of NLP applications in cancer research using
EHRs and clinical notes. This provided the foundation for our discussion on
study distribution, NLP techniques, datasets, and open research challenges.
3. Taxonomy of NLP in Cancer Research
This section presents a taxonomy of NLP applications in cancer research,
categorized based on a thorough review of research objectives and cancer
types. Figure 2 provides a visual representation of the overall taxonomy.
Moreover, studies that cover multiple cancer types are discussed separately
in this section under “Multiple Cancer Types”.
3.1. Respiratory Cancers
3.1.1. Lung Cancer
Several studies have focused on extracting specific types of information
from clinical notes for lung cancer research. Hong et al. [18] developed a rule-
based Named Entity Recognizer to extract age and temporal events from clin-
ical histories, achieving F1-scores of 86%. Ruckdeschel et al. [19], Liu et al.
[23] and Ebrahimi et al. [25] have developed methods to extract smoking sta-
tus and history from clinical notes, resulting in high F-scores and improved
patient identification for screening. Extraction of lung cancer diagnosis in-
formation has also been explored, with [21] achieving F1-scores of 90% for
named entity recognition and 89% for relating diagnoses to dates in Spanish
clinical notes. Studies by Gauthier et al. [22] and Wang et al. [26] investigated
the extraction of various clinical details, demonstrating high accuracy and re-
call rates for demographic data and cancer-related information. Radiological
information extraction was examined by Yang et al. [24], comparing trans-
former models for pulmonary nodule information extraction, with RoBERTa-
mimic achieving the best F1-score of 0.9279. Recent research has explored
large language models for information extraction, with Hu et al. [20] investi-
gating ChatGPT’s performance on lung cancer radiology reports. Social and
behavioral determinants of health (SBDoH) extraction has been studied by
Yu et al. [27] and Yu et al. [29], using bidirectional encoder representations
from transformers (BERT) based models and achieved high F1-scores. Zig-
man Suchsland et al. [28] analyzed EHRs to investigate the timeliness of lung
cancer diagnosis, revealing a median interval of 570 days from first symptoms
to diagnosis. Finally, Benedum et al. [30] evaluated the quality of oncology
6
Cancer Studies
Respiratory
Lung Cancer
[18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,
32, 33, 34, 35, 36, 37, 38, 39]
Non-Small Cell
Lung Cancer
[40, 41, 42, 43, 44]
Gastrointestinal
Colorectal
[45, 46, 47, 48, 49, 31, 50, 34, 51, 52, 36, 53, 37]
Colon
[54]
Pancreatic
[55, 56, 51, 36, 53]
Esophageal
[51, 36, 57]
Gastric/Stomach
[51, 36]
Hepatocellular
Carcinoma
[58]
Reproductive
Breast
[59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,
73, 74, 75, 31, 44, 33, 50, 76, 34, 52, 35, 58, 36, 37, 38]
Prostate
[77, 78, 79, 80, 81, 82, 83, 84, 85, 31, 44, 34, 36, 86]
Ovarian
[87, 88, 31, 76, 36, 53]
Cervical
[89, 76]
Uterine
[76]
Endometrial
[36]
Endocrine
Thyroid
[90, 91]
Skin
Basal Cell
[92]
Melanoma
[93, 36]
Central Ner-
vous System
Brain Metastases
[94]
Pediatric Brain
[31]
Hematological
Multiple Myeloma
[39]
Bone
Osteosarcoma
[32]
Other
Head and Neck
[36]
Leiomyosarcoma
[36]
Renal
[36, 86]
Urothelial
[36]
Bladder
[86]
Stage-Specific
Advanced
[95, 96]
Late-Stage/IV
[97, 98]
Unspecified
[99, 100, 101, 102, 103, 104, 105, 106]
Adverse Event
[107, 108, 109, 110, 111]
Figure 2: Taxonomy of Cancer Types and respective studies.
7
data extracted using machine learning and NLP techniques, finding less than
8% difference compared to expert manual abstraction.
3.1.2. Non-Small Cell Lung Cancer (NSCLC)
A number of studies have also demonstrated the effectiveness of auto-
mated systems in extracting and analyzing NSCLC-related information from
clinical data. An automated medical reports processing system developed by
Kersloot et al. [41], showed high performance in detecting lung cancer and
NSCLC concepts, with F1-scores ranging from 0.828 to 0.947 and 0.862 to
0.933, respectively. Similarly, Yusuf et al. [43] created a text analysis frame-
work for extracting epidermal growth factor receptor (EGFR) mutation in-
formation from unstructured clinical data, achieving 97.5% accuracy on a
sample of 362 tests. Expanding on these efforts, Adamson et al. [42] applied
NLP and machine learning methods to a nationwide EHR-derived database
of over 300,000 cancer patients. This study developed models to extract vari-
ous cancer-related variables with high performance, including 0.96 sensitivity
and 0.92 positive predictive value for extracting non-squamous histology in
NSCLC patients. Addressing data protection concerns, Paul et al. [40] built
a clinical de-identification model using conditional random fields (CRF) for
named entity recognition on EHRs. Analyzing 1,500 pathology reports from
421 advanced NSCLC patients, they found that n-gram, prefix-suffix, word
embedding, and word shape features performed best, with the model achiev-
ing F1-scores ranging from 0.65 to 0.95 for most protected health informa-
tion categories, and notably observed that performance was saturated with
around 200 training samples.
3.2. Gastrointestinal Cancers
3.2.1. Colorectal Cancer
Colorectal cancer remains a significant health concern, prompting re-
searchers to explore advanced approaches for improving diagnosis, treatment,
and follow-up care. Research at Cleveland Clinic and the University of Min-
nesota [46] evaluated a hybrid optical character recognition and NLP ap-
proach for extracting quality metric data from colonoscopy and pathology re-
ports, demonstrating high accuracy in detecting various colonoscopy-related
factors.
Similarly, a study involving three national health service (NHS)
Trusts in the UK [48] developed a research database for colorectal cancer
using routinely collected health data, implementing NLP to extract rele-
vant information from imaging and histopathology reports.
Additionally,
8
researchers have explored the application of NLP in clinical decision sup-
port and predictive modeling. A study at Cleveland Clinic [49] developed
and validated an automated clinical decision support algorithm for follow-up
colonoscopy recommendations, achieving 100% accuracy in data extraction
and 99% guideline concordance.
Li et al. [45] developed an interpretable fusion model to predict liver
metastases in postoperative colorectal cancer patients, achieving high pre-
dictive performance by integrating both free-text medical records and struc-
tured laboratory data. A study also attempted to assess the utility of NLP in
identifying individuals with chronic mobility disability from electronic health
records. Agaronnik et al. [47] analyzed 303,182 clinical notes from 14,877 col-
orectal cancer patients. Although NLP screening identified notes containing
wheelchair-associated keywords, only a small portion contained clear docu-
mentation of wheelchair use reason and duration. This research highlighted
the need for manual chart review to confirm chronic mobility disability and
emphasized inadequate disability documentation in many clinical notes.
3.2.2. Colon Cancer
Ryu et al. [54] focused on transforming colon cancer pathology reports
into the observational medical outcomes partnership (OMOP) common data
model (CDM) format. The researchers utilized NLP techniques to extract
and standardize clinical text entities from pathology reports, including sur-
gical specimens, immunohistochemical studies, and molecular studies. The
dataset comprised 18,090 reports from Seoul National University Bundang
Hospital. The extracted information was mapped to standard terminologies
and inserted into CDM tables. The study achieved 100% recognition ac-
curacy for key attributes from surgical specimen pathology and molecular
study reports, successfully creating a standardized database for colon can-
cer research. This transformation enables the integration of pathology data
with other clinical and omics data, facilitating more comprehensive cancer
research using the OMOP CDM framework.
3.2.3. Pancreatic Cancer
Sarwal et al. [55] aimed to use NLP to automatically extract pancreatic
ductal adenocarcinoma (PDAC) risk factors from unstructured clinical notes
in EHRs. The researchers developed rule-based NLP algorithms and tested
them on a dataset of 2091 clinical notes and an additional cohort of 1138
patients. The algorithms showed high sensitivity for identifying PDAC risk
9
factors, with particularly strong results for family history detection. For the
family history of PDAC, the algorithm achieved a recall of 0.933, precision
of 0.790, and F1-score of 0.856. For germline genetic mutations, the recall
was 0.851, but precision (0.350) and F1-score (0.496) were lower due to false
positives from tissue mutation misidentification. The study suggests that
NLP can be a valuable tool for automating the identification of high-risk in-
dividuals for pancreatic cancer screening, though further validation in larger
primary-care populations is recommended.
3.3. Reproductive System Cancers
3.3.1. Breast Cancer
The use of NLP to extract breast cancer phenotypes from EHRs has
been investigated in many studies. Zhou et al. [59] evaluated the generaliz-
ability of different NLP models, comparing conditional random field (CRF),
bidirectional long short-term memory CRF (BiLSTM-CRF), and Cancer-
BERT models. Using a large dataset of 72,020 breast cancer patient records,
the study found that CancerBERT models demonstrated better performance
and generalizability. Zhou et al. [60] proposed and evaluated CancerBERT,
achieving high macro F1-scores for exact and lenient matches. In the con-
text of non-English EHRs, researchers have explored NLP applications in
various languages. Studies on Spanish [61, 70] and Czech [71] clinical notes
have shown promising results using different transformer-based models and
transfer learning techniques.
Several studies have focused on predicting breast cancer outcomes and
treatment responses using NLP and machine learning techniques. Ribelles
et al. [62] investigated predictive models for early and late progression to
first-line treatment in hormone receptor-positive (HR+)/HER2-negative ad-
vanced breast cancer patients, with NLP-based approaches slightly outper-
forming manual feature extraction. Another study by Sanyal et al. [63] de-
veloped a weakly supervised deep learning model for predicting breast cancer
distant recurrence, achieving high area under the receiver operating charac-
teristic curve (AUROC), sensitivity, and specificity. Research has also been
conducted on extracting specific information from pathology reports and clin-
ical notes. A novel NLP technique called relevant word order vectorization
(RWOV) [64] was introduced for analyzing EHRs, achieving high F1-scores
when classifying hormone receptor status in breast cancer patients. The ap-
plication of NLP in clinical trial recruitment has been explored by Meystre
10
et al. [74], with machine learning-based NLP applications demonstrating high
recall and precision in extracting eligibility criteria.
The creation of extensive databases and systems for breast cancer re-
search has been examined by several studies.
A study by Jin et al. [66]
described the creation of a breast cancer-specific database system, incorpo-
rating data standards, fusion, governance, and security measures. The cross-
institutional generalizability of NLP algorithms has also been investigated
by Santus et al. [75], demonstrating good generalizability across institutions.
Some studies have also explored the use of NLP in specific clinical contexts,
such as examining the impact of palliative care consultations on end-of-life
care measures [68] and extracting treatment discontinuation rationale from
EHRs [69]. Moreover, semi-automated methods for labeling clinical records
have been explored, comparing traditional NLP techniques with IBM Wat-
son’s Natural Language Classifier [72] and developing learning health system
prototypes [73].
3.3.2. Prostate Cancer
Existing studies have utilized NLP to assess various aspects of prostate
cancer patient care and outcomes and developed NLP models to identify pa-
tients with metastatic prostate cancer (mPCa) from clinical records. Yang
et al. [77] developed an NLP model using a large dataset of radiology re-
ports from the Department of Veterans Affairs, demonstrating high accuracy
in identifying mPCa patients. Another study by Alba et al. [78] validated
an NLP algorithm to identify mPCa patients in the Veterans Affairs EHR,
achieving high specificity and sensitivity. NLP techniques have also been ap-
plied to extract cancer staging information from clinical notes. Furthermore,
Bozkurt et al. [80] compared rule-based and machine learning approaches for
extracting TNM stages from clinical notes of prostate cancer patients, finding
that different approaches performed better for different stages. Hernandez-
Boussard et al. [79] used NLP and machine learning techniques to analyze
EHR data, demonstrating high precision and recall rates for identifying dig-
ital rectal examinations and classifying anesthesia types. Similarly, Bozkurt
et al. [82] investigated the feasibility of automatically assessing pretreatment
digital rectal examination reports using NLP.
NLP techniques have been applied to evaluate guideline adherence and
treatment decisions. Coquet et al. [83] developed an automated pipeline to
assess bone scan utilization in prostate cancer patients. The study compared
rule-based and convolutional neural networks (CNN) based NLP approaches
11
for classifying patients into risk groups and evaluating adherence to clinical
guidelines. Researchers have also explored the use of NLP to extract infor-
mation on patient-centered outcomes and social determinants of health. A
study by Bozkurt et al. [81] developed an NLP approach to phenotype uri-
nary incontinence severity in prostate cancer patients, while another study
by Zhu et al. [84] used NLP to identify social isolation in prostate cancer
patients. Both studies demonstrated high accuracy in their respective tasks.
Moreover, Banerjee et al. [85] developed a weakly supervised NLP approach
to assess patient outcomes in prostate cancer treatment from clinical notes,
achieving high performance in classifying sentences regarding urinary incon-
tinence and bowel dysfunction.
3.3.3. Ovarian Cancer
A study by McGowan et al. [87] conducted at a UK cancer center evalu-
ated the use of NLP for enhancing the efficiency of gynaecological oncology
audits. The researchers utilized Google Bard to develop algorithms for ana-
lyzing the EHRs of ovarian cancer patients. Comparing NLP-generated code
against previous manual audits, they found that the NLP approach signifi-
cantly increased efficiency by enabling faster analysis of a larger dataset of
600 cases compared to the manual audit of 135 cases. In another study [88],
researchers investigated the use of NLP to predict surgical outcomes in ad-
vanced epithelial ovarian cancer (EOC) patients undergoing cytoreductive
surgery. They analyzed operative notes from 555 EOC cases performed be-
tween 2014 and 2019 using a RoBERTa-based classifier. The NLP model
achieved high-performance metrics, including an AUROC of 0.86 and an ac-
curacy of 0.81, outperforming models using only discrete clinical features.
3.3.4. Cervical Cancer
Macchia et al. [89] developed a prototype of a “Multidisciplinary Tumor
Board Smart Virtual Assistant” for locally advanced cervical cancer (LACC).
The system aimed to automate clinical stage classification from free-text di-
agnostic reports, identify inconsistencies, support education, and integrate
data-driven decision-making. Using EHRs of 96 LACC patients treated be-
tween 2015 and 2018, the system used NLP to analyze and categorize pa-
tient data from Magnetic resonance imaging (MRI), gynecologic examina-
tion, and positron emission tomography-computed tomography (PET-CT)
reports. The virtual assistant successfully classified all patients in the train-
ing set and developed a predictive model for patient achieving 94% accuracy.
12
The study demonstrates the potential for creating a smart virtual assistant
to aid multidisciplinary tumor boards in managing large volumes of patient
data and improving diagnostic accuracy for LACC cases.
3.4. Endocrine Cancers
A study by Yoo et al. [90] aimed to transform unstructured thyroid can-
cer diagnosis and staging information into the standardized OMOP CDM
format.
Using rule-based NLP on 52,133 surgical pathology reports and
56,239 iodine whole-body scan reports from three medical institutions, the
researchers successfully converted the extracted data to OMOP CDM v6.0.
Their findings revealed that papillary carcinoma was the most prevalent thy-
roid cancer type having 95.3-98.8%, with stage I accounting for 55-64% of
cases and stage III representing 24-26%.
The study achieved high preci-
sion and recall in the extraction and conversion process.
Another study
by Pathak et al. [91], focused on extracting thyroid nodule characteristics
from ultrasound reports using transformer-based NLP methods. They com-
pared five transformer models on a corpus of 490 reports from a dataset
of 184,560 clinical notes. The GatorTron model, trained on over 90 billion
words, demonstrated the best performance with strict and lenient F1-scores
of 0.8851 and 0.9495 for characteristic extraction, and an F1-score of 0.9321
for linking characteristics to nodules. This research represents a pioneering
effort in applying transformer-based NLP models to extract multiple thyroid
nodule characteristics from ultrasound reports.
3.5. Skin Cancers
A couple of studies have demonstrated the potential of NLP for Skin can-
cer research. A study by Ali et al. [92], developed and validated an automated
information extraction system for basal cell carcinoma (BCC) histopathology
reports using the general architecture for text engineering (GATE) frame-
work. The system achieved high performance across various metrics, includ-
ing a mean F1-score of 84.5%, when compared to expert human annota-
tion. Moreover, a study by Malke et al. [93] focused on melanoma research,
developing an efficient method to extract primary pathology features from
pathology reports.
This system was applied to a large dataset of 23,039
patients, generating over 368,000 individual melanoma data points. The al-
gorithm achieved a 90.4% exact or synonymous match rate when compared
to manually curated data, with a low error rate of 3.7%.
13
3.6. Central Nervous System (CNS) Cancers
Senders et al. [94] attempted to compare various NLP techniques for auto-
matically quantifying brain metastases from free-text radiology reports. The
researchers analyzed 1,479 MRI reports of patients diagnosed with brain
metastases from two tertiary care centers. They developed and evaluated
multiple bag-of-words and sequence-based NLP models to classify reports as
indicating single or multiple metastases. The least absolute shrinkage and
selection operator (LASSO) regression model performed best overall on the
test set, achieving an AUROC of 0.92 and an accuracy of 83%.
Among
sequence-based models, a 1D CNN showed the highest performance. The
study provides a framework for developing machine learning-based NLP mod-
els for medical text analysis and demonstrates their potential for automated
extraction of clinically relevant information from radiology reports.
3.7. Stage-Specific Categories
3.7.1. Advanced Cancer
Existing studies have highlighted the potential of NLP in improving data
extraction and analysis in advanced cancer care for enhancing patient man-
agement and quality of care. Lindvall et al. [95] evaluated NLP for identify-
ing advance care planning documentation in clinical notes of advanced cancer
patients, achieving high accuracy with F1-scores ranging from 0.84 to 0.97
across various domains. This method proved significantly more time-efficient
than manual chart review. Additionally, Lindvall et al. [96] aimed to use
NLP to identify cancer patients receiving palliative gastrostomy and assess
end-of-life quality indicators. The NLP approach demonstrated a high sensi-
tivity of 95.8% and specificity of 97.4% in identifying patients with palliative
indications, while also accurately assessing end-of-life process measures.
3.7.2. Late-Stage / Stage IV Solid Tumor
Several recent research has focused on leveraging NLP to improve pa-
tient identification and symptom management in late-stage or stage IV solid
tumors. A study by Ernecoff et al. [97] developed and validated EHR phe-
notypes to identify patients with late-stage diseases, including stage 4 solid-
tumor cancer. Their approach, utilizing international classification of dis-
eases (ICD) codes, NLP, and laboratory values, achieved a high sensitivity of
99.5% and a positive predictive value of 68.6% for stage 4 cancer, demonstrat-
ing the potential for efficient patient identification and equitable distribution
of palliative care. Based on computational techniques in oncology, DiMartino
14
et al. [98] investigated the application of NLP to identify uncontrolled symp-
toms in hospitalized cancer patients with advanced disease. Using a Random
Forest algorithm to analyze clinical notes, they developed models to predict
uncontrolled pain, nausea/vomiting, and dyspnea, with varying levels of ac-
curacy and sensitivity.
The pain model performed better than the other
models, achieving 61% accuracy and 69% sensitivity.
3.8. Multiple Cancer Types
A significant number of studies have explored the application of NLP
techniques to analyze and extract valuable information from clinical data
across various cancer types. Hochheiser et al. [31] developed DeepPhe-CR,
an NLP system designed to help cancer registrars abstract case details from
patient records, achieving high F1-scores for extracting key variables across
multiple cancer types. Similarly, Harrison et al. [56] developed an NLP al-
gorithm for interpreting pancreatic pathology reports, demonstrating high
accuracy and potential for enhancing EHR coding. Seesaghur et al. [44] as-
sessed the use of bone-targeting agents in patients with bone metastases from
breast, non-small cell lung, and prostate cancers using EHRs. Morin et al.
[33] developed MEDomics, an artificial intelligence framework integrating
longitudinal EHRs with real-world data for continuous pan-cancer prognos-
tication, analyzing breast and lung cancer patients. In addition, symptom
analysis and patient outcomes were the focus of several studies. Luo et al.
[50] developed a computational framework to analyze symptom patterns in
breast and colorectal cancer patients after chemotherapy. Kehl et al. [34]
investigated the use of EHRs to identify cancer patients experiencing clinical
inflection points across solid tumors and lymphoma. Luo et al. [52] analyzed
symptoms in colorectal and breast cancer patients, examining the impact of
type 2 diabetes comorbidity. Bhatt et al. [35] investigated the relationship
between social support and outcomes in hospitalized patients with advanced
cancer.
Zhao et al. [76] proposed a framework for generating real-world evidence
from unstructured clinical notes to examine the clinical utility of genetic
tests in women’s cancers. Do et al. [51] investigated patterns of metastatic
disease in cancer patients using NLP of structured radiology reports. Shi
et al. [53] developed an NLP pipeline to identify patients eligible for ge-
netic testing for hereditary cancers based on family health history data in
EHRs. Karimi et al. [58] created models to identify distant cancer recur-
rence and recurrence sites for breast cancer and hepatocellular carcinoma
15
patients. Kehl et al. [36] developed deep NLP models to extract clinical out-
comes from imaging reports and oncologist notes across various solid tumor
types. Chen et al. [57] focused on extracting information about esophagitis
presence and severity from clinical notes of patients undergoing radiother-
apy for lung and esophageal cancers. Huang et al. [86] developed an NLP
algorithm to extract clinical information from uro-oncological histopathol-
ogy reports, covering prostate, bladder, and renal cancers. Additionally, few
studies explored the extraction of temporal information and social determi-
nants of health. Wang et al. [39] investigated the extraction of specific date
information for lung cancer and multiple myeloma cases. Yu et al. [37] devel-
oped the SODA package to extract social determinants of health from clinical
narratives, examining performance across different race and gender groups
and testing generalizability using cancer and opioid use cohorts. Araki et al.
[38] investigated the feasibility of evaluating treatment response in Japanese
cancer patients using unstructured EHR data, focusing on lung and breast
cancer patients. Furthermore, Huang et al. [32] evaluated ChatGPT’s ability
to extract structured data from clinical notes, focusing on lung cancer and
pediatric osteosarcoma pathology reports.
3.9. Unspecified Cancer Types
Several studies have explored methods for extracting and classifying cancer-
related information, where the specific cancer type was not the primary focus
or was unspecified. A rule-based NLP algorithm was developed to automat-
ically extract and categorize tumor response from radiology reports. The
proposed algorithm achieved an overall accuracy of 88% in classifying tumor
response as progression or no progression [99]. Researchers have also cre-
ated NLP tools to extract specific cancer-related information, such as PD-L1
expression levels from clinical notes [100] and physician-reported pain in ra-
diation oncology consultation notes [101]. Advanced machine learning tech-
niques, including transformers, have been employed to predict cancer treat-
ment from EHRs [102]. Additionally, efforts have been made to improve the
robustness of classification models for rare cancer types, with a study devel-
oping a novel class-specialized ensemble technique that outperformed other
methods for rare cancer classification in pathology reports [103]. A study
developed an algorithm to extract eastern cooperative oncology group per-
formance status scores across 21 cancer types, improving score completeness
from 60.4% to 73.2% with 93% accuracy when applied to a database of over
480,000 patient records [104]. A study has also explored the use of NLP and
16
recurrent neural networks (RNN) to identify genomic mutation-associated
treatment changes in cancer patient progress notes, with bidirectional long
short-term memory (BiLSTM) performing best at 88.6% accuracy [106].
3.10. Adverse Event
Existing studies have also examined various kinds of adverse events as-
sociated with cancer and its treatment. A study on Japanese physicians’
progress notes achieved high concordance rates for detecting gastrointestinal
symptoms, with 83.5% accuracy for nausea/vomiting and 97.7% for diar-
rhea [107]. However, the study noted challenges in distinguishing between
current symptoms and past medical history mentions. Venous thromboem-
bolism (VTE), a significant concern in cancer patients, has been addressed
in multiple studies. A study developed a computable phenotype for incident
VTE using a combination of ICD/medication-based and NLP-based algo-
rithms [108]. This approach demonstrated high performance with a weighted
sensitivity of 96% and a positive predictive value of 98%. Another study fo-
cused on predicting VTE recurrence in anticoagulated cancer patients, using
various machine-learning algorithms on a large dataset from multiple Span-
ish hospitals [110]. The models achieved moderate predictive performance,
with AUROC scores ranging from 0.66 to 0.69.
The extraction of common terminology criteria for adverse events (CT-
CAE) symptoms from clinical notes has also been investigated.
A study
evaluated an NLP pipeline based on Apache clinical text analysis knowledge
extraction system (cTAKES) and reported high accuracy for common symp-
toms in radiation therapy patients, such as radiation dermatitis, fatigue, and
nausea [109].
However, the system faced challenges in detecting negated
symptoms, highlighting an area for future improvement. Researchers have
also explored the generalizability of machine learning methods in detecting
adverse drug events (ADEs) from clinical narratives [111]. By comparing var-
ious machine learning and deep learning methods across different datasets,
the study found that ClinicalBERT performed best, achieving F1-scores of
0.78 and 0.74 when tested on distinct datasets.
4. Discussion
The distribution of studies based on year demonstrates a notable trend
over the past six years. As illustrated in Figure 3, there is a generally up-
ward trajectory in the number of publications from 2019 to 2024. The year
17
Figure 3: Annual Distribution of Studies (2019-2024).
2019 established a solid baseline for subsequent years. 2020 experienced a
significant decrease in publications, which can be attributed to the global dis-
ruption caused by the COVID-19 pandemic. However, the number of studies
increased significantly in 2021, returning to pre-pandemic levels. A marked
increase is observed in 2023, indicating growing interest and investment in
this research area. Even though the publication data only covers the starting
months of 2024, it already indicates encouraging progress and is expected to
surpass previous years.
Figure 4 illustrates the distribution of publications on NLP for cancer
research across top journals from 2019 to 2024. JCO Clinical Cancer Infor-
matics leads with 13 publications, demonstrating its significant role in this
field. Three journals follow with 4 publications each: BMC Medical Informat-
ics and Decision Making, International Journal of Medical Informatics, and
Journal of Biomedical Informatics. JAMIA Open, BMC Medical Research
Methodology, and AMIA Annual Symposium proceedings each contribute 3
publications. Figure 5 illustrates the Top 10 journals by citation count based
on studies included in this review.
Table 1 presents the top 10 most cited papers in the field of NLP for
cancer research. These citation data reflects the number of citations up to
the first quarter of 2024. The most cited paper [96], published in 2019, has
accumulated 54 citations and explores the use of NLP to assess end-of-life
18
Figure 4: Top journals based on publication count.
Figure 5: Top 10 journals by citation count.
19
Table 1: Top 10 most cited papers.
Ref.
Title
Year
Citations
[96]
“Natural Language Processing to Assess End-of-Life Quality
Indicators in Cancer Patients Receiving Palliative Surgery”
2019
54
[33]
“An artificial intelligence framework integrating longitudinal
electronic health records with real-world data enables continuous
pan-cancer prognostication”
2021
40
[84]
“Automatically identifying social isolation from clinical
narratives for patients with prostate Cancer”
2019
32
[74]
“Automatic trial eligibility surveillance based on unstructured
clinical data”
2019
31
[60]
“CancerBERT: A cancer domain-specific language model for
extracting breast cancer phenotypes from electronic health records”
2022
28
[95]
“Natural Language Processing to Identify Advance Care Planning
Documentation in a Multisite Pragmatic Clinical Trial”
2022
28
[46]
“Application of optical character recognition with natural language
processing for large-scale quality metric data extraction in
colonoscopy reports”
2021
27
[85]
“Weakly supervised natural language processing for assessing
patient-centered outcome following prostate cancer treatment”
2019
26
[47]
“Challenges of Developing a Natural Language Processing Method
With Electronic Health Records to Identify Persons With Chronic
Mobility Disability”
2020
25
[103]
“Class imbalance in out-of-distribution datasets: Improving the
robustness of the TextCNN for the classification of rare cancer types”
2022
25
quality indicators in cancer patients undergoing palliative surgery. Other
highly cited works include studies on pan-cancer prognostication [33], social
isolation identification [84], and automatic trial eligibility surveillance [74].
This also highlights emerging research areas such as cancer-specific language
models [60] and the application of NLP in identifying advance care planning
documentation [95].
The analysis of NLP-based studies utilizing EHRs and clinical notes re-
veals a diverse distribution of cancer types, with some categories receiving
more attention than others. Respiratory cancers, particularly lung cancer,
were prominently featured in 22 studies, with an additional 5 studies specifi-
cally focusing on NSCLC. Gastrointestinal cancers were also well-represented,
with colorectal cancer being the subject of 13 studies, followed by pancreatic
cancer (5 studies), and esophageal cancer (3 studies). Among reproductive
system cancers, breast cancer emerged as the most frequently studied type,
with 29 studies dedicated to this area. Prostate cancer and ovarian can-
cer followed with 14 and 6 studies, respectively. Other cancer types, such
20
Figure 6: Distribution of Cancer Types in NLP-based Cancer Studies.
as endocrine, skin, CNS, hematological, and bone cancers, were the focus
of fewer studies, typically ranging from 1 to 2 per specific subtype.
The
analysis also included studies on stage-specific categories, unspecified cancer
types, and adverse events related to cancer treatment. This distribution pre-
sented in Figure 6 highlights the current research priorities in applying NLP
techniques to cancer-related EHRs and clinical notes, while also indicating
potential areas for future exploration in less-studied cancer types.
5. NLP Applications and Methodologies in Cancer Research
The applications of NLP in cancer research are diverse and wide-ranging.
Common tasks include information extraction, where specific entities and
attributes related to cancer diagnosis, staging, treatment, and outcomes are
retrieved from clinical notes and pathology reports [18, 31, 60, 92, 90]. For
example, existing studies have used NLP to extract tumor characteristics
from radiology reports [91] and PD-L1 expression levels from clinical notes
[100]. Text classification is another key application, involving the catego-
21
rization of clinical documents into predefined groups such as cancer stage
[89, 80], smoking status [25], or presence of metastasis [45, 77].
Named Entity Recognition (NER) is frequently employed to identify and
classify entities like cancer types, medications, and symptoms in clinical texts
[61, 40]. Relation extraction techniques are used to detect relationships be-
tween entities, such as associations between symptoms and patient attributes
[50]. NLP has also been crucial in phenotyping, which involves automat-
ically identifying patient cohorts with specific clinical characteristics from
EHR data [108, 97, 23]. Additionally, predictive modeling leveraging NLP-
derived features has been used to forecast cancer outcomes, recurrence risk,
and treatment response [63, 34, 88].
The methodologies used in these NLP applications span a wide spectrum,
from traditional rule-based approaches to cutting-edge machine learning tech-
niques.
Many studies, especially those focused on well-defined extraction
tasks, have utilized rule-based NLP approaches [18, 78, 95, 92]. These meth-
ods rely on predefined rules, regular expressions, and dictionaries to identify
relevant information. Traditional machine learning algorithms such as sup-
port vector machine (SVM), Random Forest, and Logistic Regression have
been applied to various classification and extraction tasks [77, 62, 65].
In recent years, there has been a shift towards deep learning architectures.
CNN [56, 26], RNN [63], and long short-term memory (LSTM) [81, 106]
have shown improved performance on complex NLP tasks. State-of-the-art
transformer-based models like BERT, RoBERTa, and their domain-specific
variants (e.g., ClinicalBERT, CancerBERT) have demonstrated particularly
promising results across various cancer-related NLP tasks [45, 60, 70, 91, 88].
Some researchers have also explored hybrid approaches, combining rule-based
methods with machine learning techniques to leverage the strengths of both
[21, 80, 81].
Text preprocessing and feature extraction play crucial roles in the NLP
pipeline for cancer research. Common preprocessing steps include tokeniza-
tion [18, 19, 31, 91], sentence boundary detection [91, 25], text cleaning
and normalization [80, 67, 25], and removal of stop words and punctua-
tion [25, 82]. Feature extraction techniques range from traditional bag-of-
words (BoW) and term frequency–inverse document frequency (TF-IDF) rep-
resentations [77, 62, 33] to more advanced word embeddings like Word2Vec
and GloVe [60, 63, 80], and contextual embeddings derived from transformer
models [45, 60].
The performance of these NLP models is typically assessed using standard
22
metrics such as precision, recall, and F1-score [18, 45, 31, 60, 95, 92], accuracy
[89, 46, 99], AUROC [62, 63, 58], and sensitivity and specificity [77, 97, 23].
Some studies also report additional metrics like Cohen’s Kappa [32] for inter-
rater agreement or mean absolute error (MAE) [100] for regression tasks.
6. NLP-based Datasets in Cancer Research
NLP has become an essential tool in cancer research, leveraging vast
amounts of unstructured clinical data to extract valuable insights. The pri-
mary source of data for most NLP studies in oncology is EHRs.
These
datasets vary widely in size and scope, ranging from institutional databases
to multi-center collaborations and national registries. Many studies utilize
EHRs from specific hospitals or healthcare systems. For example, the Univer-
sity of Florida Health Integrated Data Repository provided over 1.5 million
clinical notes from 20,000 cancer patients for several studies [27, 37]. Simi-
larly, Mayo Clinic EHRs containing records of 4,110 lung cancer patients [39]
and Stanford’s prostate cancer research database with 528,362 notes from
6,595 patients [85] have been instrumental in advancing NLP research in on-
cology. Larger, multi-institutional databases have also played a crucial role.
The Flatiron Health database, which aggregates EHRs from approximately
280 US cancer clinics and contains data on over 300,000 cancer patients,
has been used in multiple studies [104, 42, 30]. Another notable resource
is the MIMIC-III dataset, which includes records of 46,146 patients [19].
Cancer registry data, such as those from the Kentucky Cancer Registry and
Louisiana Tumor Registry, have been particularly useful for extracting infor-
mation from pathology reports [18, 103].
The size of datasets used in these studies varies considerably.
Large-
scale studies have employed datasets with hundreds of thousands of patient
records, such as one involving 102,475 patients [23] and another with 186,313
lung cancer patients [30]. Medium-scale studies typically involved thousands
to tens of thousands of patients, exemplified by a study using data from 5,152
patients with 366,398 clinical notes [50]. Smaller, more focused studies have
worked with hundreds of patients such as one that developed NLP systems
using data from 200 patients [107]. These datasets contains various types of
clinical documents, including clinical notes, progress reports [106, 27], radi-
ology reports [77, 32], pathology reports [56, 103], and discharge summaries
[18, 111]. This diversity allows researchers to extract a wide range of infor-
mation relevant to cancer diagnosis, treatment, and outcomes. While many
23
of these datasets are not publicly available due to privacy concerns, there is a
growing trend towards making more resources accessible to researchers. The
MIMIC-III dataset, for example, is publicly available [19], and I2B2 datasets
can be accessed upon request [102, 111]. Some institutional datasets may
also be available upon request to the authors [66, 67].
7. Open Research Challenges and Future Directions
NLP has shown significant potential in advancing cancer research and
clinical practice. However, several key challenges and opportunities for future
work have emerged. This section provides an overview of key challenges and
future directions for the application of NLP techniques in cancer research.
7.1. Data Limitations and Generalizability
Many studies are limited by small sample sizes, single-institution data,
or focus on specific cancer types, limiting the generalizability of NLP mod-
els [111, 45, 107, 31, 59, 60, 78, 95, 80, 92, 109]. This restriction in data
scope presents a significant challenge to the broad application of NLP in
oncology. To address this, future work should focus on validating NLP al-
gorithms across multiple institutions and diverse patient populations [59,
60, 79, 80, 33, 51]. This multi-institutional approach will help ensure that
the developed models are robust and applicable in various clinical settings.
Additionally, expanding datasets to include more cancer types and clinical
scenarios [61, 23, 91, 86] will enhance the versatility of NLP systems in oncol-
ogy. Researchers should also develop methods to handle variations in clinical
documentation practices across institutions [22, 97], as these differences can
significantly impact the performance of NLP models.
7.2. Model Performance and Robustness
Current NLP models face challenges in handling complex clinical lan-
guage, negations, and context. These limitations can lead to misinterpre-
tation of clinical notes and potentially impact patient care.
To improve
model performance and robustness, future research should focus on enhanc-
ing algorithms to better handle variability in report formats and vocabular-
ies [99, 98, 67]. This includes improving negation and speculation detection
[21, 109], which is crucial for accurately interpreting clinical narratives. Fur-
thermore, developing more advanced NLP techniques for automated symp-
tom extraction [50, 57] will enable a more detailed analysis of patient expe-
riences and outcomes.
24
7.3. Integration with Clinical Workflows
To maximize impact, NLP systems need seamless integration into clin-
ical practice.
This integration is essential for the practical application of
NLP in real-world healthcare settings. Future efforts should focus on de-
veloping workflow-embedded clinical decision support tools [23, 49] that can
provide real-time insights to clinicians. Creating user-friendly interfaces for
database development and querying [56] will make NLP tools more accessible
to healthcare professionals who may not have extensive technical expertise.
Additionally, implementing real-time NLP systems for continuous patient
monitoring [33] can help in the early detection of adverse events and improve
patient care.
7.4. Expanding NLP Applications
There are numerous opportunities to apply NLP to new areas of cancer
research. Extracting information from multimodal data sources (e.g., imag-
ing reports, genomic data) [78, 42, 106] can provide a more comprehensive
view of patient health. Analyzing social determinants of health in cancer
patients [27, 37, 29] through NLP can help identify factors influencing treat-
ment outcomes and patient experiences. Automating clinical trial eligibility
screening [74] using NLP can accelerate patient recruitment and improve the
efficiency of clinical research.
7.5. Ethical and Privacy Considerations
As NLP systems handle sensitive patient data, addressing privacy and
ethical concerns is crucial. Future research should focus on developing privacy-
preserving NLP techniques [20, 79] to ensure patient confidentiality while
leveraging the power of large datasets. Ensuring fairness and reducing bias
in NLP models [79, 37] is also essential to prevent disparities in healthcare
delivery and research outcomes.
7.6. Technical Advancements
Several technical areas require further research to enhance the capabilities
of NLP in cancer research. This includes exploring advanced deep learning
architectures like transformers and large language models (LLMs) [32, 42, 94],
which have shown promise in handling complex language tasks. Improving
the interpretability of NLP models [45, 32] is crucial for gaining clinician
trust and understanding model decision-making processes. Developing hy-
brid rule-based and machine learning approaches [18, 21] can combine the
25
strengths of both methodologies to create more robust and flexible NLP
systems. Additionally, the potential of LLMs in advancing cancer research
through improved text analysis and knowledge extraction is an emerging area
for future research [112].
8. Conclusion
This review examines the current state-of-the-art literature on NLP ap-
plications in analyzing EHRs and clinical notes for cancer research.
The
analysis of 94 studies published since 2019 shows a clear trend in the growth
of this field, with a notable increase in publications in 2023. The distribu-
tion of studies across cancer types revealed a concentration on specific areas.
Breast cancer was the most studied by existing studies, followed by lung
cancer, and colorectal cancer. This focus likely reflects both the prevalence
of these cancers and the availability of data. However, it also highlights po-
tential gaps in research for less common cancer types, which could benefit
from increased attention in future studies. In terms of NLP applications,
information extraction and text classification emerged as the most common
tasks. Specifically, studies focused on extracting tumor characteristics from
radiology reports, PD-L1 expression levels from clinical notes, and classify-
ing cancer stages and metastasis presence. The NLP techniques used have
evolved from rule-based approaches to more sophisticated machine learning
techniques, with a notable trend towards the use of transformer-based models
like BERT and its variants (e.g., CancerBERT).
While NLP has shown significant promise in cancer research using EHRs
and clinical notes, there remains substantial room for improvement in model
generalizability, performance, and clinical integration. Additionally, expand-
ing NLP applications to analyze social determinants of health in cancer pa-
tients and automating clinical trial eligibility screening represent promising
avenues for enhancing patient care and accelerating research. The potential
of large language models in advancing cancer research, as suggested by recent
studies, also presents an exciting frontier for future exploration. Addressing
these challenges will be crucial to revolutionizing cancer research and pa-
tient care, leading to improved diagnosis, treatment, outcomes, and more
personalized treatment approaches.
Declaration of Interests
The authors have declared no conflict of interest.
26
References
[1] R. L. Siegel, A. N. Giaquinto, A. Jemal, Cancer statistics, 2024., CA:
a cancer journal for clinicians 74 (2024).
[2] T. Schepis, S. S. De Lucia, A. Pellegrino, A. Del Gaudio, R. Maresca,
G. Coppola, M. F. Chiappetta, A. Gasbarrini, F. Franceschi, M. Can-
delli, et al., State-of-the-art and upcoming innovations in pancreatic
cancer care: a step forward to precision medicine, Cancers 15 (2023)
3423.
[3] Z. Lu, Y. Chen, D. Liu, X. Jiao, C. Liu, Y. Wang, Z. Zhang, K. Jia,
J. Gong, Z. Yang, et al., The landscape of cancer research and cancer
care in china, Nature Medicine 29 (2023) 3022–3032.
[4] A. Shmatko, N. Ghaffari Laleh, M. Gerstung, J. N. Kather, Artificial
intelligence in histopathology: enhancing cancer research and clinical
oncology, Nature cancer 3 (2022) 1026–1038.
[5] M. Veta, J. P. Pluim, P. J. Van Diest, M. A. Viergever, Breast can-
cer histopathology image analysis: A review, IEEE transactions on
biomedical engineering 61 (2014) 1400–1411.
[6] W. L. Bi, A. Hosny, M. B. Schabath, M. L. Giger, N. J. Birkbak,
A. Mehrtash, T. Allison, O. Arnaout, C. Abbosh, I. F. Dunn, et al.,
Artificial intelligence in cancer imaging: clinical challenges and appli-
cations, CA: a cancer journal for clinicians 69 (2019) 127–157.
[7] O. Elemento, C. Leslie, J. Lundin, G. Tourassi, Artificial intelligence
in cancer research, diagnosis and therapy, Nature Reviews Cancer 21
(2021) 747–752.
[8] A. Sitapati, H. Kim, B. Berkovich, R. Marmor, S. Singh, R. El-Kareh,
B. Clay, L. Ohno-Machado, Integrated precision medicine: the role
of electronic health records in delivering personalized treatment, Wi-
ley Interdisciplinary Reviews: Systems Biology and Medicine 9 (2017)
e1378.
[9] P. B. Jensen, L. J. Jensen, S. Brunak, Mining electronic health records:
towards better research applications and clinical care, Nature Reviews
Genetics 13 (2012) 395–405.
27
[10] K. Kreimeyer, M. Foster, A. Pandey, N. Arya, G. Halford, S. F. Jones,
R. Forshee, M. Walderhaug, T. Botsis, Natural language processing
systems for capturing and standardizing unstructured clinical informa-
tion: a systematic review, Journal of biomedical informatics 73 (2017)
14–29.
[11] M. Tayefi, P. Ngo, T. Chomutare, H. Dalianis, E. Salvi, A. Budrio-
nis, F. Godtliebsen, Challenges and opportunities beyond structured
data in analysis of electronic health records, Wiley Interdisciplinary
Reviews: Computational Statistics 13 (2021) e1549.
[12] S. Datta, E. V. Bernstam, K. Roberts, A frame semantic overview of
nlp-based information extraction for cancer-related ehr notes, Journal
of biomedical informatics 100 (2019) 103301.
[13] D. Aggarwal, K. Pallavi, Advancements and challenges in natural lan-
guage processing in oral cancer research: A narrative review, Cancer
Research, Statistics, and Treatment 7 (2024) 228–233.
[14] L. Wang, S. Fu, A. Wen, X. Ruan, H. He, S. Liu, S. Moon, M. Mai,
I. B. Riaz, N. Wang, et al.,
Assessment of electronic health record
for cancer research and patient care through a scoping review of cancer
natural language processing, JCO Clinical Cancer Informatics 6 (2022)
e2200006.
[15] M. Gholipour, R. Khajouei, P. Amiri, S. Hajesmaeel Gohari, L. Ahma-
dian, Extracting cancer concepts from clinical notes using natural lan-
guage processing: a systematic review, BMC bioinformatics 24 (2023)
405.
[16] D. S. Bitterman, T. A. Miller, R. H. Mak, G. K. Savova, Clinical natu-
ral language processing for radiation oncology: a review and practical
primer, International Journal of Radiation Oncology* Biology* Physics
110 (2021) 641–655.
[17] E. Sangariyavanich, W. Ponthongmak, A. Tansawet, N. Theera-
Ampornpunt, P. Numthavaj, G. J. McKay, J. Attia, A. Thakkinstian,
Systematic review of natural language processing for recurrent can-
cer detection from electronic medical records, Informatics in Medicine
Unlocked (2023) 101326.
28
[18] J. Hong, A. Davoudi, S. Yu, D. L. Mowery, Annotation and extrac-
tion of age and temporally-related events from clinical histories, BMC
Medical Informatics and Decision Making 20 (2020) 1–15.
[19] J. C. Ruckdeschel, M. Riley, S. Parsatharathy, R. Chamarthi, C. Ra-
jagopal, H. S. Hsu, D. Mangold, C. Driscoll, Unstructured data are
superior to structured data for eliciting quantitative smoking history
from the electronic health record, JCO Clinical Cancer Informatics 7
(2023) e2200155.
[20] D. Hu, B. Liu, X. Zhu, X. Lu, N. Wu, Zero-shot information extrac-
tion from radiological reports using chatgpt, International Journal of
Medical Informatics 183 (2024) 105321.
[21] O. Solarte Pabon, M. Torrente, M. Provencio, A. Rodr´ıguez-Gonzalez,
E. Menasalvas, Integrating speculation detection and deep learning to
extract lung cancer diagnosis from clinical notes, Applied Sciences 11
(2021) 865.
[22] M.-P. Gauthier, J. H. Law, L. W. Le, J. J. Li, S. Zahir, S. Nirmalaku-
mar, M. Sung, C. Pettengell, S. Aviv, R. Chu, et al.,
Automating
access to real-world evidence, JTO Clinical and Research Reports 3
(2022) 100340.
[23] S. Liu, A. B. McCoy, M. C. Aldrich, K. L. Sandler, T. J. Reese,
B. Steitz, J. Bian, Y. Wu, E. Russo, A. Wright, Leveraging natural
language processing to identify eligible lung cancer screening patients
with the electronic health record,
International Journal of Medical
Informatics 177 (2023) 105136.
[24] S. Yang, X. Yang, T. Lyu, J. L. Huang, A. Chen, X. He, D. Braithwaite,
H. J. Mehta, Y. Wu, Y. Guo, et al., Extracting pulmonary nodules and
nodule characteristics from radiology reports of lung cancer screening
patients using transformer models, Journal of Healthcare Informatics
Research (2024) 1–15.
[25] A. Ebrahimi, M. B. H. Henriksen, C. L. Brasen, O. Hilberg, T. F.
Hansen, L. H. Jensen, A. Peimankar, U. K. Wiil,
Identification of
patients’ smoking status using an explainable ai approach: a danish
29
electronic health records case study, BMC Medical Research Method-
ology 24 (2024) 114.
[26] L. Wang, L. Luo, Y. Wang, J. Wampfler, P. Yang, H. Liu, Natural
language processing for populating lung cancer clinical research data,
BMC medical informatics and decision making 19 (2019) 1–10.
[27] Z. Yu, X. Yang, C. Dang, S. Wu, P. Adekkanattu, J. Pathak, T. J.
George, W. R. Hogan, Y. Guo, J. Bian, et al.,
A study of social
and behavioral determinants of health in lung cancer patients using
transformers-based natural language processing models,
in: AMIA
Annual Symposium Proceedings, volume 2021, American Medical In-
formatics Association, 2021, p. 1225.
[28] M. Zigman Suchsland, L. Kowalski, H. A. Burkhardt, M. G. Prado,
L. G. Kessler, M. Yetisgen, M. A. Au, K. A. Stephens, F. Farjah,
A. M. Schleyer, et al., How timely is diagnosis of lung cancer? cohort
study of individuals with lung cancer presenting in ambulatory care in
the united states, Cancers 14 (2022) 5756.
[29] Z. Yu, X. Yang, Y. Guo, J. Bian, Y. Wu, Assessing the documentation
of social determinants of health for lung cancer patients in clinical
narratives, Frontiers in public health 10 (2022) 778463.
[30] C. M. Benedum, A. Sondhi, E. Fidyk, A. B. Cohen, S. Nemeth,
B. Adamson, M. Est´evez, S. Bozkurt, Replication of real-world ev-
idence in oncology using electronic health record data extracted by
machine learning, Cancers 15 (2023) 1853.
[31] H. Hochheiser, S. Finan, Z. Yuan, E. B. Durbin, J. C. Jeong, I. Hands,
D. Rust, R. Kavuluru, X.-C. Wu, J. L. Warner, et al., Deepphe-cr:
Natural language processing software services for cancer registrar case
abstraction, JCO Clinical Cancer Informatics 7 (2023) e2300156.
[32] J. Huang, D. M. Yang, R. Rong, K. Nezafati, C. Treager, Z. Chi,
S. Wang, X. Cheng, Y. Guo, L. J. Klesse, et al., A critical assessment
of using chatgpt for extracting structured data from clinical notes, npj
Digital Medicine 7 (2024) 106.
[33] O. Morin, M. Valli`eres, S. Braunstein, J. B. Ginart, T. Upadhaya,
H. C. Woodruff, A. Zwanenburg, A. Chatterjee, J. E. Villanueva-Meyer,
30
G. Valdes, et al., An artificial intelligence framework integrating longi-
tudinal electronic health records with real-world data enables continu-
ous pan-cancer prognostication, Nature Cancer 2 (2021) 709–722.
[34] K. L. Kehl, S. Groha, E. M. Lepisto, H. Elmarakeby, J. Lindsay, A. Gu-
sev, E. M. Van Allen, M. J. Hassett, D. Schrag, Clinical inflection point
detection on the basis of ehr data to identify clinical trial–ready pa-
tients with cancer, JCO Clinical Cancer Informatics 5 (2021) 622–630.
[35] S. Bhatt, P. C. Johnson, N. H. Markovitz, T. Gray, R. D. Nipp,
N. Ufere, J. Rice, M. J. Reynolds, M. W. Lavoie, M. A. Clay, et al., The
use of natural language processing to assess social support in patients
with advanced cancer, The Oncologist 28 (2023) 165–171.
[36] K. L. Kehl, W. Xu, A. Gusev, Z. Bakouny, T. K. Choueiri, I. B. Riaz,
H. Elmarakeby, E. M. Van Allen, D. Schrag, Artificial intelligence-aided
clinical annotation of a large multi-cancer genomic dataset,
Nature
communications 12 (2021) 7304.
[37] Z. Yu, C. Peng, X. Yang, C. Dang, P. Adekkanattu, B. G. Patra,
Y. Peng, J. Pathak, D. L. Wilson, C.-Y. Chang, et al., Identifying so-
cial determinants of health from clinical narratives: A study of perfor-
mance, documentation ratio, and potential bias, Journal of biomedical
informatics 153 (2024) 104642.
[38] K. Araki, N. Matsumoto, K. Togo, N. Yonemoto, E. Ohki, L. Xu,
Y. Hasegawa, H. Inoue, S. Yamashita, T. Miyazaki, Real-world treat-
ment response in japanese patients with cancer using unstructured data
from electronic health records, Health and Technology 13 (2023) 253–
262.
[39] L. Wang, J. Wampfler, A. Dispenzieri, H. Xu, P. Yang, H. Liu, Achiev-
ability to extract specific date information for cancer research,
in:
AMIA Annual Symposium Proceedings, volume 2019, American Med-
ical Informatics Association, 2019, p. 893.
[40] T. Paul, M. K. Z. Rana, P. A. Tautam, T. V. P. Kotapati, Y. Jampani,
N. Singh, H. Islam, V. Mandhadi, V. Sharma, M. Barnes, et al., Inves-
tigation of the utility of features in a clinical de-identification model: A
31
demonstration using ehr pathology reports for advanced nsclc patients,
Frontiers in digital health 4 (2022) 728922.
[41] M. G. Kersloot, F. Lau, A. Abu-Hanna, D. L. Arts, R. Cornet, Auto-
mated snomed ct concept and attribute relationship detection through
a web-based implementation of ctakes, Journal of biomedical semantics
10 (2019) 1–13.
[42] B. Adamson, M. Waskom, A. Blarre, J. Kelly, K. Krismer, S. Nemeth,
J. Gippetti, J. Ritten, K. Harrison, G. Ho, et al., Approach to ma-
chine learning for extraction of real-world data variables from electronic
health records, Frontiers in Pharmacology 14 (2023) 1180962.
[43] A. Yusuf, D. J. Boyne, D. E. O’Sullivan, D. R. Brenner, W. Y. Che-
ung, I. Mirza, T. N. Jarada, Text analysis framework for identifying
mutations among non-small cell lung cancer patients from laboratory
data, BMC Medical Research Methodology 24 (2024) 63.
[44] A. Seesaghur, P. Egger, J. Warden, A. Abbasi, B. Levick, M. Riaz,
P. McMahon, M. Thompson, S. Cheeseman,
Assessment of bone-
targeting agents use in patients with bone metastasis from breast,
lung or prostate cancer using structured and unstructured electronic
health records from a regional uk-based hospital, BMJ open 13 (2023)
e069214.
[45] J. Li, X. Wang, L. Cai, J. Sun, Z. Yang, W. Liu, Z. Wang, H. Lv,
An interpretable deep learning framework for predicting liver metas-
tases in postoperative colorectal cancer patients using natural language
processing and clinical data integration, Cancer Medicine 12 (2023)
19337–19351.
[46] S. N. Laique, U. Hayat, S. Sarvepalli, B. Vaughn, M. Ibrahim,
J. McMichael, K. N. Qaiser, C. Burke, A. Bhatt, C. Rhodes, et al.,
Application of optical character recognition with natural language pro-
cessing for large-scale quality metric data extraction in colonoscopy
reports, Gastrointestinal endoscopy 93 (2021) 750–757.
[47] N. D. Agaronnik, C. Lindvall, A. El-Jawahri, W. He, L. I. Iezzoni,
Challenges of developing a natural language processing method with
32
electronic health records to identify persons with chronic mobility dis-
ability,
Archives of physical medicine and rehabilitation 101 (2020)
1739–1746.
[48] A. Tamm, H. J. Jones, W. Perry, D. Campbell, R. Carten, J. Davies,
A. Galdikas, L. English, A. Garbett, B. Glampson, et al., Establishing
a colorectal cancer research database from routinely collected health
data: the process and potential from a pilot study, BMJ Health &
Care Informatics 29 (2022).
[49] A. Karwa, R. Patell, G. Parthasarathy, R. Lopez, J. McMichael, C. A.
Burke, Development of an automated algorithm to generate guideline-
based recommendations for follow-up colonoscopy, Clinical Gastroen-
terology and Hepatology 18 (2020) 2038–2045.
[50] X. Luo, P. Gandhi, S. Storey, Z. Zhang, Z. Han, K. Huang, A com-
putational framework to analyze the associations between symptoms
and cancer patient attributes post chemotherapy using ehr data, IEEE
Journal of Biomedical and Health Informatics 25 (2021) 4098–4109.
[51] R. K. Do, K. Lupton, P. I. Causa Andrieu, A. Luthra, M. Taya,
K. Batch, H. Nguyen, P. Rahurkar, L. Gazit, K. Nicholas, et al., Pat-
terns of metastatic disease in patients with cancer derived from natural
language processing of structured ct radiology reports over a 10-year
period, Radiology 301 (2021) 115–122.
[52] X. Luo, S. Storey, P. Gandhi, Z. Zhang, M. Metzger, K. Huang, An-
alyzing the symptoms in colorectal and breast cancer patients with or
without type 2 diabetes using ehr data, Health Informatics Journal 27
(2021) 14604582211000785.
[53] J. Shi, K. L. Morgan, R. L. Bradshaw, S.-H. Jung, W. Kohlmann, K. A.
Kaphingst, K. Kawamoto, G. Del Fiol, et al.,
Identifying patients
who meet criteria for genetic testing of hereditary cancers based on
structured and unstructured family health history data in the electronic
health record: natural language processing approach, JMIR Medical
Informatics 10 (2022) e37842.
[54] B. Ryu, E. Yoon, S. Kim, S. Lee, H. Baek, S. Yi, H. Y. Na, J.-W. Kim,
R.-M. Baek, H. Hwang, et al., Transformation of pathology reports
33
into the common data model with oncology module: use case for colon
cancer, Journal of medical Internet research 22 (2020) e18526.
[55] D. Sarwal, L. Wang, S. Gandhi, E. S. H. Pour, L. P. Janssens, A. M.
Delgado, K. A. Doering, A. K. Mishra, J. D. Greenwood, H. Liu, et al.,
Identification of pancreatic cancer risk factors from clinical notes using
natural language processing, Pancreatology (2024).
[56] J. M. Harrison,
A. Yala,
P. Mikhael,
J. Roldan,
D. Ciprani,
T. Michelakos, L. Bolm, M. Qadan, C. Ferrone, C. Fernandez-del
Castillo, et al.,
Successful development of a natural language pro-
cessing algorithm for pancreatic neoplasms and associated histologic
features, Pancreas 52 (2023) e219–e223.
[57] S. Chen, M. Guevara, N. Ramirez, A. Murray, J. L. Warner, H. J. Aerts,
T. A. Miller, G. K. Savova, R. H. Mak, D. S. Bitterman, Natural lan-
guage processing to automatically extract the presence and severity of
esophagitis in notes of patients undergoing radiotherapy, JCO Clinical
Cancer Informatics 7 (2023) e2300048.
[58] Y. H. Karimi, D. W. Blayney, A. W. Kurian, J. Shen, R. Yamashita,
D. Rubin, I. Banerjee, Development and use of natural language pro-
cessing for identification of distant cancer recurrence and sites of dis-
tant recurrence using unstructured electronic health record data, JCO
Clinical Cancer Informatics 5 (2021) 469–478.
[59] S. Zhou, N. Wang, L. Wang, J. Sun, A. Blaes, H. Liu, R. Zhang, A
cross-institutional evaluation on breast cancer phenotyping nlp algo-
rithms on electronic health records,
Computational and Structural
Biotechnology Journal 22 (2023) 32–40.
[60] S. Zhou, N. Wang, L. Wang, H. Liu, R. Zhang, Cancerbert: a cancer
domain-specific language model for extracting breast cancer pheno-
types from electronic health records, Journal of the American Medical
Informatics Association 29 (2022) 1208–1216.
[61] ´A. Garc´ıa-Barrag´an,
A. Gonz´alez Calatayud,
O. Solarte-Pab´on,
M. Provencio, E. Menasalvas, V. Robles, Gpt for medical entity recog-
nition in spanish, Multimedia Tools and Applications (2024) 1–20.
34
[62] N. Ribelles, J. M. Jerez, P. Rodriguez-Brazzarola, B. Jimenez, T. Diaz-
Redondo, H. Mesa, A. Marquez, A. Sanchez-Mu˜noz, B. Pajares,
F. Carabantes, et al., Machine learning and natural language process-
ing (nlp) approach to predict early progression to first-line treatment
in real-world hormone receptor-positive (hr+)/her2-negative advanced
breast cancer patients, European Journal of Cancer 144 (2021) 224–
231.
[63] J. Sanyal, A. Tariq, A. W. Kurian, D. Rubin, I. Banerjee,
Weakly
supervised temporal model for prediction of breast cancer distant re-
currence, Scientific reports 11 (2021) 9461.
[64] J. Thompson, J. Hu, D. P. Mudaranthakam, D. Streeter, L. Neums,
M. Park, D. C. Koestler, B. Gajewski, R. Jensen, M. S. Mayo, Relevant
word order vectorization for improved natural language processing in
electronic health records, Scientific reports 9 (2019) 9253.
[65] Z. Zeng, L. Yao, A. Roy, X. Li, S. Espino, S. E. Clare, S. A. Khan,
Y. Luo, Identifying breast cancer distant recurrences from electronic
health records using machine learning, Journal of healthcare informat-
ics research 3 (2019) 283–299.
[66] Y. Jin, W. Junren, J. Jingwen, S. Yajing, C. Xi, Q. Ke,
Research
on the construction and application of breast cancer-specific database
system based on full data lifecycle, Frontiers in Public Health 9 (2021)
712827.
[67] Y. Chen, L. Hao, V. Z. Zou, Z. Hollander, R. T. Ng, K. V. Isaac,
Automated medical chart review for breast cancer outcomes research:
a novel natural language processing extraction system, BMC medical
research methodology 22 (2022) 136.
[68] K. Brizzi, S. N. Zupanc, B. V. Udelsman, J. A. Tulsky, A. A. Wright,
H. Poort, C. Lindvall, Natural language processing to assess palliative
care and end-of-life process measures in patients with breast cancer
with leptomeningeal disease, American Journal of Hospice and Pallia-
tive Medicine® 37 (2020) 371–376.
[69] M. S. Alkaitis, M. N. Agrawal, G. J. Riely, P. Razavi, D. Sontag, Auto-
mated nlp extraction of clinical rationale for treatment discontinuation
in breast cancer, JCO Clinical Cancer Informatics 5 (2021) 550–560.
35
[70] O. Solarte-Pab´on, O. Montenegro, A. Garc´ıa-Barrag´an, M. Torrente,
M. Provencio, E. Menasalvas, V. Robles, Transformers for extracting
breast cancer information from spanish clinical narratives, Artificial
Intelligence in Medicine 143 (2023) 102625.
[71] P. Zelina, J. Hal´amkov´a, V. Nov´aˇcek, Extraction, labeling, clustering,
and semantic mapping of segments from clinical notes, IEEE Transac-
tions on NanoBioscience 22 (2023) 781–788.
[72] H. M. Trivedi, M. Panahiazar, A. Liang, D. Lituiev, P. Chang, J. H.
Sohn, Y.-Y. Chen, B. L. Franc, B. Joe, D. Hadley, Large scale semi-
automated labeling of routine free-text clinical records for deep learn-
ing, Journal of digital imaging 32 (2019) 30–37.
[73] M. N. Levine, G. Alexander, A. Sathiyapalan, A. Agrawal, G. Pond,
Learning health system for breast cancer: pilot project experience,
JCO clinical cancer informatics 3 (2019) 1–11.
[74] S. M. Meystre, P. M. Heider, Y. Kim, D. B. Aruch, C. D. Britten,
Automatic trial eligibility surveillance based on unstructured clinical
data, International journal of medical informatics 129 (2019) 13–19.
[75] E. Santus, C. Li, A. Yala, D. Peck, R. Soomro, N. Faridi, I. Mamshad,
R. Tang, C. R. Lanahan, R. Barzilay, et al., Do neural information ex-
traction algorithms generalize across institutions?, JCO clinical cancer
informatics 3 (2019) 1–8.
[76] Y. Zhao, S. J. Weroha, E. L. Goode, H. Liu, C. Wang, Generating
real-world evidence from unstructured clinical notes to examine clinical
utility of genetic tests: use case in brcaness, BMC Medical Informatics
and Decision Making 21 (2021) 1–13.
[77] R. Yang, D. Zhu, L. E. Howard, A. De Hoedt, S. B. Williams, S. J.
Freedland, Z. Klaassen,
Identification of patients with metastatic
prostate cancer with natural language processing and machine learning,
JCO clinical cancer informatics 6 (2022) e2100071.
[78] P. R. Alba, A. Gao, K. M. Lee, T. Anglin-Foote, B. Robison, E. Kat-
soulakis, B. S. Rose, O. Efimova, J. P. Ferraro, O. V. Patterson, et al.,
Ascertainment of veterans with metastatic prostate cancer in electronic
36
health records: demonstrating the case for natural language processing,
JCO clinical cancer informatics 5 (2021) 1005–1014.
[79] T. Hernandez-Boussard, D. W. Blayney, J. D. Brooks,
Leveraging
digital data to inform and improve quality cancer care, Cancer Epi-
demiology, Biomarkers & Prevention 29 (2020) 816–822.
[80] S. Bozkurt, C. J. Magnani, M. G. Seneviratne, J. D. Brooks,
T. Hernandez-Boussard, Expanding the secondary use of prostate can-
cer real world data: Automated classifiers for clinical and pathological
stage, Frontiers in Digital Health 4 (2022) 793316.
[81] S. Bozkurt, R. Paul, J. Coquet, R. Sun, I. Banerjee, J. D. Brooks,
T. Hernandez-Boussard, Phenotyping severity of patient-centered out-
comes using clinical notes: A prostate cancer use case, Learning Health
Systems 4 (2020) e10237.
[82] S. Bozkurt, K. M. Kan, M. K. Ferrari, D. L. Rubin, D. W. Blayney,
T. Hernandez-Boussard, J. D. Brooks, Is it possible to automatically
assess pretreatment digital rectal examination documentation using
natural language processing? a single-centre retrospective study, BMJ
open 9 (2019) e027182.
[83] J. Coquet, S. Bozkurt, K. M. Kan, M. K. Ferrari, D. W. Blayney, J. D.
Brooks, T. Hernandez-Boussard, Comparison of orthogonal nlp meth-
ods for clinical phenotyping and assessment of bone scan utilization
among prostate cancer patients, Journal of biomedical informatics 94
(2019) 103184.
[84] V. J. Zhu, L. A. Lenert, B. E. Bunnell, J. S. Obeid, M. Jefferson,
C. H. Halbert, Automatically identifying social isolation from clinical
narratives for patients with prostate cancer, BMC medical informatics
and decision making 19 (2019) 1–9.
[85] I. Banerjee, K. Li, M. Seneviratne, M. Ferrari, T. Seto, J. D. Brooks,
D. L. Rubin, T. Hernandez-Boussard,
Weakly supervised natural
language processing for assessing patient-centered outcome following
prostate cancer treatment, JAMIA open 2 (2019) 150–159.
[86] H. Huang, F. X. Y. Lim, G. T. Gu, M. J. Han, A. H. S. Fang, E. H.
San Chia, E. Y. T. Bei, S. Z. Tham, H. S. S. Ho, J. S. P. Yuen,
37
et al., Natural language processing in urology: automated extraction
of clinical information from histopathology reports of uro-oncology pro-
cedures, Heliyon 9 (2023).
[87] M. McGowan, F. C. Martins, J.-L. Keen, A. Whitehead, E. Davis,
P. Pathiraja, H. Bolton, P. Baldwin, Can natural language processing
be effectively applied for audit data analysis in gynaecological oncology
at a uk cancer centre?, International Journal of Medical Informatics
182 (2024) 105306.
[88] A. Laios, E. Kalampokis, M. E. Mamalis, C. Tarabanis, D. Nugent,
A. Thangavelu, G. Theophilou, D. De Jong,
Roberta-assisted out-
come prediction in ovarian cancer cytoreductive surgery using operative
notes, Cancer Control 30 (2023) 10732748231209892.
[89] G. Macchia, G. Ferrandina, S. Patarnello, R. Autorino, C. Masciocchi,
V. Pisapia, C. Calvani, C. Iacomini, A. Cesario, L. Boldrini, et al., Mul-
tidisciplinary tumor board smart virtual assistant in locally advanced
cervical cancer: A proof of concept, Frontiers in Oncology 11 (2022)
797454.
[90] S. Yoo, E. Yoon, D. Boo, B. Kim, S. Kim, J. C. Paeng, I. R. Yoo,
I. Y. Choi, K. Kim, H. G. Ryoo, et al., Transforming thyroid cancer
diagnosis and staging information from unstructured reports to the ob-
servational medical outcome partnership common data model, Applied
Clinical Informatics 13 (2022) 521–531.
[91] A. Pathak, Z. Yu, D. Paredes, E. P. Monsour, A. O. Rocha, J. P. Brito,
N. S. Ospina, Y. Wu, Extracting thyroid nodules characteristics from
ultrasound reports using transformer-based natural language process-
ing methods, in: AMIA Annual Symposium Proceedings, volume 2023,
American Medical Informatics Association, 2023, p. 1193.
[92] S. R. Ali, H. Strafford, T. D. Dobbs, B. Fonferko-Shadrach, A. S. Lacey,
W. O. Pickrell, H. A. Hutchings, I. S. Whitaker, Development and
validation of an automated basal cell carcinoma histopathology infor-
mation extraction system using natural language processing, Frontiers
in Surgery 9 (2022) 870494.
38
[93] J. C. Malke, S. Jin, S. P. Camp, B. Lari, T. Kell, J. M. Simon, V. G. Pri-
eto, J. E. Gershenwald, L. E. Haydu, Enhancing case capture, quality,
and completeness of primary melanoma pathology records via natural
language processing, JCO clinical cancer informatics 3 (2019) 1–11.
[94] J. T. Senders, A. V. Karhade, D. J. Cote, A. Mehrtash, N. Lamba,
A. DiRisio, I. S. Muskens, W. B. Gormley, T. R. Smith, M. L. Broek-
man, et al., Natural language processing for automated quantification
of brain metastases reported in free-text radiology reports, JCO clinical
cancer informatics 3 (2019) 1–9.
[95] C. Lindvall, C.-Y. Deng, E. Moseley, N. Agaronnik, A. El-Jawahri,
M. K. Paasche-Orlow, J. R. Lakin, A. Volandes, J. A. Tulsky, A.-P.
Investigators, et al., Natural language processing to identify advance
care planning documentation in a multisite pragmatic clinical trial,
Journal of pain and symptom management 63 (2022) e29–e36.
[96] C. Lindvall, E. J. Lilley, S. N. Zupanc, I. Chien, B. V. Udelsman,
A. Walling, Z. Cooper, J. A. Tulsky, Natural language processing to
assess end-of-life quality indicators in cancer patients receiving pallia-
tive surgery, Journal of palliative medicine 22 (2019) 183–187.
[97] N. C. Ernecoff, K. L. Wessell, L. C. Hanson, A. M. Lee, C. M. Shea,
S. B. Dusetzina, M. Weinberger, A. V. Bennett,
Electronic health
record phenotypes for identifying patients with late-stage disease: A
method for research and clinical application, Journal of general internal
medicine 34 (2019) 2818–2823.
[98] L. DiMartino, T. Miano, K. Wessell, B. Bohac, L. C. Hanson, Iden-
tification of uncontrolled symptoms in cancer patients using natural
language processing, Journal of pain and symptom management 63
(2022) 610–617.
[99] G. Laurent, F. Craynest, M. Thobois, N. Hajjaji, Automatic classifi-
cation of tumor response from radiology reports with rule-based natu-
ral language processing integrated into the clinical oncology workflow,
JCO Clinical Cancer Informatics 7 (2023) e2200139.
[100] E. Lin, R. Zwolinski, J. T.-Y. Wu, J. La, S. Goryachev, L. Huhmann,
C. Yildrim, D. P. Tuck, D. C. Elbers, M. T. Brophy, et al.,
Ma-
39
chine learning-based natural language processing to extract pd-l1 ex-
pression levels from clinical notes, Health Informatics Journal 29 (2023)
14604582231198021.
[101] H. Naseri, K. Kafi, S. Skamene, M. Tolba, M. D. Faye, P. Ramia,
J. Khriguian, J. Kildea, Development of a generalizable natural lan-
guage processing pipeline to extract physician-reported pain from clin-
ical reports: Generated using publicly-available datasets and tested on
institutional clinical reports for cancer patients with bone metastases,
Journal of Biomedical Informatics 120 (2021) 103864.
[102] P. N. Ahmad, Y. Liu, K. Khan, T. Jiang, U. Burhan, Bir: Biomedical
information retrieval system for cancer treatment in electronic health
record using transformers, Sensors 23 (2023) 9355.
[103] K. De Angeli, S. Gao, I. Danciu, E. B. Durbin, X.-C. Wu, A. Stroup,
J. Doherty, S. Schwartz, C. Wiggins, M. Damesyn, et al., Class imbal-
ance in out-of-distribution datasets: Improving the robustness of the
textcnn for the classification of rare cancer types, Journal of biomedical
informatics 125 (2022) 103957.
[104] A. B. Cohen, A. Rosic, K. Harrison, M. Richey, S. Nemeth, G. Amb-
wani, R. Miksad, B. Haaland, C. Jiang, A natural language processing
algorithm to improve completeness of ecog performance status in real-
world data, Applied Sciences 13 (2023) 6209.
[105] T. A. Koleck, M. Topaz, N. P. Tatonetti, M. George, C. Miaskowski,
A. Smaldone, S. Bakken,
Characterizing shared and distinct symp-
tom clusters in common chronic conditions through natural language
processing of nursing notes, Research in nursing & health 44 (2021)
906–919.
[106] M. Guan, S. Cho, R. Petro, W. Zhang, B. Pasche, U. Topaloglu, Nat-
ural language processing and recurrent network models for identify-
ing genomic mutation-associated cancer treatment change from patient
progress notes, JAMIA open 2 (2019) 139–149.
[107] Y. Mashima, T. Tamura, J. Kunikata, S. Tada, A. Yamada, M. Tani-
gawa, A. Hayakawa, H. Tanabe, H. Yokoi,
Using natural language
40
processing techniques to detect adverse events from progress notes due
to chemotherapy, Cancer Informatics 21 (2022) 11769351221085064.
[108] A. Li, W. L. da Costa Jr, D. Guffey, E. M. Milner, A. K. Allam, K. M.
Kurian, F. J. Novoa, M. D. Poche, R. Bandyo, C. Granada, et al., De-
veloping and optimizing a computable phenotype for incident venous
thromboembolism in a longitudinal cohort of patients with cancer, Re-
search and practice in thrombosis and haemostasis 6 (2022) e12733.
[109] J. C. Hong, A. T. Fairchild, J. P. Tanksley, M. Palta, J. D. Tenenbaum,
Natural language processing for abstraction of cancer treatment toxic-
ities: accuracy versus human experts, JAMIA open 3 (2020) 513–517.
[110] A. J. Mu˜noz, J. C. Souto, R. Lecumberri, B. Obispo, A. Sanchez,
J. Aparicio, C. Aguayo, D. Gutierrez, A. G. Palomo, V. Fanjul, et al.,
Development of a predictive model of venous thromboembolism recur-
rence in anticoagulated cancer patients using machine learning, Throm-
bosis Research 228 (2023) 181–188.
[111] M. M. Zitu, S. Zhang, D. H. Owen, C. Chiang, L. Li, Generalizability of
machine learning methods in detecting adverse drug events from clinical
narratives in electronic medical records, Frontiers in Pharmacology 14
(2023) 1218679.
[112] G. M. Iannantuono, D. Bracken-Clarke, C. S. Floudas, M. Roselli, J. L.
Gulley, F. Karzai,
Applications of large language models in cancer
care: current evidence and future perspectives, Frontiers in Oncology
13 (2023) 1268915.
41
