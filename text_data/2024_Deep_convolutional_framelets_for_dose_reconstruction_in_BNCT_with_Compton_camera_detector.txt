Citation: Didonna, A.; Lopez, D.R.;
Iaselli, G.; Amoroso, N.; Ferrara, N.;
Pugliese, G.M.I. Deep convolutional
framelets for dose reconstruction in
BNCT with Compton camera detector.
Preprint.
Copyright:
© 2024 by the authors.
Submitted to arXiv.org for possible
open
access
publication
under
the
terms
and
conditions
of
the
Creative
Commons
Attri-
bution
(CC
BY)
license
(https://
creativecommons.org/licenses/by/
4.0/).
Article
Deep convolutional framelets for dose reconstruction in BNCT
with Compton camera detector
Angelo Didonna1*, Dayron Ramos Lopez1,2*, Giuseppe Iaselli1,2, Nicola Amoroso1,3, Nicola Ferrara1,2 and Gabriella
Maria Incoronata Pugliese1,2
1
Istituto Nazionale di Fisica Nucleare, Sezione di Bari, 70125 Bari, Italy
2
Dipartimento Interateneo di Fisica, Università degli Studi di Bari Aldo Moro, 70125 Bari, Italy
3
Dipartimento di Farmacia-Scienze del Farmaco, Università degli Studi di Bari Aldo Moro, 70125 Bari, Italy
*
Author to whom correspondence should be addressed.
Abstract: Boron Neutron Capture Therapy (BNCT) is an innovative binary form of radiation therapy
with high selectivity towards cancer tissue based on the neutron capture reaction 10B(n,α)7Li, consist-
ing in the exposition of patients to neutron beams after administration of a boron compound with
preferential accumulation in cancer cells. The high linear energy transfer products of the ensuing
reaction deposit their energy at cell level, sparing normal tissue.
Although progress in accelerator-based BNCT has led to renewed interest in this cancer treatment
modality, in vivo dose monitoring during treatment still remains not feasible and several approaches
are under investigation. While Compton imaging presents various advantages over other imaging
methods, it typically requires long reconstruction times, comparable with BNCT treatment duration.
This study aims to develop deep neural network models to estimate the dose distribution by using
a simulated dataset of BNCT Compton camera images. The models pursue the avoidance of the
iteration time associated with the maximum-likelihood expectation-maximization algorithm (MLEM),
enabling a prompt dose reconstruction during the treatment.
The U-Net architecture and two variants based on the deep convolutional framelets framework
have been used for noise and artifacts reduction in few-iterations reconstructed images, leading to
promising results in terms of reconstruction accuracy and processing time.
Keywords: BNCT, Compton imaging, convolutional framelets, convolutional neural network (CNN),
deep learning, frames, inverse problems, Monte Carlo methods, U-Net
1. Introduction
1.1. Boron neutron capture therapy
Boron neutron capture therapy (BNCT) is a binary tumor-selective form of radiation
therapy based on the very high affinity of the nuclide boron-10 for neutron capture, resulting
in the prompt compound nuclear reaction 10B(n,α)7Li, and on the preferential accumulation
of boron-containing pharmaceuticals in cancer cells rather than normal cells.
Neutron capture therapy (NCT) was first proposed shortly after the discovery of the
neutron by Chadwick in 1932 and the description of boron neutron capture reaction by
Taylor and Goldhaber in 1935 [1]. The reaction is illustrated in Figure 1: a 10B nucleus
absorbs a slow or thermal neutron (with energy < 0.5 eV), forming for a brief time an
highly excited 11B compound nucleus [3,4] which subsequently decays, predominantly
disintegrating into an energetic alpha particle back to back with a recoiling 7Li ion , with a
range in tissue of ≈9 µm and ≈5 µm, respectively, and a high linear energy transfer (LET)
of 150 keV/µm and 175 keV/µm, respectively. The Q value of the reaction is about 2.79
MeV [5]. In about 94% of the cases, the litium nucleus is in an excited state and immediately
emits a 0.478 MeV gamma photon, leaving a combined average kinetic energy of about
2.31 MeV to the two nuclei.
The selectivity of this kind of therapy towards cancer tissue is a consequence of the
small combined range of 7Li and the alpha particle of ≈12 −14 µm, which is comparable
with cellular dimensions. By concentrating a sufficient number of boron atoms within tumor
1
arXiv:2409.15916v1  [physics.med-ph]  24 Sep 2024
2 of 16
Figure 1. Boron neutron capture reaction [2].
cells, the exposure to thermal neutrons may result into the their death with low normal
tissue complications, because of the higher radiation dose imparted to cancer cells relative
to adjacent normal cells. After the administration of the boron compound to the patient,
a proton or deuteron beam emitted from an accelerator is focused on a neutron emitting
target. A suitable neutron beam is obtained with a beam shaping assembly (BSA) and is
directed into a treatment room in which a patient is precisely placed. Typically the full dose
is administered in one or two application of 30 −90 min in BNCT [6], while in traditional
photon treatments the dose is generally split into multiple fractions administered over a
period of 3 −7 weeks. Therapeutic efficacy requires an absolute boron concentration higher
than 20 ppm and high tumor to normal tissue (T/N) and tumor to blood (T/B) concentration
ratios1 (ideally T/N > 3 and necessarily T/N > 1 [6]).
The dosimetry for BNCT is much more complex than for conventional photon radiation
therapy. While in standard radiotherapy X-rays mainly produce electrons that release
all their kinetic energy by ionization, in BNCT there are four main different radiation
components contributing to the absorbed dose in tissue [6]. The boron dose DB, which
is the therapeutic dose, is related to the locally deposited energy of about 2.33 MeV by
the emitted alpha particle and the recoiling 7Li ion in the boron neutron capture reaction
10B(n,α)7Li.
It can be shown [6] that the boron dose in a certain point is proportional to boron
concentration CB (DB ∝CB). The measurement of real time in vivo boron concentration,
necessary for dose determination, is one of the main challenges of BNCT. At present there
is no real-time in vivo method to measure boron concentration during BNCT treatment,
although several approaches are under investigation, the most promising being positron-
emission tomography, magnetic resonance imaging and prompt gamma analysis. Prompt
gamma analysis with single photon emission tomography (SPECT) or Compton imaging
systems aims to reconstruct boron distribution in vivo in real time using the prompt 478
keV gamma rays emitted by the excited lithium nucleus in boron neutron capture reaction.
1.2. Compton imaging
A Compton camera is a gamma-ray detector that uses the kinematics of Compton
scattering to reconstruct the original radiation source distribution.
The basic scheme of a Compton camera is shown in Fig. 2; The incoming gamma-ray
undergoes Compton scattering from an electron in the position-sensitive first detector
(scatterer) and then is absorbed by the second position-sensitive detector (absorber). The
Compton scattering and absorption events are together called a Compton event. The mea-
sured data are the coordinates of the first and second point of interaction d1 = (X1, Y1, Z1)
and d2 = (X2, Y2, Z2), the energy E1 deposited in the interaction of the scattered electron
in the medium of the first detector and the energy E2 deposited in the second detector.
The energy of the incoming gamma-ray is equal to the the sum of the deposited energies:
Eγ = E1 + E2. Assuming that the electron before scattering has no momentum in the
1
They are also denoted by CT/CN and CT/CB, where CT, CN and CB are the boron concentrations in tumor
tissue, normal tissue and blood, respectively.
3 of 16
Figure 2. Schematic diagram of a general Compton camera.
laboratory frame, from energy-momentum conservation it follows that the energy of the
scattered photon as a function of the scattering angle in Compton scattering is:
E′
γ =
Eγ
1 +
Eγ
mec2 (1 −cos θ)
,
(1)
which allows the estimation of the Compton scattering angle θ from the energy deposited
in the first detector and the gamma-ray energy. For each Compton event, the position of
the source is confined to the surface of a cone, called Compton cone, with the vertex in the
interaction point P1 in the scatterer, the axis passing also through the interaction point P2 in
the absorber, and the half-angle θ obtained from the energies measurements. It is possible
to estimate the original gamma source distribution from the superimposition of Compton
cones.
While SPECT imaging is characterized by quite low sensitivity, due to the presence of
the collimator, that determines a relation of inverse proportionality between the sensitivity
and the spatial resolution squared [7], Compton cameras, which apply electronic colli-
mation instead of physical collimation, are characterized by higher sensitivity; moreover
sensitivity depends on the size, type and geometry of the two detectors, and is therefore
independent of angular (and spatial) resolution, depending on the noise and spatial resolu-
tion characteristics of the detector. Another important characteristic of Compton imaging
compared with SPECT is that angular (and spatial) resolution improves with increasing
gamma ray energy, since from eq. 1:
d θ =
mc2
sin θ(Eγ −E1)2 d E1.
(2)
On the other hand, in SPECT the sensitivity decreases for higher energies, since the septal
thickness must be increased to reduce gamma ray penetration. Furthermore, Compton
imaging could in principle allow the rejection of most of the background events due to 10B
present in the shielding walls of most BNCT facilities, by filtering out all Compton cones
having zero intersection with the reconstruction region.
1.3. Compton image reconstruction
A general imaging system is associated with a linear integral operator H such that the
continuous source distribution f (x) and the expected value of the projection measurements
g(y) are related by:
g(y) = (H f )(y) =
Z
X h(y, x) f (x) dx
(3)
or more precisely g(y) = (H f )(y) + ϵ, if noise is taken into account2. In the case the case of
Compton imaging the source coordinate x = [x, y, z] in equation 3 represents a 3D location,
2
The kernel h(y, x), representing the conditional probability of detecting an event at location y given that it
was emitted at location x in the source, is also called space-variant (projection) point spread function [8,9], since it
amounts to the response of the system to a point source, that is to a Dirac delta distribution.
4 of 16
while the detector coordinate y = [d1, d2, E1, E2] is a vector containing the Compton event
detection locations and the energies deposited in the two detectors.
Since the projection operator H is a compact operator and in particular a Hilbert-
Schmidt operator3 [10,11], if we consider the discrete approximation f = [ f1, ..., fB]T of the
source distribution (pixel values) and g = [g1, ..., gD]T is the expected number of events in
each of the D detector channels, the discrete version of eq. 3 is obtained:
g = Hf
(4)
where H is a D × B matrix called system matrix.
The aim of image reconstruction is to determine an estimate ˆf (x) of f (x) given the
noisy measurements and the operator H.
Traditionally, the analytic approach has been employed to solve the inverse problem by
neglecting any explicit randomness and deterministic blurring and attenuation mechanisms
and trying to exactly invert eq. 3 with a simple enough projection operator H. On the
other hand modern reconstruction techniques employ more general linear models that can
take into account the blurring and attenuation mechanisms and generally also incorporate
probabilistic models of noise4 without requiring restrictive system geometries [11]. These
models typically do not admit an explicit solution, or an analytic solution can be difficult to
compute, so in most cases these models are dealt with by iterative algorithms, in which the
reconstructed image is progressively refined in repeated calculations. In this way a greater
accuracy can be obtained, although longer computation times are required.
The most commonly employed algorithms for Compton image reconstruction are
MLEM and MAP. The maximum likelihood (ML) criterion is the most used technique in
statistical inference for deriving estimators. In this criterion it is presumed that the observa-
tion vector g is determined by an unknown deterministic parameter f, which in this case is
the gamma source distribution to be reconstructed, following the conditional probability
p(g|f). The maximum likelihood estimate ˆf of f is the reconstructed image maximizing the
likelihood function L(f) = p(g|f) for the measured data g:
ˆf = arg max
f
p(g|f).
(5)
The maximum likelihood expectation maximization (MLEM) algorithm is an iterative procedure
whose output tends to the ML solution of the problem. In the case of inversion problems
with Poisson noise, it consists in the following iteration step [11]:
ˆf (n+1)
j
=
ˆf (n)
j
∑
i
hij ∑
i
hij
gi
∑
k
hik ˆf (n)
k
.
(6)
The two main shortcomings of MLEM reconstruction are the slow convergence (typically
30 −50 iterations are required to get usable images) and high noise.
The iterative step in eq. 6, also known as binned-mode MLEM could be applied to reconstruct
the image. However in the case of a Compton camera the number D of possible detector
elements in g can be exceedingly high, for example a practical Compton camera could
have 216 first-detector elements, the same number of second-detector elements and 28
energy channels, resulting in D ≈1012 [11]. Since a typical Compton camera dataset
size is of the order of 108 events, most of the possible detector bins will contain zero. An
3
The supports X and Y are finite and the kernel h(y, x) is bounded for all x and y, thus R
X
R
Y h2(y, x) dx < +∞.
A Hilbert-Schmidt operator can be approximated with arbitrary accuracy, in the Hilbert-Schmidt norm, by a
finite rank operator [10].
4
A reconstructed image is affected by both determinic degradations, like blur, linked to the point spread function
of the imaging procedure, and aliasing, caused by sampling, and random degradations, collectively referred to
as noise [12–14].
5 of 16
alternative approach, the so called list-mode MLEM [15–18] can be adopted in order to
reduce computational cost. In this approach the number of detector bins D is assumed to be
very large, so that most of them contain zero counts, while the occupied bins contain only
one count. This is basically equivalent to consider infinitesimal bins. If N is the number of
detected events, D = {d1, . . . , dN} denotes the set of all occupied bins and the observation
vector g becomes:
gd =
(
1
if d ∈D
0
otherwise .
(7)
The list mode iteration is then given by:
ˆf (n+1)
b
=
ˆf (n)
b
sb ∑
d∈D
hdb
gd
∑
b
hdb ˆf (n)
b
,
(8)
where sb = ∑
d
hdb > ∑
d∈D
hdb is the sum over all detector bins (and not only on the occupied
ones) of the probabilities hdb of the gamma ray emitted from the voxel b being detected
in the detector bin d. sb therefore represents the probability that of a gamma ray emitted
from b would be detected and is called sensitivity. As a first approximation sb can be
considered equal to the solid angle subtended by the scatter detector at bin b divided by
4π, which becomes essentially uniform over all the voxels if the detector is small [16]. The
calculation of the expressions of the system matrix and sensitivity is carried out in [16].
Using equation 8 the sum ranges only over the number of events rather than all detector
elements, and computational cost is thus generally reduced.
1.4. Research outline
In order to investigate the potentialities of Compton imaging with CZT detectors for
BNCT, a Geant4 simulation of a simplified detector in a BNCT setting has been implemented.
The data from the simulation has been used to reconstruct gamma sources distribution
with the list-mode MLEM algorithm.
Models based on deep neural networks for reconstructing the dose distribution from
the simulated dataset of BNCT Compton camera images while avoiding the long iteration
time associated with the MLEM algorithm have been examined.
The U-Net architecture and two variants based on the deep convolutional framelets
approach have been used for noise and artifacts reduction in few-iterations reconstructed
images, leading to promising results in terms of reconstruction accuracy and processing
time.
2. Deep learning models
The past few years have witnessed impressive advancements in the application of
deep learning to biomedical image reconstruction. While classical algorithms generally
perform well, they often require long processing times. The use of deep learning techniques
can lead to orders of magnitude faster reconstructions in some cases even with better image
quality than classical iterative methods [19–21].
There exist various approaches to apply deep learning to solve the inverse problem.
The taxonomy of deep learning approaches to solve inverse problems, based on a first
distinction between supervised and unsupervised techniques and a second distinction
considering what is known and when about the forward model H, consists of sixteen major
categories described in [20].
The present study focuses on the case of supervised image degradation reduction
with U-Nets in the deep convolutional framelets framework, with forward operator H fully
known, using a matched dataset of measurements g, the Compton events data produced in
a Geant4 simulation and ground truth images f, corresponding to the output of the 60th
iteration of the list-mode MLEM algorithm [15,16] applied to the Compton events data
6 of 16
(reconstruction time ≈24 −36 minutes). The objective in the supervised setting is to obtain
a reconstruction network rθ(·) mapping measurements g to images ˆf, where θ is a vector of
parameters to be learned.
2.1. Image degradation reduction: U-Nets and deep convolutional framelets
A simple method for embedding the forward operator H into the network architecture
is to apply an approximate inverse operator ˜H−15 to first map measurements to image
domain and then train a neural network to remove degradations (noise and artifacts) from
the resulting images [20], as illustrated in Fig. 3. The expression of the reconstruction
Figure 3. Illustration of a CNN with skip connection to remove noise and artifacts from an initial
reconstruction obtained by applying ˜H−1 to measurements [20].
network is therefore:
ˆf = rθ(g) = nθ( ˜H−1g) + ˜H−1g,
(9)
where nθ is a trainable neural network depending on parameters θ. Networks with more
complicated hierarchical skip connections are also commonly used. In this study the use of
the standard U-Net architecture and two variants satisfying the so-called frame condition,
the dual frame U-Net and the tight frame U-Net, first proposed in [22], is examined.
The deep convolutional framelets framework, introduced by Ye in [23], provides a the-
oretical understanding of convolutional encoder-decoder architectures, such as U-Nets,
by adopting the frame-theoretic viewpoint [24], according to which the forward pass of
a CNN can be regarded as a decomposition in terms of a frame that is related to pooling
operations and convolution operations with learned filters [25,26]. Deep convolutional
framelets are characterized by an inherent shrinking behavior [23], which determines the
degradation reduction capabilities allowing the solution of inverse problems.
(a)
(b)
Figure 4. Simplified 3D architecture of (a) standard U-Net, (b) dual frame U-Net [22]. These are 4D
representations, the plane perpendicular to the page corresponds three-dimensional space.
5
A matrix such that ˜H−1Hf ≈f for every image f of interest
7 of 16
Figure 5. Modified 3D tight frame U-Net. This is a 4D representation, the plane perpendicular to the
page corresponds three-dimensional space.
The three-dimensional U-Net architecture, illustrated in Fig. 4a, initially proposed for
biomedical image segmentation, is widely used for inverse problems [27]. The network is
characterized by an encoder-decoder structure organized recursively into several levels,
with the next level applied to the low-resolution signal of the previous layer [22]; the
encoder part consists of 3 × 3 convolutional layers, average pooling layers, denoted by
Φ⊤, batch normalization and ReLUs, and the decoder consists of average unpooling
layers, denoted by Φ, and 3 × 3 convolution. There are also skip connections through
channel concatenation, which allow to retain the high-frequency content of the input
signal. The pooling and unpooling layers determine an exponentially large receptive field.
As outlined in [22], the extended average pooling and unpooling layers (Φ⊤
ext :=
 I
Φ⊤

and Φext =

I
Φ

, respectively) do not satisfy the frame condition, which leads to an
overemphasis of the low frequency components of images due to the duplication of the
low frequency branch [23], resulting in artifacts.
A possible improvement is represented by the three-dimensional dual frame U-Net,
employing the dual frame of Φext, given by [22]:
˜Φext = (ΦextΦ⊤
ext)−1Φext =

I −ΦΦ⊤/2
Φ/2

,
(10)
corresponding to the architecture in Fig. 4b. In this way the frame condition is satisfied, but
there exists noise amplification linked to the condition number of I + ΦΦ⊤, which is equal
to 2 [22].
The usage of tight filter-bank frames or wavelets allows to improve the performance
of the U-Net by satisfying the frame condition with minimum noise amplification. In this
case the non-local basis Φ⊤is now composed of a tight filter-bank:
Φ⊤=

T⊤
1
· · ·
T⊤
L
⊤,
(11)
where Tk denotes the k-th subband operator. The simplest tight filter-bank frame is the
Haar wavelet transform [31,32]. In n dimensions it is composed by 2n filters. The three-
dimensional tight frame U-Net architecture is in principle essentially analogous to the
8 of 16
one-dimensional and two-dimensional ones proposed in [22]. The main difficulty is linked
to the fact that operations on three-dimensional images are computationally more expensive
and the number of filters in the filter bank rises to 8. In order to reduce the computational
cost, the large-output signal concatenation and multi-channel convolution have been
substituted by a simple weighted sum of the signals with learnable weights, as shown
in Fig. 5, representing a two-level 3D modified tight frame architecture. Notice that
this substitution drastically reduces the number of parameters to be learnt, reducing the
possibility of overfitting.
3. Methods
3.1. Monte Carlo simulation
Since Compton imaging requires detectors characterized by both high spatial and
energy resolutions [11,28], high resolution 3D CZT drift strip detectors, which currently
offer the best performance [29,30], were considered in this study.
A Geant4 simulation of the CZT detector modules in a BNCT setting was implemented
in order to assess the accuracy in the source reconstruction and optimize detector geometry.
For the simulation the G4EMStandardPhysics and G4DecayPhysics classes were used. The
range cut value of 0.7 mm was set. A small animal (or human patient irradiated body part
with comparable dimensions) was simulated with a cylinder of radius 30 mm and height
100 mm, declared with the standard soft tissue material G4_TISSUE_SOFT_ICPR. A single
3D CZT sensor module is composed by four 3D CZT drift strip detectors described in
[29], each of which ideally assumed to be a CZT 20 mm × 20 mm × 5 mm parallelepiped in
the simulation, stacked along the y direction (see Fig. 6a). Besides the configuration with
a single sensor module with the XdetZdet plane parallel to the cylinder axis, placed at a
distance of 60mm from the cylinder center, equidistant from the cylinder bases, illustrated
in Fig. 6a, other configurations with different numbers of modules in different positions
were considered.
A good configuration in terms of source reconstruction quality and cost was found
to be the four modules configuration in Fig. 6b-6c. In the four modules configuration two
(a)
(b)
(c)
Figure 6. (a) Single module geometry, (b) four modules geometry and (c) four modules geometry YZ
view.
modules are obtained by applying a rotation of ±60◦around the cylinder axis to the original
single module of the previous configuration, and with the other two modules obtained by
translating by ±10 mm the original module along the cylinder axis, so as to obtain a larger
effective module given by the union of the two. An idealized case ha been considered with
respect to the real BNCT energy spectrum [30]: all gamma rays are generated with the
same 478 keV energy, the energy of the gamma rays emitted in the boron neutron capture
reaction. The gamma emission is set to be isotropic.
Since different tumor region geometries are needed for the training phase of deep
learning algorithms, 20 different tumor region geometries were created. For 17 of these
3 : 1, 4 : 1, 5 : 1 and ∞(zero boron concentration in normal tissue) concentration ratios
9 of 16
have been considered, while for the other three only the ∞concentration ratio has been
considered, for a total of 71 different gamma sources distributions. Moreover, for each of
these, 4 different roto-translations of the tumor region were created, obtaining 355 different
different gamma sources distributions.
In order to select the events of interest, a filter was applied to consider only events
with a total energy deposition in the range 0.470 MeV −0.485 MeV and with interaction
points in the detector crystals. The simulation returns for each event the gamma source
position, Compton scattering interaction position, photoabsorption interaction position,
Compton recoil electron deposited energy and the photoabsorption deposited energy.
For each possible gamma sources distribution 300 million events were generated.
About 1 million events were detected by the apparatus in each run.
(a)
(b)
(c)
(d)
Figure 7. Ring source, T/N = 4 : 1 (a) XY gamma generation heatmap, (b) XZ gamma generation
heatmap, (c) YZ gamma generation heatmap and (d) normalized intensity as a function of x.
Fig. 7 shows the ring gamma source distribution with a concentration ratio 4 : 1 in
the parallelepipedonal region of size 160 mm × 80 mm × 80 mm. Fig. 7a is the XY gamma
generation heatmap for z = 40 mm, Fig. 7b represents the XZ gamma generation heatmap
for y = 40 mm, Fig. 7c is the YZ gamma generation heatmap for x = 80 mm and Fig. 7d the
normalized intensity as a function of x for y = z = 40 mm.
3.2. U-Nets: dataset, network architectures, training and evaluation
The dataset consists in the output of the 10th iteration of the list-mode MLEM algo-
rithm (input images) and the output of the 60th iteration (label images) of the 71 simulated
gamma source distributions and of the data augmentation gamma source distributions
obtained by applying four different rototranslations, for a total of 355 samples with the
corresponding labels. In order to further increase the size of the dataset, 41 noisy images
were created by adding one out of four different levels of Gaussian white noise to each of
the sample images (if ∆˜f denotes the difference between the maximum and minimum value
of the input image the standard deviations of the four levels are: σ0 = ∆˜f /16, σ1 = ∆˜f /20,
σ2 = ∆˜f /30, σ3 = ∆˜f /40), leaving the corresponding label unchanged, resulting into a
10 of 16
global dataset of 355 × 42 = 14910 input images with corresponding label. These were
distributed with a proportion of 70 : 10 : 20 among the training set (11130 images), valida-
tion set (1260 images) and test set (2520 images), mantaining class balance among sets and
distributing different rototranslations into different sets, so that every set contains almost
new gamma source distributions with respect to the others. Fig 8 shows an example of
input image, with noise level 1 and rototranslation 2. The corresponding label is displayed
in Fig 9.
(a)
(b)
(c)
(d)
Figure 8. An example of network input. (a) XY gamma generation heatmap, (b) XZ gamma generation
heatmap (c) YZ gamma generation heatmap and (d) normalized intensity as a function of x.
The 3D standard U-Net, 3D dual frame U-Net and 3D tight frame U-Net are described
in sections 2.1 and represented in Fig. ??(a)-(b) and Fig. 5 (they are 4D representations, the
plane perpendicular to the page corresponds to three dimensional space). All the U-Nets
include convolutional layers with 3 × 3 filters and rectified linear units (ReLU). The first
two network employ average pooling and unpooling layers. The tight frame U-Net uses
Haar wavelet decomposition with eight filters, the corresponding unpooling operation
with eight synthesis filters [31,32] and the weighted addition of nine input tensors with
learnable weights. All networks include skip connections. Every input image and label is
normalized to the interval [0, 1].
The networks were trained using ADAM algorithm [33] with a learning rate equal
to 0.001. The loss function was the normalize mean square error (NMSE), defined below.
The batch size was set equal to 1 owing to the large size of three-dimensional images.
Data was lazy-loaded to the main memory and then asynchronously loaded to the GPU.
The networks were implemented using PyTorch6. A A100 PCIe 40 GB GPU with Ampere
architecture and eight AMD EPYC 7742 64-Core CPUs (2.25 GHz) were used. All three
networks require about 7 −8 days for training. The number of training epochs nte (with
6
An optimized tensor library for deep learning using GPUs and CPUs, based on an automatic differentiation
system [34].
11 of 16
(a)
(b)
(c)
(d)
Figure 9. Corresponding label. (a) XY gamma generation heatmap, (b) XZ gamma generation
heatmap (c) YZ gamma generation heatmap and (d) normalized intensity as a function of x.
epochs running from 0 to nte −1) and best epoch with its training and validation average
NMSEs are reported in Table 1. The best epoch model was used for validation.
Network
nte
Best epoch
Tr. NMSE
Val. NMSE
U-Net
56
39
0.03396
0.02865
Dual frame U-Net
53
50
0.03280
0.02571
Tight frame U-Net
52
48
0.01102
0.01113
Table 1. Number of training epochs nte and best epoch with its training and validation NMSEs for
each network.
For quantitative evaluation, three different metrics were used: the normalized mean
square error (NMSE) value defined as
NMSE = ∥f ∗−ˆf ∥2
2
∥f ∗∥2
2
=
∑M
i=1 ∑N
j=1 ∑O
k=1[ f ∗(i, j, k) −ˆf (i, j, k)]2
∑M
i=1 ∑N
j=1 ∑O
k=1[ f ∗(i, j, k)]2
,
(12)
where M, N and O are the number of pixels in the x−, y−and z−direction and ˆf and
f ∗denote the reconstructed images and labels, respectively; the peak signal to noise ratio
(PSNR), defined by7
PSNR = 10 log10
∥f ∗∥∞2
MSE

= 20 · log10
 √
NMO∥f ∗∥∞
∥ˆf −f ∗∥2
!
;
(13)
7
The mean square error (MSE) is defined as MSE = ∥f ∗−ˆf ∥2
2/(NMO). ∥f ∗∥∞= |max(i,j,k) f ∗(i, j, k)|.
12 of 16
The structural similarity index measure (SSIM) [35], defined as
SSIM =
(2µ ˆf µ f ∗+ c1)(2σ ˆf f ∗+ c2)
(µ2
ˆf + µ2
f ∗+ c1)(σ2
ˆf + σ2
f ∗+ c2),
(14)
where µ ˆf is a average of ˆf, σ2
ˆf is a variance of ˆf and σ ˆf f ∗is a covariance of ˆf and f ∗. While
the first two metrics quantify the difference in the values of the corresponding pixels of the
reference and reconstructed images, the structural similarity index quantifies the similarity
based on luminance, contrast and structural information, similarly to the human visual
perception system. Low values of NMSE and high values of PSNR indicate similarity
between images. The structural similarity index takes values in [−1, 1], where values
close to one indicate similarity, zero indicates no similarity and values close to −1 indicate
anti-correlation.
4. Results
Fig 10, Fig 11 and Fig 12 show the predicted reconstructions of the three models given
the input in Fig 8. It can be observed that while the standard U-Net and the dual frame
U-Net are more affected by degradations, the tight frame U-Net produces a prediction very
similar to the label image in Fig 9 even if only two levels are considered in the architecture
(Fig 5). This observations are confirmed by similarity metrics reported in Table 2. The
NMSE
PSNR
SSIM
Standard U-Net
0.031803
36.119379
0.754417
Dual frame U-Net
0.029113
36.396008
0.726286
Tight frame U-Net
0.011953
40.615813
0.853548
Table 2. Average NMSE, PSNR and SSIM on the test set for the trained U-Net, dual frame U-Net and
tight frame U-Net modules.
performance of the standard U-Net and the dual frame U-Net are essentially comparable,
with the latter performing slightly better in terms of NMSE and PSNR but slightly worse in
terms of SSIM. The performance of the two networks and the presence of degradations can
be explained by considering that the standard U-Net doesn’t satisfy the frame condition
and the dual frame U-Net, while satisfying the frame condition, tends to amplify noise. The
tight frame architecture showed a considerable improvement in performance considering
all three metrics, and in particular in the SSIM, which quantifies structural information.
In terms of processing time, U-Nets regression takes generally less than a second, so
that the overall reconstruction time is dominated by the time necessary to obtain the input
image, which is of the order of 4 −6 minutes. Considering a BNCT treatment duration
of 30 −90 minutes, the obtained reconstruction time performance represents a significant
improvement compared to classical iterative methods (processing time is reduced by a
factor of about 6 with respect to the 24 −36 minutes needed for 60 iterations in the case
of list-mode MLEM), making this kind of approach a valid step towards real time dose
monitoring during BNCT treatment.
Notice that although the source geometries created in the simulation are not biologi-
cally realistic, the same procedure can be applied with distributions obtained in real medical
practice. Moreover transfer learning techniques [36] could be employed to take advantage
of the training already done with simulated datasets.
5. Conclusions
Boron Neutron Capture Therapy (BNCT) represents a promising form of cancer ther-
apy because of its high selectivity towards cancer tissue. However at present there are no
viable imaging methods capable of in vivo monitoring dose during treatment. Compared
to other imaging techniques under investigation, Compton imaging offers various advan-
13 of 16
(a)
(b)
(c)
(d)
Figure 10. U-Net predictions (a) XY gamma generation heatmap, (b) XZ gamma generation heatmap
(c) YZ gamma generation heatmap and (d) normalized intensity as a function of x.
(a)
(b)
(c)
(d)
Figure 11. Dual frame U-Net predictions (a) XY gamma generation heatmap, (b) XZ gamma genera-
tion heatmap (c) YZ gamma generation heatmap and (d) normalized intensity as a function of x.
14 of 16
(a)
(b)
(c)
(d)
Figure 12. Tight frame U-Net predictions (a) XY gamma generation heatmap, (b) XZ gamma genera-
tion heatmap (c) YZ gamma generation heatmap and (d) normalized intensity as a function of x.
tages, but the main difficulty in this type of approach is the complexity of Compton image
reconstruction, which is associated with long reconstruction times, comparable with BNCT
treatment duration. This calls for the development of new reconstruction techniques with
lower computational cost.
In order to investigate the potentialities of Compton imaging with CZT detectors for
BNCT, a Geant4 simulation of a simplified detector in a BNCT setting has been imple-
mented, considering several tumor region geometries in order to produce a large enough
dataset for the training phase of deep neural network algorithms.
In order to reduce reconstruction time, the U-Net architecture and two variants based
on the deep convolutional framelets framework, the dual frame U-Net and the tight
frame U-Net, were applied to reduce degradation in few-iterations reconstructed images.
Encouraging results were obtained both in terms of visual inspection and in terms of the
three metrics used to evaluate the similarity with the reference images (NMSE, PSNR and
SSIM), especially with the use of tight frame U-Nets. The lower performance of standard
U-Net architecture and of the dual frame variant was attributed to the fact that the former
doesn’t satisfy frame condition, while the latter tends to amplify noise. The processing time
was reduced on average by a factor of about 6 with respect to classical iterative algorithms,
with most it amounting to the starting image reconstruction time of about 4 −6 minutes.
This can be considered a good reconstruction time performance, considering typical BNCT
treatment times.
In principle it would be possible to further improve reconstruction accuracy and
reduce processing time by improving quality and time performance in the reconstruction
of the input image provided to the U-Net, for example by employing unrolled optimization
algorithms.
Data Availability Statement: The data can be shared up on request.
15 of 16
Conflicts of Interest: The authors declare no conflicts of interest.
References
1.
IAEA. Corrent Status of Neutron Capture Therapy. International Atomic Energy Agency, 2001.
2.
W. Sauerwein, A. Wittig, R. Moss, and Y. Nakagawa, editors. Neutron Capture Therapy: Principles and Applications. Springer, 2015.
3.
A. Obertelli and H. Sagawa, editors. Modern Nuclear Physics: From Fundamentals to Frontiers. Springer, 2021.
4.
T. Isao, T. Hiroshi, and K. Toshitaka, editors. Handbook of Nuclear Physics. Springer, 2023.
5.
E. B. Podgorsak, editor. Radiation Physics for Medical Physicists. Springer, 2016.
6.
IAEA. Advances in Boron Neutron Capture Therapy. International Atomic Energy Agency, 2023.
7.
P. Nillius and M. Danielsson. Theoretical bounds and optimal configurations for multi-pinhole spect. In 2008 IEEE Nuclear
Science Symposium Conference Record. IEEE, October 2008.
8.
M. Bertero, P. Boccacci, and C. De Mol. Introduction to Inverse Problems in Imaging. CRC Press, 2nd edition, 2021.
9.
G. Chen, Y. Wei, and Y. Xue. The generalized condition numbers of bounded linear operators in banach spaces. Journal of the
Australian Mathematical Society, 76(2):281–290, 2004.
10.
J. van Neerven. Functional Analysis. Cambridge University Press, corrected edition, 2024.
11.
M. N. Wernick and Aarsvold J. N., editors. Emission Tomography: The Fundamentals of PET and SPECT. Elsevier Academic Press,
2004.
12.
A. K. Jain. Fundamentals of Digital Image Processing. Pearson, 1988.
13.
R. C. Gonzalez and R. E. Woods. Digital Image Processing. Pearson, 2017.
14.
H. Kobayashi, B. L. Mark, and W. Turin. Probability, Random Processes, and Statistical Analysis: Applications to Communications,
Signal Processing, Queueing Theory and Mathematical Finance. Cambridge University Press, 2012.
15.
I. Valencia Lozano, G. Dedes, S. Peterson, D. Mackin, A. Zoglauer, S. Beddar, S. Avery, J. Polf, and K. Parodi. Comparison of
reconstructed prompt gamma emissions using maximum likelihood estimation and origin ensemble algorithms for a compton
camera system tailored to proton range monitoring. Zeitschrift für Medizinische Physik, 33(2):124–134, 2023.
16.
V. Maxim, X. Lojacono, E. Hilaire, et al. Probabilistic models and numerical calculation of system matrix and sensitivity in
list-mode mlem 3d reconstruction of compton camera images. Physics in Medicine & Biology, 61(1):243, dec 2015.
17.
S.J. Wilderman, N.H. Clinthorne, J.A. Fessler, and W.L. Rogers. List-mode maximum likelihood reconstruction of compton
scatter camera images in nuclear medicine. In 1998 IEEE Nuclear Science Symposium Conference Record. 1998 IEEE Nuclear Science
Symposium and Medical Imaging Conference (Cat. No.98CH36255), volume 3, pages 1716–1720 vol.3, 1998.
18.
L.C. Parra.
Reconstruction of cone-beam projections from compton scattered data.
IEEE Transactions on Nuclear Science,
47(4):1543–1550, 2000.
19.
H. Ben Yedder, B. Cardoen, and G. Hamarneh. Deep learning for biomedical image reconstruction: a survey. Artificial Intelligence
Review, 54(1):215–251, August 2020.
20.
G. Ongie, A. Jalal, C. A. Metzler, et al. Deep learning techniques for inverse problems in imaging. IEEE Journal on Selected Areas in
Information Theory, 1(1):39–56, 2020.
21.
J. C. Ye, Y. C. Eldar, and M. Unser, editors. Deep Learning for Biomedical Image Reconstruction. Cambridge University Press, 2023.
22.
Y. Han and J. C. Ye. Framing u-net via deep convolutional framelets: Application to sparse-view ct. IEEE Transactions on Medical
Imaging, 37(6):1418–1429, 2018.
23.
J. C. Ye, Y. Han, and E. Cha. Deep convolutional framelets: A general deep learning framework for inverse problems. SIAM
Journal on Imaging Sciences, 11(2):991–1048, 2018.
24.
P. G. Casazza and G. Kutyniok, editors. Finite Frames: Theory and Applications. Birkhäuser, 2013.
25.
P. Grohs and G. Kutyniok, editors. Mathematical Aspects of Deep Learning. Cambridge University Press, 2022.
26.
J. C. Ye. Geometry of Deep Learning: A Signal Processing Perspective. Springer, 2023.
27.
K. Jin, M. Mccann, E. Froustey, and M. Unser. Deep convolutional neural network for inverse problems in imaging. IEEE
Transactions on Image Processing, PP, 11 2016.
28.
H. Tashima and T. Yamaya. Compton imaging for medical applications. Radiol Phys Technol, 15(3):187–205, July 2022.
29.
L. Abbene, G. Gerardi, F. Principato, A. Buttacavoli, S. Altieri, N. Protti, E. Tomarchio, S. Del Sordo, N. Auricchio, M. Bettelli, N. S.
Amadè, S. Zanettini, A. Zappettini, and E. Caroli. Recent advances in the development of high-resolution 3D cadmium–zinc–
telluride drift strip detectors. Journal of Synchrotron Radiation, 27(6):1564–1576, Nov 2020.
30.
L. Abbene, F. Principato, A. Buttacavoli, G. Gerardi, M. Bettelli, A. Zappettini, S. Altieri, N. Auricchio, E. Caroli, S. Zanettini, and
N. Protti. Potentialities of high-resolution 3-d czt drift strip detectors for prompt gamma-ray measurements in bnct. Sensors,
22(4), 2022.
31.
S. Mallat. A Wavelet Tour of Signal Processing: The Sparse Way. Elsevier Academic Press, third edition, 2009.
32.
S. B. Damelin and Jr. Miller, W. The Mathematics of Signal Processing. Cambridge University Press, 2012.
33.
A. H. Sayed. Inference and Learning From Data, vol.I-III. Cambridge University Press, 2022.
34.
A. Baydin, B. Pearlmutter, R. A., and J. Siskind. Automatic differentiation in machine learning: A survey. Journal of Machine
Learning Research, 18:1–43, 04 2018.
35.
Z. Wang, A.C. Bovik, H.R. Sheikh, and E.P. Simoncelli. Image quality assessment: from error visibility to structural similarity.
IEEE Transactions on Image Processing, 13(4):600–612, 2004.
16 of 16
36.
K. P. Murphy. Probabilistic Machine Learning: An Introduction. MIT Press, 2022.
