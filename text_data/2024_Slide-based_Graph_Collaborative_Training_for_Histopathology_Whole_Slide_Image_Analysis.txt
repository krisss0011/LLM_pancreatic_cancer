SLIDE-BASED GRAPH COLLABORATIVE TRAINING FOR
HISTOPATHOLOGY WHOLE SLIDE IMAGE ANALYSIS
A PREPRINT
Jun Shi
School of Software
Hefei University of Technology
Hefei 230601, China
Tong Shu
School of Computer Science and Information Engineering
Hefei University of Technology
Hefei 230601, China
Zhiguo Jiang
Image Processing Center, School of Astronautics
Beihang University
Beijing, 102206, China
Wei Wang
Department of Pathology, the First Affiliated Hospital of USTC
University of Science and Technology of China
Hefei 230036, China
Haibo Wu
Department of Pathology, the First Affiliated Hospital of USTC
University of Science and Technology of China
Hefei 230036, China
wuhaibo@ustc.edu.cn
Yushan Zheng
School of Engineering Medicine
Beijing Advanced Innovation Center on Biomedical Engineering
Beihang University
Beijing 100191, China
yszheng@buaa.edu.cn
October 14, 2024
ABSTRACT
The development of computational pathology lies in the consensus that pathological characteristics of
tumors are significant guidance for cancer diagnostics. Most existing research focuses on the inner-
contextual information within each WSI yet ignores the possible inter-correlations between slides. As
the development of tumors is a continuous process involving a series of histological, morphological,
and genetic changes that accumulate over time, the similarities and differences between WSIs across
various stages, grades, locations and patients should potentially contribute to the representation of
WSIs and deserve to be taken into account in WSI modeling. To verify the advancement of introducing
the slide inter-correlations into the representation learning of WSIs, we proposed a generic WSI
analysis pipeline SlideGCD that can be adapted to any existing Multiple Instance Learning (MIL)
frameworks and improve their performance. With the new paradigm, the prior knowledge of cancer
development can participate in the end-to-end workflow, which concurrently initializes and refines the
slide representation, as a guide for message passing in the slide-based graph. Extensive comparisons
arXiv:2410.10260v1  [cs.CV]  14 Oct 2024
arXiv Template
A PREPRINT
and experiments are conducted to validate the effectiveness and robustness of the proposed pipeline
across 4 different tasks, including cancer subtyping, cancer staging, survival prediction, and gene
mutation prediction, with 7 representative SOTA WSI analysis frameworks as backbones.
Keywords computer-aided diagnosis · computational pathology · graph learning · whole slide image classification
1
Introduction
Histopathological characteristics of tumors, including the tendency of tissue invasion, metastasis, growth pattern, etc.,
have been proven to effectively guide cancer diagnosis and therapies by numerous studies and practices [1]. Currently,
whole slide images (WSIs) have been closely involved in medical practice as an indispensable part of the routine
diagnostic process, becoming the gold standard for cancer diagnosis. In recent years, a large amount of research
has focused on using artificial intelligence (AI) technology, especially deep learning, on examining WSIs and assist
pathologists in effective, accurate, and reproducible pathological analysis and diagnosis, and has achieved significant
accomplishments in various fields, e.g. cancer subtyping[2; 3], cancer staging[4; 5], survival prediction[6; 7], gene
mutation prediction[8; 9], etc.
Considering the special attributes (the giga-pixel resolution and the pyramid structure) that distinguish WSIs from
natural scene images, the current WSI analysis framework follows the Multiple Instance Learning (MIL) paradigm
which takes patches as the smallest instance of analysis and explores the inner-contextual information of WSI by
modeling the correlation between patches. Patch-based WSI analysis methods focus on how to model the relationships
between patches more comprehensively and efficiently, and it can be divided into the following four categories: 1)
Classical MIL methods [10; 1] treat each patch as an independent instance and generate slide-level representation by
aggregating patch-level embeddings via different pooling methods. 2) A series of pseudo-bag based methods [2; 11]
has been proposed which divide the patches of each WSI into many separated pseudo-bags for solving data scarcity of
annotated WSIs. 3) The graph-based methods [12; 13; 14; 15; 5; 9] utilize the patch-based graph where patches are
nodes and edges indicate the potential connections between them to simulate the relationships between patches and to
represent WSI. 4) The sequence-based methods [16; 17; 18] consider WSI as a sequence of patches and involve various
mechanisms or modules, e.g. Transformer or Structured State Space Models, to construct the detailed correlation among
patches. With great achievements made by the above studies, the intra-relationships among patches from the same
magnification are well-explored, and the interactions across magnifications are arousing more and more attention in
recent years [4; 19; 3].
Although the inner-contextual information of WSIs is well-delved by previous research, the inter-correlations between
WSIs have not drawn much attention. As most tumors develop through a continuous process involving a series of
histological [20], morphological [21] and genetic changes [22] that accumulate over time, the similarities and differences
between WSIs that across various stages, grades, locations and patients should potentially contribute to the analysis of
WSIs and deserve to be taken into account for attaining better slide representations. Some studies [14; 6; 23] are aware
of the importance of the inter-correlations in patch-slide-patient hierarchy yet stop within the patient level.
In this paper, we explore inter-correlations between WSIs on a larger scope and find an efficient way to unite inter-
correlations with the intra-correlations in each WSI. Specifically, we propose the Slide-based Graph Collaborative
training pipeline with knowledge Distillation (SlideGCD) for WSI representation learning that dynamically organizes
the slide-level embeddings into a slide-based graph and makes message passing between connected slides via graph
neural networks. The intuitive differences between the patch-based graph and the slide-based graph are shown in
Fig. 1. More concretely, we take existing MIL methods as the backbone to obtain the initial slide-level embeddings.
Then, SlideGCD is used to explore the contextual information implied in the extensive slide-based graph. Finally, the
slide-level predictions are obtained by conducting node classification on the slide-based graph.
The main contributions of this paper are summarized below:
• We propose a new histopathology WSI analysis paradigm that involves prior knowledge of cancer development
with coordinatively constructing the slide-based graph and conducting graph message passing during the
representation learning.
• We devise a rehearsal-based adaptive graph construction strategy to model the slide-level inter-correlations. Be-
sides, a knowledge distillation (KD) based collaborative training for the slide-based hypergraph convolutional
network is applied to transfer and enhance the intra-contextual information learned by the MIL network.
• We conduct extensive comparisons and experiments to validate the effectiveness and generalization of the
proposed pipeline across 4 different downstream tasks and 7 representative SOTA WSI analysis frameworks as
backbones.
2
arXiv Template
A PREPRINT
Figure 1: Motivation of our methods. (a) Multi-Instance Learning Frameworks. The main difference between MIL
methods lies in the implementations of pooling operations. (b) Patch-based Graph Methods. The mainstream graph-
based methods represent WSIs to graphs and transfer the WSI classification problem as graph classification. (c)
Slide-based Graph Methods. SlideGCD conceptualizes the WSI classification problem as node classification to explore
the inter-correlations between slides explicitly via GNNs.
2
Related Works
This section reviews the approaches related to graph-based WSI analysis and the methods that potentially explore the
slide-level inter-correlations.
2.1
Graph-based WSI Analysis
Due to its flexibility and interpretability, much attention has been put on the graph structure and graph neural networks.
Graph-based methods have shown competitive performance on various WSI analysis tasks. According to different
graph structures applied, existing methods can be grouped into the following three categories.
2.1.1
Methods on Regular graphs
On account of the analogy that WSI is the graph where its patches are the nodes, graph structures were introduced
into WSI analysis at its very early stage. DeepGraphConv [12] randomly samples 1000+ patches and connects them
with a feature similarity threshold to construct a patch-based graph for each WSI. PatchGCN [13] builds patch-based
graphs via spatial adjacent patches and gains better performance on the survival prediction task. LAMIL [24] and GTP
[25] follow the graph construction strategy of PatchGCN yet design different graph transformers to make efficient
message passing. NAGCN [14] introduces the hierarchical global-to-local patch-based graph to represent WSI in both
spatial and embedding space. SlideGraph+ [15] uses the biomarker attributes and neural network embeddings to build
patch-based graphs and represent the complex organization of cells and the overall tissue micro-architecture. As the idea
of multi-scale is progressively involved in WSI analysis, many graph-based methods have also kept up with this trend.
SGMF [5] constructs the structure-aware hierarchical graph that considers tissue regions and patches from different
magnifications in an interactive way. DAS-MIL [3] creates patch-based graphs on various magnifications and designs a
knowledge distillation mechanism to align the representation learned from different graphs.
2.1.2
Methods on Graph-variant
Simple graphs consider all nodes equally and their connections can only describe pair-wise relationships. To deal
with such drawbacks that deface representation learning in real-world applications, such as WSI representation, the
heterogeneous graph and the hypergraph are engaged. HEAT [19] utilizes a heterogeneous graph with various pre-
3
arXiv Template
A PREPRINT
Figure 2: Illustration of the proposed SlideGCD framework. The framework consists of three phases, (a) Sample
Pre-Processing. Each WSI is transformed into a sequence of patch embeddings following the universal settings of the
MIL paradigm. (b) Patch Interaction. Slide embeddings are generated by the backbone MIL method for each sample.
(c) Slide-based Graph Interaction. A slide-based graph is maintained and updated during each mini-batch training
(colored indicators denote samples from the current mini-batch), then graph learning and knowledge distillation are
conducted to explore slide-level correlations and align both branches.
defined types of nodes to exploit the heterogeneity within WSI and perform WSI classification. Di et al. successively
proposed two hypergraph-based WSI analysis frameworks b-HGFN[26] and HGSurvNet[27]. b-HGFN focuses on
efficiently processing the hypergraphs with large-scale vertices, where hyperedges are constructed by adopting the
K-nearest neighbor (k-NN) strategy on embedding space. HGSurvNet establishes the multi-hypergraph composed
of topology-wise sub-hypergraph and phenotype-wise hypergraph for survival prediction with WSIs. MaskHGL [9]
refines the hypergraph construction strategy with global alignment and designs a mask-reconstruction mechanism for
achieving better performance on cancer subtyping and gene mutation prediction.
2.1.3
Methods on Adaptive graphs
Apart from the application of the variants of the graph in structure, the adaptive graph where its edge connections could
be altered during training is getting attention as well. Hou et al. [28] design a dynamic structure learning module to
assist the proposed spatial-hierarchical graph neural network in learning multi-scale information in WSIs. Liu et al.
[29] develop a survival-aware structure learning module to construct the adaptive graph for global WSI representation
calculation along with the fixed initial graph. WiKG [30] conceptualizes WSIs as a form of knowledge graph structure
and dynamically builds the edges via a knowledge-aware attention mechanism during training.
Compared with the previous patch-based graph methods mentioned above, this work exploringly molds the WSIs into a
slide-based graph with a rehearsal-based adaptive graph construction module to exploit the slide-level inter-correlations
implied in the continuous changes during tumor development.
2.2
Slide-level Inter-Correlation Exploration
In clinical practice, each patient probably has multiple WSIs. How to obtain more accurate diagnostic results through
multiple slide-level predictions has become a concern for many colleagues. Fan et al. [6] propose an aggregation module
that takes slide-level embeddings produced by the front MIL framework to generate patient-level prediction. HVTSurv
[23] and P&SrE [31] choose the Transformer model for interaction between the patient and its belonging slides. The
difference is that HVTSurv cascades three transformer blocks for patch-level, WSI-level, and patient-level interaction
respectively, yet P&SrE considers that the patient-level embeddings and slide-level embeddings are equal and thus
utilizes a single transformer block for their interaction. In addition, some other methods, although not intentionally
focusing on the slide inter-correlation, potentially acknowledge the consistency among slides. NAGCN [14], HEAT
[19] and MaskHGL [9] are aware that there should be a consistency between the constructed graphs in structure or
node types. In their graph construction strategies, NAGCN and MaskHGL apply a hierarchical clustering method based
on all the patches no matter which WSI it comes from to align the graph structure across slides. HEAT employs a
pre-trained network to classify the patches into pre-defined node types thus achieving node-level consistency.
4
arXiv Template
A PREPRINT
From the perspective of slide-level inter-correlation exploration, the above methods are not comprehensive enough,
as they either involve slide-level interactions limited within the single patient or do not model the slide-level inter-
correlations in an explainable way. The proposed SlideGCD lifts the patient-level restriction and explicitly constructs a
slide-based graph to explore the contextual information.
3
Methodology
In this section, we describe our proposed framework which consists of three phases: sample pre-processing, patch
interaction, and slide-based graph interaction, as illustrated in Fig. 2. In the first phase, each WSI sample is processed
into a sequence of patch embeddings with a pre-trained patch encoder. For the patch interaction phase, we engage the
existing MIL method as the backbone to generate slide-level embeddings. In the slide-based graph interaction phase,
a rehearsal-based adaptive graph construction strategy is exploited to build and maintain a slide-based graph during
training. Then, the SlideGNN is deployed to explore the slide inter-correlation based on the slide-based graph and
refine the slide embeddings for solving downstream tasks more precisely. Additionally, an online distillation is designed
between the MIL head and the SlideGNN to solve the problem of knowledge misalignment.
3.1
Sample Pre-Processing
Assuming there is a dataset with N WSIs denoted as D = {(Bi, yi)}N
i=1. Each WSI Bi = {Ii,j}Mi
j=1 is annotated
with a label yi ∈{0, ..., C −1}, where Ii,j is tiled patch without patch-level label, Mi is the number of patches and
C represents the number of categories. Then, there is a pre-trained patch encoder f(·), where we used PLIP [32], to
transform the patch Ik into patch embeddings xk ∈R512.
3.2
Patch Interaction
After obtaining the patch embeddings, an aggregator network is needed to exploit the patch correlations and generate
slide embeddings. We leave this job to the existing MIL network which will be called Backbone in our following
statement. In an ideal implementation, the Backbone can be any MIL network with any architecture as long as it
can produce fixed Ds dimensional slide-level embeddings si ∈RDs. The MIL Head is the relevant sub-network of
the Backbone for making predictions ˆyMIL for downstream tasks. Note that the slide embeddings are quite unstable
during the first few training epochs. Such instability might defect the subsequent graph learning. Therefore, we set a
few warmup epochs at the beginning of the training for backbone pre-convergence, in which only the MIL network is
involved in forward and backward.
We employed several representative MIL methods as the Backbone and conducted different downstream tasks for the
proposed SlideGCD, more analysis can be found in Section 4.
3.3
Slide-based Graph Interaction
With the slide embeddings, the requirements for slide-based graph interaction have been fulfilled. In this section, we
describe the main contributions including the rehearsal-based adaptive graph construction strategy, the details of the
designed SlideGNN, and the collaborative training with knowledge distillation.
3.3.1
Rehearsal-based Adaptive Graph Construction
With the inspiration of the idea of the Memory Bank [33; 34] and the rehearsal-based continual learning [35; 36], a
Class-Aware Node Buffer is designed to store the previous slide embeddings which will participate in the slide-based
graph construction and will be replayed in graph learning. Specifically, the Class-Aware Node Buffer defines a storage
space QT = [QT
11, QT
12, ..., QT
1C], where Q ∈RL×Ds represents that it is able to deposit L slide embeddings and
partitioned matrix Q1c ∈R
L
C ×Ds indicates the sub-queue that is responsible for storing slide embeddings with c-th
category. Each slide embedding stored in the buffer or the current mini-batch will correspond to a node in the subsequent
slide-based graph and will be considered as its initial node embedding.
In addition, the rehearsal buffer will be updated during each mini-batch of training. During the warmup stage, we
directly apply the First-In-First-Out (FIFO) strategy to update the node buffer, in which the newest mini-batch of slide
embeddings will be randomly pushed into the node buffer and the outdated slide embeddings at the end of the buffer
will be popped out simultaneously. In the formal training stage, we first calculate the centers of each sub-queue in the
embedded space, and then each slide embedding in the current mini-batch is going to replace the farthest stored sample
5
arXiv Template
A PREPRINT
Figure 3: Illustration of the update of the Node Buffer in embedded space. Left: the initial state of the Node Buffer
after the warmup, where the centers of each category are close. Right: the updated state after a mini-batch with 2
samples. The appended positive sample is too far from the center even compared with the farthest stored node thus it
won’t be updated into the buffer since we consider it as an amplified disturbance from the former network update. The
appended negative sample is close enough to the center to replace the farthest negative node marked by stripes. At last,
the outcome of the update is that the negative center shifts away from the positive center as we expected.
in the corresponding sub-queue as long as it is closer. As updates continue, ultimately the sub-queues will be separated
from each other. The following loss function is applied to ensure that during formal buffer updating.
Lupdate = −
X
u∈U
log
exp(u · q+/τ)
PC
i=0 exp(u · qi/τ)
+
X
u∈U
C
X
i=0
1qi̸=q+( u · qi
∥u∥∥qi∥),
(1)
where U is the enqueued slide embeddings, qi indicates the center of i-th sub-queue, the q+ represents the center which
corresponds to the category of u and the τ is the temperature coefficient. 1qi̸=q+(·) means that this term is not 0 only if
qi ̸= q+. An illustration of the update is shown in Fig. 3.
After getting the preliminary separable nodes, we conduct the adaptive graph generation (AGG) strategy to infer the
inter-dependencies from the embedding space for connecting these nodes with hyperedges. Our AGG strategy consists
of a linear layer that transforms the slide embeddings into an intermediate hidden space and a k-NN clustering operator
that will be performed on the intermediate embeddings to connect each node with its k nearest neighbors with a
hyperedge. Eventually, the slide embeddings in the current mini-batch and the slide embeddings retrieved from the
node buffer are formulated as a hypergraph G. The adaptive graph generation process can be formulated as:
G = (X(0), E), E = KNN(P, k), P = Linear(X(0))
(2)
where X(0) ∈R(L+B)×Ds is the node embeddings sequence that consists of the data in the buffer with a length of
L and the current mini-batch data with a length of B (batch size) and E is the set of hyperedges that describes the
connections between nodes.
3.3.2
Graph Learning via SlideGNN
With the slide-based graph representation, the SlideGNN composed of two hypergraph convolutional layers [38] and a
Centering-Attention module is applied to explore the implied information, as:
X(i+1) = LeakyReLU(HGC(X(i), E)),
(3)
6
arXiv Template
A PREPRINT
H = Concat(X(0), X(1), X(2)), H ∈RL×3DS,
(4)
where HGC(·) denotes the hypergraph convolution and X(i) contains the information accumulated from the node itself
to its i-hop neighbors.
Given that the adaptive graphs can involve graph heterophily that nodes with different categories are connected, we
designed the Centering-Attention module to alleviate such heterophily by rebalancing the participation of k-hop
information. The Centering-Attention module is implemented with channel-wise attention and Centering operation
[39] which prevent the attention score from always being positive even when facing defective partial information. The
computations can be formulated as:
H′ = H · Centering(a) = H · (a −Mean(a)),
(5)
a = Sigmoid(ReLU(HTW0)W1),
(6)
where W0, W1 ∈RL×L are the learnable weights, a ∈R3DS is the attention score before Centering. Finally, an
MLP classifier ClsGraph with one linear layer is used to make final predictions ˆyG for current mini-batch:
ˆyG = Softmax(Linear(H′)),
(7)
3.3.3
Collaborative Training with Knowledge Distillation
With the rehearsal-based adaptive graph and the SlideGNN, this framework is capable of exploiting the slide inter-
correlations from the given WSI dataset. However, there is no interaction between the graph branches and the MIL head
(HeadMIL), thus the well-learned slide intrinsic knowledge implied in the HeadMIL may be neglected. To associate
it with the slide inter-correlations and constrain both branches, we involved the knowledge distillation to transfer the
knowledge learned by HeadMIL to the SlideGNN.
We treat the HeadMIL and the SlideGNN as the teacher and student model separately, letting SlideGNN draw on the
beneficial information learned by HeadMIL. Specifically, a response-based knowledge distillation loss, JS divergence
loss, is adopted as:
LKD =
C
X
i
pG
i log(
2pG
i
pG
i + pMIL
i
) +
C
X
i
pMIL
i
log(
2pMIL
i
pG
i + pMIL
i
),
pG
i =
exp(ˆyG
i /t)
P
j exp(ˆyG
j /t),
pMIL
i
=
exp(ˆyMIL
i
/t)
P
j exp(ˆyMIL
j
/t)
(8)
where t is the temperature coefficient.
Then, the final loss of SlideGCD can be written as below, LCE(·) represents the Cross-Entropy loss function, and β is
the weight contributed by the buffer update:
L = LCE(ˆyMIL, y) + LCE(ˆyG, y) + LKD + βLupdate.
(9)
3.4
Inference
At the inference stage, all parameters and the Class-Aware Node Buffer are frozen. When a WSI is inputted, 1) its
initial embedding will be made with the backbone, 2) the initial slide embedding will be inserted into the slide-based
graph with the same rehearsal-based adaptive graph construction strategy, 3) the SlideGNN will make message passing
to refine its embedding for final prediction.
4
Experiments
4.1
Datasets
We conducted extensive experiments on various downstream tasks to verify the effectiveness of the proposed pipeline,
including cancer subtyping, cancer staging, survival prediction, and gene mutation prediction.
4.1.1
Cancer Subtyping
Two publicly available WSI datasets are used to evaluate our proposed pipeline in the downstream task of cancer
subtyping, including the TCGA-BRCA and the TCGA-NSCLC released by The Cancer Genome Atlas (TCGA) project
7
arXiv Template
A PREPRINT
Table 1: Comparisons of the baselines and corresponding SlideGCD collaboration version on cancer subtyping. †:
When reproducing HiGT, we applied the default setting on multi-scale from its original paper that only considered the
thumbnail, 5×, and 10× magnifications. That is the reason why the performance of HiGT gaps with other methods.
Method
SlideGCD
TCGA-BRCA
TCGA-NSCLC
ACC(%)
AUC(%)
F1(%)
ACC(%)
AUC(%)
F1(%)
ABMIL [10]
✗
88.97±0.85
89.87±0.89
81.61±2.27
86.96±1.16
95.14±0.51
86.89±1.20
✔
89.77±1.04
91.33±1.52
83.87±1.83
91.04±2.42
97.10±1.49
91.02±2.45
∆
+0.80
+1.46
+2.26
+4.08
+1.96
+4.13
PatchGCN [13]
✗
84.80±1.77
87.18±1.55
75.11±4.57
86.62±2.38
94.81±1.82
86.59±2.43
✔
86.00±0.87
89.79±1.30
76.49±0.78
89.63±1.68
97.62±0.75
89.60±1.69
∆
+1.20
+2.61
+1.38
+3.01
+2.81
+3.01
TransMIL [16]
✗
88.17±1.00
90.99±0.91
82.09±1.75
85.82±1.67
94.82±1.17
85.77±1.67
✔
90.70±1.73
92.82±2.00
85.91±2.62
90.70±3.00
96.53±1.22
90.68±3.03
∆
+2.53
+1.83
+3.82
+4.85
+1.71
+4.91
DTFDMIL [2]
✗
89.30±0.44
90.08±0.86
83.17±1.43
86.42±1.07
95.59±0.66
86.40±1.06
✔
91.50±0.50
92.83±0.93
86.52±0.78
90.84±1.83
96.31±1.84
90.82±1.84
∆
+2.20
+2.75
+3.35
+4.42
+0.72
+4.42
HiGT †[4]
✗
86.09±1.13
86.20±0.59
77.93±1.14
85.42±1.96
93.93±0.42
85.33±2.06
✔
88.43±0.40
87.93±2.07
81.47±0.34
87.32±1.53
94.65±0.58
87.28±1.56
∆
+2.34
+1.73
+3.54
+1.90
+0.72
+1.95
S4MIL [17]
✗
87.84±0.50
89.29±1.71
81.18±1.00
88.03±0.86
95.05±0.70
88.01±0.87
✔
89.30±1.62
90.12±2.34
83.35±1.79
89.50±1.88
96.04±1.42
89.48±1.88
∆
+1.46
+0.83
+2.17
+1.47
+0.99
+1.47
[40]1. Specifically, TCGA-BRCA contains 998 diagnostic digital slides of two breast cancer subtypes, made up of
794 WSIs of invasive ductal carcinoma (IDC) and 204 WSIs of invasive lobular carcinoma (ILC). TCGA-NSCLC is a
collection of two subtype projects for lung cancer, i.e. lung squamous cell carcinoma (LUSC) and lung adenocarcinoma
(LUAD), for a total of 995 diagnostic WSIs, including 496 WSIs of LUSC and 499 WSIs of LUAD.
4.1.2
Cancer Staging
In the cancer staging task, we used the same WSIs with another set of labels for staging from the two public datasets
mentioned above, TCGA-BRCA and TCGA-NSCLC. Concretely, we excluded samples without grading labels and
categorized the remaining WSIs as early-stage (Stage I&II) and late-stage (Stage III&IV). In TCGA-BRCA, there are
713 WSIs of early-stage and 232 WSIs of late-stage. In TCGA-NSCLC, there are 726 WSIs of early-stage and 180
WSIs of late-stage. Note that the staging task is normally harder than subtyping because it relies more on subtle cellular
morphological features and the natural class imbalance of its datasets.
4.1.3
Survival Prediction
As to the survival prediction task, we evaluated SlideGCD with the TCGA-BLCA (437 WSIs) cohort following the
setting of previous studies [13].
4.1.4
Gene Mutation Prediction
An in-house clinical dataset USTC-EGFR2 is used to evaluate whether the slide inter-correlation can benefit the
efficiency of gene mutation prediction via H&E histopathology WSIs. USTC-EGFR contains a total of 754 WSIs of
lung histopathology from five categories of samples, including 165 WSIs of negative (Neg), 118 WSIs with a missense
mutation in exon 21 (L858R), 184 WSIs with in-frame deletions in exon 19 (19del), 146 WSIs of wild type (Wild) and
141 WSIs with other driver gene mutations (Others). All labels have been confirmed by pathologists.
1https://portgdc.cancer.gov/
2The study was approved by the Medical Research Ethics Committee of the First Affiliated Hospital of the University of Science
and Technology of China (Anhui Provincial Hospital) under the protocol No.2022-RE-454.
8
arXiv Template
A PREPRINT
Table 2: Comparsions on cancer staging. The ACCs are not reported because the serious class imbalance on cancer
staging makes the ACC of all methods approach the proportion of the class with more samples in the test set, thereby
making the accuracy less referenceable.
Method
SlideGCD
TCGA-BRCA
TCGA-NSCLC
AUC(%)
F1(%)
AUC(%)
F1(%)
ABMIL [10]
✗
58.75±1.84
46.00±3.15
63.98±1.96
58.24±3.56
✔
60.79±3.18
48.24±6.36
67.57±2.02
58.03±6.48
∆
+2.04
+2.24
+3.59
-0.21
PatchGCN [13]
✗
57.96±1.80
49.28±4.61
59.66±1.63
53.46±5.66
✔
61.17±3.38
51.54±1.99
65.85±5.17
53.36±5.89
∆
+3.21
+2.26
+6.19
-0.10
TransMIL [16]
✗
58.25±3.11
47.38±4.26
61.91±1.51
54.64±3.34
✔
59.79±3.35
51.93±3.70
63.47±2.65
56.97±4.02
∆
+1.54
+4.55
+1.56
+2.33
DTFDMIL [2]
✗
58.14±2.52
53.72±1.37
59.73±1.74
54.74±2.72
✔
60.23±1.78
54.25±2.86
69.50±3.48
58.64±6.23
∆
+2.09
+0.53
+9.77
+3.90
HiGT [4]
✗
56.23±1.58
50.86±4.44
58.77±2.65
50.65±2.25
✔
56.41±2.85
49.72±5.63
59.44±3.60
50.09±5.78
∆
+0.18
-1.14
+0.67
-0.56
S4MIL [17]
✗
58.55±5.04
52.37±2.86
62.29±3.25
54.65±5.28
✔
61.13±2.20
54.69±2.63
67.54±2.35
59.55±5.21
∆
+2.58
+2.32
+5.25
+4.90
4.2
Implementation Details
Before training, the 256×256 patches within tissue regions were split under 20× lenses. During training, the Adam
optimizer with CosineAnnealing learning rate scheduler was employed. We directly adopted the default setting of
hyper-parameters to the baseline from its public repository and remained fixed when applying SlideGCD for the
fairness of comparison except the learning rate will be reset to 1e-4 after the warmup for SlideGCD. All methods are
implemented in Python with the PyTorch 1.8 and PyTorch Geometric (PyG) libraries. We ran the experiments on a
computer with an NVIDIA RTX 3090 GPU.
All experiments are performed using the same five-fold cross-validation splits. The average accuracy (ACC), macro-
average F1 score (F1), and macro-average area under the receiver operating characteristic curve (AUC) are calculated
for evaluating the classification performance, i.e. cancer subtyping, cancer staging and gene mutation prediction tasks.
The concordance index (C-Index) is calculated to evaluate the performance of the survival prediction task.
4.3
Results and Analysis
We evaluate the effectiveness of the proposed SlideGCD by comparing its improvement on various state-of-the-art
WSI analysis approaches and different downstream tasks. For the cancer subtyping and the cancer staging tasks, we
select 6 influential previous SOTA methods as baselines: i) ABMIL [10], ii) PatchGCN [13], iii) TransMIL [16],
iv) DTFDMIL [2], v) HiGT [4], vi) S4MIL [17]. For the survival prediction tasks, we choose 2 classic methods, i)
ABMIL-Surv and ii) PatchGCN, that performed well in the reported results in [13] for this task. For the gene mutation
prediction, we choose DTFDMIL as one of the two selected baselines since it gains the best overall performance on our
subtyping and staging experiments. The other one is MaskHGL [9] for it is one of the latest WSI analysis methods that
pay special attention to the fine-grained gene mutation prediction task. The experimental results for each downstream
task are presented respectively in Tables 1-4.
Overall, the proposed SlideGCD is capable of substantially improving the accuracy of baseline models in most
application scenarios. Especially for the pseudo-bag based method DTFDMIL, the SlideGCD significantly improved its
performance on 3 different WSI classification tasks, including but not limited to achieving the best performance on
TCGA-BRCA (Subtyping) with 91.50% ACC, 92.83% AUC and 86.52% F1, and achieving over 4% improvement of
ACC & F1 on TCGA-NSCLC (Subtyping), and 9.77% of AUC gain on TCGA-NSCLC (Staging).
9
arXiv Template
A PREPRINT
Table 3: Comparisons on survival prediction.
Method
SlideGCD
TCGA-BLCA
C-Index
ABMIL-Surv
✗
52.72±4.55
✔
54.29±6.52
∆
+1.57
PatchGCN [13]
✗
55.63±3.91
✔
57.45±4.00
∆
+1.82
Table 4: Comparisons on gene mutation prediction.
Method
SlideGCD
USTC-EGFR
ACC(%)
AUC(%)
F1(%)
DTFDMIL [2]
✗
57.49±2.13
85.47±0.32
55.80±1.52
✔
59.91±2.80
85.73±1.43
59.53±2.91
∆
+2.42
+0.26
+3.73
MaskHGL [9]
✗
61.52±2.86
86.82±0.99
60.22±3.58
✔
62.24±3.20
87.51±1.31
61.56±3.76
∆
+0.72
+0.69
+1.34
Each dataset we applied has its characteristics. For example, the dataset (TCGA-NSCLC) used in cancer subtyping
corresponds to the most common binary classification without class imbalance. The cancer staging reveals the
imbalanced binary classification and the fine-grained gene mutation prediction represents the multi-class classification
problem. Moreover, the regression problem is validated by the survival prediction task. All these multi-task experiments
have proven the robustness and generalization of the proposed SlideGCD.
One exception appears on HiGT, the multi-scale method that makes further consideration in hierarchical interaction
across different magnifications via self-attention variant, in the cancer grading task. A foreseeable reason is the implicit
contextual information at low magnification (e.g. thumbnails, 5×, and 10×) makes it difficult to achieve accurate cancer
grading. Additionally, the unaligned patch clustering in HiGT, which is performed for each WSI separately, disturbs the
connection measurement between WSIs and increases the heterogeneity of the slide-based graph. One another unideal
situation occurred with MaskHGL on gene mutation prediction where the improvements were not significant enough
as well. The problem may be with the Masked Hypergraph ReConstruction (MHRC) module that is responsible for
the mask reconstruction in MaskHGL. The learnable mask token in MHRC bridges the different slide representations
since it participates in every round of training that involves the mask operation, thus the inter-correlation may have been
learned in MaskHGL.
We are also aware that the improvement in the TCGA-BRCA cohort is smaller compared with TCGA-NSCLC in both
cancer subtyping and staging settings. Considering the varying difficulty levels of each dataset, the TCGA-BRCA
cohort is harder than TCGA-NSCLC. It might suggest that the benefits brought by SlideGCD decline as the difficulty
increases. The deeper reason is the separability of node embeddings is affected by the dataset difficulty and that narrows
the potential of slide-based graph learning guided by the connection reflecting similar pathological patterns. However,
even so, our SlideGCD can still achieve universal improvement in more complex downstream tasks, e.g. survival
prediction and fine-grained gene mutation prediction.
4.4
Ablation Studies and Discussion
In this section, we discuss the effect of two ambiguous designs in SlideGCD. 1) Why use distillation instead of fusion
strategies? 2) Is the hypergraph representation necessary? Can we use the simple graph instead?
4.4.1
Distillation Vs. Fusion
There are many ways to gather knowledge from multiple branches of a neural network. The first idea is the Fusion
strategy including Feature-level Fusion and Logits-level Fusion. In our case, the fusion strategy could be a substitute
as long as it is well-performed and does not introduce new parameters. Therefore, comparisons were made between
10
arXiv Template
A PREPRINT
Table 5: Ablation on distillation and fusion.
Interaction Strategy
TCGA-BRCA (Subtyping)
ACC(%)
AUC(%)
F1(%)
DTFDMIL
89.30±0.44
90.08±0.86
83.17±1.43
SlideGCD-DTFDMIL
w LogitsAddFusion
89.57±2.79
90.57±2.45
83.01±5.03
w FeatCatFusion
87.31±0.71
86.80±1.94
79.25±1.71
w FeatAddFusion
88.90±0.88
90.17±0.92
82.12±1.16
w Distillation (KLDiv)
91.89±1.49
93.35±1.31
87.20±2.17
w Distillation (JSDiv)
91.50±0.50
92.83±0.93
86.52±0.78
Table 6: Ablation on different graph convolution operation.
GraphConv Operation
TCGA-BRCA (Subtyping)
ACC(%)
AUC(%)
F1(%)
DTFDMIL
89.30±0.44
90.08±0.86
83.17±1.43
SlideGCD-DTFDMIL
w GCNConv [43]
90.76±0.74
91.27±1.25
84.74±1.13
w GATConv [44]
90.17±0.77
91.57±1.94
83.74±1.90
w GINConv [45]
89.83±2.67
91.03±2.13
84.42±3.75
w HyperGraphConv [38]
91.50±0.50
92.83±0.93
86.52±0.78
five classic strategies in Table 5 including both fusion and distillation: i) LogitsAddFusion: The outputted logits from
both branches are added together for final predictions. ii) FeatCatFusion: The embeddings outputted from the MIL
backbone and the final graph convolutional layer are concatenated and then inputted to a linear layer to generate final
logits for predictions. iii) FeatAddFusion: The same embeddings are sent to a project layer to align channels, and
then added together to input a linear layer to generate final logits for predictions. iv) Distillation (KLDiv): The LJS is
replaced by the KL divergence loss following [42]. v) Distillation (JSDiv): The full version of SlideGCD. As shown in
Table 5, only the LogitsAddFusion strategy slightly improved DTFDMIL with 89.57% ACC and 90.57% AUC among
these three fusion strategies. Yet both common distillation strategies made significant performance rises for DTFDMIL
without bringing extra computations. It demonstrates that the distillation is more suitable on this occasion that the two
branches sensibly concern different aspects of information. Besides, the additional symmetry of JS divergence compared
to KL divergence makes the network more stable and robust, which is reflected in the minor standard deviations at
approximately equal metrics.
4.4.2
Hypergraph Vs. Simple Graph
The difference between a hypergraph with a simple graph is their definition of edge where the hyperedge can connect
more than two nodes. From this perspective, the simple graph can be viewed as a special case of hypergraph. Then
could the SlideGCD pipeline take effect without the hypergraph representation and the hypergraph convolutional layers?
To answer this question, we conducted comparisons that replaced the hypergraph and related layers with the simple
graph and three widely used graph convolution layers. As shown in Table 6, it is gratifying that all modifications of the
SlideGCD work properly and bring visible performance increase to the baseline. In conclusion, we have demonstrated
the improvements brought by SlideGCD are not bound to any specific graph convolution operation but are achieved by
the framework itself.
4.5
Hyper-parameters Verification
In this section, we systematically explore the effect of hyper-parameters in SlideGCD with the backbone of DTFDMIL
on the TCGA-BRCA (Subtyping) task. The results come from the five-fold cross-validation on the validation set. The
impact of the following hyper-parameters will be discussed: 1) the size of node buffer L, 2) the nearest neighbors k, 3)
the distillation temperature t, 4) the loss weight of buffer update β, and 5) the temperature in buffer update τ.
11
arXiv Template
A PREPRINT
Figure 4: Performance curves on the validation dataset in the five-fold cross-validation, where the error bar indicates
the standard deviation of the metrics and the dashed line parallel to the horizontal axis represents the metrics that the
baseline (DTFDMIL) can achieve.
Figure 5: T-SNE visualizations of the overall distribution of the nodes from the node buffer and 20 highlighted
hyperedges for TCGA-BLCA. Each point corresponds to a patient and its color goes deeper as the survival time
increases. The stars in each sub-figure make up the hyperedge.
12
arXiv Template
A PREPRINT
4.5.1
Size of node buffer L
L determines the exact number of nodes in the slide-based graph and greatly affects the capacity of the class-aware
sub-queue. When L is set too large, the node buffer will contain much more outdated slide embeddings that might
defect the performance of the SlideGCD and will introduce more extra computation as well. When it is too small, the
effect of the slide-based graph might be inapparent since there is a lack of sufficient homogeneous information in the
slide-based graph. We tuned L in the range of [1024, 4096] with a step of 512. The curve in Fig. 4(A) shows that the
performance of SlideGCD is indeed altered, but it can still stably surpass the baseline. Eventually, we choose L = 3072
as the optimal value for balancing the accuracy and computational complexity.
4.5.2
Nearest neighbors k
k is another important hyper-parameter that controls the connection density in the slide-based graph and thus influences
the message passing during graph learning. Experimentally, we tuned k ∈[6, 8, 10, 12, 14, 16] for verification. From
Fig. 4(B), it is known that SlideGCD is less sensitive to k than L since the validated AUCs are quite steady and always
at a relatively high level compared with the baseline. We choose k = 12 as the default setting for a better AUC.
4.5.3
Distillation temperature t
This hyper-parameter manages the effect of distillation. In a higher temperature situation (i.e. t > 1), distillation focuses
on transferring knowledge from the teacher model. When getting a lower temperature (i.e. t < 1), distillation tends to
alleviate the impact of noise in negative samples [42]. In our application, our objective is to transfer the well-learned
knowledge in MIL head to the SlideGNN, thus a relatively large temperature coefficient should have a better effect.
Following the results in Fig. 4(C), we set t = 1.5.
4.5.4
Loss weight of buffer update β
β controls the contribution from the buffer update. The balance between each component of the final loss is important
for achieving the best performance. We tested it in the range of [1.0, 2.0] with a step of 0.25 since the buffer update is
not the main supervision signal in our framework. As shown in Fig. 4(D), the model performance is not sensitive to it.
Empirically, we set β = 1.75.
4.5.5
Temperature in buffer update loss τ
τ supervises the effect of contrastive learning. In SlideGCD, the node embeddings continuously shift during training
resulting in many noises and ultimately leading to heterogeneity in the slide-based graph. Under the circumstances, we
wish the buffer update strategy which is based on contrastive learning could alleviate the impact of noise brought by the
over-shifting slide embeddings. The curves in Fig. 4(E) validate the rationality of the motivation since the performances
reach the peak with a lower temperature τ = 0.5.
4.6
Interpretability and Visualization
To intuitively discuss the effect of the slide-based graph learning, we visualize the overall distribution of the node
embeddings within the node buffer (on TCGA-BLCA) via T-SNE where we highlight 20 hyperedges to assess its node
distribution. Following the discretization of survival time in [13], the patients are normally divided into 4 buckets
(bins: 0-3) as the increment of survival time. As shown in Fig. 5, all sub-figures share the same background which
represents the overall distribution of the node embeddings in the buffer where each point indicates a node, and the color
goes deeper as the survival time extends. The pointed stars are from the same hyperedge and the index is above each
subgraph.
From the overall background of Fig. 5, it can be clearly observed that the class-aware node buffer can significantly
separate the nodes from different buckets and the distribution of the node embeddings follows a pattern that the survival
time of nodes gradually extends in a circular arc shape from top right to bottom and then to left. Inspecting each
sub-figure, nodes are more inclined to associate with other nodes in the same bucket (having close survival times). As
the survival time increases (the edge index grows), the center of the hyperedge is shifting along that pattern. The above
observations intuitively validate that the proposed pipeline has achieved the association of homogeneous samples and
also prove the improvement brought by SlideGCD is explainable and traceable.
13
arXiv Template
A PREPRINT
5
Conclusion
In this paper, we present an end-to-end generic pipeline SlideGCD for histopathology whole slide image analysis, which
exploringly takes the unrestricted slide inter-correlations into account via the slide-based graph and proves its consistent
improvements. The rehearsal-based adaptive graph construction strategy we devised, models the WSI dataset into a
slide-based graph where WSIs are nodes and their connections can be updated during training. Besides, knowledge
distillation is applied to train MIL and the graph branch collaboratively and try not to lose the inner-contextual
knowledge learned by HeadMIL as much as possible. Extensive experiments and visualizations are conducted to
demonstrate the effectiveness and robustness in an interpretable way.
Although the proposed SlideGCD achieved promising improvements on various backbones and downstream tasks, some
upgrades still could be made. For example, buffer update strategies based on other principles, such as uncertainty, may
optimize the training and inference overhead. The proposed pipeline can significantly benefit from the development of
the rehearsal buffer. We hope that this work can attract much attention to the exploration of the slide-level interaction
and we believe this will assist in the advancement of foundation models for computational pathology.
References
[1] M. Y. Lu, D. F. Williamson, T. Y. Chen, R. J. Chen, M. Barbieri, and F. Mahmood, “Data-efficient and weakly
supervised computational pathology on whole-slide images,” Nat Biomed Eng., vol. 5, no. 6, pp. 555–570, 2021.
[2] H. Zhang, Y. Meng, Y. Zhao, Y. Qiao, X. Yang, S. E. Coupland, and Y. Zheng, “Dtfd-mil: Double-tier feature
distillation multiple instance learning for histopathology whole slide image classification,” in Proc. IEEE/CVF
Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2022, pp. 18802–18812.
[3] G. Bontempo, F. Bolelli, A. Porrello, S. Calderara, and E. Ficarra, “A graph-based multi-scale approach with
knowledge distillation for wsi classification,” IEEE Trans. Med. Imag., vol. 43, no. 4, pp. 1412-1421, April 2024.
[4] Z. Guo, W. Zhao, S. Wang, and L. Yu, “Higt: Hierarchical interaction graph-transformer for whole slide image
analysis,” in Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent., 2023, pp. 755–764.
[5] J. Shi, L. Tang, Y. Li, X. Zhang, Z. Gao, Y. Zheng, C. Wang, T. Gong, and C. Li, “A structure-aware hierarchical
graph-based multiple instance learning framework for pt staging in histopathological image,” IEEE Trans. Med.
Imag., vol. 42, no. 10, pp. 3000-3011, Oct. 2023.
[6] L. Fan, A. Sowmya, E. Meijering, and Y. Song, “Cancer survival prediction from whole slide images with
self-supervised learning and slide consistency,” IEEE Trans. Med. Imag., vol. 42, no. 5, pp. 1401-1412, May 2023.
[7] W. Hou, C. Lin, L. Yu, J. Qin, R. Yu, and L. Wang, “Hybrid graph convolutional network with online masked
autoencoder for robust multimodal cancer survival prediction,” IEEE Trans. Med. Imag., vol. 42, no. 8, pp.
2462-2473, Aug. 2023.
[8] Y. Zheng, K. Wu, J. Li, K. Tang, J. Shi, H. Wu, Z. Jiang, and W. Wang, “Partial-label contrastive representation
learning for fine-grained biomarkers prediction from histopathology whole slide images,” IEEE J. Biomed. Health
Inform., 2024.
[9] J. Shi, T. Shu, K. Wu, Z. Jiang, L. Zheng, W. Wang, H. Wu, and Y. Zheng, “Masked hypergraph learning for
weakly supervised histopathology whole slide image classification,” Comput Methods Programs Biomed., vol.
253, p. 108237, 2024.
[10] M. Ilse, J. Tomczak, and M. Welling, “Attention-based deep multiple instance learning,” in Int. Conf. Mach. Learn.,
2018, pp. 2127–2136.
[11] P. Liu, L. Ji, X. Zhang, and F. Ye, “Pseudo-bag mixup augmentation for multiple instance learning-based whole
slide image classification,” IEEE Trans. Med. Imag., vol. 43, no. 5, pp. 1841-1852, May 2024.
[12] R. Li, J. Yao, X. Zhu, Y. Li, and J. Huang, “Graph cnn for survival analysis on whole slide pathological images,”
in Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent., 2018, pp. 174–182.
[13] R. J. Chen, M. Y. Lu, M. Shaban, C. Chen, T. Y. Chen, D. F. Williamson, and F. Mahmood, “Whole slide images
are 2d point clouds: Context-aware survival prediction using patch-based graph convolutional networks,” in Proc.
Int. Conf. Med. Image Comput. Comput.-Assist. Intervent., 2021, pp. 339–349.
[14] Y. Guan, J. Zhang, K. Tian, S. Yang, P. Dong, J. Xiang, W. Yang, J. Huang, Y. Zhang, and X. Han, “Node-aligned
graph convolutional network for whole-slide image representation and classification,” in Proc. IEEE/CVF Conf.
Comput. Vis. Pattern Recognit. (CVPR), 2022, pp. 18813–18823.
[15] W. Lu, M. Toss, M. Dawood, E. Rakha, N. Rajpoot, and F. Minhas, “Slidegraph+: Whole slide image level graphs
to predict her2 status in breast cancer,” Med. Image Anal., vol. 80, p. 102486, 2022.
14
arXiv Template
A PREPRINT
[16] Z. Shao, H. Bian, Y. Chen, Y. Wang, J. Zhang, X. Ji, et al., “Transmil: Transformer based correlated multiple
instance learning for whole slide image classification,” Proc. Adv. Neural Inf. Process. Syst., vol. 34, 2021,
pp. 2136–2147.
[17] L. Fillioux, J. Boyd, M. Vakalopoulou, P.-H. Cournède, and S. Christodoulidis, “Structured state space models for
multiple instance learning in digital pathology,” in Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent.,
2023, pp. 594–604.
[18] S. Yang, Y. Wang, and H. Chen, “Mambamil: Enhancing long sequence modeling with sequence reordering in
computational pathology,” 2024, arXiv:2403.06800.
[19] T. H. Chan, F. J. Cendra, L. Ma, G. Yin, and L. Yu, “Histopathology whole slide image analysis with heterogeneous
graph representation learning,” in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), 2023, pp. 15661–
15670.
[20] C. Rivera and B. Venegas, “Histological and molecular aspects of oral squamous cell carcinoma,” Oncol Lett.,
vol. 8, no. 1, pp. 7–11, 2014.
[21] K. Simon, “Colorectal cancer development and advances in screening,” Clin Interv Aging., vol. 11, pp. 967–976,
2016.
[22] Z. Seferbekova, A. Lomakin, L. R. Yates, and M. Gerstung, “Spatial biology of cancer evolution,” Nat Rev Genet.,
vol. 24, no. 5, pp. 295–313, 2023.
[23] Z. Shao, Y. Chen, H. Bian, J. Zhang, G. Liu, and Y. Zhang, “Hvtsurv: Hierarchical vision transformer for patient-
level survival prediction from whole slide image,” in Proc. 37th AAAI Conf. Artif. Intell., 2023, pp. 2209–2217.
[24] D. Reisenbüchler, S. J. Wagner, M. Boxberg, and T. Peng, “Local attention graph-based transformer for multi-
target genetic alteration prediction,” in Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent., 2022,
pp. 377–386.
[25] Y. Zheng, R. H. Gindra, E. J. Green, E. J. Burks, M. Betke, J. E. Beane, and V. B. Kolachalama, “A graph-
transformer for whole slide image classification,” IEEE Trans. Med. Imag., vol. 41, no. 11, pp. 3003-3015, Nov.
2022.
[26] D. Di, J. Zhang, F. Lei, Q. Tian, and Y. Gao, “Big-hypergraph factorization neural network for survival prediction
from whole slide image,” IEEE Trans. Image Process, vol. 31, pp. 1149–1160, 2022.
[27] D. Di, C. Zou, Y. Feng, H. Zhou, R. Ji, Q. Dai, and Y. Gao, “Generating hypergraph-based high-order representa-
tions of whole-slide histopathological images for survival prediction,” IEEE Trans. Pattern Anal. Mach. Intell.,
vol. 45, no. 5, pp. 5800–5815, 2022.
[28] W. Hou, H. Huang, Q. Peng, R. Yu, L. Yu, and L. Wang, “Spatial-hierarchical graph neural network with dynamic
structure learning for histological image classification,” in Proc. Int. Conf. Med. Image Comput. Comput.-Assist.
Intervent., 2022, pp. 181–191.
[29] P. Liu, L. Ji, F. Ye, and B. Fu, “Graphlsurv: A scalable survival prediction network with adaptive and sparse
structure learning for histopathological whole-slide images,” Comput Methods Programs Biomed., vol. 231,
p. 107433, 2023.
[30] J. Li, Y. Chen, H. Chu, Q. Sun, T. Guan, A. Han, and Y. He, “Dynamic graph representation with knowledge-aware
attention for histopathology whole slide image analysis,” 2024, arXiv:2403.07719.
[31] F. Li, M. Wang, B. Huang, X. Duan, Z. Zhang, Z. Ye, and B. Huang, “Patients and slides are equal: A multi-level
multi-instance learning framework for pathological image analysis,” in Proc. Int. Conf. Med. Image Comput.
Comput.-Assist. Intervent., 2023, pp. 63–71.
[32] Z. Huang, F. Bianchi, M. Yuksekgonul, T. J. Montine, and J. Zou, “A visual–language foundation model for
pathology image analysis using medical twitter,” Nat Med., vol. 29, no. 9, pp. 2307–2316, 2023.
[33] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick, “Momentum contrast for unsupervised visual representation
learning,” in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 9729–9738, 2020.
[34] J. Li, Y. Zheng, K. Wu, J. Shi, F. Xie, and Z. Jiang, “Lesion-aware contrastive representation learning for
histopathology whole slide images analysis,” in Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent.,
2022, pp. 273–282.
[35] M. De Lange, R. Aljundi, M. Masana, S. Parisot, X. Jia, A. Leonardis, G. Slabaugh, and T. Tuytelaars, “A
continual learning survey: Defying forgetting in classification tasks,” IEEE Trans. Pattern Anal. Mach. Intell.,
vol. 44, no. 7, pp. 3366–3385, 2021.
15
arXiv Template
A PREPRINT
[36] Y. Huang, W. Zhao, S. Wang, Y. Fu, Y. Jiang, and L. Yu, “Conslide: Asynchronous hierarchical interaction
transformer with breakup-reorganize rehearsal for continual whole slide image analysis,” in Proc. IEEE Int. Conf.
Comput. Vis., 2023, pp. 21349–21360.
[37] A. v. d. Oord, Y. Li, and O. Vinyals, “Representation learning with contrastive predictive coding,” 2018,
arXiv:1807.03748.
[38] S. Bai, F. Zhang, and P. H. Torr, “Hypergraph convolution and hypergraph attention,” Pattern Recognit., vol. 110,
p. 107637, 2021.
[39] M. Caron, H. Touvron, I. Misra, H. Jégou, J. Mairal, P. Bojanowski, A. Joulin, “Emerging Properties in Self-
Supervised Vision Transformers,” in Proc. IEEE Int. Conf. Comput. Vis., 2021, pp. 9650–9660.
[40] C. Kandoth, M. D. McLellan, F. Vandin, K. Ye, B. Niu, C. Lu, et al., “Mutational landscape and significance
across 12 major cancer types,” Nature, vol. 502, no. 7471, pp. 333–339, 2013.
[41] J. L. Katzman, U. Shaham, A. Cloninger, J. Bates, T. Jiang, and Y. Kluger, “Deepsurv: personalized treatment
recommender system using a cox proportional hazards deep neural network,” BMC Med. Res. Methodol., vol. 18,
pp. 1–12, 2018.
[42] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural network,” 2015, arXiv:1503.02531.
[43] T. N. Kipf and M. Welling, “Semi-supervised classification with graph convolutional networks,” 2016,
arXiv:1609.02907.
[44] P. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Lio, Y. Bengio, et al., “Graph attention networks,” Proc.
Int. Conf. Learn. Represent., 2018.
[45] K. Xu, W. Hu, J. Leskovec, and S. Jegelka, “How powerful are graph neural networks?,” 2018, arXiv:1810.00826.
16
