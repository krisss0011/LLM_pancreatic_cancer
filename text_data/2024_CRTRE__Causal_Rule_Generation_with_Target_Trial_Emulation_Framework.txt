CRTRE: Causal Rule Generation with Target Trial
Emulation Framework
Junda Wang*, Weijian Li†, Han Wang‡, Hanjia Lyu†, Caroline P. Thirukumaran†,
Addisu Mesfin†, Hong Yu§, and Jiebo Luo†
*University of Massachusetts Amherst, MA, USA
†University of Rochester, NY, USA
‡Shanghai Maritime University, Shanghai, China
§University of Massachusetts Lowell, MA, USA
jundawang@umass.edu, {weijianatusa, hanakookqwq}@gmail.com, hlyu5@ur.rochester.edu,
{caroline thirukumaran, addisu mesfin}@urmc.rochester.edu, Hong.Yu@umassmed.edu, jluo@cs.rochester.edu
Abstract—Causal inference and model interpretability are
gaining increasing attention, particularly in the biomedical do-
main. Despite recent advance, decorrelating features in nonlinear
environments with human-interpretable representations remains
underexplored. In this study, we introduce a novel method called
causal rule generation with target trial emulation framework
(CRTRE), which applies randomize trial design principles to
estimate the causal effect of association rules. We then incor-
porate such association rules for the downstream applications
such as prediction of disease onsets. Extensive experiments on six
healthcare datasets, including synthetic data, real-world disease
collections, and MIMIC-III/IV, demonstrate the model’s superior
performance. Specifically, our method achieved a β error of
0.907, outperforming DWR (1.024) and SVM (1.141). On real-
world datasets, our model achieved accuracies of 0.789, 0.920, and
0.300 for Esophageal Cancer, Heart Disease, and Cauda Equina
Syndrome prediction task, respectively, consistently surpassing
baseline models. On the ICD code prediction tasks, it achieved
AUC Macro scores of 92.8 on MIMIC-III and 96.7 on MIMIC-
IV, outperforming the state-of-the-art models KEPT and MSMN.
Expert evaluations further validate the model’s effectiveness,
causality, and interpretability.
Index Terms—Causal Inference, Association Rule, Target Trial
Emulation
I. INTRODUCTION
With the rapid growth of Machine Learning (ML) in the
healthcare domain, methods have shown encouraging capa-
bility for solving a broad range of clinical tasks, such as
disease understanding, diagnosis, and treatment planning, by
leveraging a large number of Electric Health Record (EHR)
data. Although these methods bring benefits to both patients
and healthcare professionals [1, 2], increased concerns on
judgment errors [3, 4] as well as deficiency of understanding
the workflow of ML systems [5] have become major road-
blockers for the development and deployment of ML-based
healthcare systems. An important factor underlines the afore-
mentioned challenges is interpretability, i.e., that the black-
box ML models are often associated with a limited capacity
for performance analysis [6]. Therefore, building interpretable
ML models for healthcare becomes an imperative research
direction.
Numerous methods aimed at improving model interpretabil-
ity have recently emerged, focusing on simplifying complex
models to provide clearer insights into their decision-making
processes [7, 8, 9]. However, explanations of black-box models
often cannot be perfectly faithful to the original models and
leave out much information which cannot be made sense
of [10]. In addition, traditional ML models might be influenced
by the data they are trained on, leading to unexpected bias and
overfitting problems when applied to real-world environments.
Recently, methods propose associative inference [11, 12,
13], which has achieved promising results. However, these
methods recognize diseases based on correlations and prob-
ability among patients’ symptoms and medical history, while
doctors prefer to diagnose according to the best causal ex-
planations [14]. To help identify causal explanations, several
methods have been proposed to address the agnostic distri-
bution, including domain generalization which is becoming
one of the most prominent learning paradigms [15]. Another
study examines the distribution shift issue from a causal
perspective, such as causal transfer learning [16] and Structural
Causal Model (SCM) [17] to identify causal variables based
on the conditional independence test. Other researchers focus
on more general methods under the stability guarantee by
variable decorrelation through sample reweighting such as
DWR [12, 18, 18, 19, 20, 21]. They leveraged co-variate
balancing to eliminate the impact of confounding, assessing
the effect of the target feature by reweighting the data so
that the distribution of covariates is equalized across different
target feature values. In spite of their advantageous analyt-
ical qualities, these approaches are usually limited to linear
environments or binary datasets, and rarely employed in high-
dimensional real-world applications due to the complex causal
graph and strict assumptions.
To address the aforementioned challenges, we propose a
novel method, causal rule generation with target trial em-
ulation framework (CRTRE), which is interpretable and
effective in both linear and nonlinear environments for stable
prediction. CRTRE utilizes an association rule mining algo-
rithm to extract rules as model features. To capture interactions
among features, we employ a function F(x) and perform a
Taylor expansion. A key aspect of our method is the use of a
target trial emulation framework [22], to identify independence
arXiv:2411.06338v1  [cs.LG]  10 Nov 2024
among variables in both linear and nonlinear context, which
is essential for learning causal relationships accurately. Unlike
previous methods that primarily eliminated linear relation-
ships, CRTRE addresses nonlinear dependencies, leading to
a more comprehensive understanding of variable interactions
and ensuring stability in predictions. Our results show that
CRTRE not only enhanced interpretability but also improved
the performance of a broad range of clinical applications built
upon both traditional ML and the recent AI models.
Experiments on synthetic datasets demonstrated that our
method significantly improved model parameter estimation
and enhanced prediction stability and effectiveness across
varying distributions in nonlinear environments, thereby prov-
ing its superiority over existing approache [13, 18] We also
show that CRTRE improved prediction of disease onsets.
Specifically, we evaluated CRTRE on three diverse real-
world datasets and demonstrated that our method substantially
outperformed other state-of-the-art models such as SVM. To
evaluate and compare CRTRE with the recent AI methods, we
evaluated our method on the ICD code prediction task. CRTRE
demonstrated superior performance, surpassing other state-of-
the-art deep-learning-based models such as KEPT [23, 24]
and MSMN [25] on both MIMIC-III [26] and MIMIC-IV
datasets [27]. Finally, to evaluate whether CRTRE outputs
better association rules (for causality and interpretability), we
asked three physicians with expertise in Cardiology, ENT, and
Neurosurgery, respectively to rate the identified association
rules. Our results show that physicians provided more favor-
able agreement with the association rules our method identified
than existing methods [19].
The main contributions of our work are as follows:
(1) We expand the stable learning problem from linear envi-
ronment to a nonlinear environment so that stable learning
can be widely applied in the real world. As far as we
know, this is the first work in this direction.
(2) This is the first study where we extend association rule
generation with target trial emulation framework for
causal rule identification.
(3) We demonstrate the superiority of CRTRE on both syn-
thetic and real-world medical datasets for a broad range
of clinical applications.
(4) Our results show that physicians prefer our association
rules for decision making, illustrating the clinical appli-
cability of CRTRE.
II. RELATED WORK
A. Interpretability in Healthcare
Increasing efforts have been devoted to Machine Learning
(ML) interpretability, which is essential for healthcare applica-
tions. Among them, Generalized Additive Models (GAM) [28]
are a set of classic methods with univariate terms providing
straightforward interpretabilities. GA2M-model [29] brings
additional capability for real-world datasets with the selected
interacting pairs based on GAMs. [30] identified association
rules to assist physicians for clinical diagnoses and treatment
plans of their patients.
[31] applied association rules to identify important features
from clinical images. [32] developed methods to incorporate
association rules as features for downstream healthcare ap-
plications. However, most aforementioned methods generated
association rules based on joint probability distribution, which
has limited causal inference.
B. Association Rule Mining
Association rule mining identifies important association
rules for downstream applications such as predictive modeling
[33, 34]. We define symptoms X as X = x1, x2, ..., xn and
disease outcome Y . X ⇒Y indicates that the disease Y
is related to the symptoms X. We deployed three metrics
to evaluate the significance of rules: support(X) = P(X)
is the probability that the set appears in the total item set;
confidence(X ⇒Y ) = support(X ∩Y )/support(X) is a
measure of reliability; lift(X ⇒Y ) = confidence(X ⇒
Y )/support(Y ) reflects the correlation between X and Y
in the association rules [? ]. In each association rule, X
is antecedent and Y is the consequent. A rule that has a
higher support and confidence has a stronger association rule.
We defined a threshold of support and confidence. If the
association rule passes the threshold, then we classify the rule
as strong association rule.
Each association rule has two attributes: causality and as-
sociation. An association may exhibit both high causality and
association, or it may have a high association but low causality.
Identifying the causal significance of an association rule, how-
ever, remains a critical challenge, particularly in contexts like
diagnosis systems where causality is crucial. For example, tra-
ditional algorithms like Apriori [35] and FP-Growth [36] focus
on generating strong association rules based on correlations,
often disregarding causality. These algorithms, though efficient
in identifying frequent patterns or associations, do not address
the need for causal understanding. Furthermore, [37] proposed
enhancements to the Apriori algorithm for greater efficiency,
yet this method still focuses on correlation-based association
rules. In medical diagnosis systems, this leads to inconsis-
tencies between the rules generated by such algorithms and
the causal reasoning doctors rely on. Therefore, developing
methods to extract rules that reflect true causal relationships,
rather than mere associations, remains an important challenge.
C. Causal Inference
One key challenge in healthcare is dealing with both
observed and unobserved confounders across different envi-
ronments [19]. This has led to the growing popularity of
causal inference methods, which are well-suited to addressing
such issues. For instance, causal inference approaches that
utilize network and hierarchical structures enable researchers
to derive causal explanations from data [38]. A completely
constructed causal graph among various features based on
an unconfoundedness assumption that helps to reduce the
influence of confounders [39].
For many machine learning algorithms, ensuring reliable
performance depends on meeting two key assumptions. The
Fig. 1: We first extracted the features from clinical notes in tabular form, filtering out irrelevant attributes to focus on the most pertinent
variables. Using the Apriori algorithm, we then generated association rules from the dataset, identifying significant associations between
medical conditions, symptoms, diseases and treatments. After generating the initial set of rules, we pruned redundant or irrelevant ones
to ensure relevance and quality. Finally, we applied our novel regularizer to score each rule, assessing its clinical relevance and statistical
significance. This combination of the Apriori algorithm and our regularizer produced a concise, meaningful set of association rules, offering
valuable insights for clinical decision-making.
first assumes that the test data is drawn from the same
distribution as the training data, and the second requires the
model to be correctly specified. Nevertheless, in practical
applications, our understanding of the test data and the un-
derlying true model is typically limited. In situations where
model specification is erroneous, the unknown distributional
shift between training and test data results in inaccuracy in
parameter estimation and instability in predictions on unknown
test data. To address these problems, a Differentiated Variable
Decorrelation (DVD) algorithm is proposed to eliminate the
correlations of various variables in different environments by
reweighting datasets [40]. Moreover, [41] prove the effective-
ness of stable learning and demonstrates the necessary of the
stable prediction.
A growing area of interest in machine learning is stable
learning, which focuses on building models that perform
consistently across different environments. Given various en-
vironments e ∈E within datasets De = (Xe, Y e), the goal
is to train a predictive model in one environment, ei, that
achieves uniformly minimal error in a different environment,
ej. This is accomplished by learning the causal relationships
between features Xei and targets Y ei under environment ei.
Researchers propose the Deep Global Balancing Regression
(DGBR) algorithm [20] and Decorrelated Weighting Regres-
sion (DWR) algorithm [18, 19] for stable prediction across
unknown environments. They successively regard each vari-
able as a treatment variable by using a balancing regularizer
with theoretical guarantee.
In Equation 1, W is sample weight, X·,j is the jth variable
in X, and X·,−j = X/{X·,j}. With the global balancing
regularizer in Equation 1, a Global Balancing Regression
algorithm is proposed to optimize global sample weights and
causality for classification task.
min
Pn
i=1 Wi · log (1 + exp ((1 −2Yi) · (Xiβ)))
s.t.
Pp
j=1

xT
−j·(W ⊙X·,j)
W T ·X·,j
−
XT
i−j(W ⊙(1−X·,j))
W T ·(1−X·,j)

2
2
≤λ1
(1)
However, deploying the above algorithms on real-world
datasets pose challenges. Methods like DGBR or DWR are
designed to remove linear confounding by focusing on linear
environments, which limits their effectiveness. In contrast,
our approach not only handles linear relationships but also
effectively eliminates nonlinear confounding, making it more
suitable for complex real-world scenarios.
Target trial emulation has recently gained prominence as a
robust methodology in observational studies, particularly for
emulating randomized controlled trials (RCTs) where direct
experimentation is unfeasible.
[42] have highlighted the
importance of this approach, emphasizing the structured design
of observational analyses to mimic an RCT, thus improving
causal inference. By explicitly specifying the trial protocol,
such as eligibility criteria, treatment strategies, and follow-
up procedures, researchers aim to reduce biases, including
immortal time bias and confounding by indication. In this
study, we incorporate the target trial emulation framework for
identifying causal association rules.
III. METHOD
We propose an interpretable model based on association
rules and causal inference for EHR datasets to obtain the
causality between features through a three-stage process.
(i) Association and Transformation Rules Mining We
initially apply Apriori to generate the association rules.
(ii) Rule Selection Since Apriori generates rules where re-
dundancy is common, we develop rule-selection algo-
rithm to select non-redundant rules.
(iii) Causality
Computation
We
introduce
a
novel
causalscore
to
compute
causality
significance.
Our method attempts to minimize the influence of
confounding variables using the principles of emulation
trial
framework.
Specifically,
we
followed
inverse
probability
of
censoring
weighting
by
employing
statistical techniques such as propensity score matching
or adjustment methods to mitigate the confounding
challenge. By controlling for potential confounders,
causal score reflects a more accurate estimation of the
direct relationship, allowing rules with higher scores to
be prioritized as potential causal rules.
In the following we describe the details of each step.
A. Association and Transformation Rules Mining
Initially, we implement the Apriori algorithm [43] to iden-
tify association rules and construct a rule matrix for both
positive and negative samples. This method counteracts the
asymmetrical distribution of data. Rule representations, de-
noted as < A i, C i|θi >, are subsequently constructed, where
A i represents the antecedent of the rule Ri, C i signifies the
consequent of the rule, and θi indicates the confidence of the
rule. We define a frequency function to compute the confidence
of each rule: {R} = {∪iRi} = {∪ifrequent(Ai ∪Ci)}. Ac-
cording to the rules generated, rule sets ∪i{Xi :< Ai, Ci|θi >
} are built for dataset D where each rule is considered as a
feature. Rule sets are then transformed into a zero-one matrix
X leveraging one-hot encoding.
B. Rule Selection
Massive rules could be generated during the mining process,
causing redundancy or even negative effects. To extract rules
with strong correlations between features, we introduce an
integer programming objective function:
Min
∥W∥2
2 + ∥max(0, 1 −Y h(x)∥2
2
h(x) = (W T X ⊙rep(I(R > 0), n)θ + b)
s.t.
P
i I(Ri > 0) ≤λ1
P
i I(Ri > 0) ≥λ2
{Ri} ∈{0, 1}
(2)
Here, ⊙denotes the Hadamard product, and I(R > 0) is an
indicator function that converts R, a set of rules, into a binary
vector of dimension 1 ∗r. The value of the indicator function
is one when the rule is selected; otherwise, it is zero. The
estimated parameters of the rep(I(R > 0), n), repeat function,
are represented by W, and b symbolizes the estimated bias.
The function is designed to expand the vector I(R1∗r > 0)
into a matrix of dimension n ∗r, where all rows mirror the
first row. λ1 and λ2 represent the boundaries for the number
of selected rules.
As we exclusively consider a binary classification problem
in this context, which is a typical setup for most healthcare
diagnostic issues, we use the inverse of the confidence of
the negative class rule as the score. However, the number
of rules identified by the association rule algorithm, such as
Apriori, can be extensive, leading to an exceptionally high
dimension of R that cannot fit into Equation 2. Consequently,
we remove one redundant rule at a time during each n-fold
cross-validation run, based on a feature ranking criteria w2
i .
Despite the systematic removal of redundant rules, re-
dundant items within rules can still influence the model’s
performance. To address this issue, we initiate an iterative
process to remove one item from each rule at a time, which
results in an updated R with a reduced dimension. We then
rebuild the cross-validation sets and input data into SVM
models to achieve an average accuracy. At every iteration,
the item that enhances the model’s average accuracy most
significantly will be deleted. The code is shown in Appendix A
For comparison, we also built baseline models (i.e., SVM,
Random Forest, Boosting algorithms, Logistic Regression,
Neural Network(MLP), and DWR), using the traditional fea-
ture selection method Backward-SFS [44]. Our results show
that our method outperformed all aforementioned baseline
models II.
C. Causality Computation
We follow the principle of the target trial emulation frame-
work. Specifically, we implement based on the assumption of
DWR model, where the principal objective lies in the decor-
relation of variables to discern causality. To adeptly manage
the nonlinear relationships pervasive in real-world scenarios,
we model these relationships utilizing Taylor expansion, rep-
resented by a function F(x) as depicted in Equation 3. The
derivatives of each fixed point can be interpreted as parameters
to be resolved by transforming them into a polynomial fitting
problem. This transformation is validated by the condition
stipulating the equality of two polynomials solely when their
degree and coefficients align.
xp1 ∼
F(xj) = fp1p2(xp2(0)) + f ′
p1p2(xp2(0))xp2+
f ′′
p1p2(xp2(0))
2!
x2
p2 + . . . +
f (p)
p1p2(xp2(0))
p!
xp
p2 + Rp(xp2)
(3)
where xp1(0) and xp2(0) are two different features which
are expanded at 0 by using Taylor expansion. The elimi-
nation of the impact of intersecting areas is achieved by
balancing the weight W as is represented in Equation 4.
If xp1 and xp2 are independent and nonlinearly uncorre-
lated, the derivatives of their relation functions are all 0:
∥{Fp2→p1} / {fp1p2(xp2(0))}∥= 0 where Fp2→p1 are the
relationship function between xp1(0) and xp2(0) can be cal-
culated using Equation 5
minFp2→p1 Rp(x)2 ≡P
p1̸=p2
Pn
i=1 [wixip2 −F (wixip1)]2
⇒Xp2 (wixp2) Fp2→p1 = Yp1
(4)
Xp2 =


n
Pn
i=1 wixip2
· · ·
Pn
i=1 wk
i xk
ip2
Pn
i=1 wixip2
Pn
i=1 w2
i x2
ip2
· · ·
Pn
i=1 wk+1
i
xk+1
ip2
...
...
...
...
Pn
i=1 wk
i xk
ip2
Pn
i=1 wk+1
i
xk+1
ip2
· · ·
Pn
i=1 w2k
i x2k
ip2


Fp2→p1 =


fp1p2(xp2(0))
f ′
p1p2(xp2(0))
...
f (p)
p1p2(xp2(0))

, Yp1 =


Pn
i=1 yi
Pn
j=1 xiyi
...
Pn
i=1 xk
i yi


Fp2→p1 =
 X T
p2Xp2
−1 X T
p2Yp1
(5)
where wi is the weight for each sample and n is the number
of datasets. Combined with Figure 1, physical meaning can be
given to the above variables: r(w) is the regularizer term; C
is the factor to expand the influence of the intersection area to
get the real causality comparing with W applied to eliminate
the influence of the public area:
Min
Pn
i=1(Wi + C)((−yi log (ˆp (Xi)) −(1 −yi) log (1 −ˆp (Xi))))
ˆp (Xi) = expit (Xiw + w0) =
1
1+exp(−Xiw−w0) , r(w) ≤λ3
∥F (i)
p2→p1,i>0∥2
2 ≤γ, ∥W ∥2
2 ≤λ1,
 Pn
k=1 Wk −1
2 ≤λ2
(6)
When we have a smaller γ value, the difference between β and
the true correlation coefficient (disjoint region and the target)
will become smaller, resulting greater mutual information loss.
Lemma 1. If the number of features in the datasets and the
terms in the Taylor expansion are fixed, when n →∞there
exists W ⪰0(the proof is shown in appendix) such that
lim
n→∞∥F (i)
p2→p1,i>0∥2
2
CRTRE is versatile and can be effectively integrated into
various ML models and applications, including integrating
Chain of Thought prompt with longformer [45] for the ICD
code prediction task. The ICD prediction task involves pre-
dicting ICD codes from clinical notes.
To achieve this, we first preprocess the clinical notes using
MedSpaCy [46], a specialized NLP toolkit tailored for clinical
text. MedSpaCy is employed to extract all Concept Unique
Identifier (CUI) codes from the clinical notes. Each extracted
CUI code serves as a feature, while the corresponding ICD
code is treated as a label. This allows us to construct associ-
ation rules between CUIs and ICD codes.
Next, we apply our regularization strategy and loss function
to filter the association rules, specifically targeting those with
strong causal relationships. The regularizer is designed to
promote independence among variables in a nonlinear context,
ensuring that only the most relevant and causally significant
rules are retained. This filtering process is vital for enhancing
the model’s ability to learn meaningful and generalizable
patterns from the data.
After identifying the causal rules, we match the CUIs
extracted from the clinical notes to determine which rules
are satisfied. These matched rules are then used to create
prompts in a cloze-style format. We combine these prompts
with ICD code descriptions and the original clinical notes to
form a comprehensive input for the KEPTLongformer model,
facilitating an effective reranking process. Specifically, we
formulate the multi-label classification task as follows:
xp = c1, r1 : [MASK], c2, r2 : [MASK], . . . , cn, rn : [MASK]
where ri represents the satisfied rule set of ICD code
candidates generated from previous models and ci represents
the description of each ICD. The [MASK] tokens serve as
placeholders, which the model fills with specific tokens (”yes”
or ”no”) to decide whether a code should be assigned to a
clinical note based on the context provided.
To refine the predicted ICD code candidates generated by
different models, we employ a cloze-style prompt approach
rather than a generative prompt design typically used for
few-shot learning. This reranking approach, inspired by code
reranking techniques [24], uses the KEPTLongformer model
to evaluate each candidate code’s likelihood of being correct
(positive or negative) for the given clinical note. By filling the
[MASK] tokens with the appropriate vocabulary, KEPTLong-
former determines if the code is appropriate for assignment.
IV. EXPERIMENT
A. Validation on Synthetic Dataset
To examine the proposed constraints’ effect on eliminat-
ing linear and nonlinear connotation relationships, we follow
previous work [18] to conduct evaluations on synthetically
generated datasets. Notice that a different objective function 7
is built for regression task, where Wi is the sample weight and
the variable ζ is slack variable. In this experiment, we only
expand two terms by the Taylor expansion.
minw,b,ζ,ζ∗1
2wT w + Pn
i=1(C + Wi) (ζi + ζ∗
i )
subject to yi −wT ϕ (xi) −b ≤ε + ζi
wT ϕ (xi) + b −yi ≤ε + ζ∗
i
ζi, ζ∗
i ≥0, i = 1, . . . , n
∥F (i)
p2→p1,i>0∥2
2 ≤γ
∥W∥2
2 ≤λ1, (Pn
k=1 Wk −1)2 ≤λ2
(7)
To test the stability of the algorithms, we generate a set
of environment e with a distinct distribution PXY . Following
Kuang’s experiment [18]. In addition to the linear settings,
we propose to include nonlinear evaluations under a nonlinear
environment as shown in Appendix E and the baselines are
shown in Appendix C
Generating Various Environments To test the stability of
the algorithms, we generate a set of environment e with a
distinct distribution distribution PXY . Following the Kuang’s
experiment [18], we generate different environments based
on various P(S|V ). To simplify the problem, we simulate
P(Sb|V on a subset Sb ∈S, where the dimension of Sb is 0.2∗
p. We applied the bias rate equation Pr = Q
Si∈Sb |r|−5∗Di
to tune the P(Sb|V , where Di = |f(S) −sign(r) ∗Vi| , r ∈
[−3, −1) ∪(1, 3]. r > 1 indicates that Y and Sb have positive
unstable relationships, while r < −1 corresponds to the
negative unstable relationships. The higher absolute value of r
the stronger connection between Sb and Y , leading to generate
different environments. The result is shown in Figure 3.
B. Causal Experiment Results and Explanation
To compare our regularizers with DWR, we apply Pear-
son Correlation to calculate the relationship strength among
features. Since Pearson Correlation can only describe linear
relationship, we construct nonlinear pairs WVi with (WV)2
j ,
(WV)3
j and exp(WVj) in addition to WVi with WVj. The
result can be found in Figure 3. Both DWR and the proposed
regularizer can handle pure linear relationships (experimental
environment(A)) but improvements are achieved from the
proposed regularizer. As we add nonlinear relationships to the
Fig. 2: Figures describe the βS, βV and RMSE with various environments.
Raw
DWR
Ours
0.00
0.04
0.08
0.12
0.16
a.Linear Relationship
Raw
DWR
Ours
0.00
0.04
0.08
0.12
0.16
b.Linear Relationship(non-linear)
Raw
DWR
Ours
0.00
0.05
0.10
0.15
0.20
c.Square Relationship
Raw
DWR
Ours
0.000
0.036
0.072
0.108
0.144
d.Cubic Relationship
Raw
DWR
Ours
0.000
0.024
0.048
0.072
0.096
e.Exponential Relationship
Ridge
Lasso
OLS
DWR
SVM DWR_SVM Ours
0.780
1.184
1.588
1.992
2.396
f.Beta Error
Fig. 3: Figures (a)-(d) describe the distribution of the Pearson Coefficient values among various relationships. Figure (a) reports the β errors
of different models. Figure (f) is under a linear environment and other figures are under nonlinear environments. Our model is able to provide
the greatest reduction of both linear and nonlinear relationships.
linear experimental environment, DWR start to have difficulty
with the linear relationship part while the proposed method is
still able to reduce a large amount of the relationships. For non-
linear environments, compared with the original unweighted
dataset, DWR unexpectedly increases nonlinear relationships
where there are no existing nonlinear relationships (square,
cubic and exponential). Instead, our model does not incur
nonlinear relationships but instead reduce them. To further
validate its effectiveness on various sample sizes and the
number of features, we calcualte the βS and betaV errors:
error(β) = P
i |βtrue −β| , based on 9 kinds of datasets as
shown in the figure I.
To further confirm that the coefficients estimated by our
model are based on causality, we repeat experiments 50 times
to calculate P ∥β −ˆβ∥, where β and ˆβ represent the true
value and estimated parameters, respectively. In Figure 3,
we find that the difference between the estimated parameters
and the true values is smaller with our model, compared to
other models in the nonlinear environment. Notice that our
model achieves much smaller distribution variance as well
as much smaller average values of β errors comparing to
baselines. Although the regularizer of DWR can solve the
stable problem in linear environments, it retains or expands
nonlinear confounding in the nonlinear environments. From
the above results, we find that our model is able to reduce
correlations among all predictors and avoid being affected by
nonlinear confounding, resulting a reduced estimation bias in
more general environments.
C. Validation on Three Real-World Datasets
To further validate the effectiveness of our model in real-
world scenarios, we perform experiments on three different
EHR datasets in appendix D. All data are carefully pre-
possessed to ensure no sensitive information is exposed. To
further prove that our model can calculate causality rather
than probability, we design a counterfactual experiment to
test by calculating the accuracy, f1 score, precision and recall.
We choose the ten least supported negative-sample-associated
TABLE I: Results under varying sample size n and number of variables within nonlinear environments.
Method
n=1000, m=5
n=1000, m=10
n=1000, m=15
βS Error
βV Error
β Error
βS Error
βV Error
β Error
βS Error
βV Error
β Error
OLS
3.357
0.430
1.894
3.605
0.729
2.167
3.823
0.866
2.345
Lasso
3.390
0.326
1.858
3.586
0.647
2.117
3.940
0.390
2.165
Ridge
3.357
0.430
1.893
3.604
0.729
2.166
3.822
0.866
2.344
SVM
2.067
0.240
1.153
2.273
0.375
1.324
2.366
0.410
1.388
DWR
2.279
0.249
1.264
2.566
0.658
1.612
3.258
1.182
2.220
DWR SVM
1.799
0.303
1.051
2.077
0.483
1.280
2.494
0.918
1.706
OUR
1.555
0.199
0.877
1.898
0.373
1.135
2.265
0.382
1.323
n=2000, m=5
n=2000, m=10
n=2000, m=15
βS Error
βV Error
β Error
βS Error
βV Error
β Error
βS Error
βV Error
β Error
OLS
3.253
0.444
1.849
3.521
0.630
2.075
4.071
0.561
2.316
Lasso
3.278
0.250
1.764
3.490
0.473
1.982
4.260
0.168
2.214
Ridge
3.253
0.444
1.848
3.520
0.630
2.075
4.071
0.561
2.316
DWR
2.147
0.231
1.189
2.244
0.493
1.369
2.749
0.974
1.861
SVM
2.020
0.271
1.145
2.158
0.315
1.237
2.453
0.349
1.401
DWR SVM
1.675
0.305
0.990
1.861
0.407
1.134
2.317
0.572
1.445
OUR
1.544
0.214
0.879
1.719
0.292
1.006
2.125
0.323
1.224
n=3000, m=5
n=3000, m=10
n=3000, m=15
βS Error
βV Error
β Error
βS Error
βV Error
β Error
βS Error
βV Error
β Error
OLS
3.297
0.335
1.816
3.593
0.579
2.086
3.736
0.611
2.173
Lasso
3.279
0.074
1.677
3.803
0.179
1.991
3.703
0.527
2.115
Ridge
3.297
0.335
1.816
3.593
0.579
2.086
3.735
0.611
2.173
DWR
2.178
0.150
1.164
1.970
0.415
1.192
2.610
0.547
1.578
SVM
2.066
0.217
1.141
2.046
0.338
1.192
2.261
0.329
1.295
DWR SVM
1.764
0.284
1.024
1.833
0.312
1.072
2.082
0.484
1.283
OUR
1.748
0.065
0.907
1.618
0.171
0.894
2.007
0.325
1.166
rules and select the the rule with the lowest absolute weight
which is calculated by SVM classifier under normal training.
We construct the spurious correlation between the rule and
labels. For example, we set the chosen rule as ri, and we pull
all the samples in the training set that satisfy {ri = 1, y = 1}
in the test set, and put all the samples in the test set that
satisfy {ri = 0, y = 0} in the training set. This process will
increase the value of the joint probability P(ri = 1, y = 1)
and P(ri = 0, y = 0), which is contrary to the truth:
ri = 1 ⇒y = 0. For each dataset, we tune the parameters so
that all models perform as well as possible.
Based on diagnostic and procedure codes, patients with CES
who underwent surgery between 2000 and 2015 were selected.
Patient demographics (age, gender, race, comorbidities, and
insurance status) and hospital characteristics (measured by
hospital bed number quartiles).
Pre-Processing: We convert the continuous variables into cat-
egorical variables before feeding them to the model. To handle
missing data in the datasets, we adopted MICE (Multiple
imputations by chained equations) by transforming imputation
problems into estimation problems where each variable will be
regressed on the other variables. This method provides promis-
ing flexibility since every variable can be assigned a suitable
distribution [47]. Then we apply the SMOTE algorithm [48]
to address the class imbalance issue in our datasets.
Feature Selection: Redundant information in EHR datasets
may cause noise and irrelevant information during feature
extraction. A feature selection method [49] is adopted. To
improve the robustness of the model, we divide the dataset
randomly into five groups for cross-validation. Each time we
extract one group as the test set to analyze and measure the
average performance in the feature selection process. Due to
the high complexity of our model, we apply and compare the
four baseline models: XGboost, SVM, Logistic Regression,
and Random Forest to extract important features in feature
selection and input the set of the features with the highest
average AUROC scores into our model. In the end, we extract
13, 47, and 45 features for Heart Disease, Esophageal Cancer,
and Cauda Equina Syndrome, respectively.
1) Results: To measure the performance of models, we
compute accuracy, precision, recall and F1 scores. The results
are shown in Figure 2, and Table II. In addition to measuring
the performance of the traditional models, we consider the
filtered rules as zero-one matrix X into the baselines rather
than the original datasets. In another counterfactual experiment
as shown in Table II, we increase the spurious probability
and construct the relationship which is contrary to the truth.
We found that most of the baselines calculate parameters
based on probability which results in worse performance,
while our model is much higher than the other models. In
addition, we extracted the weights of different rules learned
from various models. We also asked doctors to evaluate these
rules, as detailed in Appendix F. We then calculated the
alignment between the model-learned weights and the doctors’
scores. To measure the similarity between them, we used
Spearman Coefficients. Ultimately, we found that our model
demonstrated a higher degree of similarity compared to other
models, indicating that our model is better at learning the true
causality across different environments.
D. Validation on the ICD Coding Task
In real-world experimental settings, we evaluated our model
on both the MIMIC-III and MIMIC-IV datasets, achieving
state-of-the-art results as shown in Table III in comparison
with three other NLP methods for the ICD coding task (i.e.,
TABLE II: Prediction performances over various healthcare datasets on the counterfactual experiment.
Non Rule-based
Rule-based
XGBoost
RF
SVM
LR
MLP
XGBoost
RF
SVM
LR
MLP
DWR
Ours
Heart Disease
Accuracy
0.903
0.887
0.885
0.869
0.947
0.869
0.868
0.960
0.934
0.878
0.937
0.960
F1
0.880
0.863
0.899
0.882
0.952
0.882
0.879
0.963
0.940
0.892
0.943
0.964
Precision
0.880
0.846
0.886
0.882
0.941
0.857
0.864
0.972
0.939
0.850
0.931
0.966
Recall
0.880
0.880
0.912
0.882
0.963
0.909
0.897
0.956
0.945
0.940
0.958
0.964
Causality
-
-
-
-
-
0.398
0.274
0.455
0.458
0.402
0.320
0.528
Esophageal Cancer
Accuracy
0.788
0.750
0.827
0.808
0.750
0.738
0.727
0.900
0.812
0.846
0.854
0.900
F1
0.776
0.683
0.809
0.800
0.735
0.708
0.697
0.888
0.783
0.824
0.825
0.885
Precision
0.704
0.737
0.827
0.808
0.720
0.723
0.692
0.867
0.804
0.843
0.842
0.874
Recall
0.864
0.636
0.792
0.833
0.750
0.699
0.713
0.913
0.771
0.812
0.811
0.900
Causality
-
-
-
-
-
0.130
0.236
0.281
0.327
0.160
0.314
0.339
Cauda Equina Syndrome
Accuracy
0.788
0.75
0.827
0.808
0.750
0.883
0.779
0.887
0.886
0.891
0.891
0.893
F1
0.776
0.683
0.809
0.800
0.735
0.880
0.780
0.883
0.882
0.888
0.887
0.888
Precision
0.704
0.737
0.827
0.808
0.720
0.818
0.706
0.825
0.822
0.831
0.831
0.834
Recall
0.864
0.636
0.792
0.833
0.750
0.951
0.874
0.950
0.952
0.953
0.953
0.951
Causality
-
-
-
-
-
0.231
0.298
0.279
0.132
0.262
0.308
0.477
TABLE III: Results on MIMIC-III-ICD9-50 datasets and MIMIC-IV-
ICD9-50 datasets.
Model
MIMIC-III-ICD9-50
MIMIC-IV-ICD9-50
AUC
F1
AUC
F1
Macro
Micro
Macro
Micro
Macro
Micro
Macro
Micro
Joint LAAT
92.36
94.24
66.95
70.84
94.92
96.31
69.93
74.33
MSMN
92.50
94.39
67.64
71.78
95.13
96.46
71.85
75.78
KEPT
92.63
94.76
68.91
72.85
95.20
96.65
71.7
76.02
CRTRE
92.8
99.53
69.35
73.17
95.39
96.70
72.21
76.34
automatically assigning ICD codes based on the corresponding
EHR note):
• Joint LAAT
Joint LAAT [50] introduces a hierarchical
joint learning approach, designed to predict both ICD
codes and their parent codes. By leveraging the ICD code
hierarchy, the model improves accuracy in medical code
prediction.
• MSMN
MSMN utilizes synonyms with an adapted
multi-head attention mechanism to achieve SOTA results
on the MIMIC-III-50 task. This model captures richer se-
mantic relationships, improving performance in medical
code prediction.
• KEPT
KEPT tackles the ICD coding challenge with
a prompt-based fine-tuning approach, addressing the
long-tail distribution problem. By injecting domain-
specific knowledge (hierarchy, synonym, and abbrevi-
ation), KEPT significantly improves performance on
MIMIC-III datasets.
For the MIMIC-III-ICD9-50 dataset, our model achieved
an AUC Macro of 92.8, outperforming Joint LAAT (92.36),
MSMN (92.50), and KEPT (92.63). In terms of AUC Micro,
our model achieved 99.53, compared to 94.24 for Joint LAAT,
94.39 for MSMN, and 94.76 for KEPT. Similarly, for F1
Macro, our model’s achieved the best 69.35, outperforming
Joint LAAT, MSMN, and KEPT ( 66.95, 67.64, and 68.91,
respectively). On the MIMIC-IV-ICD9-50 dataset, our model
demonstrated superior performance, achieving an AUC Macro
of 95.39, compared to 94.92 for Joint LAAT, 95.13 for MSMN,
and 94.97 for KEPT. Our model also achieved an AUC Micro
of 96.70, surpassing Joint LAAT (96.31), MSMN (96.46), and
KEPT (96.41). For F1 Macro, our model scored 72.21, out-
performing Joint LAAT (69.93), MSMN (71.85), and KEPT
(71.35). These results confirm the superior performance and
generalizability of our model across different datasets and
tasks, demonstrating the importance of causal rules.
V. CONCLUSION
In this paper, we present an interpretable causal inference
approach focusing on nonlinear environments for healthcare
applications. The proposed method extracts underlying asso-
ciation rules from the raw features as representations. A novel
regularizer is constructed to handle both linear and nonlinear
confoundings in real-world applications. The superior perfor-
mances on four datasets (one synthetic and three real-world
EHR datasets) from different domains compared to baseline
methods validate both the effectiveness and generalizability of
the proposed method. Consistent ratings between healthcare
professionals and our method on the extracted rules on real-
world datasets further validate the model’s interpretability.
Future works include exploring the applicability of adopting
current framework into other Machine Learning applications.
For example, we would like to extend the proposed causal
rules extraction method as a general approach to provide nature
language processing models the ability to analyze the causal
relationship and enhance the model interpretability.
REFERENCES
[1] S. C. Herpertz, S. K. Huprich, M. Bohus, A. Chanen,
M. Goodman, L. Mehlum, P. Moran, G. Newton-Howes,
L. Scott, and C. Sharp, “The challenge of transforming
the diagnostic system of personality disorders,” Journal
of personality disorders, vol. 31, no. 5, pp. 577–589,
2017.
[2] W. Li, W. Zhu, E. R. Dorsey, and J. Luo, “Predicting
parkinson’s disease with multimodal irregularly collected
longitudinal smartphone data,” in 2020 IEEE Interna-
tional Conference on Data Mining (ICDM). IEEE, 2020,
pp. 1106–1111.
[3] C. S. Royce, M. M. Hayes, and R. M. Schwartzstein,
“Teaching critical thinking: a case for instruction in
cognitive biases to reduce diagnostic errors and improve
patient safety,” Academic Medicine, vol. 94, no. 2, pp.
187–194, 2019.
[4] T. K. Gandhi, A. Kachalia, E. J. Thomas, A. L. Puopolo,
C. Yoon, T. A. Brennan, and D. M. Studdert, “Missed and
delayed diagnoses in the ambulatory setting: a study of
closed malpractice claims,” Annals of internal medicine,
vol. 145, no. 7, pp. 488–496, 2006.
[5] P.
Croskerry,
“From
mindless
to
mindful
prac-
tice—cognitive bias and clinical decision making,” N
Engl J Med, vol. 368, no. 26, pp. 2445–2448, 2013.
[6] M. A. Ahmad, C. Eckert, and A. Teredesai, “Interpretable
machine learning in healthcare,” in Proceedings of the
2018 ACM international conference on bioinformatics,
computational biology, and health informatics, 2018, pp.
559–560.
[7] M. Du, N. Liu, and X. Hu, “Techniques for interpretable
machine learning,” Communications of the ACM, vol. 63,
no. 1, pp. 68–77, 2019.
[8] M. R. Zafar and N. M. Khan, “Dlime: A deterministic
local interpretable model-agnostic explanations approach
for computer-aided diagnosis systems,” arXiv preprint
arXiv:1906.10263, 2019.
[9] M. T. Ribeiro, S. Singh, and C. Guestrin, “Model-
agnostic interpretability of machine learning,” arXiv
preprint arXiv:1606.05386, 2016.
[10] C. Rudin, “Stop explaining black box machine learning
models for high stakes decisions and use interpretable
models instead,” Nature Machine Intelligence, vol. 1,
no. 5, pp. 206–215, 2019.
[11] H. Yu, J. Liu, X. Zhang, J. Wu, and P. Cui, “A survey
on evaluation of out-of-distribution generalization,” arXiv
preprint arXiv:2403.01874, 2024.
[12] X. Zhang, P. Cui, R. Xu, L. Zhou, Y. He, and Z. Shen,
“Deep stable learning for out-of-distribution generaliza-
tion,” in Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, 2021, pp.
5372–5382.
[13] K. Kuang, L. Li, Z. Geng, L. Xu, K. Zhang, B. Liao,
H. Huang, P. Ding, W. Miao, and Z. Jiang, “Causal
inference,” Engineering, vol. 6, no. 3, pp. 253–263, 2020.
[14] G. W. Imbens and D. B. Rubin, Causal inference in
statistics, social, and biomedical sciences.
Cambridge
University Press, 2015.
[15] K. Muandet, D. Balduzzi, and B. Sch¨olkopf, “Domain
generalization via invariant feature representation,” in
International Conference on Machine Learning. PMLR,
2013, pp. 10–18.
[16] M. Rojas-Carulla, B. Sch¨olkopf, R. Turner, and J. Pe-
ters, “Invariant models for causal transfer learning,” The
Journal of Machine Learning Research, vol. 19, no. 1,
pp. 1309–1342, 2018.
[17] J. Pearl, “Causal inference in statistics: An overview,”
Statistics surveys, vol. 3, pp. 96–146, 2009.
[18] K. Kuang, R. Xiong, P. Cui, S. Athey, and B. Li, “Stable
prediction with model misspecification and agnostic dis-
tribution shift,” in Proceedings of the AAAI Conference
on Artificial Intelligence, vol. 34, 2020, pp. 4485–4492.
[19] P. Cui and S. Athey, “Stable learning establishes some
common ground between causal inference and machine
learning,” Nature Machine Intelligence, vol. 4, no. 2, pp.
110–115, 2022.
[20] K. Kuang, P. Cui, S. Athey, R. Xiong, and B. Li,
“Stable prediction across unknown environments,” in
Proceedings of the 24th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining,
2018, pp. 1617–1626.
[21] K. Kuang, H. Zhang, R. Wu, F. Wu, Y. Zhuang, and
A. Zhang, “Balance-subsampled stable prediction across
unknown test data,” ACM Transactions on Knowledge
Discovery from Data (TKDD), vol. 16, no. 3, pp. 1–21,
2021.
[22] M. A. Hern´an, W. Wang, and D. E. Leaf, “Target
trial emulation: a framework for causal inference from
observational data,” Jama, vol. 328, no. 24, pp. 2446–
2447, 2022.
[23] Z. Yang, S. Kwon, Z. Yao, and H. Yu, “Multi-label
few-shot icd coding as autoregressive generation with
prompt,” in Proceedings of the AAAI Conference on
Artificial Intelligence, vol. 37, no. 4, 2023, pp. 5366–
5374.
[24] Z. Yang, S. Wang, B. P. S. Rawat, A. Mitra, and
H. Yu, “Knowledge injected prompt based fine-tuning
for multi-label few-shot icd coding,” in Proceedings of
the conference on empirical methods in natural language
processing. Conference on empirical methods in natural
language processing, vol. 2022.
NIH Public Access,
2022, p. 1767.
[25] Z. Yuan, C. Tan, and S. Huang, “Code synonyms do mat-
ter: Multiple synonyms matching network for automatic
icd coding,” arXiv preprint arXiv:2203.01515, 2022.
[26] S. Wang, M. B. McDermott, G. Chauhan, M. Ghassemi,
M. C. Hughes, and T. Naumann, “Mimic-extract: A data
extraction, preprocessing, and representation pipeline for
mimic-iii,” in Proceedings of the ACM conference on
health, inference, and learning, 2020, pp. 222–235.
[27] A. E. Johnson, L. Bulgarelli, L. Shen, A. Gayles,
A. Shammout, S. Horng, T. J. Pollard, S. Hao, B. Moody,
B. Gow et al., “Mimic-iv, a freely accessible electronic
health record dataset,” Scientific data, vol. 10, no. 1, p. 1,
2023.
[28] T. J. Hastie and R. J. Tibshirani, Generalized additive
models.
Routledge, 2017.
[29] Y. Lou, R. Caruana, J. Gehrke, and G. Hooker, “Accu-
rate intelligible models with pairwise interactions,” in
Proceedings of the 19th ACM SIGKDD international
conference on Knowledge discovery and data mining,
2013, pp. 623–631.
[30] S. J. Lee and K. Siau, “A review of data mining tech-
niques,” Industrial Management & Data Systems, 2001.
[31] I. Ahmed, G. Jeon, and F. Piccialli, “A deep-learning-
based smart healthcare system for patient’s discomfort
detection at the edge of internet of things,” IEEE Internet
of Things Journal, vol. 8, no. 13, pp. 10 318–10 326,
2021.
[32] M. Sornalakshmi, S. Balamurali, M. Venkatesulu, M. N.
Krishnan, L. K. Ramasamy, S. Kadry, and S. Lim, “An
efficient apriori algorithm for frequent pattern mining us-
ing mapreduce in healthcare data,” Bulletin of Electrical
Engineering and Informatics, vol. 10, no. 1, pp. 390–403,
2021.
[33] ˙I. Perc¸ın, F. H. Ya˘gin, E. G¨uldo˘gan, and S. Yolo˘glu,
“Arm: An interactive web software for association rules
mining and an application in medicine,” in 2019 In-
ternational Artificial Intelligence and Data Processing
Symposium (IDAP).
IEEE, 2019, pp. 1–5.
[34] C. Ordonez, N. Ezquerra, and C. A. Santana, “Constrain-
ing and summarizing association rules in medical data,”
Knowledge and information systems, vol. 9, no. 3, pp.
1–2, 2006.
[35] C. Borgelt and R. Kruse, “Induction of association rules:
Apriori implementation,” in Compstat.
Springer, 2002,
pp. 395–400.
[36] J. Han, J. Pei, and Y. Yin, “Mining frequent patterns with-
out candidate generation,” ACM sigmod record, vol. 29,
no. 2, pp. 1–12, 2000.
[37] X. Yuan, “An improved apriori algorithm for mining
association rules,” in AIP conference proceedings, vol.
1820.
AIP Publishing LLC, 2017, p. 080005.
[38] J. Pearl, “Theoretical impediments to machine learning
with seven sparks from the causal revolution,” arXiv
preprint arXiv:1801.04016, 2018.
[39] J. Ma, Y. Dong, Z. Huang, D. Mietchen, and J. Li,
“Assessing the causal impact of covid-19 related policies
on outbreak dynamics: A case study in the us,” arXiv
preprint arXiv:2106.01315, 2021.
[40] Z. Shen, P. Cui, J. Liu, T. Zhang, B. Li, and Z. Chen,
“Stable learning via differentiated variable decorrela-
tion,” in Proceedings of the 26th ACM SIGKDD Inter-
national Conference on Knowledge Discovery & Data
Mining, 2020, pp. 2185–2193.
[41] R. Xu, P. Cui, Z. Shen, X. Zhang, and T. Zhang,
“Why stable learning works? a theory of covariate shift
generalization,” arXiv preprint arXiv:2111.02355, 2021.
[42] M. A. Hern´an and J. M. Robins, “Using big data to
emulate a target trial when a randomized trial is not
available,” American journal of epidemiology, vol. 183,
no. 8, pp. 758–764, 2016.
[43] R. Agrawal, R. Srikant et al., “Fast algorithms for mining
association rules,” in Proc. 20th int. conf. very large data
bases, VLDB, vol. 1215.
Citeseer, 1994, pp. 487–499.
[44] F. J. Ferri, P. Pudil, M. Hatef, and J. Kittler, “Comparative
study of techniques for large-scale feature selection,” in
Machine intelligence and pattern recognition.
Elsevier,
1994, vol. 16, pp. 403–413.
[45] I. Beltagy, M. E. Peters, and A. Cohan, “Long-
former: The long-document transformer,” arXiv preprint
arXiv:2004.05150, 2020.
[46] H. Eyre, A. B. Chapman, K. S. Peterson, J. Shi, P. R.
Alba, M. M. Jones, T. L. Box, S. L. DuVall, and
O. V. Patterson, “Launching into clinical space with
medspaCy: a new clinical text processing toolkit in
Python,” AMIA Annu Symp Proc, vol. 2021, pp. 438–
447, 2021.
[47] J. N. Wulff and L. E. Jeppesen, “Multiple imputation by
chained equations in praxis: guidelines and review,” Elec-
tronic Journal of Business Research Methods, vol. 15,
no. 1, pp. 41–56, 2017.
[48] A. Fern´andez, S. Garcia, F. Herrera, and N. V. Chawla,
“Smote for learning from imbalanced data: progress and
challenges, marking the 15-year anniversary,” Journal
of artificial intelligence research, vol. 61, pp. 863–905,
2018.
[49] X.-w. Chen and J. C. Jeong, “Enhanced recursive feature
elimination,” in Sixth international conference on ma-
chine learning and applications (ICMLA 2007).
IEEE,
2007, pp. 429–435.
[50] T. Vu, D. Q. Nguyen, and A. Nguyen, “A label attention
model for icd coding from clinical text,” arXiv preprint
arXiv:2007.06351, 2020.
[51] M. Pal, “Random forest classifier for remote sensing
classification,” International journal of remote sensing,
vol. 26, no. 1, pp. 217–222, 2005.
[52] T. Chen and C. Guestrin, “Xgboost: A scalable tree
boosting system,” in Proceedings of the 22nd acm sigkdd
international conference on knowledge discovery and
data mining, 2016, pp. 785–794.
[53] J. A. Suykens and J. Vandewalle, “Least squares support
vector machine classifiers,” Neural processing letters,
vol. 9, no. 3, pp. 293–300, 1999.
[54] S. Agatonovic-Kustrin and R. Beresford, “Basic con-
cepts of artificial neural network (ann) modeling and
its application in pharmaceutical research,” Journal of
pharmaceutical and biomedical analysis, vol. 22, no. 5,
pp. 717–727, 2000.
[55] N. Y. S. D. of Health and N. Y. S. S. Bureau, Statewide
Planning and Research Cooperative System Annual Re-
port Series.
New York State Department of Health,
1984.
[56] P. Joo, W. Li, A. Phan, G. Ramirez, C. P. Thirukumaran,
J. Luo, E. N. Menga, and A. Mesfin, “96. health care
disparities in complication and mortality rates following
surgical management of cauda equina syndrome,” The
Spine Journal, vol. 22, no. 9, pp. S52–S53, 2022.
[57] G. D. Hutcheson, “Ordinary least-squares regression,” L.
Moutinho and GD Hutcheson, The SAGE dictionary of
quantitative management research, pp. 224–228, 2011.
[58] R. Tibshirani, “Regression shrinkage and selection via
the lasso,” Journal of the Royal Statistical Society: Series
B (Methodological), vol. 58, no. 1, pp. 267–288, 1996.
[59] A. E. Hoerl and R. W. Kennard, “Ridge regression:
applications to nonorthogonal problems,” Technometrics,
vol. 12, no. 1, pp. 69–82, 1970.
[60] A. Asuncion and D. Newman, “Uci machine learning
repository,” 2007.
APPENDIX
A. Algorithm
We combine algorithm 1 with object function 2 to select the robust rules and prune the redundant items. In the RulesSelection
function, we delete one rule each time with lowest ∥w∥2
2 and save the rule sets with the highest accuracy. In the ItemReduce
function, we apply cross-validation to train SVM model and save the item sets with best accuracy.
Algorithm 1 Rules Selection and Item Reduction
Input: Rules{Xi} are the association rules obtained by Apriori algorithm with training datasets. data is EHR datasets.
Output: Bestrules
1: function RULESSELECTION(Rules, data)
2:
Bestrules ←Rules
3:
Objfunction is objective function
4:
Select ←Bestrules
5:
Bestaccuracy ←Select
6:
Lastrules ←∅
7:
while Select ̸= Lastrules do
8:
Lastrules ←Select
9:
w ←argmin Objectfunction(Select, data)
10:
Selected ←argmin w2
i
11:
Temprules ←{Bestrules}/{Selected}
12:
Tempaccuracy ←Temprules
13:
if Tempaccuracy > Bestaccuracy then
14:
Bestaccuracy ←Tempaccuracy
15:
Select ←Temprules
16:
end if
17:
end while
18:
return Bestrules
19: end function
20: function ITEMREDUCE(Bestrules, data)
21:
Bestauc ←SV M(Bestrules, data)
22:
Lastrules ←∅
23:
while Bestrules ̸= Lastrules do
24:
Item ←argmax SV M({Bestrules}/{Item})
25:
Accuracy ←SV M({Bestrules}/{Item})
26:
if Accuracy ≥Bestauc then
27:
Bestauc ←Accuracy
28:
Bestrules ←{Bestrules}/{Item}
29:
end if
30:
end while
31:
return Bestrules
32: end function
More details such as proof, algorithm or code could be see our anonymous github1
B. Proof
Lemma 2. If the number of features in the datasets and the terms in the Taylor expansion are fixed, when n →∞there exists
W ⪰0 such that
lim
n→∞∥F (i)
p2→p1,i>0∥2
2
1More details are released at https://anonymous.4open.science/r/Causal-Inference-via-Nonlinear-Variable-Decorrelation-for-Healthcare-Applications-20BF/
supplementary.pdf
Proof. Based on our regularizer, we know that






n
P
i wixip2
· · ·
P
i wk
i xk
ip2
P
i wixip2
P
i w2
i x2
ip2
· · ·
P
i wk+1
i
xk+1
ip2
...
...
P
i
P
i wk
i xk
ip2
P
i wk+1
i
xk+1
ip2
...
P
i w2k
i x2k
ip2











fp1p2 (xp2(0))
fp1p2 (xp2(0))
...
f (p)
p1p2 (xp2(0))




=





P
i yi
P
i wixip2yi
...
P
i wk
i xk
ip2yi





We assume that the covariance is 0:
cov (ˆxip2, yi) = cov
 ˆx2
ip2, yi

= cov
 ˆx3
ip2, yi

= · · · = cov
 ˆxk
ip2, yi

= 0
Combine with the following equation, we can get
n →∞: 1
n
X
n
ˆxip2yi −1
n2
X
n
ˆxip2
X
n
yi = 1
n
X
n
ˆx2
ip2yi −1
n2
X
n
ˆx2
ip2
X
n
yi
= 1
n
X
n
ˆxk
ip2yi −1
n2
X
n
ˆxk
ip2
X
n
yi = 0






n
P
i ˆxip2
· · ·
P
i ˆxk
ip2
P
i ˆxip2
P
i ˆx2
ip2
· · ·
P
i ˆxk+1
ip2
...
...
...
P
i ˆxk
ip2
P
i ˆxk+1
ip2
...
P
i ˆx2k
ip2











fp1p2 (xp2(0))
f ′
p1p2 (xp2(0))
...
f (p)p1p2 (xp2(0))




= 1
n



P
i yiˆxip2
P
i yi
...
P
i ˆxk
ip2
P
i yi














P
i ˆx2
ip2
P
i ˆxip2 −P
i ˆxip2
P
i ˆx3
p2
P
i ˆxip2 −P
i ˆx2
ip2
· · ·
P
i ˆxk+1
ip2
P
i ˆxip2 −P
i ˆxk
ip2
P
i ˆx3
ip2
P
i ˆx2
ip2
2
−P
i ˆxip2
P
i ˆx4
ip2
P
i ˆx2
ip2 −P
i ˆx2
ip2
· · ·
P
i ˆxk+2
ip2
P
i ˆx2
ip2 −P
i ˆxk
ip2
...
...
...
...
P
i ˆxk+1
ip2
P
i ˆxk
ip2 −P
i ˆxk
ip2
P
i ˆxk+2
ip2
P
i ˆxk
ip2 −P
i ˆxk
ip2
· · ·
P
i ˆx2k
ip2
P
i ˆxk
ip2 −P
i ˆxk
ip2
















fp1p2 (xp2(0))
f ′′p1p2 (xp2(0))
...
f (p)
p1p2 (xp2(0)




= 0

P
i ˆx2
ip2
P
i ˆxip2 −P
i ˆxip2
P
i ˆx3
ip2
P
i ˆxip2 −P
i ˆx2
ip2
· · ·
P
i ˆxk+1
ip2
P
i ˆxip2 −P
i ˆxk
ip2
P
i ˆx3
ip2
P
i ˆx2
ip2 −P
i ˆxip2
P
i ˆx4
ip2
P
i ˆx2
ip2 −P
i ˆx2
ip2
· · ·
P
i ˆxk+2
ip2
P
i ˆx2
ip2 −P
i ˆxk
ip2
...
...
...
P
i ˆxk+1
ip2
P
i ˆxk
ip2 −P
i ˆxk
ip2
P
i ˆxk+2
ip2
P
i ˆxk
ip2 −P
i ˆxk
ip2
· · ·
P
i ˆx2k
ip2
P
i ˆxk
ip2 −P
i ˆxk
ip2

̸= 0
ˆx2
ip2 is influenced by the wi which can be adjusted, and the determinant of matrix is not equal to 0, hence the equation has
only the trivial solution. We can get
f ′
p1p2 (xp2(0)) = f ′′
p1p2 (xp2(0)) = · · · = f (p)
p1p2 (xp2(0)) = 0
If we can prove under our regularizer, we can prove our method can work:
n →∞: (ˆxip2, yi) = cov
 ˆx2
ip2, yi

= cov
 ˆx3
ip2, yi

= · · · = cov
 ˆxk
ip2, yi

= 0
We set
 ˆxip2, ˆx2
ip2, . . . , ˆxk
ip2

is kernel density estimators: g(xip2. We set the weight wi is:
wi =
Q
iq g
 xq
ij

ˆG (g (xi1) , g (xi2) , . . . , g (xip))
n →∞: E

ˆxq
p1

= 1
n
X
i
xq
ip1
Q
iq g
 xq
ij

ˆG (g (xi1) , g (xi2) , . . . , g (xip))
=
Z
. . .
Z
xq
ij
Y
l
g (xq
il) dxi1dx1
i1 . . . dxq
ip + o(1) =
Z
xq1
il g (xq1
il ) dxq1
il + o(1)
n →∞: E

ˆxq
p1, ˆxp2

= 1
n
X
i
xq
ip1xip1
 
Q
iq g
 xq
ij

ˆG (g (xi1) , g (xi2) , . . . , g (xip))
!2
=
ZZ
xq1
il ximg (xq1
il ) g (xim) dxq1
il dxim + o(1)
=
Z
xq1
il g (xq1
il ) dxq1
il
Z
ximg (xim) dxim + o(1)
n →∞: cov
 ˆxq
ip1, ˆxp1

= E

ˆxq
p1

E [ˆxp1] −E

ˆxq
p1, ˆxp2

= 0
We can get:
f ′
p1p2 (xp2(0)) = f ′′
p1p2 (xp2(0)) = · · · = f (p)
p1p2 (xp2(0)) = 0
C. Baseline
We compare our model with five traditional methods for real-world prediction task:
• Logistic Regression
We leverage the logistic regression classifier with L-BFGS solver for classification.
• Random Forest
We apply standard Random Forest classifier to solve the classification problem [51].
• XGboost
We adopt XGBoost, an extreme gradient boosting methods, to compare with other models [52].
• SVM
We apply supervised learning models, SVM, with linear kernel to analyze data for classification [53].
• MLP
We use the traditional neural network multi-layer perceptron to solve this classification task [54].
We conduct a series of ablative studies to evaluate the stability of our model. Table IV summarizes the results of the
experiment with various values of C and Lagrange penalty operators γ, and λ. For each sell, we fix the Lagrange penalty
operators and increase C to calculate the β errors and RMSE errors. The higher C indicates higher integrated mutual information
is fed into the model and magnifies the impact of confounding. Higher γ values will reduce more confounding effects and
diminish mutual information. Here we choose the best parameters (γ = 600, λ = 0.0005, C = 0.5) based on the smallest
RMSE also with a smaller β error comparing to (γ = 1000, λ = 0.0005, C = 0.5) which has the same RMSE.
D. Datasets
Esophageal Cancer consists of data from 261 patients who underwent esophagectomy for esophageal cancer between 2009 and
2018. The collected characteristics include patient demographics, medical and surgical history, clinical tumor staging, adjuvant
chemoradiotherapy, esophagectomy procedure type, postoperative pathologic tumor staging, adjuvant chemoradiotherapy,
postoperative complications, cancer recurrence, and mortality.
Cauda Equina Syndrome (CES) is extracted from the Statewide Planning and Research Cooperative System (SPARCS) [55],
a comprehensive database of all payers for all hospitalizations in New York State [56].
E. Experiment Settings
For synthesis experiment, we compare our model with five baseline methods. For DWR-based methods, we adopt the code
as well as the parameters published by the original authors:
• Ordinary Least Square (OLS) [57]:
min ∥Y −Xβ∥2
2
• Lasso [58]:
min ∥Y −Xβ∥2
2 + λ1∥β∥1
• Ridge [59]:
min ∥Y −Xβ∥2
2 + λ1∥β∥2
• Decorrelated Weighting Regression (DWR) [18]:
minW,β
Pn
i=1 Wi · (Yi −Xi,β)2
s.t
Pp
j=1
XT
,jΣW X,−j/n −XT
,jW/n · XT
,−jW/n
2
2 < λ2
• Support Vector Machines (SVM) [53]:
min
w,b,ζ,ζ∗
1
2wT w +
n
X
i=1
(ζi + ζ∗
i )
TABLE IV: Hyperparameter study on the synthetic dataset. γ and λ are Lagrange penalty operators.
γ = 600, λ = 0.0001
γ = 600, λ = 0.0005
γ = 600, λ = 0.001
C = 0
C = 0.5
C = 1
C = 0
C = 0.5
C = 1
C = 0
C = 0.5
C = 1
βS Error
1.956
1.919
1.996
1.769
1.926
2.003
1.956
2.026
2.073
βV Error
0.238
0.179
0.166
0.245
0.187
0.178
0.246
0.199
0.175
RMSE Error
4.943
4.732
4.680
4.854
4.726
4.675
4.951
4.856
4.808
γ = 800, λ = 0.0001
γ = 800, λ = 0.0005
γ = 800, λ = 0.001
C = 0
C = 0.5
C = 1
C = 0
C = 0.5
C = 1
C = 0
C = 0.5
C = 1
βS Error
1.954
2.022
2.070
1.784
2.025
2.068
1.960
2.019
2.009
βV Error
0.240
0.197
0.172
0.234
0.195
0.176
0.245
0.195
0.174
RMSE Error
4.945
4.859
4.825
4.849
4.860
4.793
4.961
4.858
4.674
γ = 1000, λ = 0.0001
γ = 1000, λ = 0.0005
γ = 1000, λ = 0.001
C = 0
C = 0.5
C = 1
C = 0
C = 0.5
C = 1
C = 0
C = 0.5
C = 1
βS Error
1.962
2.022
2.075
1.959
1.928
2.073
1.962
2.024
2.006
βV Error
0.242
0.196
0.173
0.250
0.187
0.178
0.244
0.189
0.169
RMSE Error
4.938
4.859
4.812
4.950
4.726
4.811
4.947
4.854
4.672
• SVM combined with DWR(DWR SVM):
minw,b,ζ,ζ∗1
2wT w + Pn
i=1 Wi (ζi + ζ∗
i )
s.t Pp
j=1
XT
,jΣW X,−j/n −XT
,jW/n · XT
,−jW/n
2
2 < λ2
Linear Environment:
For this setting, we construct features S that causes unstable V by auxiliary variables z with linear
relationship among features only:
Z,1, · · · , Z,p
iid
∼N(0, 1), X,1, · · · , X,pv
iid
∼N(0, 1)
S,i = 0.8 ∗Z,i + 0.2 ∗Z,i+1, i = 1, 2, · · · , ps
V·,j = 0.8 ∗X·,j + 0.2 ∗X·,j+1 + N(0, 1)
Nonlinear Environment:
In this setting, we combined square relationship and exponential relationship to generate various
environment including potential nonlinear confounding to test our reweighted regularizer:
V·,j = X·,j + 0.4 ∗X·,j+1 + 0.4 ∗exp(X·,j+1)
+ 0.4 ∗X2
·,j+1 + 0.1 ∗X3
·,j+1 + N(0, 1)
S·,j = Z·,j + 0.4 ∗Z·,j+1 + 0.4 ∗exp(Z·,j+1)
+ 0.4 ∗Z2
·,j+1 + 0.1 ∗Z3
·,j+1 + N(0, 1)
To further test the robustness of our algorithm, we assume that there are unobserved nonlinear terms, and construct the
label Y as shown in Equation 8. Combined with weighed SVM loss function, we train our model to estimate the regression
coefficient β. In this experiment, we set βs =
 1
3, −2
3, 1, −1
3, 2
3, −1, · · ·
	
, βv = −→0 , and ε = N(0, 0.3). In the experiment, we
will set different dimension of β, hence if the dimension of βS is higher than 6, we will set the element of which index is
larger than 6 as the i%6-th of βV .
Ypoly = f(S) + ε = [S, V] · [βs, βv]T + S·,1S·,2 + ε
(8)
Heart Disease is retrieved from the repository of the University of California, Irvine [60]. We follow previous work to use
13 of 76 attributes: Age, Sex, cp, threstbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, cam and thal.
F. Human Evaluation
Quantitative performance does not always align with real-world practice. To ensure the quality, we ask doctors in Cardiology,
ENT and Neurosurgery departments (three doctors in each) to rate each extracted rule based on their domain knowledge. Results
can be found in Table II. Rule scores by the models are based on feature importance. Spearman Coefficients is adopted to
compute rating consistency between our model and doctors. As can be observed, causality rankings of the baseline models
vary greatly, indicating their unstable performances. However, our model is able to achieve consistent higher causal values,
suggesting a better aligned rating mechanism with human experts and some examples can be found in the Table V. In the
experiment, we sort the rules in descending order by calculating the importance and show the top five rules compared with
the doctor’s score in Table V (in our main paper). The scoring criteria are as follows:
• Score 4:
Strongly agree that the rule contains causality.
• Score 3:
Agree that the rule contains causality.
• Score 2:
Disagree with this rule.
• Score 1:
Strongly disagree with this rule.
TABLE V: Rules filtered by algorithm are sorted in a descending order by our algorithm compared with the scores given by doctors.
Association Rules
Scores
Heart Disease
age middle, #major vessels0, fixed defect, pressure normal, ST-T wave abnormality ⇒heart disease
4
age middle, cholesterol edge, #major vessels0, lower than 120mg/ml ⇒heart disease
3
non-anginal pain, cholesterol high, no exercise induced angina ⇒heart disease
4
ST-T wave abnormality, downsloping ⇒heart disease
4
fixed defect, #major vessels0, cholesterol edge ⇒heart disease
4
Esophageal Cancer
Modified Ryan Score 2.0, Esophagectomy Procedure 4 ⇒recurrence
2
tobacco use, Alcohol Use, Neoadjuvant Radiation, Histological Grade 2, Final Histology 1 ⇒recurrence
4
Histological Grade 3, Neoadjuvant Radiation, Esophagectomy Procedure 4, Final Histology 1 ⇒recurrence
4
clinical m Stage 1, Histological Grade 3, Neoadjuvant Radiation, Esophagectomy Procedure 4, Final Histology 1 ⇒recurrence
4
esoph tumor location 4, Esophagectomy Procedure 5, Histological Grade 3 ⇒recurrence
3
Cauda Equina Syndrome
elixsum, beds, procedure 03 09 ⇒die360
4
Emergency, diagnosis 344 60, complication 240days ⇒die360
4
diagnosis 344 60, life threatening, complication 240days ⇒die360
4
if aa ⇒die360
4
or potentially disabling conditions, complication 240days ⇒die360
4
