IEEE TRANSACTIONS AND JOURNALS TEMPLATE
1
ManiNeg: Manifestation-guided Multimodal
Pretraining for Mammography Classification
Xujun Li, Xin Wei, Jing Jiang, Danxiang Chen, Wei Zhang, and Jinpeng Li, Member, IEEE
Abstractâ€” Breast cancer is a significant threat to human
health. Contrastive learning has emerged as an effective
method to extract critical lesion features from mammo-
grams, thereby offering a potent tool for breast cancer
screening and analysis. A crucial aspect of contrastive
learning involves negative sampling, where the selection
of appropriate hard negative samples is essential for driv-
ing representations to retain detailed information about
lesions. In contrastive learning, it is often assumed that
features can sufficiently capture semantic content, and
that each minibatch inherently includes ideal hard nega-
tive samples. However, the characteristics of breast lumps
challenge these assumptions. In response, we introduce
ManiNeg, a novel approach that leverages manifestations
as proxies to mine hard negative samples. Manifesta-
tions, which refer to the observable symptoms or signs
of a disease, provide a knowledge-driven and robust ba-
sis for choosing hard negative samples. This approach
benefits from its invariance to model optimization, facil-
itating efficient sampling. To support ManiNeg and fu-
ture research endeavors, we developed the MVKL dataset,
which includes multi-view mammograms, corresponding
reports, meticulously annotated manifestations, and patho-
logically confirmed benign-malignant outcomes. We eval-
uate ManiNeg on the benign and malignant classification
task. Our results demonstrate that ManiNeg not only im-
proves representation in both unimodal and multimodal
contexts but also shows generalization across datasets.
The MVKL dataset and our codes are publicly available at
https://github.com/wxwxwwxxx/ManiNeg.
Index Termsâ€” Mammography, Computer-aided Diagno-
sis, Contrastive Learning, Negative Sampling
I. INTRODUCTION
B
REAST cancer remains a formidable challenge to global
health. For example, it constitutes one-third of all new
cancer cases among women in the US, making it the second
most lethal cancer among women, trailing only behind lung
cancer [1]. Mammography, as an early screening method, has
proven effective in lowering the mortality rate associated with
Li, X., Jiang, J., Chen, D, and Zhang, W. are with Department of
Oncology, Ningbo NO.2 Hospital. They are also with Department of
Breast Surgery, Ningbo NO.2 Hospital, Ningbo 315000, China.
Wei, X. and Li, J. are with Ningbo Institute of Life and Health Industry,
University of Chinese Academy of Sciences, Ningbo 315010, China.
This work was supported by National Natural Science Foundation
of China (62106248), Project of Ningbo Leading Medical and Health
Discipline (2022-B13), Ningbo Clinical Research Center for Medical
Imaging (2021L003), and Provincial and Municipal Co-construction Key
Discipline for Medical Imaging (2022-S02).
Corresponding author: Jinpeng Li (lijinpeng@ucas.ac.cn).
Image
Repel
a
ð‘¥2
ð‘¥ð‘–
ð‘¥ð‘—
ð‘¥ð‘˜
ð‘¥ð‘™
ð‘¦ð‘–
ð‘¦ð‘—
ð‘¦ð‘˜
ð‘¦ð‘™
ð‘§ð‘–
ð‘§ð‘—
ð‘§ð‘˜
ð‘§ð‘™
Image
b
ð‘¥ð‘–
ð¼
ð‘§ð‘–
ð¼
ð‘§ð‘—
ð‘€
ð‘“ð¼
Projector ð‘”
ð‘”âˆ˜ð‘“ð¼
Manifestation
ð‘¥ð‘˜
ð¼
ð‘¥ð‘—
ð‘€
ð‘¥ð‘™
ð‘€
ð‘§ð‘˜
ð¼
ð‘§ð‘™
ð‘€
ð‘”âˆ˜ð‘“ð‘€
Attract
Legend
ð‘¥1
Fig. 1.
Contrastive pretraining scheme for mammography analysis.
(a) Unimodal learning with images. (b) Multimodal learning with images
and manifestations. i and j denote a pair of views from instance x1,
marked in green. k and l denote a pair of views from instance x2,
marked in yellow. fI(Â·) and fM(Â·) represent the encoders for images
and manifestations, respectively. g(Â·) is the shared projector. Samples
are drawn closer to the positive samples (e.g., zi and zj attract each
other) and are repelled from negative samples (e.g., zi and zk repel
each other) in the representation sphere. Based on these, the model
learns features from the instances in an unsupervised manner.
breast cancer. Extracting critical information from mammo-
grams is crucial for enhancing breast cancer detection rates
and further analyzing breast lumps. Contrastive learning, a
powerful deep learning-based method for extracting represen-
tations, has gained prominence. Originating from unsupervised
learning, it discerns whether two image views belong to the
same instance, offering an advantage over supervised learning
by obviating the need for labels and yielding more robust,
generalizable representations due to its non-task-specific train-
ing approach [2]. Its advantageous properties have led to its
expansion into multimodal and supervised variants.
As Fig. 1 shows, contrastive learning involves creating pairs
of views from an instance through data augmentation or cross-
modal matching, then sampling a set of these views into mini-
batches. Then, views from the same instance are designated
as positive samples, while those from different instances are
negative samples. The model minimizes the distance between
positive sample representations and maximizes the distance
between negative ones, utilizing a loss function to highlight
essential features of the instance.
arXiv:2409.15745v1  [eess.IV]  24 Sep 2024
2
IEEE TRANSACTIONS AND JOURNALS TEMPLATE
Negative sampling is pivotal in contrastive learning, in-
fluencing the differentiation between positive and negative
samples. Hard negative samples, i.e., semantically similar but
distinct from positive samples, encourage the model to explore
semantic differences, leading to the extraction of informative
and aligned representations. SimCLR [3] employs the uniform
sampling to select hard negative samples with a broad array
of candidates. This method, laying the groundwork for many
studies, relies on two key assumptions: First, the representa-
tions closely correspond to the semantic content of interest,
allowing their use in hard negative sample selection. Second,
each batch likely contains hard negative samples, which the
cross-entropy calculation can then emphasize. In large datasets
with a focus on image saliency and common practice of large
batch sizes, these assumptions are generally applicable.
However, the small size and obscured nature of breast
lumps, challenge these assumptions. Unlike in scenarios where
image saliency is assumed, the alignment between represen-
tations and breast lump characteristics during training is not
guaranteed, and the representations themselves evolve as the
model is optimized. This complicates hard negative sample
selection, traditionally reliant on random batch sampling or
memory banks [3], [4], as sampling across the entire dataset
at each training step is computationally prohibitive. More-
over, the skewed distribution of mammographic data and
constraints on batchsize due to dataset scale limit the efficacy
of contrastive learning approaches like SimCLR. With the
evolution of contrastive learning towards multimodal domains,
additional modalities present a promising avenue to circum-
vent these constraints. In the image-text contrastive learning,
text, when accurately describing corresponding images, aligns
closely with the targeted semantics and remains constant
throughout the training process, thereby indicating its potential
as a proxy for semantic-guided hard negative sampling.
The selection of hard negative samples necessitates a well-
defined metric to quantify semantic discrepancies between
instances. While text similarity comparison offers a plausible
approach, its complexity and the nuanced nature of textual
similarity render it less effective for the stringent requirements
of hard negative sampling analysis. On the contrary, in medical
imaging analysis, manifestations emerge as a superior proxy.
Manifestations, encapsulating the symptoms and signs of a
disease in a structured format, are pivotal for diagnosis,
maintaining a direct and significant correlation with the lesions
of interest. The structured nature of manifestations simplifies
the semantic distance measurement, enabling the evaluation
of semantic similarity between instances through a straight-
forward application of the Hamming distance.
Building on these insights, we introduce ManiNeg, a novel
manifestation-guided hard negative sampling strategy tailored
to effectively navigate the challenges posed by representation-
based approaches and the characteristics of mammography
images. Empirical studies validate that ManiNeg significantly
enhances representation learning in both unimodal and multi-
modal settings, and the generalization across datasets.
We have developed the Mammography Visual-Knowledge-
Linguistic (MVKL) dataset. This dataset mirrors the authentic
data landscape encountered in medical practice. Each case in
the MVKL dataset encompasses three modalities: mammogra-
phy images, detailed manifestations, and radiology reports, all
accompanied by pathologically confirmed benign-malignant
outcomes and pixel-level annotations of breast lumps. Through
the creation and annotation of extensive manifestation tables,
we facilitate direct evaluation of ManiNegâ€™s impact. We make
the MVKL dataset publicly accessible, aiming to foster con-
tinued research in this and related areas.
To summarize, our primary contributions are manifold:
â€¢ We critically evaluate the conventional hard negative sam-
pling methods prevalent in contrastive learning, highlight-
ing their inadequacies for mammographic data analysis,
and advocate for the use of manifestations as a viable
proxy to surmount these challenges.
â€¢ We introduce the ManiNeg framework, designed to op-
timize hard negative sampling through a strategic distri-
bution and methodological approach, grounded in lesion
manifestations. Our rigorous testing underscores Ma-
niNegâ€™s practicality and efficacy.
â€¢ We have meticulously compiled and will disseminate
the MVKL dataset, featuring multi-view mammograms,
corresponding radiology reports, pathologically validated
benign-malignant labels, and unique manifestations, to
support a wide range of innovations for the community.
Section 2 reviews literature on deep learning for mammog-
raphy, contrastive learning, and negative sampling. Section
3 introduces the MVKL dataset, including its organization,
annotation, modalities, and manifestation tables. Section 4
details the ManiNeg method, covering its design and im-
plementation during training. Section 5 validates ManiNegâ€™s
effectiveness through various tests, assessing its impact on
contrastive learning. Section 6 discusses ManiNegâ€™s limitations
and future prospects. The article concludes with Section 7,
summarizing our findings and contributions.
II. RELATED WORKS
Mammography Image Analysis. Mammography is the
foremost screening tool for breast cancer due to its efficiency
and effectiveness. Yet, the precision in analyzing breast lumps,
particularly those that are concealed, remains a formidable
challenge in radiology. This challenge has catalyzed a surge in
research exploring the enhancement of mammographic exam-
ination through advanced deep learning techniques. Elkorany
and Elsharkawy [5] leverages multiple models to distill fea-
tures from mammograms, employing a Term Variance feature
selection algorithm to isolate the most pertinent features.
Prodan et al. [6] introduces a novel data augmentation strategy
utilizing StyleGAN [7] to generate additional data. Saber et al.
[8] adapts models pre-trained on ImageNet to a Long Short-
Term Memory (LSTM) network, facilitating the extraction
of features. Given that mammograms encompass multiple
perspectives, the integration of multi-scale and multi-view
features has been proven effective for a more nuanced analysis
of breast lumps [9]. Expanding on this, Liu et al. [10] employs
an array of graph convolutional networks to amalgamate
features from both unilateral and bilateral mammographic
views. Moreover, semi-supervised techniques, such as multiple
AUTHOR et al.: TITLE
3
Hard Negative
Easy Negative
Anchor 
Lesion
Hamming Distance
Sampling Probability
Manifestation 
Vector
ManiNeg Distribution
Uniform Distribution
Fig. 2.
ManiNeg and uniform sampling. We assume independent traits in the manifestation have a 50% occurrence probability for illustration. On
a 4-bit manifestation scenario, where the distribution of Hamming distances between negatives and the anchor aligns with the binomial distribution
B(4, 0.5). Uniform sampling most frequently results in a Hamming distance of 2, missing the ideal hard negatives at a distance of 1. ManiNeg,
sampling by Hamming distance, directly targets these hard negatives, effectively enhancing sample selection for improved learning.
instance learning, have demonstrated potential in mammogram
analysis under scenarios with limited labels [11].
Contrastive Learning. Contrastive learning, a cornerstone
in the realm of self-supervised learning, has progressively
found application in supervised and multimodal learning con-
texts [12]. SimCLR [3], a foundational contrastive learning
framework, meticulously examines the influence of data aug-
mentation, network architecture, and loss functions on model
efficacy. It notably underscores the critical role of the negative
sample size (i.e., batch size) on model performance. MoCo
[4] introduces a momentum encoder and a memory bank
mechanism to enlarge the negative sample pool. SwAV [13],
diverging from direct optimization among samples, clusters
them to prototypes to optimize sample-to-prototype distances.
Multimodal Contrastive Learning. The versatility of con-
trastive learning, unconstrained by modality homogeneity,
paves the way for its extension into multimodal domains. CLIP
[14] epitomizes this transition by utilizing separate encoders
for images and texts, aligning their representations via a
contrastive loss. Various scales of ResNet [15] and ViT [16]
function as image encoders, while the Transformer architecture
[17] serves as the text encoder. VSE++ [18] enhances model
performance through a hard negative mining strategy. ViLT
[19] merges patch-based image embeddings with text embed-
dings via a transformer. BEiT3 [20] demonstrates the efficacy
of discrete image tokens, generated through VQ-VAE [21], in
improving performance. ALBEF [22] introduces a pre-modal
fusion alignment loss, fostering improved intermodal rela-
tionship learning. VLMo [23] incorporates modality-specific
modules within the Transformer, alternating between self-
attention and modality expert modules to integrate and learn
features across modalities. BLIP [24] trains a captioner to
recognize data noise, allowing for pretraining on large-scale,
noisy datasets. PaLI [25] extends unimodal text and image
models for text generation tasks, culminating in scalable
multimodal models. REFERS [26] aligns features extracted
from X-Ray images with corresponding radiology reports
through contrastive learning, effectively leveraging report data.
Hager et al. [27] further validates the utility of tabular data in
enhancing multimodal contrastive learning approaches.
Hard Negative Sampling. The concept of contrastive loss
incorporates a weighting mechanism for hard negative sam-
ples via cross-entropy, thereby legitimizing uniform random
sampling as an effective strategy for hard negative sample
selection [3]. Progressing from this foundation, numerous
studies have delved into optimizing the selection of hard
negative samples. MoCo [4] broadens the negative sample
spectrum with its memory bank mechanism. Concurrently, Cao
et al. [28] delve into refining memory bank size optimization
through a maximum traceable distance metric. Wu et al. [29]
innovatively selects hard negative samples by gauging mutual
information between representations and sampling within a
specified proximity to the positive anchor. Drawing inspiration
from data mixing techniques, Kalantidis et al. [30] intro-
duces a representation-driven hard negative mixing strategy
to dynamically fabricate hard negative samples. Robinson
et al. [31] conceptualizes a latent class distribution along-
side a von Mises-Fisher distribution, centered around posi-
tive samples, to differentially weight hard negative samples
across distinct classes via importance sampling. DiHT [32]
further extrapolates this approach to the multimodal sphere.
Tabassum et al. [33] amalgamates anchor similarity, model
uncertainty, and representativeness in the hard negative sample
selection calculus to enhance sample quality. Ge et al. [34]
innovates non-semantic negative sample generation through
patch-based and texture-centric augmentations, steering model
focus towards semantic discernment. Neill and Bollegala [35]
predicates negative sampling on semantics, inferred through
pretrained representations. VSE++ [18] employs a triplet-
based loss function, prioritizing the learning influence of the
most challenging negative samples, a technique also embraced
by ALBEF [22] and VLMo [23].
In summary, most existing studies presume two fundamen-
tal assumptions about negative sampling: a strict alignment
4
IEEE TRANSACTIONS AND JOURNALS TEMPLATE
Fig. 3.
Schematic of a binary manifestation vector. The manifestation
is initially annotated according to the header listed in Table I and
subsequently expanded into a 35-dimensional binary vector. We show a
binary manifestation vector surrounding its corresponding breast lump.
Green: presence; Red: absence.
between representations and semantics, and the inherent pres-
ence of hard negative samples within each mini-batch. Such
presuppositions suggest that traditional methods might falter
in specialized contexts like mammography analysis, where
these assumptions are less applicable. ManiNeg introduces an
innovative solution by leveraging an auxiliary modality as a
semantic proxy, directly addressing these challenges.
III. DATASET
We have curated and meticulously annotated the first mul-
timodal mammographic dataset, termed the Mammography
Visual-Knowledge-Linguistic dataset (MVKL), to provide a
holistic view of mammographic analysis.
Mammography. Mammography captures the breastâ€™s X-ray
images to identify and analyze suspicious high-density areas
indicative of breast lumps. To ensure a thorough examination
of these lumps, a standard mammogram for a unilateral
breast typically encompasses two conventional views: the
mediolateral oblique (MLO) and the craniocaudal (CC) views.
These diverse physical perspectives are crucial for contrastive
learning, as they enable the model to discern essential features
by comparing different views. Accordingly, we preserved all
original views from each examination to enrich the datasetâ€™s
utility for learning algorithms.
Manifestations. Manifestations, indicative of disease symp-
toms and signs, serve as a fundamental diagnostic cornerstone.
They originate from patient complaints and clinical findings,
characterized by their structured nature. Clinicians and ra-
diologists often document critical manifestations in medical
reports, facilitating the extraction of such data through Natural
Language Processing (NLP) techniques. For instance, the
Chest14 dataset [36] utilized NLP to gather various diagnostic
labels from chest X-ray data. Nonetheless, NLP methods
may introduce noise, and potentially insightful manifestations
occasionally omitted by radiologists could provide valuable
information. To address these challenges, we developed a
generic table format to systematically catalog breast lump
characteristics, ensuring comprehensive case annotation.
The manifestations encompasse 17 principal traits catego-
rized into four mass traits, four calcification traits, and nine
miscellaneous traits, as detailed in Table I. The manifestations
are transformed into a 35-dimensional binary vector, each
dimension reflecting the presence or absence of specific traits.
Fig. 3 shows a schematic diagram of such a manifestation
binary vector. This binary vector not only simplifies model
processing but also enables the assessment of case similarities
through the Hamming distance, offering a straightforward and
effective means for comparing mammographic cases.
TABLE I
THE MANIFESTATIONS. THE MISCELLANEOUS OPTIONS ARE
INDEPENDENT, AND THE REST OPTIONS ARE MUTUALLY EXCLUSIVE.
Manifestations
Options
mass shape
irregular, lobulated, ovoid, round
mass edge
microlobulated, obscured, spiculated,
well-circumscribed
mass density
low, median, high
mass size
â‰¤2cm, 2-5cm, >5cm
calcification shape
branching, crescentic/annular/gritty/thread-like,
granular/popcorn-like/large rod-like/eggshell-like
calcification size
coarse, tiny, uneven
calcification density
low, high, uneven
calcification
distribution
scattered, clustered, linear/segmental
miscellaneous
architectural distortion, focal asymmetrical
density, duct sign, comet tail sign, halo sign,
focal skin thickening/retraction, nipple retraction,
abnormal blood vessel shadow, abnormal lymph
node shadow
Radiology Reports. While the textual modality is not the
primary focus of our current research, it plays a critical role
in multimodal studies, and thus, radiology reports form an
integral part of the MVKL dataset. These reports, penned by
radiologists, succinctly detail the location of breast lumps,
essential manifestations, and the Breast Imaging Reporting and
Data System (BI-RADS) categories in a concise, free-text for-
mat. Notably, BI-RADS offers a preliminary benign-malignant
classification of lumps based on imaging and patient feedback,
frequently aligning closely with pathological outcomes. The
BI-RADS framework classifies breast lumps into seven risk
levels, from 0 (incomplete) to 6 (proven malignancy), with
intermediate categories providing a nuanced risk assessment.
Ensuring comprehensiveness, each radiology report within the
MVKL dataset is accompanied by a BI-RADS categorization.
Labels. All breast lumps documented in the MVKL dataset
are corroborated with pathologically confirmed benign or
malignant outcomes, serving as the objective ground truth for
benign-malignant predictions in our research.
Mask of Breast Lumps. All breast lumps are annotated
AUTHOR et al.: TITLE
5
TABLE II
LABEL DISTRIBUTIONS. BEN: BENIGN; MAL: MALIGNANT.
Partition
Training
Validation
Test
Label
Ben.
Mal.
Ben.
Mal.
Ben.
Mal.
MVKL
621
1325
102
174
158
384
CBIS-DDSM
1494
1083
189
98
428
276
with pixel-based masks on their corresponding mammograms,
enhancing the datasetâ€™s utility for detailed imaging analysis.
Collection Procedure. Focusing on breast lumps as the
primary unit of analysis, the MVKL dataset encompasses
data from recent clinical studies conducted at Ningbo No.2
Hospital. This includes breast lumps that underwent biopsy
examinations, along with their corresponding mammograms
and radiology reports. A systematic annotation process was
employed, involving physicians who annotated manifestations
based on a predefined schema and pixel-based masks. This
process unfolded in two stages: initially, five attending and
chief physicians performed a collaborative preliminary annota-
tion, leveraging biopsy results and radiology reports to ensure
accuracy and reduce annotation burden. Subsequently, a senior
chief physician reviewed these annotations to resolve any
inconsistencies. Ultimately, the dataset compiled encompasses
2764 breast lumps from 2671 mammographic examinations,
with a detailed label distributions provided in Table II.
Privacy Statement. Upon data collection, all potentially
identifying information was anonymized. This includes remov-
ing specific details from Dicom headers, such as names of
patients and physicians, dates of birth, examination dates, and
identifiers like Accession Numbers, Patient IDs, Study IDs,
Study Instance UIDs, Series Instance UIDs, and SOP Instance
UIDs, ensuring the privacy and confidentiality of patient data.
IV. METHOD
In this section, we first review the paradigm of contrastive
learning and analyze its negative sampling scheme. Then we
elaborate on the concept and implementation of ManiNeg
and explain how it addresses the issue of hard negative
sampling. Finally, we illustrate how ManiNeg functions within
the training process with an intuitive demonstration.
A. A In-depth Look into Contrastive Learning
Contrastive learning, a self-supervised learning approach,
has progressively emerged as a pivotal technique for achieving
multimodal alignment. This evolution has seen variations in
models and training objectives across different methodologies.
For the purpose of clarity and universality, we use SimCLR [3]
as a foundational model to elucidate the basic principles of
contrastive learning.
Basic Framework. Illustrated in Fig. 1, the contrastive
learning framework posits the generation of a pair of differ-
ing views {xi, xj} from the same instance x. Within this
framework, for any given anchor view xi, its counterpart
xj originating from the same instance is tagged as a pos-
itive sample and is attracted closer in the representational
space. Conversely, views emanating from disparate instances
{xk|k Ì¸= i, k Ì¸= j} are designated as negative samples and are
distanced. This mechanism of view generation predominantly
leverages data augmentation techniques in self-supervised
learning contexts.
SimCLR implements a bifurcated model structure to process
and represent data. Initially, a backbone network f(Â·), exempli-
fied by ResNet50, functions to extract feature representations
yi from input views, denoted as yi = f(xi). Subsequently,
a MLP, g(Â·), projects these extracted features into a distinct
projection space, represented as zi = g(yi). The contrastive
learning process predominantly operates within this projection
space zi during the pretraining phase. However, for down-
stream tasks, the model reverts to utilizing the feature yi for
validation, thereby preserving a richer information spectrum
from the initial input within yi. For simplicity and clarity,
future references to views, representations, or samples within
this discussion will pertain to the projection space vector z,
unless explicitly indicated otherwise.
The core objective of contrastive learning in its pretraining
phase is to discern the positive sample pair amongst all
pairs within the same batch for each view. This identification
challenge is addressed through a loss function known as the
normalized temperature-scaled cross entropy loss (NT-Xent):
â„“(zi, zj) = âˆ’log
exp(sim(zi, zj)/Ï„)
P2N
k=1 1[kÌ¸=i] exp(sim(zi, zk)/Ï„)
.
(1)
Here, Ï„ represents the temperature parameter, 1 the indica-
tor function, and sim(Â·) denotes the similarity measure, which
in the context of contrastive learning, is often calculated using
cosine similarity, i.e., sim(u, v) =
uÂ·v
|u||v|.
Hard Negative Sampling Schemes. The minibatches dur-
ing the training process of SimCLR are generated via uniform
sampling. SimCLR implicitly weights hard negative samples
through the NT-Xent loss function. As can be inferred from
its name, NT-Xent is composed of two parts:
H(p, q) = âˆ’p log(q) , p = 1 ,
(2)
q(zi, zj) =
exp(sim(zi, zj)/Ï„)
P2N
k=1 1[kÌ¸=i] exp(sim(zi, zk)/Ï„)
,
(3)
where q(zi, zj) captures the difference in similarity between
positive and negative sample pairs. Specifically, if a negative
sample zk, k Ì¸= j exhibits a high similarity to zi, it sig-
nificantly contributes to the denominator of q(zi, zj), thus
playing a crucial role in (2). Such negative samples, which
are challenging to differentiate from the anchor samples, are
termed hard negative samples.
Hard negative sampling encompasses two phases: initially,
a minibatch is created via uniform sampling from the dataset.
Following the inference of this minibatch, the hard negative
samples contained within it are then weighted using NT-
Xent. The process of sampling hard negative samples thus
displays relatively low efficiency. Consequently, it is inferred
that acquiring an adequate number of hard negative samples
necessitates a large batch size during training, a finding that
aligns with the primary conclusions drawn from SimCLR.
6
IEEE TRANSACTIONS AND JOURNALS TEMPLATE
Exploring into sampling efficiency prompts the question:
what proportion of a minibatch comprises hard negative sam-
ples? Introducing a model-independent proxy to represent the
features of interest in the input data can provide insight.
Proxies stands for the original entities. In the context of
breast lumps, manifestations fulfill the role of such a proxy,
enabling the assessment of semantic similarity through the
comparison of proxies. Breast lumps with akin manifestations,
while similar, also differ semantically, rendering them prime
candidates for hard negative samples.
The MVKL dataset employs binary vectors to symbolize
manifestations, allowing the semantic differences between
manifestations to be quantified via the Hamming distance.
This metric also indicates the challenge level of the samples.
Assuming the independence and equal probability of each
manifestation dimension, the Hamming distance between an
anchor sample and negative samples adheres to a binomial
distribution, as depicted by the uniform curve in Fig. 2.
Hence, when uniformly sampling minibatches from the
dataset, especially when dealing with multiple semantic fea-
tures (a common scenario, even in binary classification tasks,
where classification often hinges on multiple features), the
sampling equates to navigating a binomial distribution within
the semantic space. According to the Central Limit Theorem,
this distribution will approximate a Gaussian distribution char-
acterized by a mean Âµ = npm and a standard deviation Ïƒ =
p
npm(1 âˆ’pm), where n represents the manifestation size,
and pm is the probability of a particular trait being positive.
Notably, Âµ escalates more rapidly relative to n than does Ïƒ,
indicating that the procurement of hard negative samples with
a close Hamming distance becomes increasingly improbable
with more complex data and a greater diversity of features.
This concept is visually demonstrated in Fig. 4, suggesting that
a uniformly sampled minibatch may contain only a minimal
proportion of hard negative samples.
B. ManiNeg in Motivation
Addressing the limitations inherent in the traditional hard
negative sampling approach poses a significant challenge
within the realm of self-supervised contrastive learning due to
the absence of alternative means to describe semantics beyond
model representations. However, the advent of multimodal
contrastive learning offers a promising solution. Multimodal
contrastive learning aims to align views from different modal-
ities of the same instance within a unified representation space,
ensuring that each modality reflects the intended semantics
in its unique way. When a modality possesses a well-defined
similarity measure, it enables the bypassing of model represen-
tations for hard negative sample selection, effectively serving
as a proxy for semantics..
Leveraging the manifestation modality as such a proxy, we
have explored the distribution of semantic differences via the
Hamming distance within a uniformly sampled minibatch.
Crucially, since manifestations remain invariant throughout
model optimization, we can extend the Hamming distance
calculation across the entire dataset, thereby circumventing
the minibatch limitation. This extension allows for the direct
10
15
20
25
30
35
40
45
50
Manifestation size n
0
2
4
6
8
10
12
14
Hamming distance lower bound (
3 )
(x;
,
2)
0.0013
(x;
,
2) < 0.0013
Fig. 4.
ManiNeg concept in probability. Since each trait within a man-
ifestation is independent with an occurrence probability of pm = 0.5,
the Hamming distance x between an anchor and a negative sampleâ€™s
manifestation adheres to a binomial distribution. As the number of traits
n increases, this binomial distribution converges towards a Gaussian
distribution, N (Âµ, Ïƒ2), where its cumulative density function is repre-
sented as Î¦(x; Âµ, Ïƒ2). Based on that, we can delineate the correlation
between the manifestation size n and the minimum threshold for sam-
pling Hamming distances, defined as inf{x|Î¦(x; Âµ, Ïƒ2)â‰¥0.0013},
effectively Âµ âˆ’3Ïƒ. It reveals a direct relationship: as n escalates,
the threshold for hard negative samplingâ€”or the lower bound of the
Hamming distanceâ€”likewise increases. This increment underscores the
growing scarcity of hard negative samples with the expansion of man-
ifestation size, highlighting a pivotal challenge in efficiently identifying
such samples as the complexity of the data representation increases.
sampling of hard negatives based on a specific distribution,
embodying the essence of the ManiNeg approach.
ManiNeg, through its innovative use of an additional man-
ifestation modality as a semantic proxy, adeptly overcomes
the challenges associated with hard negative sampling based
on representations. This strategy ensures a high degree of
semantic alignment at the data level, mitigating the risk
of selecting poor hard negative samples due to misaligned
representations. Most importantly, while the proportion of hard
negative samples in a uniformly sampled minibatch might be
minimal, ManiNeg enables the precise and targeted identifica-
tion of hard negative samples across the entire dataset, thereby
addressing the issue of sampling efficiency at its core.
C. ManiNeg in Implementation
Sampling Scheme. 1) Initial Sampling. An anchor instance
is randomly selected from the dataset without replacement,
ensuring each instance has an equal chance of chosen. 2)
Hamming Distance Calculation. For the chosen anchor, the
Hamming distances to all other instances in the dataset are
computed, providing a measure of similarity. 3) Distribution
Definition. A truncated Gaussian distribution is defined over
the Hamming distances. From this distribution, several dis-
tances are sampled, reflecting a controlled variability in the
degree of dissimilarity from the anchor. 4) Instance Selection.
For each sampled Hamming distance, an instance is uniformly
selected from the group of instances that match the distance.
This step ensures diversity in the sampled instances, which are
then combined to form a minibatch for training.
The probability density function of the truncated Gaussian
AUTHOR et al.: TITLE
7
distribution defined in Step 3) is compued by:
f(x; Âµ, Ïƒ2, a, b) =
(
Ï•(x;Âµ,Ïƒ2)
Î¦(b;Âµ,Ïƒ2)âˆ’Î¦(a;Âµ,Ïƒ2),
if a â‰¤x â‰¤b
0,
others
(4)
where x represents the the Hamming distance, Î¦ and Ï• are
the cumulative distribution function and the probability density
function of the Gaussian distribution N(Âµ, Ïƒ2). a and b are the
upper and lower bounds of the truncated Gaussian distribution.
The lower bound a, set at 1, ensures exclusion of the anchor
instance from being re-sampled as a negative sample. The up-
per bound b, determined by analyzing the maximum Hamming
distance across the entire dataset, is set at 18. This range
encapsulates the spectrum of semantic dissimilarities within
the dataset. The mean Âµ and standard deviation Ïƒ act as ad-
justable hyperparameters that influence the variance in sample
difficulty. These settings allow for a dynamic adjustment based
on direct observations from sampling outcomes, simplifying
the hyperparameter tuning. The distribution, referred to as
the ManiNeg curve, is visually represented in Fig. 2, serving
as a graphical reference to the underlying principles of this
sampling methodology.
Manifestation Deduplication. To prevent redundancy in
the minibatch, instances with identical manifestations are fil-
tered to retain only one, underlining the principle that samples
with no semantic differences are not suitable as negative
samples in contrastive learning.
Hardness Annealing. The training regimen incorporates a
hardness annealing strategy, gradually increasing the difficulty
of the negative samples as the model becomes more adept.
This approach allows the model to initially grasp broader
features before honing in on more nuanced distinctions, with
the flexibility to adjust Âµ in (4) within the truncated Gaussian
distribution facilitating this progression.
Pseudocode. To summarize, the complete training process
is summarized in Algorithm 1.
The computationally intensive steps, particularly those in-
volving pre-calculable distances, can be pre-processed and
stored, streamlining the training by eliminating the need for
real-time computation of distances for every training step.
This pre-computation significantly enhances the practicality
and efficiency of ManiNeg, making it a viable and effective
method for leveraging hard negative samples.
D. Further Demonstrations on ManiNeg
The ManiNeg sampling approach, predicated on Hamming
distances, offers a visually interpretable method to demonstrate
its sampling and annealing process. This visualization can be
understood from two distinct angles.
Distance between the anchor and the negatives. The
Hamming distances between the anchor and negative samples
directly correspond to the outcomes sampled according to the
specified truncated Gaussian distribution. Figure 5(a) show-
cases minibatches sampled under various hardness settings (Âµ),
illustrating the annealing process and the distribution of the
sampling scheme for reference.
Algorithm 1 Python-style Pseudocode of ManiNeg.
# Variable initialization
dataset=mvkl.dataset(batchsize=1).shuffle()
batchsize
t gaussian # Eq. (4)
model
# Training process
for anchor in dataset:
sample space = defaultdict(list)
for neg in dataset: # pre-computable
if neg == anchor:
continue
h d = Hamming distance(anchor, neg)
sample space[h d].append(neg)
t gaussian.annealing() # according to the training step
h d samples = t gaussian.sample(size=batchsize-1)
batch = list()
batch.append(anchor)
for h d in h d samples:
sample = random.sample(sampling space[h d],1)
batch.append(sample)
manifestation deduplicate(batch)
model.train(batch)
Distance between all negative pairs. Efficiency precludes
the exclusive selection of the anchor as the positive sample
within a minibatch. Adhering to standard contrastive learning,
each sample within the batch is treated as a positive instance,
with the loss function (1) computed individually and the mini-
batch loss determined by averaging these individual losses.
Thus, the focus shifts to the distribution of Hamming distances
among all negative pairs within the batch.
A formal analysis of this distribution is challenging due to
its derivation from multiple overlapping distributions, which
are significantly influenced by the datasetâ€™s characteristics.
For instance, traits within real manifestations often exhibit
dependencies, and the distribution of each trait can vary
widely, complicating the derivation of a generalized formal
expression. Despite these challenges, the distribution can be
empirically visualized through sampling experiments, as de-
picted in Fig. 5(b). This visualization reveals that increasing
the hardness of negative samples (i.e., decreasing Âµ in (4))
correlates with a reduction in the average Hamming distance
between negative pairs, which is consistent with expectations.
This analysis underscores two critical insights. First, it
highlights a pragmatic approach for selecting hyperparameters
in the truncated distribution. By evaluating the effects of
different hyperparameters through sampling and visualizing
in Fig.5(b), we can fine-tune the setup without engaging in
model optimization, streamlining the hyperparameter selection
process. Second, this methodology serves as a preliminary
assessment tool for determining a datasetâ€™s compatibility with
ManiNeg. The success of ManiNeg is intricately linked to
the datasetâ€™s distribution, which can be complex and dataset-
specific. Thus, a decreasing trend in the mean Hamming dis-
tance among negative pairs, as observed in Fig.5(b), suggests
the datasetâ€™s potential suitability for ManiNeg.
8
IEEE TRANSACTIONS AND JOURNALS TEMPLATE
(a)
0
1
2
3
4
5
6
7
8
9
10 11
Hamming Distance, =0
0.0
0.1
0.2
0.3
Freq
0
1
2
3
4
5
6
7
8
9
10 11
Hamming Distance, =4
0.00
0.05
0.10
0.15
Freq
0
1
2
3
4
5
6
7
8
9
10 11
Hamming Distance, =11
0.0
0.1
0.2
Freq
Histogram
Sampling scheme
(b)
0
5
10
15
Hamming Distance, =0
0.00
0.05
0.10
0.15
Freq
0
5
10
15
20
Hamming Distance, =4
0.00
0.05
0.10
Freq
0
5
10
15
20
Hamming Distance, =11
0.00
0.05
0.10
Freq
Histogram
Fig. 5.
Demonstration of ManiNeg using different values of Âµ for sampling. (a) Histogram of the Hamming distances between the anchor and the
negative samples. (b) Histogram of the Hamming distances between all negative pairs within the minibatch.
V. EXPERIMENTS AND RESULTS
We first introduce the experimental setup and evaluation
protocols, and then validate ManiNeg in unimodal, multi-
modal, and cross-dataset scenarios.
A. Experimental Setups
Experimental Procedure. Our experimental framework is
detailed in the Basic Framework section outlined in Section
IV-A. During pretraining, models are developed using con-
trastive learning in both unimodal and multimodal settings,
with the downstream task focused on the benign-malignant
classification of breast lumps. Reflecting practical application
requirements, only the image modality is employed in the
downstream task. Given the small and concealed nature of
breast lumps, the capability of models to extract relevant
features is a critical factor in the evaluation.
Modalities. The application of contrastive learning spans
unimodal representation generation and multimodal represen-
tation alignment. While ManiNeg introduces an additional
manifestation modality as a semantic proxyâ€”impacting only
the instance sampling procedureâ€”the core pretraining of mod-
els remains applicable under both unimodal and multimodal
conditions. To ensure a thorough assessment of ManiNeg, we
examine models pretrained under these varied scenarios.
In the unimodal context, instances comprise solely of dif-
ferent mammogram views xcc
i
and xmlo
j
, with i and j denote
their origin from the same instance. The model structure is
depicted in Fig. 1(a), with the substitution of zcc
i , zmloj into
(1) resulting in the unimodal loss function â„“uni expressed as
â„“uni = â„“(zcc
i , zmlo
j
) .
(5)
In multimodal settings, Hager et al. [27] has demonstrated
the feasibility of integrating tabular data, such as manifes-
tations, as an additional modality. Manifestations xM
j
are
mapped into a shared representation space zM
j
utilizing a
shallow neural network fM(Â·) and a shared projector g(Â·),
facilitating closer alignment with mammogram representations
zI
i . This approach maintains image unimodal contrastive learn-
ing to enhance image feature extraction, with the networkâ€™s
configuration illustrated in Fig. 1, and the multimodal loss
function â„“multi defined as
â„“M = 1
2(â„“inter(zcc
i , zM
j ) + â„“inter(zmlo
i
, zM
j )) ,
â„“multi = â„“M + â„“uni .
(6)
Here, â„“inter mirrors the form of (1) but excludes negative
sample pairs from identical modalities, thereby omitting pairs
such as {zcc
i , zcc
k |k
Ì¸=
i} from the denominator of (1).
We use ResNet50 [15] as the feature extractor fI(Â·), while
manifestations are processed through two linear layers. The
shared projector g(Â·) consists of two linear layers, fostering a
cohesive and efficient learning environment across modalities.
Datasets. The MVKL dataset, detailed in Section III, was
partitioned into training, validation, and test subsets following
a 7:1:2 ratio, ensuring that mammograms from the same
patient remained within the same subset. The specifics of this
distribution are cataloged in Table II for reference.
Subsequent validations of the downstream task were con-
ducted on two datasets. Initially, the MVKL dataset, identical
to the pretraining phase, was utilized, employing pathology-
verified labels as the ground truth. The datasetâ€™s division
scheme was maintained consistently throughout both the pre-
training and validation phases.
To evaluate the generalization capacity, validations were
extended to the CBIS-DDSM dataset [37], which comprises
3,568 mammogram cases marked with breast lumps catego-
rized as either mass or calcification. Each lump is accompanied
by a pathology-verified label, mirroring the ground truth
approach adopted for the MVKL dataset. The CBIS-DDSM
dataset was divided according to its original scheme, with
an additional 10% of the training set allocated for validation
purposes. The division details are also presented in Table II.
Metrics. To mitigate the potential biases induced by label
imbalance or threshold adjustments, area under the receiver
operating characteristic (AUC) was used for evaluation.
AUTHOR et al.: TITLE
9
Baseline Methods. Two benchmark methods were selected
for comparative analysis against ManiNeg. The first, referred
to as uniform, follows the original SimCLR approach detailed
in the hard negative sampling scheme part of Section IV-A.
This method is emblematic of numerous contrastive learning
studies that do not explicitly tackle the challenge of negative
sample hardness. The second comparative method, stemming
from the research of Robinson et al. [31], employs a von
Mises-Fisher distribution centered around the anchor sample
for hard negative sampling, thereby favoring the selection of
negative samples closer to the positive sample. This approach
is denoted as vMF in subsequent discussions.
Data Augmentation. To augment the mammography im-
ages, a series of transformations were applied: RandomRe-
sizedCrop within the scale of (0.5, 1), RandomHorizontalFlip
with a 50% probability, and two iterations of RandAugment
[38], excluding any color-related augmentations. These aug-
mentations were consistently applied across all mammogram-
related experiments. For manifestations, no data-level aug-
mentations were introduced; instead, a Dropout with a 50%
probability was applied to the manifestation features yM.
Hyperparameters. Detailed hyperparameter settings are
documented in Table III, providing a transparent overview of
the experimental configurations.
B. Evaluation Protocol
Two primary methodologies are considered to evaluate the
downstream tasks. The first method involves freezing the pre-
trained modelâ€™s parameters to directly evaluate the generated
representations. The second method employs the pretrained
model as a starting point, upon which further fine-tuning is
conducted for the downstream task.
In alignment with established methodologies from Sim-
CLR [3] and CLIP [14], three distinct evaluation protocols are
utilized for downstream task assessment. Given the exclusive
use of the image modality for downstream task validation, the
pretrained models referenced herein specifically pertain to the
pretrained image branch fI(Â·).
Linear Probe (LP) maintains the pretrained modelâ€™s pa-
rameters and employs logistic regression to categorize the
representations into benign or malignant classes.
Linear Evaluation (LE) preserves the pretrained modelâ€™s
parameters but introduces an additional trainable linear layer
for classifying the representations.
Fine-tuning (FT) preserves the pretrained modelâ€™s parame-
ters in a fixed state but introduces an additional trainable linear
layer for classifying the representations.
C. Evaluation Results
We evaluate the methods on MVKL and CBIS-DDSM
under both unimodal and multimodal pretraining scenarios.
All the experiments are repeated 10 times using the same
hyperparameters and different random seeds. The mean and
the standard deviation are calculated base on these results.
Unimodal. The results on MVKL are shown in Table IV,
and the results on CBIS-DDSM are recorded in Table V.
The challenge in extracting representations of breast lumps,
TABLE III
HYPERPARAMETERS.
Hyperparameters
Value
Pretraining
Peak learning rate
1e-4
Minimal learning rate
1e-7
Learning rate schedule
Cosine annealing
Training steps
9000
Warmup steps
300
Batch size
64
Temperature Ï„
trainable, initialized by 0.7
Weight decay
1e-4
Input resolution
2562
ManiNeg, maximum Âµ
11
ManiNeg, minimum Âµ
0
ManiNeg, Ïƒ
3
ManiNeg, annealing schedule
Linear
ManiNeg, annealing, step at minimum Âµâ€ 
150th
Downstream, linear evaluation
Peak learning rate
1e-3
Minimal learning rate
1e-6
Learning rate schedule
Cosine annealing
Maximum epochs
1000
Early stopping patience
100
Batch size
48
Weight decay
1e-6
Input resolution
2562
Downstream, fine-tuning
Peak learning rate
5e-5
Minimal learning rate
5e-7
Learning rate schedule
Cosine annealing
Layer-wise learning rate decayâ€¡
0.1
Maximum epochs
1000
Early stopping patience
100
Batch size
48
Weight decay
5e-5
Input resolution
2562
Downstream, linear probe
L2 regularization strength Î»
3.16
Maximum iteration
1000
â€  During the training process, Âµ starts from a maximum value of 11 and
stops at a minimum value of 0 at the 150th training step, remaining
unchanged thereafter. The decrease in Âµ is linear.
â€¡ The learning rate on the pretrained parameters is 0.1 times that of the
learning rate on the appended randomly initialized linear layer.
owing to their small and concealed nature, underscores the
limitations of self-supervised learning in isolating critical
lesion characteristics without lesion-specific information. De-
spite these challenges, ManiNeg demonstrates a performance
that is slightly superior or comparable to the best outcomes
among the baseline methods. This suggests that ManiNegâ€™s
strategy of explicitly sampling hard negative samples endows
it with enhanced robustness against the baseline approaches.
Multimodal. Given that ManiNeg integrates manifestation
data during the batch sampling phase, it logically extends to
include this modality in the pretraining process as well. The
outcomes of multimodal pretraining are available in Tables VI
10
IEEE TRANSACTIONS AND JOURNALS TEMPLATE
TABLE IV
UNIMODAL PRETRAINING RESULTS ON MVKL (MEANÂ±STD).
LP
LE
FT
Uniform
57.71Â±1.75
72.47Â±0.64
76.38Â±0.72
vMF [31]
60.45Â±1.23
71.72Â±0.75
77.53Â±0.19
ManiNeg
60.46Â±1.22
72.73Â±0.27
77.54Â±1.15
TABLE V
UNIMODAL PRETRAINING RESULTS ON CBIS-DDSM (MEANÂ±STD).
LP
LE
FT
Uniform
63.38Â±0.70
67.06Â±0.45
72.33Â±1.02
vMF [31]
60.58Â±1.06
65.46Â±0.52
72.00Â±0.45
ManiNeg
64.64Â±0.91
67.44Â±1.56
72.92Â±0.82
and VII, representing evaluations on the MVKL and CBIS-
DDSM datasets, respectively.
Incorporating manifestation data into pretraining enables
the model to identify lesion-specific information within the
images, leveraging the manifestations as a guide. The results
indicate a significant performance uplift with ManiNeg in this
multimodal setting compared to baseline methods, highlighting
the added value of multimodal integration.
An additional insight from these evaluations is the perfor-
mance of the vMF method relative to the uniform sampling ap-
proach. Although the vMF was conceived as an enhancement
over the uniform method, it occasionally produces inferior
outcomes across several tests. The vMF approach, despite its
intent to refine the selection of negative samples within a
uniformly sampled minibatch, can, based on its hyperparam-
eter settings, apply a more aggressive weighting to negative
samples than what is seen with cross-entropy weighting in uni-
form sampling. This aggressive approach could exacerbate the
challenges related to misalignment between representation and
semantics, as well as sampling efficiency. The empirical data
from these experiments supports this hypothesis, illustrating
the nuanced impact of different negative sampling strategies
on model performance.
TABLE VI
MULTIMODAL PRETRAINING RESULTS ON MVKL (MEANÂ±STD).
LP
LE
FT
Uniform
63.52Â±0.82
73.78Â±0.67
77.75Â±0.37
vMF [31]
59.11Â±1.16
72.01Â±0.69
76.44Â±0.41
ManiNeg
65.16Â±1.26
74.36Â±0.35
79.82Â±0.51
Multimodal Alignment. Ideal hard negative samples play
a pivotal role in enhancing a modelâ€™s feature extraction ca-
pabilities, leading to more informative representations. This
benefit is particularly evident through modality alignment,
where models pretrained with ManiNeg, uniform, and vMF
approaches are assessed for their ability to align image and
manifestation representations. In experiments, the cosine dis-
tance between image and manifestation representations of all
TABLE VII
MULTIMODAL PRETRAINING RESULTS ON CBIS-DDSM (MEANÂ±STD).
LP
LE
FT
Uniform
60.88Â±0.88
67.47Â±0.70
70.51Â±0.71
vMF [31]
63.78Â±1.57
64.03Â±1.40
70.60Â±0.55
ManiNeg
64.71Â±0.93
70.54Â±0.90
74.55Â±0.99
positive pairs in the test set was measured, with results plotted
in Fig. 6. These findings indicate that ManiNeg achieves
the smallest inter-modal distance, suggesting that the image
branch of the model has effectively assimilated more informa-
tion from the manifestations, thereby improving the precision
in localizing and analyzing lesions.
VI. DISCUSSIONS
While ManiNeg demonstrates theoretical and empirical ad-
vantages, a consideration of its application scenarios is crucial
for its broader adoption across datasets and tasks. ManiNeg,
similar to the uniform method, predicates on certain assump-
tions regarding the data, especially concerning the semantic
proxy, such as manifestations. For the proxyâ€™s differences to
meaningfully reflect semantic distinctions, the semantic proxy
must be thoughtfully curated. Furthermore, given ManiNegâ€™s
reliance on Hamming distanceâ€”which treats disparities in the
semantic proxy uniformlyâ€”each aspect of the proxy should
contribute equitably to the downstream taskâ€™s objectives. A
scenario where a specific trait directly correlates with the taskâ€™s
outcome (often the â€™gold standardâ€™ in medical contexts) might
render the semantic proxyâ€™s Hamming distance ineffectual,
making supervised contrastive learning [12] a more fitting
approach. However, the trend in contrastive learning towards
generating universal representations that are not narrowly
tailored to a single task implies that ManiNegâ€™s uniform
treatment of semantic proxy elements could offer enhanced
generalization for diverse downstream tasks. The effectiveness
of ManiNegâ€™s sampling also depends on the distribution of
the semantic proxy, which is influenced by the dataâ€™s intrinsic
properties and the proxyâ€™s design. To ensure sampling ef-
fectiveness, the procedure illustrated in Fig. 5(b) should be
employed to validate ManiNegâ€™s applicability to new datasets,
with larger semantic proxies likely yielding benefits due to the
central limit theorem.
A key goal of deep learning, and self-supervised learn-
ing in particular, is to minimize annotation costs. Although
ManiNeg necessitates the additional step of annotating man-
ifestationsâ€”a task not typically included in clinical work-
flowsâ€”the medical training required for accurate annotation
ensures that this process remains feasible, albeit potentially
limiting ManiNegâ€™s large-scale application. Thus, for extensive
pretraining across a broad spectrum of tasks with ample data,
utilizing large batch sizes and the uniform method may be
practical. Conversely, in specialized fields with constrained
data volumes, where the inefficiency of hard negative sampling
becomes a significant issue, the annotation costs become
justifiable, positioning ManiNeg as a preferable solution.
AUTHOR et al.: TITLE
11
0.6
0.8
1.0
Cosine Distance
(a) ManiNeg, mean distance=0.745
0.00
0.05
0.10
0.15
Freq
0.7
0.8
0.9
1.0
1.1
Cosine Distance
(b) Uniform, mean distance=0.912
0.00
0.05
0.10
Freq
0.4
0.6
0.8
1.0
1.2
Cosine Distance
(c) vMF, mean distance=0.848
0.00
0.05
0.10
0.15
Freq
Histogram
Fig. 6. Multimodal alignment illustrations. The models pretrained in the multimodal scenario with (a) ManiNeg, (b) uniform, and (c) vMF are used to
plot histograms of the cosine distances between image representations and manifestation representations for all positive pairs in the test set. The
mean distance is noted in the histogram titles and marked on the histograms with blue vertical lines.
Future developments for ManiNeg will focus on extending
its application to diverse datasets and tasks, including those
on a larger scale. Addressing the challenges of designing
and acquiring a suitable semantic proxy modality will be
critical. Data-driven approaches may offer solutions to these
challenges, warranting further exploration into ManiNegâ€™s
robustness against noise and its adaptability beyond tabular
data to other accessible modalities and similarity measures.
These considerations will guide the direction of ManiNegâ€™s
ongoing evolution and its potential broadening to encompass
a wider array of applications.
VII. CONCLUSION
The development of ManiNeg is aimed at addressing spe-
cific challenges encountered in the self-supervised contrastive
learning process for mammographic imaging. In this study,
we introduce ManiNeg, a novel hard negative sample sam-
pling scheme designed for mammographic contrastive learn-
ing. Diverging from traditional uniform sampling methods,
ManiNeg leverages the manifestation modality as a semantic
proxy, enabling direct sampling of hard negative samples. This
innovative approach effectively tackles the potential misalign-
ment between representations and semantics, as well as the
efficiency issues inherent in uniform sampling. Demonstrated
through both sampling demonstrations and downstream task
validations, ManiNegâ€™s sampling scheme has shown significant
advantages, highlighting its effectiveness in enhancing model
learning and performance.
We firmly believe that the concept of directly sampling hard
negative samples holds substantial promise for advancing the
field of contrastive learning, particularly in medical imaging
contexts. Consequently, our future endeavors will concentrate
on expanding the application of ManiNeg across a broader
spectrum of datasets and tasks. Additionally, we will explore
the utilization of different semantic proxies to further refine
and adapt the ManiNeg approach. By continuing to evolve
ManiNeg, we aim to unlock new potentials in self-supervised
learning, paving the way for more accurate and efficient
diagnostic tools in mammography and beyond.
REFERENCES
[1]
R. L. Siegel, K. D. Miller, N. S. Wagle, and A. Jemal, â€œCancer
statistics, 2023,â€ Ca Cancer J Clin, vol. 73, no. 1, pp. 17â€“48, 2023.
[2]
T. Wang and P. Isola, â€œUnderstanding contrastive representation
learning through alignment and uniformity on the hypersphere,â€
in International Conference on Machine Learning, PMLR, 2020,
pp. 9929â€“9939.
[3]
T. Chen, S. Kornblith, M. Norouzi, and G. Hinton, â€œA simple frame-
work for contrastive learning of visual representations,â€ in Interna-
tional conference on machine learning, PMLR, 2020, pp. 1597â€“1607.
[4]
K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick, â€œMomentum contrast
for unsupervised visual representation learning,â€ in Proceedings of the
IEEE/CVF conference on computer vision and pattern recognition,
2020, pp. 9729â€“9738.
[5]
A. S. Elkorany and Z. F. Elsharkawy, â€œEfficient breast cancer
mammograms diagnosis using three deep neural networks and term
variance,â€ Scientific Reports, vol. 13, no. 1, p. 2663, 2023.
[6]
M. Prodan, E. Paraschiv, and A. Stanciu, â€œApplying deep learning
methods for mammography analysis and breast cancer detection,â€
Applied Sciences, vol. 13, no. 7, p. 4272, 2023.
[7]
T. Karras, S. Laine, and T. Aila, â€œA style-based generator archi-
tecture for generative adversarial networks,â€ in Proceedings of the
IEEE/CVF conference on computer vision and pattern recognition,
2019, pp. 4401â€“4410.
[8]
A. Saber, A. G. Hussien, W. A. Awad, A. Mahmoud, and A. Allakany,
â€œAdapting the pre-trained convolutional neural networks to improve
the anomaly detection and classification in mammographic images,â€
Scientific Reports, vol. 13, no. 1, p. 14 877, 2023.
[9]
Z. Cao, Z. Yang, X. Zhuo, et al., â€œDeeplima: Deep learning based le-
sion identification in mammograms,â€ in Proceedings of the IEEE/CVF
International Conference on Computer Vision (ICCV) Workshops,
2019.
[10]
Y. Liu, F. Zhang, C. Chen, S. Wang, Y. Wang, and Y. Yu, â€œAct like a
radiologist: Towards reliable multi-view correspondence reasoning for
mammogram mass detection,â€ IEEE Transactions on Pattern Analysis
and Machine Intelligence, vol. 44, no. 10, pp. 5947â€“5961, 2021.
[11]
M. Kallenberg, K. Petersen, M. Nielsen, et al., â€œUnsupervised deep
learning applied to breast density segmentation and mammographic
risk scoring,â€ IEEE transactions on medical imaging, vol. 35, no. 5,
pp. 1322â€“1331, 2016.
[12]
P. Khosla, P. Teterwak, C. Wang, et al., â€œSupervised contrastive
learning,â€ Advances in neural information processing systems, vol. 33,
pp. 18 661â€“18 673, 2020.
[13]
M. Caron, I. Misra, J. Mairal, P. Goyal, P. Bojanowski, and A. Joulin,
â€œUnsupervised learning of visual features by contrasting cluster
assignments,â€ Advances in neural information processing systems,
vol. 33, pp. 9912â€“9924, 2020.
[14]
A. Radford, J. W. Kim, C. Hallacy, et al., â€œLearning transferable
visual models from natural language supervision,â€ in International
conference on machine learning, PMLR, 2021, pp. 8748â€“8763.
[15]
K. He, X. Zhang, S. Ren, and J. Sun, â€œDeep residual learning
for image recognition,â€ in Proceedings of the IEEE conference on
computer vision and pattern recognition, 2016, pp. 770â€“778.
[16]
A. Dosovitskiy, L. Beyer, A. Kolesnikov, et al., â€œAn image is worth
16x16 words: Transformers for image recognition at scale,â€ ICLR,
2021.
[17]
A. Vaswani, N. Shazeer, N. Parmar, et al., â€œAttention is all you need,â€
Advances in neural information processing systems, vol. 30, 2017.
[18]
F. Faghri, D. J. Fleet, J. R. Kiros, and S. Fidler, â€œVse++: Improving
visual-semantic embeddings with hard negatives,â€ in Proceedings
of the British Machine Vision Conference (BMVC), 2018. [Online].
Available: https://github.com/fartashf/vsepp.
[19]
W. Kim, B. Son, and I. Kim, â€œVilt: Vision-and-language transformer
without convolution or region supervision,â€ in International Confer-
ence on Machine Learning, PMLR, 2021, pp. 5583â€“5594.
[20]
W. Wang, H. Bao, L. Dong, et al., â€œImage as a foreign language:
BEiT pretraining for vision and vision-language tasks,â€ in Proceed-
12
IEEE TRANSACTIONS AND JOURNALS TEMPLATE
ings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, 2023.
[21]
A. Van Den Oord, O. Vinyals, et al., â€œNeural discrete representation
learning,â€ Advances in neural information processing systems, vol. 30,
2017.
[22]
J. Li, R. Selvaraju, A. Gotmare, S. Joty, C. Xiong, and S. C. H. Hoi,
â€œAlign before fuse: Vision and language representation learning with
momentum distillation,â€ Advances in neural information processing
systems, vol. 34, pp. 9694â€“9705, 2021.
[23]
H. Bao, W. Wang, L. Dong, et al., â€œVlmo: Unified vision-
language
pre-training
with
mixture-of-modality-experts,â€
arXiv
preprint arXiv:2111.02358, 2021.
[24]
J. Li, D. Li, C. Xiong, and S. Hoi, â€œBlip: Bootstrapping language-
image pre-training for unified vision-language understanding and gen-
eration,â€ in International Conference on Machine Learning, PMLR,
2022, pp. 12 888â€“12 900.
[25]
X. Chen, X. Wang, S. Changpinyo, et al., â€œPali: A jointly-scaled mul-
tilingual language-image model,â€ arXiv preprint arXiv:2209.06794,
2022.
[26]
H.-Y. Zhou, X. Chen, Y. Zhang, R. Luo, L. Wang, and Y. Yu,
â€œGeneralized radiograph representation learning via cross-supervision
between images and free-text radiology reports,â€ Nature Machine
Intelligence, vol. 4, no. 1, pp. 32â€“40, 2022.
[27]
P. Hager, M. J. Menten, and D. Rueckert, â€œBest of both worlds:
Multimodal contrastive learning with tabular and imaging data,â€ in
Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, 2023, pp. 23 924â€“23 935.
[28]
R. Cao, Y. Wang, Y. Liang, et al., â€œExploring the impact of negative
samples of contrastive learning: A case study of sentence embedding,â€
in Findings of the Association for Computational Linguistics: ACL
2022, 2022, pp. 3138â€“3152.
[29]
M. Wu, M. Mosse, C. Zhuang, D. Yamins, and N. Goodman,
â€œConditional negative sampling for contrastive learning of visual
representations,â€ in International Conference on Learning Represen-
tations, 2020.
[30]
Y. Kalantidis, M. B. Sariyildiz, N. Pion, P. Weinzaepfel, and D. Larlus,
â€œHard negative mixing for contrastive learning,â€ Advances in Neural
Information Processing Systems, vol. 33, pp. 21 798â€“21 809, 2020.
[31]
J. Robinson, C.-Y. Chuang, S. Sra, and S. Jegelka, â€œContrastive
learning with hard negative samples,â€ International Conference on
Learning Representations, 2021.
[32]
F. Radenovic, A. Dubey, A. Kadian, et al., â€œFiltering, distillation, and
hard negatives for vision-language pre-training,â€ in Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition,
2023, pp. 6967â€“6977.
[33]
A. Tabassum, M. Wahed, H. Eldardiry, and I. Lourentzou, â€œHard
negative sampling strategies for contrastive representation learning,â€
arXiv preprint arXiv:2206.01197, 2022.
[34]
S. Ge, S. Mishra, C.-L. Li, H. Wang, and D. Jacobs, â€œRobust
contrastive learning using negative samples with diminished seman-
tics,â€ Advances in Neural Information Processing Systems, vol. 34,
pp. 27 356â€“27 368, 2021.
[35]
J. O. Neill and D. Bollegala, â€œSemantically-conditioned nega-
tive samples for efficient contrastive learning,â€ arXiv preprint
arXiv:2102.06603, 2021.
[36]
X. Wang, Y. Peng, L. Lu, Z. Lu, M. Bagheri, and R. M. Summers,
â€œChestx-ray8: Hospital-scale chest x-ray database and benchmarks on
weakly-supervised classification and localization of common thorax
diseases,â€ in Proceedings of the IEEE conference on computer vision
and pattern recognition, 2017, pp. 2097â€“2106.
[37]
R. S. Lee, F. Gimenez, A. Hoogi, K. K. Miyake, M. Gorovoy, and
D. L. Rubin, â€œA curated mammography data set for use in computer-
aided detection and diagnosis research,â€ Scientific data, vol. 4, no. 1,
pp. 1â€“9, 2017.
[38]
E. D. Cubuk, B. Zoph, J. Shlens, and Q. V. Le, â€œRandaugment:
Practical automated data augmentation with a reduced search space,â€
in Proceedings of the IEEE/CVF conference on computer vision and
pattern recognition workshops, 2020, pp. 702â€“703.
