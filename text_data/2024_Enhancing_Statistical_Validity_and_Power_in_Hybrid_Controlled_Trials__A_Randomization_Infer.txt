Enhancing Statistical Validity and Power in
Hybrid Controlled Trials: A Randomization
Inference Approach with Conformal
Selective Borrowing
Ke Zhu1,2, Shu Yangâˆ—1, and Xiaofei Wang2
1Department of Statistics, North Carolina State University, Raleigh, NC 27695, USA
2Department of Biostatistics and Bioinformatics, Duke University, Durham, NC 27710, USA
Abstract
Randomized controlled trials (RCTs) are the gold standard for causal inference
but may lack power because of small populations in rare diseases and limited par-
ticipation in common diseases due to equipoise concerns. Hybrid controlled trials,
which integrate external controls (ECs) from historical studies or large observational
data, improve statistical efficiency and are appealing for drug evaluations. However,
non-randomized ECs can introduce biases and inflate the type I error rate, especially
when the RCT sample size is small. To address this, we propose a Fisher randomiza-
tion test (FRT) that employs a semiparametric efficient test statistic combining RCT
and EC data, with assignments resampled using the actual randomization procedure.
The proposed FRT controls the type I error rate even with unmeasured confounding
among ECs. However, borrowing biased ECs can reduce FRT power, so we introduce
conformal selective borrowing (CSB) to individually borrow comparable ECs. We
propose an adaptive procedure to determine the selection threshold, minimizing the
mean squared error of a class of CSB estimators and enhancing FRT power. The
advantages of our method are demonstrated through simulations and an application
to a lung cancer RCT with ECs from the National Cancer Database. Our method is
available in the R package intFRT.
Keywords: causal inference, data fusion, randomization test, real-world data and evidence,
small sample size
âˆ—Address for correspondence: Shu Yang, Department of Statistics, North Carolina State University, NC
27695, USA. Email: syang24@ncsu.edu
1
arXiv:2410.11713v2  [stat.ME]  14 Nov 2024
1
Introduction
Randomized controlled trials (RCTs) are the gold standard for making causal inferences
on the treatment effect of a new treatment relative to a control treatment. However, large
RCTs are often infeasible to conduct in practice when the indications of interest involve
rare diseases (U.S. Food and Drug Administration 2022) or common conditions where few
patients are willing to participate due to a lack of equipoise (Miller & Joffe 2011). As
a result, RCTs in such a context often lack sufficient statistical power to detect realistic
treatment effect sizes. Meanwhile, historical studies or large external databases contain
observational real-world data (RWD) under control conditions. Hybrid controlled trials
have attracted extensive interest as an effective tool to increase the power of RCTs with
small sample sizes. However, most existing methods for such trials rely on asymptotic p-
values. The type I error rate in hybrid controlled trials is often inflated due to small sample
sizes and potential biases associated with ECs. Moreover, since ECs are not randomized,
they may systematically differ from randomized controls (RCs), even after adjusting for
measured confounders. Directly incorporating these ECs may introduce hidden bias into the
RCT analysis, compromising the validity of the statistical inference. Strictly controlling
the type I error rate in hybrid controlled trials, especially with small sample sizes and
unmeasured confounding, remains an open problem.
To address this problem, we extend the randomization inference framework to hybrid
controlled trials. To utilize ECs, we use a doubly robust estimator of the average treatment
effect (ATE) as the test statistic, which incorporates both RCT and EC data and effectively
balances the measured confounders between RCT and EC (Li et al. 2023). Then, Fisher
randomization tests (FRTs) are performed using only the randomization in the RCT. In
contrast to the asymptotic inference in Li et al. (2023), which relies on (i) large sample
2
sizes for both the RCT and EC, (ii) correct specification of at least one of the two nuisance
models, and (iii) no unmeasured confounders, the FRT strictly controls the type I error rate
without requiring any of these conditions, thus achieving model-free, finite-sample exact
inference. The validity of the FRT relies solely on the randomization within the RCT,
which is typically well-managed by the study design. Furthermore, we perform a power
analysis for FRT in hybrid controlled trials and show that incorporating unbiased ECs with
correctly specified models can enhance statistical power. However, EC borrowing is not a
free lunch, as we find that including biased ECs may diminish power.
The power issue motivates us to to develop a method that selectively incorporates
unbiased ECs rather than indiscriminately borrowing all ECs Unlike observational studies,
where the assumption of no unmeasured confounders is untestable, a key advantage of
hybrid controlled trials is that the bias in ECs can be identified by comparing EC units to
RC units, allowing us to test the comparability of ECs. Leveraging this advantage, existing
methods mitigate hidden bias by penalized estimation and selective borrowing (Chen, Ning,
Shen & Qin 2021, Gao et al. 2023, Huang et al. 2023), where selection consistency depends
on asymptotic arguments, potentially leading to inferior performance in small samples.
We propose a novel approach called Conformal Selective Borrowing, which selec-
tively incorporates unbiased ECs using conformal inference (Vovk et al. 2005, Lei et al.
2018). We measure the bias of each EC using a score function that can flexibly accom-
modate either parametric or machine learning models. We then calibrate this score to
conformal p-values, which test the exchangeability of each EC. These conformal p-values
are valid in finite samples, distribution-free, and do not depend on the asymptotic prop-
erties of models. In summary, Conformal Selective Borrowing offers three advantages:
(i) it makes individual borrowing decisions for each EC, (ii) it is flexible in incorporating
3
RCT Treatment
RCT Control
External Control
Fisher Randomization Test
Conformal Selective Borrowing
Reasoned Basis for Inference
Improve
Power
Post-selection
Inference
Randomization
Comparison
Identification of Hidden BiasÂ 
Figure 1: Randomization inference in hybrid controlled trials.
either computationally efficient parametric models or off-the-shelf machine learning mod-
els for bias estimation, and (iii) it provides finite-sample guarantees and performs stably
with small samples. We consider four state-of-the-art variants of conformal inference: full
conformal, split conformal, jackknife+, and CV+ (Barber et al. 2021).
This paper proposes an FRT method with Conformal Selective Borrowing in hybrid
controlled trials. The proposed method leverages the two key advantages of hybrid con-
trolled trials: (i) randomization within the RCT data allows us to use FRT to control the
type I error rate, and (ii) the presence of RC enables us to evaluate bias in ECs using confor-
mal p-values, selectively borrow unbiased ECs, and enhance power. Furthermore, FRT can
straightforwardly account for selection uncertainty introduced by Conformal Selective
Borrowing and offer valid post-selection inference. Figure 1 illustrates the motivation and
advantages of the proposed methods in hybrid controlled trials. We identify a risk-benefit
trade-off in the power of FRT associated with different selection thresholds for the conformal
p-values. This trade-off is analogous to the mean squared error (MSE) trade-offs observed
in various data integration estimators in recent literature (Yang et al. 2023, Oberst et al.
2022, Lin et al. 2024). To ensure robust performance across varying bias magnitudes, we
4
propose a data-adaptive procedure for determining the selection threshold to minimize the
MSE of the Conformal Selective Borrowing estimator. The advantages of our methods
are demonstrated through simulation studies and a lung cancer randomized clinical trial
that integrates ECs from the National Cancer Database (NCDB).
1.1
Related work
Hybrid controlled trials aim to integrate ECs to boost RCT efficiency (Pocock 1976).
For an overview of RCT and RWD integration, see Colnet et al. (2024). A key challenge
is bias in ECs, which stems from factors like selection bias, non-concurrency, and measure-
ment error (U.S. Food and Drug Administration 2023). Statistically, biases are categorized
as measured and unmeasured confounding. Measured confounding, or covariate shift, refers
to systematic differences in observed covariates between RCs and ECs. To address mea-
sured confounding, covariate balancing techniques such as matching, inverse propensity
score weighting, calibration weighting, and their augmented counterparts can be employed
(Li et al. 2023, Valancius et al. 2024, Li & Luedtke 2023). When there is unmeasured
confounding between RCT and EC, a rich body of literature addresses the hidden bias by
various strategies, including test-then-pool (Viele et al. 2014, Yang et al. 2023, Gao & Yang
2023, Dang et al. 2023), subset or selective borrowing based on penalized bias estimation
(Chen, Ning, Shen & Qin 2021, Gao et al. 2023, Huang et al. 2023), bias correction (Stuart
& Rubin 2008, Cheng et al. 2023, Li & Jemielita 2023, van der Laan et al. 2024), using ECs
for improving nuisance function estimation (Schuler et al. 2022, Gagnon-Bartsch et al. 2023,
Karlsson et al. 2024), weighted combination (Chen et al. 2020, Chen, Zhang & Ye 2021,
Cheng & Cai 2021, Oberst et al. 2022, Rosenman et al. 2023, Chen et al. 2023), Bayesian
power prior methods (Hobbs et al. 2011, Kwiatkowski et al. 2024, Alt et al. 2024, Lin et al.
2024), and sensitivity analysis (Yi et al. 2023). None of these methods use randomization
5
inference or conformal inference to address unmeasured confounding in hybrid controlled
trials with a small sample size.
Randomization inference, introduced by Fisher (Fisher 1935), provides finite-sample
exact p-values for any test statistic and is widely endorsed (Rosenberger et al. 2019,
Proschan & Dodd 2019, Young 2019, Bind & Rubin 2020, Carter et al. 2023).
Ran-
domization tests are useful for small sample trials or complex designs, including cluster
experiments with few clusters (Rabideau & Wang 2021) and adaptive experiments (Simon
& Simon 2011, Plamadeala & Rosenberger 2012, Nair & Janson 2023, Freidling et al. 2024).
Randomization tests have appeared in regulatory guidance documents to ensure type I er-
ror rate control in adaptive designs when conventional statistical methods fail (European
Medicines Agency 2015, U.S. Food and Drug Administration 2019, Carter et al. 2023). For
an overview of randomization inference, see Zhang & Zhao (2023) and Ritzwoller et al.
(2024). Nevertheless, the randomization inference hasnâ€™t been applied to hybrid controlled
trials, especially with selective borrowing to address unmeasured confounding.
Conformal inference, or conformal prediction, is a model-free method providing
finite-sample valid uncertainty quantification for individual predictions (Vovk et al. 2005),
particularly useful in high-stakes scenarios with black-box machine learning models (An-
gelopoulos et al. 2023). Two main applications are most relevant to this paper. The first
involves using conformal inference to infer individual treatment effects (Chernozhukov et al.
2021, Lei & Cand`es 2021). The second line is in outlier detection (Guan & Tibshirani 2022,
Bates et al. 2023, Liang et al. 2024). These studies inspire us to treat biased ECs as outliers
and use conformal p-values to test their exchangeability. Our primary goal, however, is to
boost FRT power by selectively borrowing unbiased ECs with conformal p-values. The
adaptive selection threshold that minimized the estimatorâ€™s MSE is also a novel approach.
6
2
Randomization inference
2.1
Semiparametric efficient estimator
Consider nR patients in the RCT, nE patients in the EC group, and n = nR + nE
patients in total. Let S = 1 for patients in RCT and S = 0 for patients in the EC group.
Let the binary treatment denote by A, where A = 1 stands for treatment and A = 0 stands
for control. We denote T = {i : Ai = 1, Si = 1}, C = {i : Ai = 0, Si = 1}, R = T âˆªC, and
E = {i : Si = 0}. Let X denote the baseline covariates, Y denote the observed outcome,
and Y (0) and Y (1) denote the potential outcomes. In an RCT, we randomize nR patients
into either the treatment group or the control group based on the known propensity score
e(x) = P(A = 1 | X = x, S = 1). This results in n1 patients in the treatment group and n0
patients in the control group. For nE patients in the EC group, since all of them are under
control, we have A = 0 for S = 0. Let Ï€(x) = P(S = 1 | X = x) denote the sampling
score of participating in the RCT. We consider average treatment effect (ATE) in the RCT
population as our estimand Ï„ = E{Y (1) âˆ’Y (0) | S = 1}. For RCT data, the following
standard identification assumptions are considered (Imbens & Rubin 2015).
Assumption 1 (RCT identification). (i) (Consistency) Y = AY (1) + (1 âˆ’A)Y (0). (ii)
(Positivity) 0 < e(x) < 1 for all x such that fX|S(x|1) > 0, where fX|S(x|s) is the condi-
tional p.d.f. of X given S = s. (iii) (Randomization) Y (a) âŠ¥âŠ¥A | (X, S = 1), a = 0, 1.
Under Assumption 1, Ï„ is identifiable based on RCT data. We denote the conditional
outcome mean functions by Âµa(x) = E(Y | X = x, A = a, S = 1), a = 0, 1. We estimate
Âµa(x) and e(x) with only RCT data and denote the estimated functions by Ë†Âµa,R(x) and
7
Ë†e(x), respectively. An RCT-only doubly robust estimator of Ï„ is
Ë†Ï„R = 1
nR
X
iâˆˆR

Ë†Âµ1,R(Xi) +
Ai
Ë†e(Xi){Yi âˆ’Ë†Âµ1,R(Xi)} âˆ’Ë†Âµ0,R(Xi) âˆ’
1 âˆ’Ai
1 âˆ’Ë†e(Xi){Yi âˆ’Ë†Âµ0,R(Xi)}

,
which is referred to as the No Borrowing approach hereafter. In RCTs, since the propensity
score model e(x) is known, Ë†Ï„R is consistent and asymptotically normal regardless of whether
Âµa(x) is correctly specified for a = 0, 1. Thus, Ë†Ï„R serves as a model-assisted covariate-
adjusted ATE estimator whose asymptotic variance attains the semiparametric efficiency
bound if Âµa(x) is correctly specified for a = 0, 1 (Cao et al. 2009).
The efficiency of Ë†Ï„R could be improved by borrowing information from EC data. To
incorporate EC data for estimating Ï„, many scholars have considered the following assump-
tion (Li et al. 2023, Valancius et al. 2024).
Assumption 2 (Mean exchangeability). E{Y (0) | X, S = 0} = E{Y (0) | X, S = 1}.
Under Assumptions 1 and 2, Ï„ could be identified with both RCT and EC data. We
estimate Âµ0(x) with RCT and EC data and denote the estimated functions by Ë†Âµ0,R+E(x).
Let Ë†Ï€E(x) denote the estimated sampling score. The variance ratio between RC and EC
is denoted by r(x) = V{Y (0) | X = x, A = 0, S = 1}

V{Y (0) | X = x, A = 0, S = 0}.
Let Ë†rE(x) denote the estimated variance ratio. Li et al. (2023) proposed a doubly robust
estimator of Ï„ with RCT data and all EC data,
Ë†Ï„R+E = 1
nR
X
iâˆˆRâˆªE

Si Ë†Âµ1,R(Xi) + Si
Ai
Ë†e(Xi){Yi âˆ’Ë†Âµ1,R(Xi)} âˆ’Si Ë†Âµ0,R+E(Xi)
(1)
âˆ’Ë†Ï€E(Xi)
Si(1 âˆ’Ai) + (1 âˆ’Si)Ë†rE(Xi)
Ë†Ï€E(Xi){1 âˆ’Ë†e(Xi)} + {1 âˆ’Ë†Ï€E(Xi)}Ë†rE(Xi){Yi âˆ’Ë†Âµ0,R+E(Xi)}

,
which is referred to as the Full Borrowing approach hereafter.
The term â€œFullâ€ here
8
refers to incorporating the full set of ECs to construct Ë†Ï„R+E, while down-weighting those
ECs based on similarity measured by X, thereby addressing bias caused by observed con-
founders.
Ë†Ï„R+E is consistent and asymptotically normal if either (i) Âµa(x) is correctly
specified for a = 0, 1, or (ii) both Ï€(x) and e(x) are correctly specified.
If all models
for Âµa(x), a = 0, 1, Ï€(x), and e(x) are correctly specified, the asymptotic variance of Ë†Ï„R
achieves the semiparametric efficiency bound (Li et al. 2023).
However, asymptotic inference for Ë†Ï„R+E may be invalid due to three main reasons: (i) it
assumes nR â†’âˆ, which contradicts the motivation for EC borrowing, where the sample
size of the RCT is typically small; (ii) it relies on the correct specification of at least one of
the two nuisance models, which may be violated because sophisticated models are difficult
to work with under small sample sizes; and (iii) it depends on Assumption 2, which may
be violated due to unmeasured confounders. To address these issues, we consider a finite-
sample exact randomization inference framework that maintains strict type I error rate
control even if all models are misspecified and Assumption 2 fails. We consider Ë†Ï„R and
Ë†Ï„R+E as candidate test statistics and propose a new class of test statistics in Section 3 to
achieve improved power across various scenarios.
2.2
Fisher randomization test
In the randomization inference framework, we are conditional on the potential out-
comes Yi(a) and covariates Xi for i âˆˆR âˆªE, and consider the randomized assignment
A = (A1, . . . , An) as the sole source of randomness. Since Ai for i âˆˆR is well controlled
and known in the RCT, we can fully leverage this advantage to guarantee the validity of
inference without any additional distributional assumptions. Let A denote the set of all
possible assignments generated by the actual RCT design. Since all external units are under
control, we have Ai = 0 for i âˆˆE. In addition to Bernoulli trials where Ai
i.i.d.
âˆ¼Bernoulli(p)
9
for i âˆˆR, randomization inference can also accommodate more complex experimental de-
signs, such as randomized block experiments (Fisher 1926), covariate-adaptive randomized
experiments (Bugni et al. 2018), and rerandomized experiments (Morgan & Rubin 2012).
Consider Fisherâ€™s sharp null hypothesis H0 : Yi(0) = Yi(1), âˆ€i âˆˆR, which states no
treatment effect for any units in RCT. Based on H0, we could impute all potential outcomes
Y imp
i
(0) = Y imp
i
(1) = Yi for i âˆˆR. Let T(A) denote the test statistic, which depends on
the assignment A âˆˆA. T(A) could be |Ë†Ï„R(A)|, |Ë†Ï„R+E(A)|, or the estimator introduced in
Section 3. The theoretical guarantee of type I error rate control holds for any test statistic,
including those involving ECs, even if these ECs have hidden biases. This is one of the key
merits of randomization inference. We define the p-value for measuring the extremeness
of the observed T(A) against H0 as pFRT = PAâˆ—{T(Aâˆ—) â‰¥T(A)}, where Aâˆ—âˆˆA has the
same distribution as A and is independent of A, and PAâˆ—is taken over the distribution of
Aâˆ—.
Theorem 1. Under H0, for Î± âˆˆ(0, 1), we have PA(pFRT â‰¤Î±) â‰¤Î±, where PA is taken over
the distribution of A. If we further assume that T(A) takes distinct values for different
A âˆˆA, then we have PA(pFRT â‰¤Î±) = âŒŠÎ±|A|âŒ‹/|A| > Î± âˆ’1/|A|, where âŒŠxâŒ‹represents the
greatest integer less than or equal to x
In practice, we use Monte Carlo to approximate pFRT.
Based on the RCTâ€™s actual
randomization, we generate the new assignment Ab
i for i âˆˆR and set Ab
i â‰¡0 for i âˆˆE since
the randomization in the RCT does not affect the assignments of the ECs. We denote the
new assignment vector as Ab = (Ab
1, . . . , Ab
n). We repeatedly generate assignments for B
times and obtain Ë†pFRT =
 PB
b=1 I{T(Ab) â‰¥T(A)}+1

/(B +1), where we add one to both
the numerator and denominator to prevent Ë†pFRT from being zero (Phipson & Smyth 2010).
Theorem 1 shows that FRT exactly controls the type I error rate in finite samples,
10
regardless of Assumption 2, because, under H0, the reference distribution is derived from
true randomization, which is well-controlled in clinical trials. However, the power of FRT
depends on the choice of test statistic, which varies under different scenarios related to
Assumption 2.
2.3
Model-based power analysis
There are two primary approaches for conducting a power analysis of FRT: model-based
or simulation-based (Rosenberger & Lachin 2015, Lehmann & Romano 2022). We first
perform a model-based power analysis under Assumption 2, highlighting how low variance
of a consistent test statistic enhances the power of FRT. In the following section, we conduct
a simulation-based power analysis for a more challenging scenario where Assumption 2 does
not hold, demonstrating that the high bias of an inconsistent test statistic significantly
reduces the power of FRT.
Let M denote the total number of possible assignments, F1,n,M(t) = PA(T(A) â‰¤t)
denote the randomization distribution of T(A), and F0,n,M(t) = PAâˆ—(T(Aâˆ—) â‰¤t) denote
the reference distribution of T(Aâˆ—) under H0. Both F1,n,M and F0,n,M are discrete in finite
samples. To apply empirical process theory and derive asymptotic rates for testing power,
we assume continuous super-population distributions F1,n and F0,n, with F1,n,M and F0,n,M
representing the empirical distribution functions based on M independent samples drawn
from F1,n and F0,n, respectively.
In cases where these assumptions do not hold, FRT
still controls the type I error rate, and we will investigate its power through simulation
in Section 4. Based on those notations, the p-value and the power can be expressed as
pFRT = PAâˆ—{T(Aâˆ—) â‰¥T(A)} = 1 âˆ’F0,n,M
 T(A)

, and Ïˆn,M = PA(pFRT â‰¤Î±) = PA{1 âˆ’
F0,n,M
 T(A)

â‰¤Î±} = 1 âˆ’F1,n,M
 F âˆ’1
0,n,M(1 âˆ’Î±)

.
Theorem 2. For fixed n > 0, suppose the following conditions hold:
11
(a) There are continuous cumulative distribution functions (c.d.f.) F0,n and F1,n, such
that F0,n,M and F1,n,M are the empirical distribution functions based on M independent
samples drawn from F0,n and F1,n, respectively.
(b) There is Ïƒn > 0 and a continuous c.d.f. F such that F0,n(t) = F(t/Ïƒn) for all t âˆˆR.
(c) For ATE Ï„, F1,n(t) = F0,n(t âˆ’Ï„) = F
 (t âˆ’Ï„)/Ïƒn

, for all t âˆˆR.
For 0 < Î¹ < 0.5 and large enough M, we have E(Ïˆn,M) â‰¥1 âˆ’F (F âˆ’1(1 âˆ’Î±) âˆ’Ï„/Ïƒn) âˆ’
O (M âˆ’0.5+Î¹), where E is taken with respect to M independent samples drawn from F0,n and
F1,n.
For a given Ï„ Ì¸= 0, significance level Î±, and design with possible assignments M, Theorem
2 shows that the power of the FRT also depends on the variance of the test statistic, Ïƒn.
Under Assumptions 1 and 2, and with all working models correctly specified, Ë†Ï„R+E is
consistent and has a variance that is less than or equal to that of Ë†Ï„R (Li et al. 2023).
Consequently, using Ë†Ï„R+E as the test statistic improves the power of the FRT compared to
using Ë†Ï„R, as confirmed by simulations in Section 4 and subplot (B) in Figure 2.
2.4
Simulation-based power analysis
When unmeasured confounding exists between RCT and EC data, Assumption 2 is
violated, rendering Ë†Ï„R+E inconsistent. In such cases, asymptotic inference based on Ë†Ï„R+E is
invalid and fails to control the type I error rate. In contrast, since Theorem 1 holds for any
test statistic, FRT can still control the type I error with the inconsistent test statistic Ë†Ï„R+E,
highlighting a core merit of FRTs. However, the violation of Assumption 2 subsequently
causes Assumption (c) in Theorem 2 to be unfulfilled, rendering FRT with Ë†Ï„R+E unable
to achieve a power improvement over FRT with Ë†Ï„R. Furthermore, employing Ë†Ï„R+E as the
test statistic results in a substantial loss of power compared to using Ë†Ï„R, as illustrated in
12
Type I error = 0.048
Type I error = 0.038
Type I error = 0.066
0.00
0.25
0.50
0.75
1.00
0
10
20
0
10
20
0
10
20
Exact pâˆ’value
(A) Distribution under H0 (No Hidden Bias in ECs)
Power = 0.334
Power = 0.486
Power = 0.484
0.00
0.25
0.50
0.75
1.00
0
50
100
150
0
50
100
150
0
50
100
150
Exact pâˆ’value
(B) Distribution under H1 (No Hidden Bias in ECs)
Type I error = 0.048
Type I error = 0.056
Type I error = 0.064
0.00
0.25
0.50
0.75
1.00
0
10
20
0
10
20
0
10
20
Exact pâˆ’value
(C) Distribution under H0 (Hidden Bias in ECs)
Power = 0.334
Power = 0.186
Power = 0.454
0.00
0.25
0.50
0.75
1.00
0
50
100
150
0
50
100
150
0
50
100
150
Exact pâˆ’value
(D) Distribution under H1 (Hidden Bias in ECs)
Method
No Borrow (Î³ = 1)
Full Borrow (Î³ = 0)
Conformal Selective Borrow (Î³^)
Figure 2: Simulated distributions of p-values under H0 and H1.
subplot (D) of Figure 2.
Based on the power analysis, we find that, compared to Ë†Ï„R, Ë†Ï„R+E improves the power
of the FRT by leveraging all ECs under Assumption 2, but results in a severe decrease in
power when Assumption 2 does not hold. The trade-off between Ë†Ï„R and Ë†Ï„R+E generally
arises between a causal estimator that ignores additional information and assumptions,
and one that incorporates them but risks bias if the assumptions fail (RothenhÂ¨ausler 2020,
RothenhÂ¨ausler et al. 2021). In the next section, instead of choosing between Ë†Ï„R and Ë†Ï„R+E, we
construct a class of ATE estimators, Ë†Ï„Î³, indexed by a tuning parameter Î³ and encompassing
Ë†Ï„R and Ë†Ï„R+E as special cases. We then propose a data-adaptive procedure to select Î³ that
minimizes the MSE of Ë†Ï„Î³, thereby enhancing the power of FRT when using Ë†Ï„Î³ as the test
statistic.
13
3
Conformal Selective Borrowing
Motivated by realistic scenarios in which some ECs satisfy Assumption 2 while oth-
ers do not, we propose a Conformal Selective Borrowing approach that uses conformal
inference to select comparable ECs. We propose conformal p-values pâˆ—
j âˆˆ(0, 1] to test
the exchangeability of each individual EC j âˆˆE. The selected EC set is then defined as
Ë†E(Î³) = {j âˆˆE : pâˆ—
j > Î³}, where Î³ âˆˆ[0, 1] is a selection threshold. Substituting E with Ë†E(Î³)
in (1), we obtain,
Ë†Ï„Î³ = 1
nR
X
iâˆˆRâˆªË†E(Î³)

Si Ë†Âµ1,R(Xi) + Si
Ai
Ë†e(Xi){Yi âˆ’Ë†Âµ1,R(Xi)} âˆ’Si Ë†Âµ0,R+ Ë†E(Î³)(Xi)
(2)
âˆ’Ë†Ï€ Ë†E(Î³)(Xi)
Si(1 âˆ’Ai) + (1 âˆ’Si)Ë†r Ë†E(Î³)(Xi)
Ë†Ï€ Ë†E(Î³)(Xi){1 âˆ’Ë†e(Xi)} + {1 âˆ’Ë†Ï€ Ë†E(Î³)(Xi)}Ë†r Ë†E(Î³)(Xi){Yi âˆ’Ë†Âµ0,R+ Ë†E(Î³)(Xi)}

.
The proposed methods represent a class of ATE estimators: when Ë†E(1) = âˆ…with no
ECs borrowed, let Ë†Ï„1 â‰¡Ë†Ï„R; when Ë†E(0) = E with all ECs borrowed, we have Ë†Ï„0 = Ë†Ï„R+E.
Hereafter, we will use Ë†Ï„1 and Ë†Ï„0 to refer to the No Borrowing and Full Borrowing ATE
estimators, respectively. For 0 < Î³ < 1, Ë†Ï„Î³ balances the trade-off between borrowing more
ECs with a smaller Î³ and discarding more ECs with a larger Î³. By using T(A) = |Ë†Ï„Î³| as
the test statistic for FRT and allowing Ë†E(Î³) to vary with resampling A in FRT, it could
account for selection uncertainty and provide valid post-selection inference by Theorem 1.
Figure 2 shows that the Conformal Selective Borrowing can improve power compared
to the No Borrowing, regardless of whether Assumption 2 holds for all ECs. The next two
sections introduce how to compute conformal p-values and a data-adaptive procedure for
selecting Î³ to minimize the MSE of Ë†Ï„Î³.
14
3.1
Conformal p-values
3.1.1
Full conformal p-value
We first consider full conformal inference (Vovk et al. 2005), which fully utilizes all data
in C for both training and calibration. We use a score function s(x, y) to measure the
â€œnonconformityâ€ of (x, y).
For example, we can use the absolute residual as the score
function: si = |Yi âˆ’Ë†fj(Xi)| for i âˆˆC and sj = |Yj âˆ’Ë†fj(Xj)|, where Ë†fj(x) is a prediction
model fitted by the augmented set C âˆª{j}. Intuitively, if (Xj, Yj) is not exchangeable
(see Remark 1 for a formal definition) with {(Xi, Yi)}iâˆˆC, sj should be large compared to
{si}iâˆˆC. To measure the extremeness of observing sj under the exchangeability, we define
the full conformal p-value as the proportion of the elements in {si}iâˆˆC that are larger than
or equal to sj:
pfull
j
=
P
iâˆˆC I(si â‰¥sj) + 1
|C| + 1
,
where I is the indicator function, and the â€œ+1â€ accounts for including sj itself. If pfull
j
is
smaller than a threshold Î³, we reject the hypothesis of exchangeability and discard EC j.
We have the following theoretical guarantee, which states that if EC j is exchangeable with
the RCs, the rejection rate is less than Î³.
Proposition 1. For an EC j âˆˆE, suppose that (Xj, Yj) and the RCs {(Xi, Yi)}iâˆˆC are
exchangeable. For Î³ âˆˆ(0, 1), we have P(pfull
j
â‰¤Î³) â‰¤Î³. Further assuming sj and {si}iâˆˆC
have distinct values, we have P(pfull
j
â‰¤Î³) =

âŒŠÎ³ (|C| + 1)âŒ‹
	 
(|C| + 1) > Î³ âˆ’1/(|C| + 1).
Remark 1 (Definition of exchangeability). The random variables z1, . . . , zn are exchange-
able if, for any permutation Ï‰ of 1, . . . , n, the random variables zÏ‰(1), . . . , zÏ‰(n) have the
same joint distribution as z1, . . . , zn. The i.i.d. assumption is stronger than exchange-
ability, as the latter can hold with dependence (Shafer & Vovk 2008). The exchangeability
15
required by conformal inference is stronger than the mean exchangeability (Assumption 2),
which allows the construction of a statistically valid estimator within the asymptotic infer-
ence framework (Li et al. 2023, Valancius et al. 2024).
To compute full conformal p-values for all ECs j âˆˆE, the prediction model must be refit
nE times, which is time-consuming for large EC samples. Thus, we consider split conformal
inference (Papadopoulos et al. 2002), requiring only one model fit while preserving validity.
3.1.2
Split conformal p-value
We randomly split C into a calibration set C1 and a training set C \ C1 according to a
prespecified sample size ratio, for example, 1 : 2. We can still use the absolute residual as
the score function: si = |Yi âˆ’Ë†fâˆ’C1(Xi)| for i âˆˆC1 and sj = |Yj âˆ’Ë†fâˆ’C1(Xj)|, where Ë†fâˆ’C1(x)
is a prediction model fitted by the training set C \C1. We define the split conformal p-value
as the proportion of {si}iâˆˆC1 that are larger than sj,
psplit
j
=
P
iâˆˆC1 I(si â‰¥sj) + 1
|C1| + 1
.
Proposition 2. For an EC j âˆˆE, suppose that (Xj, Yj) and the RCs {(Xi, Yi)}iâˆˆC are
exchangeable. For Î³ âˆˆ(0, 1), we have P(psplit
j
â‰¤Î³) â‰¤Î³. Further assuming sj and {si}iâˆˆC
have distinct values, we have P(psplit
j
â‰¤Î³) =

âŒŠÎ³(|C1| + 1)âŒ‹
	 
(|C1| + 1) > Î³ âˆ’1/(|C1| + 1).
While split conformal p-values are computationally efficient, they lose statistical effi-
ciency due to data splitting. Next, we introduce Jackknife+ p-values (Barber et al. 2021),
which fully utilize training data and remain computationally feasible.
16
3.1.3
Jackknife+ p-value
We use the leave-one-out training set C \ {i} to fit prediction models Ë†fâˆ’i(x) and use the
absolute residual as the score function: si = |Yi âˆ’Ë†fâˆ’i(Xi)| and s(i)
j
= |Yj âˆ’Ë†fâˆ’i(Xj)| for
i âˆˆC. We define the Jackknife+ p-value as the proportion of {si}iâˆˆC that are larger than
the corresponding {s(i)
j }iâˆˆC,
pjackknife+
j
=
P
iâˆˆC I(si â‰¥s(i)
j ) + 1
|C| + 1
.
Proposition 3. For an EC j âˆˆE, suppose that (Xj, Yj) and the RCs {(Xi, Yi)}iâˆˆC are
exchangeable. For Î³ âˆˆ(0, 1), we have P(pjackknife+
j
â‰¤Î³) â‰¤2Î³ âˆ’1/(|C| + 1) < 2Î³.
Remark 2. The factor of 2 cannot be reduced without further assumptions, as shown by
pathological cases in Barber et al. (2021), though the empirical error rate is close to Î³.
We fit the prediction model using n0 leave-one-out datasets, which is feasible since n0
is usually small when borrowing ECs. If model fitting is computationally expensive, an
alternative is K-fold cross-validation, known as CV+ (Barber et al. 2021).
3.1.4
CV+ p-value
We randomly split C into K disjoint folds: C = âˆªK
k=1Ck. We use the training set C \ Ck
to fit prediction models Ë†fâˆ’Ck(x) and use the absolute residual as the score function: si =
|Yiâˆ’Ë†fâˆ’Ck(i)(Xi)| and s(i)
j
= |Yj âˆ’Ë†fâˆ’Ck(i)(Xj)| for i âˆˆC, where k(i) âˆˆ{1, . . . , K} is a function
that indicates i âˆˆCk. Thus, for i Ì¸= iâ€² and k(i) = k(iâ€²), we have s(i)
j
= s(iâ€²)
j . We define the
CV+ p-value as the proportion of {si}iâˆˆC that are larger than the corresponding {s(i)
j }iâˆˆC,
pcv+
j
=
P
iâˆˆC I(si â‰¥s(i)
j ) + 1
|C| + 1
.
17
The following theoretical guarantee is a generalization of Proposition 3, where K = |C|.
Proposition 4. For an EC j âˆˆE, suppose that (Xj, Yj) and the RCs {(Xi, Yi)}iâˆˆC are
exchangeable. For Î³ âˆˆ(0, 1), we have P(pcv+
j
â‰¤Î³) â‰¤2Î³+

(1âˆ’2Î³)(mâˆ’1)âˆ’1
	 
(|C|+m) <
2Î³ +
 1 âˆ’K/|C|

/ (K + 1), where m = |C|/K is assumed to be an integer for simplicity.
3.2
Adaptive selection threshold
Since we construct pâˆ—
j individually and make borrowing decisions collectively, one might
consider choosing a selection threshold Î³ that controls the family-wise type I error rate or
false discovery rate for testing the exchangeability of all ECs (Bates et al. 2023). However, in
our context, the power of the conformal tests is of greater concern. The classical test-then-
pool approach has been criticized for its low power in detecting hidden bias, particularly
when the sample size of randomized controls is small (Li et al. 2020). Even if we effectively
control the family-wise type I error rate, low-power conformal tests may still result in
many biased ECs being incorrectly borrowed, leading to an increase in the MSE of Ë†Ï„Î³ and
a reduction in the power of the FRT. Therefore, we propose a data-adaptive procedure to
directly minimize the MSE of Ë†Ï„Î³ and thereby improve the power of the FRT.
We decompose MSE(Î³) â‰¡E(Ë†Ï„Î³ âˆ’Ï„)2 = {E(Ë†Ï„Î³) âˆ’Ï„}2 + V(Ë†Ï„Î³). The main challenge
lies in estimating the squared bias {E(Ë†Ï„Î³ âˆ’Ï„)}2 as the true Ï„ is unknown. Fortunately,
since the No Borrowing estimator Ë†Ï„1 is consistent for Ï„, we approximate {E(Ë†Ï„Î³ âˆ’Ï„)}2 by
{E(Ë†Ï„Î³ âˆ’Ë†Ï„1)}2 = E(Ë†Ï„Î³ âˆ’Ë†Ï„1)2 âˆ’V(Ë†Ï„Î³ âˆ’Ë†Ï„1). We then use (Ë†Ï„Î³ âˆ’Ë†Ï„1)2 to estimate E(Ë†Ï„Î³ âˆ’Ë†Ï„1)2
and apply bootstrap to estimate V(Ë†Ï„Î³) and V(Ë†Ï„Î³ âˆ’Ë†Ï„1). Combining these yields estimated
MSE for each Î³ over finite grids, and we select Î³ that minimizes this estimated MSE. The
full procedure is outlined in Algorithm 1.
Finally, we theoretically analyze the data-adaptive selection threshold procedure from
a non-asymptotic perspective with a fixed n (Wainwright 2019).
We decompose Ë†Ï„Î³ =
18
Algorithm 1 Adaptive Selection Threshold
Input: Threshold grid Î“ = {0, 0.1, . . . , 1}, number of bootstrap samples L = 100.
for Î³ âˆˆÎ“ do
â–·Step 1 (ATE Estimation for Original and Bootstrap Samples)
Compute Ë†Ï„Î³ from the original sample.
for l = 1, . . . , L do
Compute Ë†Ï„ (l)
Î³
from the l-th bootstrap sample.
end for
end for
for Î³ âˆˆÎ“ \ {1} do
â–·Step 2 (MSE Calculation for Each Î³)
Compute bV(Ë†Ï„Î³ âˆ’Ë†Ï„1) = (L âˆ’1)âˆ’1 PL
l=1
n
(Ë†Ï„ (l)
Î³ âˆ’Ë†Ï„ (l)
1 ) âˆ’Lâˆ’1 PL
lâ€²=1(Ë†Ï„ (lâ€²)
Î³
âˆ’Ë†Ï„ (lâ€²)
1 )
o2
.
Compute bV(Ë†Ï„Î³) = (L âˆ’1)âˆ’1 PL
l=1

Ë†Ï„ (l)
Î³ âˆ’Lâˆ’1 PL
lâ€²=1 Ë†Ï„ (lâ€²)
Î³
2
.
Compute [
MSE(Î³) = (Ë†Ï„Î³ âˆ’Ë†Ï„1)2 âˆ’bV(Ë†Ï„Î³ âˆ’Ë†Ï„1) + bV(Ë†Ï„Î³).
end for
Compute [
MSE(1) = (L âˆ’1)âˆ’1 PL
l=1

Ë†Ï„ (l)
1 âˆ’Lâˆ’1 PL
lâ€²=1 Ë†Ï„ (lâ€²)
1
2
.
Find Ë†Î³ = arg minÎ³âˆˆÎ“ [
MSE(Î³).
â–·Step 3 (Optimal Threshold Selection)
Output: Ë†Î³.
Ï„ + Î´Î³ + ÏµÎ³, where Î´Î³ â‰¡E(Ë†Ï„Î³) âˆ’Ï„ and E(ÏµÎ³) = 0. Let Îº2
Î³ â‰¡V(Ë†Ï„Î³ âˆ’Ë†Ï„1) = V(ÏµÎ³ âˆ’Ïµ1) and
Ïƒ2
Î³ â‰¡V(Ë†Ï„Î³) = V(ÏµÎ³).
Theorem 3. For fixed n > 0 and Î³ âˆˆÎ“, suppose ÏµÎ³ is a centered sub-Gaussian variable
with parameter Ï•Î³ > 0, i.e., E {exp(Î»ÏµÎ³)} â‰¤exp
 Ï•2
Î³Î»2/2

for all Î» âˆˆR. For Î¹ > 0, there
exists a constant c > 0 such that with probability at least 1 âˆ’4Î¹, we have
max
Î³âˆˆÎ“
[
MSE(Î³) âˆ’MSE(Î³)
 â‰¤câˆ†|Î´1| + câˆ†Î¦
p
log (|Î“|/Î¹)
+ max
n
cÎ¦2p
log (|Î“|/Î¹), cÎ¦2 log (|Î“|/Î¹)
o
+ max
Î³âˆˆÎ“ |bV(Ë†Ï„Î³ âˆ’Ë†Ï„1) âˆ’Îº2
Î³| + max
Î³âˆˆÎ“ |bV(Ë†Ï„Î³) âˆ’Ïƒ2
Î³|,
where âˆ†= maxÎ³âˆˆÎ“ |Î´Î³|, Î¦ = maxÎ³âˆˆÎ“ Ï•Î³, Î´1 is the bias of the consistent estimator Ë†Ï„1, and
19
|Î“| is the cardinality of the set Î“.
Theorem 3 demonstrates that the discrepancy between the estimated MSE and the true
MSE vanishes as long as the maximum bias âˆ†is bounded and the bias of the consistent
estimator Ë†Ï„1, the maximum proxy variance Î¦, and the maximum errors in the two variance
estimations are sufficiently small.
Theorem 4. Under the same assumptions as in Theorem 3, for any Î¹ > 0, there exists a
constant c > 0 such that, with probability at least 1 âˆ’8Î¹, the following holds:
(Ë†Ï„Ë†Î³ âˆ’Ï„)2 âˆ’min
Î³âˆˆÎ“ (Ë†Ï„Î³ âˆ’Ï„)2 â‰¤2câˆ†|Î´1| + 2câˆ†Î¦
p
log (|Î“|/Î¹)
+ 2 max
n
cÎ¦2p
log (|Î“|/Î¹), cÎ¦2 log (|Î“|/Î¹)
o
+ 2 max
Î³âˆˆÎ“ |bV(Ë†Ï„Î³ âˆ’Ë†Ï„1) âˆ’Îº2
Î³| + 2 max
Î³âˆˆÎ“ |bV(Ë†Ï„Î³) âˆ’Ïƒ2
Î³|.
Theorem 4 provides a bound for the excess risk of Ë†Ï„Ë†Î³ in comparison to the oracle es-
timator. Although Ë†Ï„Ë†Î³ generally outperforms Ë†Ï„1 in terms of MSE, it may exhibit excess
risk in certain challenging cases, as shown in Figure 3 (C) in the simulation. This phe-
nomenon highlights the super-efficiency of Ë†Ï„Ë†Î³, similar to the behavior of the Hodges esti-
mator (Le Cam 1953) and recent integrated estimators in data fusion (Yang et al. 2023,
Oberst et al. 2022). Notably, FRT can still control the type I error rate even if excess risk
is present or the assumptions in Theorem 3 are not satisfied.
4
Simulation
We conduct simulations to evaluate the repeated sampling performance of the proposed
methods under small sample sizes and varying magnitudes of hidden bias, including chal-
lenging cases where separating biased ECs is difficult. Specifically, the sample sizes for
the RT, RC, and EC groups are set as (n1, n0, nE) = (50, 25, 50). Similar results for a
20
larger EC sample size (nE = 300) are included in the Supplemental Material. We generate
covariates X âˆ¼N(0, Ip) with dimension p = 2 and Ip is the identity matrix. The sampling
indicator S âˆ¼Bernoulli(Ï€(X)) is generated with Ï€(X) = {1 + exp (Î·0 + XTÎ·)}âˆ’1, where
Î·0 is chosen to ensure E(S) = nR/n, and Î· = (0.1, 0.1). The assignment is generated by
A âˆ¼Bernoulli(n1/nR) for S = 1 and A = 0 for S = 0. Let Îµ âˆ¼N(0, 1) denote the noise.
For the RCT sample (S = 1), we generate the potential outcomes as Y (0) = XTÎ²0 + Îµ
with Î²0 = (1, 1), and Y (1) = Ï„0 + XTÎ²1 + Îµ with Ï„0 = 0.4 and Î²1 = (2, 2). For the EC
sample (S = 0), we consider two scenarios: (i) the scenario without hidden bias, where
Y (0) = XTÎ²0 + 0.5Îµ; (ii) the scenario where part of the ECs have hidden bias b, where
a random proportion Ï of the ECs is biased, with Y (0) = âˆ’b + XTÎ²0 + 0.5Îµ, and the
remaining proportion (1 âˆ’Ï) are unbiased, with Y (0) = XTÎ²0 + 0.5Îµ. We consider pro-
portions of biased ECs Ï = 50% and magnitudes of hidden bias b = 1, 2, . . . , 8. Note that
hidden bias refers to bias that remains due to unmeasured confounders, even after bal-
ancing the observed covariates. Under the alternative hypothesis, the observed outcome is
Y = AY (1) + (1 âˆ’A)Y (0); under the null hypothesis, the observed outcome is Y = Y (0).
We consider No Borrowing (NB), Full Borrowing (FB), and Conformal Selective
Borrowing (CSB) as estimators of Ï„ and test statistics for FRT. We also consider Adaptive
Lasso Selective Borrowing (ALSB) by Gao et al. (2023). Given its higher computational
cost (approximately 10 times slower than CSB), we omit FRTs for this method and instead
compare CSB+FRT with ALSB+asymptotic inference. CV+ p-values are computed using
10 folds. We use Algorithm 1 to determine Ë†Î³. We also consider various fixed thresholds
Î³ = 0.4, 0.6, 0.8 in the Supplemental Material. We set B = 5000 to approximate pFRT and
replicate the simulation 500 times per scenario.
Figure 3 shows the main simulation results for FRTs. In the first case, with a hidden
21
0.0
0.2
0.4
0.6
0
2
4
6
8
Magnitude of Hidden Bias
(A) Absolute Bias
0.06
0.08
0.10
0.12
0.14
0
2
4
6
8
Magnitude of Hidden Bias
(B) Variance
0.1
0.3
0.5
0
2
4
6
8
Magnitude of Hidden Bias
(C) MSE
0.0
0.2
0.4
0.6
0
2
4
6
8
Magnitude of Hidden Bias
(D) Type I Error Rate
0.2
0.4
0.6
0
2
4
6
8
Magnitude of Hidden Bias
(E) Power
0.0
0.1
0.2
0.3
0.4
0.5
0
2
4
6
8
Magnitude of Hidden Bias
(F) #Biased / #Selected
Method
No Borrow (Î³ = 1)
Full Borrow (Î³ = 0)
Conformal Selective Borrow (Î³^)
Figure 3: Simulation results across different hidden bias magnitudes.
bias magnitude of b = 0, the results indicate that: (i) all methods exhibit negligible bias;
(ii) FB and CSB reduce MSE by 42% and 20%, respectively, compared to NB; (iii) all
methods effectively control the type I error rate; and (iv) FB and CSB increase power by
46% and 45%, respectively, compared to NB.
The following eight cases, where there is hidden bias (b = 1, . . . , 8), show that: (i)
FB exhibits a large bias, approximately 125%-203% of its standard deviation (SD). The
absolute bias of FB decreases with b when b â‰¥3 because large b values increase V{Y (0) |
X = x, A = 0, S = 0}, causing FB to down-weight ECs with small Ë†r(Xi) in (1). CSB
performs better at bias control, with bias ranging from 0%-22% of its SD; (ii) compared
to NB, FB increases MSE by up to 454%, and CSB decreases MSE by 13%-16% (except
when b = 1, 2, where MSE increase by 1%-18%). (iii) In line with Theorem 1, all methods
22
b: 6
b: 7
b: 8
b: 3
b: 4
b: 5
b: 0
b: 1
b: 2
0.5
0.6
0.7
0.8
0.5
0.6
0.7
0.8
0.5
0.6
0.7
0.8
âˆ’8
âˆ’4
0
4
âˆ’8
âˆ’4
0
4
âˆ’8
âˆ’4
0
4
Sampling Score
Outcome
RCT Controlled
EC (Selected)
EC (Unselected)
Figure 4: Selection performance of Conformal Selective Borrowing.
control the type I error rate well; (iv) compared to NB, FB decreases power by up to
51%. In contrast, CSB increases power by 13%-36% (except when b = 2, 3, 4, where power
decreases by 7%-20%). In challenging cases where 0 < b â‰¤4, the efficiency loss of CSB
occurs because small biases make it hard to distinguish biased ECs from unbiased ECs.
Such loss is inevitable when aiming to gain efficiency in scenarios without hidden bias, a
phenomenon known in the transfer learning literature as the cost of transferability detection
(Cai et al. 2024). This phenomenon also occurs for other data integration estimators under
hidden bias (see Figure 2 in Yang et al. (2023), Figure 4 in Oberst et al. (2022), and Figure
2 in Lin et al. (2024)).
Finally, we examine the selection performance of CSB. Subplot (F) in Figure 3 shows
the proportion of biased ECs among the selected ECs, referred to as the false selection rate
23
(FSR). Since 50% of the ECs are biased, FBâ€™s FSR stays constant at 0.5 when b Ì¸= 0. CSBâ€™s
FSR is 0.22 at b = 1 (the hardest case) and nearly zero when b â‰¥2. We do not expect
CSB to perfectly separate biased ECs from unbiased ones due to (i) the small sample size
of reference objects (RCs) and (ii) finite sample noise. In most cases, CSB discards biased
ECs and some unbiased ones that arenâ€™t sufficiently similar to RCs, as shown in Figure
4. In these small sample cases, CSB outperforms ALSB in both estimation and selection.
Moreover, ALSB, relying on asymptotic inference, fails to control the type I error rate, as
demonstrated in the Supplemental Material.
5
Real data application
5.1
The CALGB 9633 and NCDB data
Description. We apply the proposed methods to an RCT conducted by the Cancer
and Leukemia Group B (CALGB), known as CALGB 9633, which investigated the treat-
ment effect of adjuvant chemotherapy in patients with stage IB non-small-cell lung cancer
(Strauss et al. 2008). In CALGB 9633 (S = 1), n1 = 167 patients were randomized to
adjuvant chemotherapy (A = 1), and n0 = 168 were randomized to observation (A = 0).
We extract data for 11,700 patients from the National Cancer Database (NCDB) as the
EC sample (A = 0, S = 0) to improve CALGB 9633â€™s statistical efficiency. The NCDB is a
clinical oncology database sourced from hospital registry data, jointly run by the American
Cancer Society and the American College of Surgeons, covering 70% of U.S. cancer cases.
RMST. We use the Restricted Mean Survival Time (RMST), Y = min(T, tâˆ—), as the
primary endpoint, where T represents the survival time and tâˆ—is the truncation time.
RMST measures survival time up to a clinically relevant truncation point and serves as
a compelling alternative to the hazard ratio when the proportional hazards assumption
is violated (HernÂ´an 2010, Royston & Parmar 2013). We consider the difference in 3-year
24
RMST between the treatment and control groups for the RCT population Ï„ = E{Y (1) âˆ’
Y (0) | S = 1} as the estimand, where Y (a) = min{T(a), 3} and T(a) is the potential
survival time, a = 0, 1. Five baseline covariates in CALGB 9633 and NCDB are considered:
sex, age, race, histology, and tumor size.
Pseudo-observations. The censoring rates of T in CALGB 9633 and NCDB are 42%
and 48%, respectively. We use a â€œonce-for-allâ€ approach to transform right-censored sur-
vival times into pseudo-observations for RMST, allowing standard causal inference methods
as if outcomes were non-censored (Andersen et al. 2003, Overgaard et al. 2017, Andersen
et al. 2017, Zeng et al. 2023). To address covariate-dependent censoring, we stratify by sex,
race, and histology, applying transformations separately within each dataset (Andersen &
Pohar Perme 2010). The stratified Kaplanâ€“Meier estimator is used to estimate survival
functions, with pseudo-observations generated via the jackknife method, as implemented
in the R package eventglm (Sachs & Gabriel 2022). More details are in the Supplement
Material. We treat the pseudo-observations for 3-year RMST as the outcome hereafter.
Matching.
We use nearest-neighbor matching to mitigate the covariate imbalance
between CALGB 9633 and NCDB. Tumor size was imputed for eight missing values in
CALGB 9633 using the median of 4. NCDB samples with missing values or covariates
outside the CALGB 9633 range were excluded, leaving 10,241 samples. We perform 1:1
nearest-neighbor matching using MatchIt (Ho et al. 2011), treating the sampling indica-
tor S as a â€œtreatmentâ€ and targeting the average treatment effect on the treated (ATT).
This preserves all RCT samples and matches 335 NCDB samples. Distributional balance
for the baseline covariates and the estimated sampling score Ë†P(S = 1|X) improves signifi-
cantly after matching, with a visual comparison in the Supplementary Material. However,
certain covariates, such as tumor size, remain imbalanced, which could not be addressed
25
Table 1: Analysis results for CALGB 9633 + NCDB.
Method
Est
SE
CI
Asym p
Exact p
#EC
No Borrow (Dif-in-Means)
0.135
0.072
(-0.007, 0.276)
0.062
0.060
0
No Borrow (AIPW)
0.142
0.074
(-0.003, 0.286)
0.055
0.051
0
Full Borrow
0.241
0.061
(0.122, 0.361)
<0.001
0.031
335
Conformal Selective Borrow
0.138
0.058
(0.024, 0.252)
0.018
0.046
264
Note: â€œEstâ€ is the point estimate of ATE for the RCT population. â€œSEâ€, â€œCIâ€, and â€œAsym pâ€ are the
standard error, confidence interval, and p-value, respectively, based on asymptotic inference. â€œExact pâ€
is the proposed exact p-value based on FRT. â€œ#ECâ€ is the number of borrowed ECs.
by matching without resorting to methods that would undesirably discard RCT samples.
This motivates the use of the doubly robust estimator in Sections 2.1 and 3. Notably,
while a doubly robust estimator alone can address covariate imbalance, matching as a pre-
processing step reduces reliance on correct model specification (Ho et al. 2007). A summary
table of the pre-processed data is in the Supplementary Material.
5.2
Data analysis
We apply No Borrowing, Full Borrowing, and Conformal Selective Borrowing to
estimate the ATE and perform FRTs. For comparison, we also apply No Borrowing without
covariate adjustment, i.e., difference-in-means estimator. In addition to the proposed exact
p-value, we also compute the standard error, confidence interval, and p-value based on
asymptotic inference for all approaches (Li et al. 2023). Since the outcome shows a high
proportion of truncation at 3 years, resulting in a highly skewed distribution, we apply the
conformal quantile regression (Romano et al. 2019) to compute the conformal score. We
utilize the Jackknife+ p-value (Barber et al. 2021) introduced in Section 3.1.3.
Table 1 presents the analysis results. For No Borrowing using Dif-in-Means and AIPW,
asymptotic and exact p-values range from 0.051 to 0.062. In contrast, Full Borrowing
(using all 335 ECs) gives an asymptotic p-value of < 0.001 and an exact p-value of 0.031,
indicating a significantly positive ATE. Similarly, Conformal Selective Borrowing (using
26
0
1
2
3
0.40
0.45
0.50
0.55
Sampling Score
Outcome (3âˆ’year RMST)
CALGB 9633 Controlled
NCDB Controlled (Selected)
NCDB Controlled (Unselected)
Figure 5: 3-year RMST (Outcome) vs. Sampling Score estimated by 5 covariates. The
shaded area is constructed using quantile regression on the CALGB 9633 controlled data.
178 ECs) shows an asymptotic p-value of 0.018 and an exact p-value of 0.046, also indicat-
ing a significantly positive ATE. The ATE estimate from Conformal Selective Borrowing
falls between No Borrowing and Full Borrowing, indicating a trade-off between these two
approaches. Figure 5 shows that, given the observed confounder X, Conformal Selective
Borrowing tends to select ECs whose outcomes are more similar to RCs, reducing hidden
bias that cannot be addressed by balancing X alone. The combination of FRT and con-
formal p-values may raise computational concerns, though they can be accelerated with
parallel computing. In our real data analysis, 10,000 Monte Carlo iterations for FRT and
Jackknife+ with n0 = 168 took about 23 minutes on a personal MacBook using 8 cores.
27
6
Conclusion and discussion
This paper extends the FRT to hybrid controlled trials and proposes Conformal Selective
Borrowing to mitigate hidden bias when incorporating ECs. Without hidden bias among
ECs, Full Borrowing combined with FRT controls the type I error rate and increases
power, as expected based on previous literature (Li et al. 2023, Valancius et al. 2024).
In the presence of hidden bias among ECs, Full Borrowing with FRT still controls the
type I error rate due to the merit of randomization in RCTs, but it reduces power, high-
lighting that EC borrowing comes with trade-offs. Regardless of hidden bias in ECs, FRT
with Conformal Selective Borrowing controls the type I error rate and increases power
in most scenarios. The Conformal Selective Borrowing ATE estimator with the adap-
tive selection threshold improves the efficiency compared to the No Borrowing approach in
terms of MSE.
In RCT, beyond the sharp null, FRTs could be asymptotically valid for testing the
weak null using studentized/prepivoted test statistics (Wu & Ding 2021, Cohen & Fogarty
2022). Randomization-based confidence intervals can be constructed by inverting a series
of FRTs (Luo et al. 2021), with analytical methods for this inversion developed by Zhu &
Liu (2023) and Fiksel (2024). Randomization inference can test bounded null hypotheses
and construct confidence intervals for quantiles of individual treatment effects (Caughey
et al. 2023). Extending these methods to hybrid controlled trials would be valuable.
Hidden bias or heterogeneity among multiple sources is common in data integration and
transfer learning tasks, causing efficiency loss even after balancing measured confounders.
The mainstream approach often involves penalized bias estimation methods like adaptive
Lasso. Our work shows that conformal inference provides more stable performance and
flexibility in finite samples.
Extending our method to other tasks, such as developing
28
individual treatment regimes (Chu et al. 2023, Li et al. 2024), exploring treatment effect
heterogeneity (Wu & Yang 2022), and improving experimental design (Ventz et al. 2022,
Guo et al. 2024, Ruan et al. 2024), would be of significant interest.
Acknowledgement
This project is supported by the Food and Drug Administration (FDA) of the U.S.
Department of Health and Human Services (HHS) as part of a financial assistance award
U01FD007934 totaling $1,674,013 over two years funded by FDA/HHS. It is also supported
by the National Institute On Aging of the National Institutes of Health under Award
Number R01AG06688, totaling $1,565,763 over four years. The contents are those of the
authors and do not necessarily represent the official views of, nor an endorsement by,
FDA/HHS, the National Institutes of Health, or the U.S. Government.
Supplementary Material
The Supplementary Material provides proofs and additional numerical results. The R
package intFRT is available at https://github.com/ke-zhu/intFRT.
References
Alt, E. M., Chang, X., Jiang, X., Liu, Q., Mo, M., Xia, H. A. & Ibrahim, J. G. (2024),
â€˜LEAP: The latent exchangeability prior for borrowing information from historical dataâ€™,
Biometrics 80(3), ujae083.
Andersen, P. K., Klein, J. P. & RosthÃ¸j, S. (2003), â€˜Generalised linear models for correlated
pseudo-observations, with applications to multi-state modelsâ€™, Biometrika 90(1), 15â€“27.
Andersen, P. K. & Pohar Perme, M. (2010), â€˜Pseudo-observations in survival analysisâ€™,
Statistical Methods in Medical Research 19(1), 71â€“99.
Andersen, P. K., Syriopoulou, E. & Parner, E. T. (2017), â€˜Causal inference in survival
29
analysis using pseudo-observationsâ€™, Statistics in Medicine 36(17), 2669â€“2681.
Angelopoulos, A. N., Bates, S. et al. (2023), â€˜Conformal prediction: A gentle introductionâ€™,
Foundations and TrendsÂ® in Machine Learning 16(4), 494â€“591.
Barber, R. F., Candes, E. J., Ramdas, A. & Tibshirani, R. J. (2021), â€˜Predictive inference
with the jackknife+â€™, The Annals of Statistics 49(1), 486â€“507.
Bates, S., Cand`es, E., Lei, L., Romano, Y. & Sesia, M. (2023), â€˜Testing for outliers with
conformal p-valuesâ€™, The Annals of Statistics 51(1), 149â€“178.
Bind, M.-A. C. & Rubin, D. B. (2020), â€˜When possible, report a Fisher-exact P value
and display its underlying null randomization distributionâ€™, Proceedings of the National
Academy of Sciences 117(32), 19151â€“19158.
Bugni, F. A., Canay, I. A. & Shaikh, A. M. (2018), â€˜Inference under covariate-adaptive
randomizationâ€™, Journal of the American Statistical Association 113(524), 1784â€“1796.
Cai, T., Li, M. & Liu, M. (2024), â€˜Semi-supervised triply robust inductive transfer learningâ€™,
Journal of the American Statistical Association in press.
Cao, W., Tsiatis, A. A. & Davidian, M. (2009), â€˜Improving efficiency and robustness of
the doubly robust estimator for a population mean with incomplete dataâ€™, Biometrika
96(3), 723â€“734.
Carter, K., Scheffold, A. L., Renteria, J., Berger, V. W., Luo, Y. A., Chipman, J. J. &
Sverdlov, O. (2023), â€˜Regulatory guidance on randomization and the use of randomization
tests in clinical trials: A systematic reviewâ€™, Statistics in Biopharmaceutical Research
16(4), 428â€“440.
Caughey, D., Dafoe, A., Li, X. & Miratrix, L. (2023), â€˜Randomisation inference beyond
the sharp null: Bounded null hypotheses and quantiles of individual treatment effectsâ€™,
Journal of the Royal Statistical Society Series B: Statistical Methodology 85(5), 1471â€“
1491.
Chen, C., Wang, M. & Chen, S. (2023), â€˜An efficient data integration scheme for synthe-
30
sizing information from multiple secondary datasets for the parameter inference of the
main analysisâ€™, Biometrics 79(4), 2947â€“2960.
Chen, S., Zhang, B. & Ye, T. (2021), â€˜Minimax rates and adaptivity in combining experi-
mental and observational dataâ€™, arXiv preprint arXiv:2109.10522 .
Chen, W.-C., Wang, C., Li, H., Lu, N., Tiwari, R., Xu, Y. & Yue, L. Q. (2020), â€˜Propensity
score-integrated composite likelihood approach for augmenting the control arm of a ran-
domized controlled trial by incorporating real-world dataâ€™, Journal of Biopharmaceutical
Statistics 30(3), 508â€“520.
Chen, Z., Ning, J., Shen, Y. & Qin, J. (2021), â€˜Combining primary cohort data with external
aggregate information without assuming comparabilityâ€™, Biometrics 77(3), 1024â€“1036.
Cheng, D. & Cai, T. (2021), â€˜Adaptive combination of randomized and observational dataâ€™,
arXiv preprint arXiv:2111.15012 .
Cheng, Y., Wu, L. & Yang, S. (2023), Enhancing treatment effect estimation: A model
robust approach integrating randomized experiments and external controls using the
double penalty integration estimator, in â€˜Proceedings of the Thirty-Ninth Conference
on Uncertainty in Artificial Intelligenceâ€™, Vol. 216 of Proceedings of Machine Learning
Research, pp. 381â€“390.
Chernozhukov, V., WÂ¨uthrich, K. & Zhu, Y. (2021), â€˜An exact and robust conformal infer-
ence method for counterfactual and synthetic controlsâ€™, Journal of the American Statis-
tical Association 116(536), 1849â€“1864.
Chu, J., Lu, W. & Yang, S. (2023), â€˜Targeted optimal treatment regime learning using
summary statisticsâ€™, Biometrika 110(4), 913â€“931.
Cohen, P. L. & Fogarty, C. B. (2022), â€˜Gaussian prepivoting for finite population causal
inferenceâ€™, Journal of the Royal Statistical Society Series B: Statistical Methodology
84(2), 295â€“320.
Colnet, B., Mayer, I., Chen, G., Dieng, A., Li, R., Varoquaux, G., Vert, J.-P., Josse,
31
J. & Yang, S. (2024), â€˜Causal inference methods for combining randomized trials and
observational studies: A reviewâ€™, Statistical Science 39(1), 165â€“191.
Dang, L. E., Tarp, J. M., Abrahamsen, T. J., Kvist, K., Buse, J. B., Petersen, M. &
van der Laan, M. (2023), â€˜A cross-validated targeted maximum likelihood estimator for
data-adaptive experiment selection applied to the augmentation of RCT control arms
with external dataâ€™, arXiv preprint arXiv:2210.05802v3 .
European
Medicines
Agency
(2015),
â€˜Guideline
on
adjustment
for
base-
line
covariates
in
clinical
trialsâ€™,
https://www.ema.europa.eu/en/
adjustment-baseline-covariates-clinical-trials-scientific-guideline.
Fiksel, J. (2024), â€˜On exact randomization-based covariate-adjusted confidence intervalsâ€™,
Biometrics 80(2), ujae051.
Fisher, R. (1926), â€˜The arrangement of field experimentsâ€™, Journal of the Ministry of Agri-
culture 33, 503â€“515.
Fisher, R. A. (1935), The Design of Experiments, 1st edn, Oliver and Boyd, Edinburgh.
Freidling, T., Zhao, Q. & Gao, Z. (2024), â€˜Selective randomization inference for adaptive
experimentsâ€™, arXiv preprint arXiv:2405.07026 .
Gagnon-Bartsch, J. A., Sales, A. C., Wu, E., Botelho, A. F., Erickson, J. A., Miratrix, L. W.
& Heffernan, N. T. (2023), â€˜Precise unbiased estimation in randomized experiments using
auxiliary observational dataâ€™, Journal of Causal Inference 11(1), 20220011.
Gao, C. & Yang, S. (2023), â€˜Pretest estimation in combining probability and non-
probability samplesâ€™, Electronic Journal of Statistics 17(1), 1492â€“1546.
Gao, C., Yang, S., Shan, M., Ye, W., Lipkovich, I. & Faries, D. (2023), â€˜Integrating ran-
domized placebo-controlled trial data with external controls: A semiparametric approach
with selective borrowingâ€™, arXiv preprint arXiv:2306.16642 .
Guan, L. & Tibshirani, R. (2022), â€˜Prediction and outlier detection in classification
problemsâ€™, Journal of the Royal Statistical Society Series B: Statistical Methodology
32
84(2), 524â€“546.
Guo, B., Laird, G., Song, Y., Chen, J. & Yuan, Y. (2024), â€˜Adaptive hybrid control design
for comparative clinical trials with historical control dataâ€™, Journal of the Royal Statistical
Society Series C: Applied Statistics 73(2), 444â€“459.
HernÂ´an, M. A. (2010), â€˜The hazards of hazard ratiosâ€™, Epidemiology 21(1), 13â€“15.
Ho, D. E., Imai, K., King, G. & Stuart, E. A. (2007), â€˜Matching as nonparametric prepro-
cessing for reducing model dependence in parametric causal inferenceâ€™, Political Analysis
15(3), 199â€“236.
Ho, D., Imai, K., King, G. & Stuart, E. A. (2011), â€˜Matchit: Nonparametric preprocessing
for parametric causal inferenceâ€™, Journal of Statistical Software 42(8), 1â€“28.
Hobbs, B. P., Carlin, B. P., Mandrekar, S. J. & Sargent, D. J. (2011), â€˜Hierarchical com-
mensurate and power prior models for adaptive incorporation of historical information
in clinical trialsâ€™, Biometrics 67(3), 1047â€“1056.
Huang, Y., Huang, C.-Y. & Kim, M.-O. (2023), â€˜Simultaneous selection and incorporation
of consistent external aggregate informationâ€™, Statistics in Medicine 42(30), 5630â€“5645.
Imbens, G. W. & Rubin, D. B. (2015), Causal Inference in Statistics, Social, and Biomedical
Sciences, Cambridge University Press.
Karlsson, R., Wang, G., Krijthe, J. H. & Dahabreh, I. J. (2024), â€˜Robust integration of
external control data in randomized trialsâ€™, arXiv preprint arXiv:2406.17971 .
Kwiatkowski, E., Zhu, J., Li, X., Pang, H., Lieberman, G. & Psioda, M. A. (2024), â€˜Case
weighted power priors for hybrid control analyses with time-to-event dataâ€™, Biometrics
80(2), ujae019.
Le Cam, L. (1953), â€˜On some asymptotic properties of maximum likelihood estimates and
related Bayes estimatesâ€™, University of California Publications in Statistics 1, 277â€“330.
Lehmann, E. & Romano, J. P. (2022), Testing Statistical Hypotheses, 4th edn, Springer
International Publishing.
Lei, J., Gâ€™Sell, M., Rinaldo, A., Tibshirani, R. J. & Wasserman, L. (2018), â€˜Distribution-
33
free predictive inference for regressionâ€™, Journal of the American Statistical Association
113(523), 1094â€“1111.
Lei, L. & Cand`es, E. J. (2021), â€˜Conformal inference of counterfactuals and individual treat-
ment effectsâ€™, Journal of the Royal Statistical Society Series B: Statistical Methodology
83(5), 911â€“938.
Li, L. & Jemielita, T. (2023), â€˜Confounding adjustment in the analysis of augmented ran-
domized controlled trial with hybrid control armâ€™, Statistics in Medicine 42(16), 2855â€“
2872.
Li, S. & Luedtke, A. (2023), â€˜Efficient estimation under data fusionâ€™, Biometrika
110(4), 1041â€“1054.
Li, T., Shi, C., Wen, Q., Sui, Y., Qin, Y., Lai, C. & Zhu, H. (2024), Combining experimen-
tal and historical data for policy evaluation, in â€˜Proceedings of the 41st International
Conference on Machine Learning (ICML)â€™, Vol. 235.
Li, W., Liu, F. & Snavely, D. (2020), â€˜Revisit of test-then-pool methods and some practical
considerationsâ€™, Pharmaceutical Statistics 19(5), 498â€“517.
Li, X., Miao, W., Lu, F. & Zhou, X.-H. (2023), â€˜Improving efficiency of inference in clinical
trials with external control dataâ€™, Biometrics 79(1), 394â€“403.
Liang, Z., Sesia, M. & Sun, W. (2024), â€˜Integrative conformal p-values for out-of-
distribution testing with labelled outliersâ€™, Journal of the Royal Statistical Society Series
B: Statistical Methodology p. qkad138.
Lin, X., Tarp, J. M. & Evans, R. J. (2024), â€˜Data fusion for efficiency gain in ATE estima-
tion: A practical review with simulationsâ€™, arXiv preprint arXiv:2407.01186 .
Luo, X., Dasgupta, T., Xie, M. & Liu, R. Y. (2021), â€˜Leveraging the Fisher randomization
test using confidence distributions: Inference, combination and fusion learningâ€™, Journal
of the Royal Statistical Society Series B: Statistical Methodology 83(4), 777â€“797.
Miller, F. & Joffe, S. (2011), â€˜Equipoise and the dilemma of randomized clinical trials.â€™,
34
The New England Journal of Medicine 364(5), 476â€“480.
Morgan, K. L. & Rubin, D. B. (2012), â€˜Rerandomization to improve covariate balance in
experimentsâ€™, The Annals of Statistics 40(2), 1263â€“1282.
Nair, Y. & Janson, L. (2023), â€˜Randomization tests for adaptively collected dataâ€™, arXiv
preprint arXiv:2301.05365 .
Oberst, M., Dâ€™Amour, A., Chen, M., Wang, Y., Sontag, D. & Yadlowsky, S. (2022), â€˜Un-
derstanding the risks and rewards of combining unbiased and possibly biased estimators,
with applications to causal inferenceâ€™, arXiv preprint arXiv:2205.10467 .
Overgaard, M., Parner, E. T. & Pedersen, J. (2017), â€˜Asymptotic theory of generalized
estimating equations based on jack-knife pseudo-observationsâ€™, The Annals of Statistics
45(5), 1988â€“2015.
Papadopoulos, H., Proedrou, K., Vovk, V. & Gammerman, A. (2002), Inductive confidence
machines for regression, in â€˜Machine learning: ECML 2002: 13th European conference
on machine learning Helsinki, Finland, August 19â€“23, 2002 proceedings 13â€™, Springer,
pp. 345â€“356.
Phipson, B. & Smyth, G. K. (2010), â€˜Permutation p-values should never be zero: Calculat-
ing exact p-values when permutations are randomly drawnâ€™, Statistical Applications in
Genetics and Molecular Biology 9(1), 1â€“12.
Plamadeala, V. & Rosenberger, W. F. (2012), â€˜Sequential monitoring with conditional
randomization testsâ€™, The Annals of Statistics 40(1), 30â€“44.
Pocock, S. J. (1976), â€˜The combination of randomized and historical controls in clinical
trialsâ€™, Journal of Chronic Diseases 29(3), 175â€“188.
Proschan, M. A. & Dodd, L. E. (2019), â€˜Re-randomization tests in clinical trialsâ€™, Statistics
in Medicine 38(12), 2292â€“2302.
Puelz, D., Basse, G., Feller, A. & Toulis, P. (2022), â€˜A graph-theoretic approach to random-
ization tests of causal effects under general interferenceâ€™, Journal of the Royal Statistical
35
Society Series B: Statistical Methodology 84(1), 174â€“204.
Rabideau, D. J. & Wang, R. (2021), â€˜Randomization-based confidence intervals for cluster
randomized trialsâ€™, Biostatistics 22(4), 913â€“927.
Ritzwoller, D. M., Romano, J. P. & Shaikh, A. M. (2024), â€˜Randomization inference:
Theory and applicationsâ€™, arXiv preprint arXiv:2406.09521 .
Romano, Y., Patterson, E. & Cand`es, E. J. (2019), Conformalized quantile regression,
in â€˜Proceedings of the 33rd International Conference on Neural Information Processing
Systemsâ€™, pp. 3543â€“3553.
Rosenberger, W. F. & Lachin, J. M. (2015), Randomization in Clinical Trials: Theory and
Practice, John Wiley & Sons.
Rosenberger, W. F., Uschner, D. & Wang, Y. (2019), â€˜Randomization: The forgotten
component of the randomized clinical trialâ€™, Statistics in Medicine 38(1), 1â€“12.
Rosenman, E. T., Basse, G., Owen, A. B. & Baiocchi, M. (2023), â€˜Combining observational
and experimental datasets using shrinkage estimatorsâ€™, Biometrics 79(4), 2961â€“2973.
RothenhÂ¨ausler, D. (2020), â€˜Model selection for estimation of causal parametersâ€™, arXiv
preprint arXiv:2008.12892 .
RothenhÂ¨ausler, D., Meinshausen, N., BÂ¨uhlmann, P. & Peters, J. (2021), â€˜Anchor regression:
Heterogeneous data meet causalityâ€™, Journal of the Royal Statistical Society Series B:
Statistical Methodology 83(2), 215â€“246.
Royston, P. & Parmar, M. K. (2013), â€˜Restricted mean survival time: an alternative to
the hazard ratio for the design and analysis of randomized trials with a time-to-event
outcomeâ€™, BMC Medical Research Methodology 13(1), 1â€“15.
Ruan, X., Wang, J., Wang, Y. & Wei, W. (2024), Electronic medical records assisted
digital clinical trial design, in â€˜Proceedings of The 27th International Conference on Ar-
tificial Intelligence and Statisticsâ€™, Vol. 238 of Proceedings of Machine Learning Research,
pp. 2836â€“2844.
36
Sachs, M. C. & Gabriel, E. E. (2022), â€˜Event history regression with pseudo-observations:
computational approaches and an implementation in Râ€™, Journal of Statistical Software
102, 1â€“34.
Schuler, A., Walsh, D., Hall, D., Walsh, J., Fisher, C., for Alzheimerâ€™s Disease, C. P.,
Initiative, A. D. N. & Study, A. D. C. (2022), â€˜Increasing the efficiency of randomized
trial estimates via linear adjustment for a prognostic scoreâ€™, The International Journal
of Biostatistics 18(2), 329â€“356.
Shafer, G. & Vovk, V. (2008), â€˜A tutorial on conformal prediction.â€™, Journal of Machine
Learning Research 9(3), 371â€“421.
Simon, R. & Simon, N. R. (2011), â€˜Using randomization tests to preserve type I error with
response adaptive and covariate adaptive randomizationâ€™, Statistics & Probability Letters
81(7), 767â€“772.
Strauss, G. M., Herndon, J. E., Maddaus, M. A., Johnstone, D. W., Johnson, E. A.,
Harpole, D. H., Gillenwater, H. H., Watson, D. M., Sugarbaker, D. J., Schilsky, R. L. et al.
(2008), â€˜Adjuvant paclitaxel plus carboplatin compared with observation in stage IB non-
small-cell lung cancer: CALGB 9633 with the cancer and leukemia group B, radiation
therapy oncology group, and north central cancer treatment group study groupsâ€™, Journal
of Clinical Oncology 26(31), 5043â€“5051.
Stuart, E. A. & Rubin, D. B. (2008), â€˜Matching with multiple control groups with adjust-
ment for group differencesâ€™, Journal of Educational and Behavioral Statistics 33(3), 279â€“
306.
U.S. Food and Drug Administration (2019), â€˜Adaptive design clinical trials for drugs and
biologics guidance for industryâ€™, https://www.fda.gov/media/78495/download.
U.S. Food and Drug Administration (2022), â€˜Rare Diseases at FDAâ€™, https://www.fda.
gov/patients/rare-diseases-fda.
U.S. Food and Drug Administration (2023), â€˜Considerations for the design and conduct
37
of externally controlled trials for drug and biological products guidance for industryâ€™,
https://www.fda.gov/media/164960/download.
Valancius, M., Pang, H., Zhu, J., Cole, S. R., Funk, M. J. & Kosorok, M. R. (2024), â€˜A
causal inference framework for leveraging external controls in hybrid trialsâ€™, Biometrics
80(4), ujae095.
van der Laan, M., Qiu, S. & van der Laan, L. (2024), â€˜Adaptive-TMLE for the average
treatment effect based on randomized controlled trial augmented with real-world dataâ€™,
arXiv preprint arXiv:2405.07186 .
Ventz, S., Khozin, S., Louv, B., Sands, J., Wen, P. Y., Rahman, R., Comment, L., Alexan-
der, B. M. & Trippa, L. (2022), â€˜The design and evaluation of hybrid controlled trials
that leverage external data and randomizationâ€™, Nature Communications 13(1), 5783.
Viele, K., Berry, S., Neuenschwander, B., Amzal, B., Chen, F., Enas, N., Hobbs, B.,
Ibrahim, J. G., Kinnersley, N., Lindborg, S. et al. (2014), â€˜Use of historical control data
for assessing treatment effects in clinical trialsâ€™, Pharmaceutical Statistics 13(1), 41â€“54.
Vovk, V., Gammerman, A. & Shafer, G. (2005), Algorithmic Learning in a Random World,
Vol. 29, Springer.
Wainwright, M. J. (2019), High-dimensional statistics:
A non-asymptotic viewpoint,
Vol. 48, Cambridge university press.
Wu, J. & Ding, P. (2021), â€˜Randomization tests for weak null hypotheses in randomized
experimentsâ€™, Journal of the American Statistical Association 116(536), 1898â€“1913.
Wu, L. & Yang, S. (2022), Integrative R-learner of heterogeneous treatment effects combin-
ing experimental and observational studies, in â€˜Proceedings of the First Conference on
Causal Learning and Reasoningâ€™, Vol. 177 of Proceedings of Machine Learning Research,
pp. 904â€“926.
Yang, S., Gao, C., Zeng, D. & Wang, X. (2023), â€˜Elastic integrative analysis of randomised
trial and real-world data for treatment heterogeneity estimationâ€™, Journal of the Royal
38
Statistical Society Series B: Statistical Methodology 85(3), 575â€“596.
Yi, Y., Zhang, Y., Du, Y. & Ye, T. (2023), â€˜Testing for treatment effect twice using internal
and external controls in clinical trialsâ€™, Journal of Causal Inference 11(1), 20220018.
Young, A. (2019), â€˜Channeling Fisher: Randomization tests and the statistical insignifi-
cance of seemingly significant experimental resultsâ€™, The Quarterly Journal of Economics
134(2), 557â€“598.
Zeng, S., Li, F., Hu, L. & Li, F. (2023), â€˜Propensity score weighting analysis of survival
outcomes using pseudo-observationsâ€™, Statistica Sinica 33(3), 2161â€“2184.
Zhang, Y. & Zhao, Q. (2023), â€˜What is a randomization test?â€™, Journal of the American
Statistical Association 118(544), 2928â€“2942.
Zhu, K. & Liu, H. (2023), â€˜Pair-switching rerandomizationâ€™, Biometrics 79(3), 2127â€“2142.
39
SUPPLEMENTARY MATERIAL
Section A presents the proofs, Section B includes additional simulation results, and
Section C provides further details on the real data.
A
Proofs
A.1
Proof of Theorem 1
Proof of Theorem 1. Under H0, the imputed potential outcomes are the same as the true
potential outcomes. Thus, the distribution of T âˆ—â‰¡T(Aâˆ—) is the same as that of T â‰¡T(A).
With simplified notations, we have
PA(pFRT â‰¤Î±) = PA {PAâˆ—(T âˆ—â‰¥T) â‰¤Î±} .
In a finite sample, A can take only a finite set of values, which implies that T must also
take on a finite set of values. Suppose these values are
T1 > . . . > Tm > . . . > TM,
and
PA(T = Tm) = PAâˆ—(T âˆ—= Tm) = Î±m,
m = 1, . . . , M.
For T âˆˆ{T1, . . . , TM}, we have Î±1 â‰¤PAâˆ—(T âˆ—â‰¥T) â‰¤PM
m=1 Î±m = 1. If 0 < Î± < Î±1, we
have
PA(pFRT â‰¤Î±) = PA {PAâˆ—(T âˆ—â‰¥T) â‰¤Î±} = 0 â‰¤Î±.
40
If Î±1 â‰¤Î± < 1, âˆƒËœ
M âˆˆ{1, . . . , M âˆ’1}, such that P Ëœ
M
m=1 Î±m â‰¤Î± and P Ëœ
M+1
m=1 Î±m > Î±. Then,
we have
PA(pFRT â‰¤Î±) = PA {PAâˆ—(T âˆ—â‰¥T) â‰¤Î±} = PA {T âˆˆ{T1, . . . , T Ëœ
M}} =
Ëœ
M
X
m=1
Î±m â‰¤Î±.
If T(A) takes distinct values for different A âˆˆA, pFRT is uniformly distributed:
PA

pFRT = a
|A|

=
1
|A|,
a = 1, . . . , |A|.
Thus, we have
PA(pFRT â‰¤Î±) = âŒŠÎ±|A|âŒ‹
|A|
> Î±|A| âˆ’1
|A|
= Î± âˆ’1
|A|.
Remark S1. If T is a continuous random variable, suppose its distribution function is
F(t) = P(T â‰¤t), then the proof could be simplified as
PA {PAâˆ—(T âˆ—â‰¥T) â‰¤Î±} = P {1 âˆ’F(T) â‰¤Î±}
= P

T â‰¥F âˆ’1(1 âˆ’Î±)
	
= 1 âˆ’F{F âˆ’1(1 âˆ’Î±)}
= Î±.
However, T is discrete with finite values, and we provide a rigorous proof in the finite-
sample setting.
A.2
Proof of Theorem 2
We invoke two lemmas from the Supplementary Material of Puelz et al. (2022).
41
Lemma S1 (Lemma 5 in Puelz et al. (2022)). Suppose Assumptions (b) and (c) in Theorem
2 hold, for some r âˆˆ(0.5, 1 + O(logâˆ’1 M)), we have
E(F1,n(qÎ±) âˆ’F1,n(qÎ±,M)) â‰¥âˆ’O(M âˆ’r),
Lemma S2 (Lemma 4 in Puelz et al. (2022)). Suppose Assumption (a) of Theorem 2 holds,
for any 0 < Î¹ < 0.5 and large enough M, we have
E(F1,n,M(z) âˆ’F1,n(z)) = O(M âˆ’0.5+Î¹),
for any z âˆˆR.
Proof of Theorem 2. Let qÎ±,M = F âˆ’1
0,n,M(1 âˆ’Î±) and qÎ± = F âˆ’1
0,n(1 âˆ’Î±). Thus, we have
ÏˆN,M = 1 âˆ’F1,n,M
 F âˆ’1
0,n,M(1 âˆ’Î±)

= 1 âˆ’F1,n,M
 qÎ±,M

= 1 âˆ’F1,n(qÎ±)
|
{z
}
T1
+ F1,n(qÎ±) âˆ’F1,n(qÎ±,M)
|
{z
}
T2
+ F1,n(qÎ±,M) âˆ’F1,n,M(qÎ±,M)
|
{z
}
T3
.
(S1)
By Assumptions (b) and (c), we have
T1 = 1 âˆ’F1,n
 F âˆ’1
0,n(1 âˆ’Î±)

= 1 âˆ’F
 F âˆ’1(1 âˆ’Î±) âˆ’Ï„/ÏƒN

.
Combined with Lemmas S1 and S2, we have
E(ÏˆN,M) â‰¥1 âˆ’F
 F âˆ’1(1 âˆ’Î±) âˆ’Ï„/ÏƒN

âˆ’O(M âˆ’r) âˆ’O(M âˆ’0.5+Î¹).
The result follows from that r > 0.5 > 0.5 âˆ’Î¹ > 0.
42
A.3
Proof of Proposition 1
Proof of Proposition 1. Since the calibration set (Xi, Yj)iâˆˆC and external control (Xj, Yj)
are exchangeable, we have (si)iâˆˆC and sj are exchangeable. Thus, we have
P(pfull
j
â‰¤Î³) =P
P
iâˆˆC I(si â‰¥sj) + 1
|C| + 1
â‰¤Î³

â‰¤âŒŠÎ³ (|C| + 1)âŒ‹
|C| + 1
â‰¤Î³,
where the first inequality is due to exchangeability and the possibility of ties in (si)iâˆˆC and
sj.
If sj and {si}iâˆˆC have distinct values, pfull
j
is uniformly distributed due to exchangeability.
That is,
P

pfull
j
=
a
|C| + 1

=
1
|C| + 1,
a = 1, . . . , |C| + 1.
Thus, we have
P(pfull
j
â‰¤Î³) = âŒŠÎ³ (|C| + 1)âŒ‹
|C| + 1
> Î³ (|C| + 1) âˆ’1
|C| + 1
= Î³ âˆ’
1
|C| + 1.
43
A.4
Proof of Proposition 2
Proof of Proposition 2. Since the calibration set (Xi, Yj)iâˆˆC and external control (Xj, Yj)
are exchangeable, we have (si)iâˆˆC1 and sj are exchangeable. Thus, we have
P(psplit
j
â‰¤Î³) =P
P
iâˆˆC1 I(si â‰¥sj) + 1
|C1| + 1
â‰¤Î³

â‰¤âŒŠÎ³(|C1| + 1)âŒ‹
|C1| + 1
â‰¤Î³,
where the first inequality is due to exchangeability and the possibility of ties in (si)iâˆˆC1 and
sj.
If sj and {si}iâˆˆC1 have distinct values, psplit
j
is uniformly distributed due to exchange-
ability. That is,
P

psplit
j
=
a
|C1| + 1

=
1
|C1| + 1,
a = 1, . . . , |C1| + 1.
Thus, we have
P(psplit
j
â‰¤Î³) = âŒŠÎ³(|C1| + 1)âŒ‹
|C1| + 1
> Î³(|C1| + 1) âˆ’1
|C1| + 1
= Î³ âˆ’
1
|C1| + 1.
A.5
Proof of Proposition 3
Lemma S3. Consider a matrix R âˆˆR(n+1)Ã—(n+1) with elements Rij. Define the set
S =
(
j âˆˆ{1, . . . , n + 1} :
n+1
X
i=1
I(Rij < Rji) â‰¥(1 âˆ’Î³)(n + 1)
)
,
Î³ âˆˆ(0, 1).
44
Then, we have
s â‰¤2Î³(n + 1) âˆ’1 < 2Î³(n + 1),
where s = |S|.
Proof. Since
n+1
X
i=1
I(Rij < Rji) â‰¥(1 âˆ’Î³)(n + 1)
â‡”
n+1
X
i=1
I(Rij â‰¥Rji) â‰¤Î³(n + 1),
by summing over all j âˆˆS, we have
X
jâˆˆS
n+1
X
i=1
I(Rij â‰¥Rji) â‰¤sÎ³(n + 1).
For i Ì¸= j, since I(Rij â‰¥Rji) + I(Rji â‰¥Rij) â‰¥1, we have
X
jâˆˆS
X
iâˆˆS
I(Rij â‰¥Rji) =
X
jâˆˆS
X
iâˆˆS,iÌ¸=j
I(Rij â‰¥Rji) + s
â‰¥s(s âˆ’1)
2
+ s.
By combining these two inequalities, we obtain
s(s âˆ’1)
2
+ s â‰¤
X
jâˆˆS
X
iâˆˆS
I(Rij â‰¥Rji)
â‰¤
X
jâˆˆS
n+1
X
i=1
I(Rij â‰¥Rji)
â‰¤sÎ³(n + 1).
45
Thus, we have
(s âˆ’1)
2
+ 1 â‰¤Î³(n + 1)
â‡’
s â‰¤2Î³(n + 1) âˆ’1 < 2Î³(n + 1).
Proof of Proposition 3. For iâ€², jâ€² âˆˆC âˆª{j}, we define
Riâ€²jâ€² =
ï£±
ï£´
ï£´
ï£´
ï£²
ï£´
ï£´
ï£´
ï£³
+âˆ
iâ€² = jâ€²,
Yiâ€² âˆ’Ë†fâˆ’(iâ€²,jâ€²) (Xiâ€²)

iâ€² Ì¸= jâ€²,
where Ë†fâˆ’(iâ€²,jâ€²) is a prediction model fitted by the leave-two-out augmented set (C âˆª{j}) \
{iâ€², jâ€²}. For i âˆˆC, since (C âˆª{j}) \ {i, j} = C \ {i}, we have Ë†fâˆ’i(x) = Ë†fâˆ’(i,j)(x), thereby,
si = |Yi âˆ’Ë†fâˆ’i(Xi)| = Rij,
s(i)
j
= |Yj âˆ’Ë†fâˆ’i(Xj)| = Rji.
Thus, we have
P(pjackknife+
j
â‰¤Î³) =P
 P
iâˆˆC I(si â‰¥s(i)
j ) + 1
|C| + 1
â‰¤Î³
!
=P
 P
iâˆˆCâˆª{j} I(Rij â‰¥Rji)
|C| + 1
â‰¤Î³
!
=P
ï£«
ï£­X
iâˆˆCâˆª{j}
I(Rij < Rji) â‰¥(1 âˆ’Î³)(|C| + 1)
ï£¶
ï£¸
â‰¤2Î³ âˆ’
1
|C| + 1
<2Î³,
46
where first inequality is due to exchangeability and Lemma S3.
A.6
Proof of Proposition 4
Lemma S4. Suppose m = n/K is an integer, and the n + m units are evenly divided into
K + 1 sets, denoted by C1, . . . , CK+1. Consider a matrix R âˆˆR(n+m)Ã—(n+m) with elements
Rij = Rji if i and j belong to the same set. Define the set
S =
(
j âˆˆ{1, . . . , n + m} :
n+m
X
i=1
I(Rij < Rji) â‰¥(1 âˆ’Î³)(n + 1)
)
,
Î³ âˆˆ(0, 1).
Then, we have
s â‰¤2Î³(n + 1) + m âˆ’2,
where s = |S|.
Proof. For j âˆˆS, by definition, we have
n+m
X
i=1
I(Rij â‰¥Rji) â‰¤(n + m) âˆ’(1 âˆ’Î³)(n + 1).
Since Rij = Rji if i and j belong to the same set, we have
n+m
X
i=1
I(Rij â‰¥Rji) =
X
i/âˆˆCk(j)
I(Rij â‰¥Rji) +
X
iâˆˆCk(j)
I(Rij â‰¥Rji)
=
X
i/âˆˆCk(j)
I(Rij â‰¥Rji) + m,
47
where Ck(j) is the set containing unit j. Thus, we have
X
i/âˆˆCk(j)
I(Rij â‰¥Rji) â‰¤(n + m) âˆ’(1 âˆ’Î³)(n + 1) âˆ’m
=Î³(n + 1) âˆ’1.
By summing over all j âˆˆS, we have
X
jâˆˆS
X
i/âˆˆCk(j)
I(Rij â‰¥Rji) â‰¤s{Î³(n + 1) âˆ’1}.
(S2)
On the other hand, for i Ì¸= j, since I(Rij â‰¥Rji) + I(Rji â‰¥Rij) â‰¥1, we have
X
jâˆˆS
X
iâˆˆS,iÌ¸=j
I(Rij â‰¥Rji) â‰¥s(s âˆ’1)
2
.
Since Rij = Rji if i and j belong to the same set, we have
X
jâˆˆS
X
iâˆˆS,iÌ¸=j
I(Rij â‰¥Rji) =
X
jâˆˆS
X
iâˆˆS,i/âˆˆCk(j)
I(Rij â‰¥Rji) +
X
jâˆˆS
X
iâˆˆS,iâˆˆCk(j),iÌ¸=j
I(Rij â‰¥Rji)
=
X
jâˆˆS
X
iâˆˆS,i/âˆˆCk(j)
I(Rij â‰¥Rji) +
K+1
X
k=1
sk(sk âˆ’1)
2
,
where sk = |Ck âˆ©S|. Thus, we have
X
jâˆˆS
X
iâˆˆS,i/âˆˆCk(j)
I(Rij â‰¥Rji) â‰¥s(s âˆ’1)
2
âˆ’
K+1
X
k=1
sk(sk âˆ’1)
2
.
(S3)
48
By combining (S2) and (S3), we have
s(s âˆ’1)
2
âˆ’
K+1
X
k=1
sk(sk âˆ’1)
2
â‰¤
X
jâˆˆS
X
iâˆˆS,i/âˆˆCk(j)
I(Rij â‰¥Rji)
â‰¤
X
jâˆˆS
X
i/âˆˆCk(j)
I(Rij â‰¥Rji)
â‰¤s{Î³(n + 1) âˆ’1}.
Since sk â‰¤m, we have
K+1
X
k=1
sk(sk âˆ’1)
2
â‰¤s(m âˆ’1)
2
.
Thus, we have
s â‰¤2Î³(n + 1) + m âˆ’2.
Proof of Proposition 4. We consider m = |C|/K is an integer for simplicity.
Let CK+1
contain j and other m âˆ’1 hypothetical points. For iâ€², jâ€² âˆˆâˆªK+1
k=1 Ck, we define
Riâ€²jâ€² =
ï£±
ï£´
ï£´
ï£´
ï£²
ï£´
ï£´
ï£´
ï£³
+âˆ
k(iâ€²) = k(jâ€²),
Yiâ€² âˆ’Ë†fâˆ’(Ck(iâ€²),Ck(jâ€²)) (Xiâ€²)

k(iâ€²) Ì¸= k(jâ€²),
where Ë†fâˆ’(Ck(iâ€²),Ck(jâ€²)) is a prediction model fitted by the leave-two-set-out augmented set
(âˆªK+1
k=1 Ck) \ (Ck(iâ€²) âˆªCk(jâ€²)). Since C = âˆªK
k=1Ck and Ck(j) = CK+1, we have (âˆªK+1
k=1 Ck) \ (Ck(i) âˆª
49
Ck(j)) = C \ Ck(i) for i âˆˆC. Thus, for i âˆˆC, we have Ë†fâˆ’Ck(i)(x) = Ë†fâˆ’(Ck(i),Ck(j))(x), thereby,
si = |Yi âˆ’Ë†fâˆ’Ck(i)(Xi)| = Rij,
s(i)
j
= |Yj âˆ’Ë†fâˆ’Ck(i)(Xj)| = Rji.
Thus, we have
P(pcv+
j
â‰¤Î³) =P
 P
iâˆˆC I(si â‰¥s(i)
j ) + 1
|C| + 1
â‰¤Î³
!
=P
 P
iâˆˆCâˆª{j} I(Rij â‰¥Rji)
|C| + 1
â‰¤Î³
!
=P
ï£«
ï£­X
iâˆˆCâˆª{j}
I(Rij < Rji) â‰¥(1 âˆ’Î³)(|C| + 1)
ï£¶
ï£¸
â‰¤P
ï£«
ï£­
X
iâˆˆâˆªK+1
k=1 Ck
I(Rij < Rji) â‰¥(1 âˆ’Î³)(|C| + 1)
ï£¶
ï£¸
â‰¤2Î³(|C| + 1) + m âˆ’2
|C| + m
â‰¤2Î³ + (1 âˆ’2Î³)(m âˆ’1) âˆ’1
|C| + m
â‰¤2Î³ + 1 âˆ’K/|C|
K + 1
,
where the second inequality is due to exchangeability and Lemma S4.
A.7
Proof of Theorem 3
Proof of Theorem 3. Since ÏµÎ³ is a centered sub-Gaussian variable with parameter Ï•Î³, we
have ÏµÎ³ âˆ’Ïµ1 as a centered sub-Gaussian variable with parameter 2Î¦, where Î¦ = maxÎ³âˆˆÎ“ Ï•Î³.
Moreover, we have (ÏµÎ³ âˆ’Ïµ1)2 âˆ’Îº2
Î³ is a centered sub-exponential variable with parameters
(c1Î¦2, c1Î¦2), where c1 is a constant. By Ë†Ï„Î³ âˆ’Ë†Ï„1 = (Î´Î³ âˆ’Î´1) + (ÏµÎ³ âˆ’Ïµ1) and using the con-
centration inequalities for sub-Gaussian and sub-exponential variables (Wainwright 2019),
50
it follows that, with probability at least 1 âˆ’4Î¹,
max
Î³âˆˆÎ“ |(Ë†Ï„Î³ âˆ’Ë†Ï„1)2 âˆ’(Î´Î³ âˆ’Î´1)2 âˆ’Îº2
Î³|
= max
Î³âˆˆÎ“ |2(Î´Î³ âˆ’Î´1)(ÏµÎ³ âˆ’Ïµ1) + (ÏµÎ³ âˆ’Ïµ1)2 âˆ’Îº2
Î³|
â‰¤8
âˆš
2âˆ†Î¦
p
log (|Î“|/Î¹) + max
nâˆš
2c1Î¦2p
log (|Î“|/Î¹), 2c1Î¦2 log (|Î“|/Î¹)
o
,
(S4)
where âˆ†= maxÎ³âˆˆÎ“ |Î´Î³|.
By (S4), it follows that, with probability at least 1 âˆ’4Î¹,
max
Î³âˆˆÎ“
[
MSE(Î³) âˆ’MSE(Î³)

= max
Î³âˆˆÎ“
(Ë†Ï„Î³ âˆ’Ë†Ï„1)2 âˆ’bV(Ë†Ï„Î³ âˆ’Ë†Ï„1) + bV(Ë†Ï„Î³) âˆ’Î´2
Î³ âˆ’Ïƒ2
Î³

â‰¤max
Î³âˆˆÎ“
(Ë†Ï„Î³ âˆ’Ë†Ï„1)2 âˆ’Îº2
Î³ + Ïƒ2
Î³ âˆ’Î´2
Î³ âˆ’Ïƒ2
Î³
 + max
Î³âˆˆÎ“ |bV(Ë†Ï„Î³ âˆ’Ë†Ï„1) âˆ’Îº2
Î³| + max
Î³âˆˆÎ“ |bV(Ë†Ï„Î³) âˆ’Ïƒ2
Î³|
â‰¤max
Î³âˆˆÎ“
(Î´Î³ âˆ’Î´1)2 âˆ’Î´2
Î³
 + câˆ†Î¦
p
log (|Î“|/Î¹) + max
n
cÎ¦2p
log (|Î“|/Î¹), cÎ¦2 log (|Î“|/Î¹)
o
+ max
Î³âˆˆÎ“ |bV(Ë†Ï„Î³ âˆ’Ë†Ï„1) âˆ’Îº2
Î³| + max
Î³âˆˆÎ“ |bV(Ë†Ï„Î³) âˆ’Ïƒ2
Î³|
â‰¤câˆ†|Î´1| + câˆ†Î¦
p
log (|Î“|/Î¹) + max
n
cÎ¦2p
log (|Î“|/Î¹), cÎ¦2 log (|Î“|/Î¹)
o
+ max
Î³âˆˆÎ“ |bV(Ë†Ï„Î³ âˆ’Ë†Ï„1) âˆ’Îº2
Î³| + max
Î³âˆˆÎ“ |bV(Ë†Ï„Î³) âˆ’Ïƒ2
Î³|,
where c is a constant.
A.8
Proof of Theorem 4
Proof of Theorem 4. Since ÏµÎ³ is a centered sub-Gaussian variable with parameter Ï•Î³, we
have Ïµ2
Î³ âˆ’Ïƒ2
Î³ as a centered sub-exponential variable with parameter (c2Î¦2, c2Î¦2), where c2
is a constant. By Ë†Ï„Î³ âˆ’Ï„ = Î´Î³ +ÏµÎ³ and using the concentration inequalities for sub-Gaussian
and sub-exponential variables (Wainwright 2019), it follows that, with probability at least
51
1 âˆ’4Î¹,
max
Î³âˆˆÎ“ |(Ë†Ï„Î³ âˆ’Ï„)2 âˆ’Î´2
Î³ âˆ’Ïƒ2
Î³|
= max
Î³âˆˆÎ“ |2Î´Î³ÏµÎ³ + Ïµ2
Î³ âˆ’Ïƒ2
Î³|
â‰¤2
âˆš
2âˆ†Î¦
p
log (|Î“|/Î¹) + max
nâˆš
2c2Î¦2p
log (|Î“|/Î¹), 2c2Î¦2 log (|Î“|/Î¹)
o
.
(S5)
By (S4) and (S5), it follows that, with probability at least 1 âˆ’8Î¹,
max
Î³âˆˆÎ“
[
MSE(Î³) âˆ’(Ë†Ï„Î³ âˆ’Ï„)2
= max
Î³âˆˆÎ“
(Ë†Ï„Î³ âˆ’Ë†Ï„1)2 âˆ’bV(Ë†Ï„Î³ âˆ’Ë†Ï„1) + bV(Ë†Ï„Î³) âˆ’(Ë†Ï„Î³ âˆ’Ï„)2
â‰¤max
Î³âˆˆÎ“
(Ë†Ï„Î³ âˆ’Ë†Ï„1)2 âˆ’Îº2
Î³ + Ïƒ2
Î³ âˆ’(Ë†Ï„Î³ âˆ’Ï„)2 + max
Î³âˆˆÎ“ |bV(Ë†Ï„Î³ âˆ’Ë†Ï„1) âˆ’Îº2
Î³| + max
Î³âˆˆÎ“ |bV(Ë†Ï„Î³) âˆ’Ïƒ2
Î³|
â‰¤max
Î³âˆˆÎ“
(Î´Î³ âˆ’Î´1)2 âˆ’Î´2
Î³
 + câˆ†Î¦
p
log (|Î“|/Î¹) + max
n
cÎ¦2p
log (|Î“|/Î¹), cÎ¦2 log (|Î“|/Î¹)
o
+ max
Î³âˆˆÎ“ |bV(Ë†Ï„Î³ âˆ’Ë†Ï„1) âˆ’Îº2
Î³| + max
Î³âˆˆÎ“ |bV(Ë†Ï„Î³) âˆ’Ïƒ2
Î³|
â‰¤câˆ†|Î´1| + câˆ†Î¦
p
log (|Î“|/Î¹) + max
n
cÎ¦2p
log (|Î“|/Î¹), cÎ¦2 log (|Î“|/Î¹)
o
+ max
Î³âˆˆÎ“ |bV(Ë†Ï„Î³ âˆ’Ë†Ï„1) âˆ’Îº2
Î³| + max
Î³âˆˆÎ“ |bV(Ë†Ï„Î³) âˆ’Ïƒ2
Î³|,
(S6)
where c is a constant.
Since
min
Î³âˆˆÎ“
[
MSE(Î³) âˆ’min
Î³âˆˆÎ“ (Ë†Ï„Î³ âˆ’Ï„)2
 â‰¤max
Î³âˆˆÎ“
[
MSE(Î³) âˆ’(Ë†Ï„Î³ âˆ’Ï„)2 ,
and
min
Î³âˆˆÎ“
[
MSE(Î³) âˆ’(Ë†Ï„Ë†Î³ âˆ’Ï„)2
 =
[
MSE(Ë†Î³) âˆ’(Ë†Ï„Ë†Î³ âˆ’Ï„)2 â‰¤max
Î³âˆˆÎ“
[
MSE(Î³) âˆ’(Ë†Ï„Î³ âˆ’Ï„)2 ,
52
we have
(Ë†Ï„Ë†Î³ âˆ’Ï„)2 âˆ’min
Î³âˆˆÎ“ (Ë†Ï„Î³ âˆ’Ï„)2 â‰¤2 max
Î³âˆˆÎ“
[
MSE(Î³) âˆ’(Ë†Ï„Î³ âˆ’Ï„)2 .
The result follows from (S6).
B
Additional simulation results
B.1
Adaptivity of the selection threshold
Figure S1 illustrates how Ë†Î³ changes with the magnitude of b: (i) When there is no
bias (b = 0), Ë†Î³ approaches 0 to borrow all ECs and maximize power; (ii) with moderate
bias (b = 1, 2, 3), where distinguishing between biased and unbiased ECs is challenging, Ë†Î³
increases to help discard the biased ECs; (iii) when the bias is large (b â‰¥4), Ë†Î³ decreases
but remains non-zero, retaining more unbiased ECs while easily discarding the biased ones.
B.2
Various selection thresholds
Figure S2 shows the performance of the fixed selection threshold Î³ and the adaptive
selection threshold Ë†Î³ when nE = 50. As discussed in Section 3.2, smaller Î³ selects more ECs
but risks greater bias when distinguishing between biased and unbiased ECs is difficult.
This creates a power trade-off across different bias levels, similar to MSE simulation results
in data integration (Yang et al. 2023, Oberst et al. 2022, Lin et al. 2024). We find that (i)
CSB with Î³ = 0.6 improves power compared to NB, except in extreme cases like b = 2, 3,
where it decreases power slightly, and (ii) CSB with Ë†Î³ further improves power but also risks
power loss in difficult scenarios. The power trade-off does not compromise the Type I error
rate, which remains controlled with all selection thresholds.
53
b: 0
b: 1
b: 2
b: 3
b: 4
b: 5
b: 6
b: 7
b: 8
0
100 200 300 0
100 200 300 0
100 200 300 0
100 200 300 0
100 200 300 0
100 200 300 0
100 200 300 0
100 200 300 0
100 200 300
0.00
0.25
0.50
0.75
1.00
count
Î³^
Figure S1: Ë†Î³ versus b when nE = 50.
0.00
0.05
0.10
0.15
0
2
4
6
8
Magnitude of Hidden Bias
(A) Absolute Bias
0.07
0.08
0.09
0.10
0.11
0.12
0
2
4
6
8
Magnitude of Hidden Bias
(B) Variance
0.07
0.08
0.10
0
2
4
6
8
Magnitude of Hidden Bias
(C) MSE
0.0
0.2
0.4
0.6
0
2
4
6
8
Magnitude of Hidden Bias
(D) Type I Error Rate
0.2
0.3
0.4
0.5
0.6
0
2
4
6
8
Magnitude of Hidden Bias
(E) Power
0.0
0.1
0.2
0.3
0
2
4
6
8
Magnitude of Hidden Bias
(F) #Biased / #Selected
Method
No Borrow (Î³ = 1)
Conformal Selective Borrow (Î³ = 0.8)
Conformal Selective Borrow (Î³ = 0.6)
Conformal Selective Borrow (Î³ = 0.4)
Conformal Selective Borrow (Î³^)
Figure S2: Simulation results for various selection threshold Î³â€™s when nE = 50.
54
B.3
Adaptive Lasso Selective Borrowing
Figure S3 presents the simulation results for ALSB with asymptotic inference. Un-
like FRTs, ALSB with asymptotic inference fails to control the type I error rate in this
small sample size scenario. Additionally, CSB demonstrates better estimation and selection
performance in most cases.
B.4
A larger sample size of ECs
Figures S4, S5, S6, S7, and S8 show the simulation results for nE = 300. The conclusion
is similar to that in the main text.
55
0.00
0.02
0.04
0.06
0.08
0
2
4
6
8
Magnitude of Hidden Bias
(A) Absolute Bias
0.09
0.10
0.11
0.12
0
2
4
6
8
Magnitude of Hidden Bias
(B) Variance
0.09
0.10
0.11
0.12
0
2
4
6
8
Magnitude of Hidden Bias
(C) MSE
0.0
0.2
0.4
0.6
0
2
4
6
8
Magnitude of Hidden Bias
(D) Type I Error Rate
0.2
0.3
0.4
0.5
0.6
0.7
0
2
4
6
8
Magnitude of Hidden Bias
(E) Power
0.0
0.1
0.2
0.3
0.4
0
2
4
6
8
Magnitude of Hidden Bias
(F) #Biased / #Selected
Method
No Borrow (Î³ = 1)
Adaptive Lasso Selective Borrow
Conformal Selective Borrow (Î³^)
Figure S3: Comparison of CSB + FRT and ALSB + asymptotic inference when nE = 50.
56
0.0
0.5
1.0
1.5
0
2
4
6
8
Magnitude of Hidden Bias
(A) Absolute Bias
0.075
0.100
0.125
0.150
0.175
0
2
4
6
8
Magnitude of Hidden Bias
(B) Variance
0.1
0.3
1.0
3.0
0
2
4
6
8
Magnitude of Hidden Bias
(C) MSE
0.0
0.2
0.4
0.6
0
2
4
6
8
Magnitude of Hidden Bias
(D) Type I Error Rate
0.00
0.25
0.50
0
2
4
6
8
Magnitude of Hidden Bias
(E) Power
0.0
0.1
0.2
0.3
0.4
0.5
0
2
4
6
8
Magnitude of Hidden Bias
(F) #Biased / #Selected
Method
No Borrow (Î³ = 1)
Full Borrow (Î³ = 0)
Conformal Selective Borrow (Î³^)
Figure S4: Simulation results when nE = 300. ALSBâ€™s exact p-value is unavailable due to
computation.
57
b: 6
b: 7
b: 8
b: 3
b: 4
b: 5
b: 0
b: 1
b: 2
0.16
0.18
0.20
0.16
0.18
0.20
0.16
0.18
0.20
âˆ’10
âˆ’5
0
âˆ’10
âˆ’5
0
âˆ’10
âˆ’5
0
Sampling Score
Outcome
RCT Controlled
EC (Selected)
EC (Unselected)
Figure S5: Selection performance of Conformal Selective Borrowing (Ë†Î³) when nE = 300.
b: 0
b: 1
b: 2
b: 3
b: 4
b: 5
b: 6
b: 7
b: 8
0
100 200 3000
100 200 3000
100 200 3000
100 200 3000
100 200 3000
100 200 3000
100 200 3000
100 200 3000
100 200 300
0.00
0.25
0.50
0.75
1.00
count
Î³^
Figure S6: Ë†Î³ versus b when nE = 300.
58
0.00
0.05
0.10
0.15
0
2
4
6
8
Magnitude of Hidden Bias
(A) Absolute Bias
0.07
0.08
0.09
0.10
0.11
0
2
4
6
8
Magnitude of Hidden Bias
(B) Variance
0.07
0.08
0.10
0
2
4
6
8
Magnitude of Hidden Bias
(C) MSE
0.0
0.2
0.4
0.6
0
2
4
6
8
Magnitude of Hidden Bias
(D) Type I Error Rate
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0
2
4
6
8
Magnitude of Hidden Bias
(E) Power
0.0
0.1
0.2
0.3
0
2
4
6
8
Magnitude of Hidden Bias
(F) #Biased / #Selected
Method
No Borrow (Î³ = 1)
Conformal Selective Borrow (Î³ = 0.8)
Conformal Selective Borrow (Î³ = 0.6)
Conformal Selective Borrow (Î³ = 0.4)
Conformal Selective Borrow (Î³^)
Figure S7: Simulation results for various selection threshold Î³â€™s when nE = 300.
59
0.0
0.1
0.2
0.3
0.4
0
2
4
6
8
Magnitude of Hidden Bias
(A) Absolute Bias
0.08
0.09
0.10
0.11
0
2
4
6
8
Magnitude of Hidden Bias
(B) Variance
0.1
0.2
0.3
0
2
4
6
8
Magnitude of Hidden Bias
(C) MSE
0.0
0.2
0.4
0.6
0
2
4
6
8
Magnitude of Hidden Bias
(D) Type I Error Rate
0.25
0.50
0.75
1.00
0
2
4
6
8
Magnitude of Hidden Bias
(E) Power
0.0
0.1
0.2
0.3
0.4
0
2
4
6
8
Magnitude of Hidden Bias
(F) #Biased / #Selected
Method
No Borrow (Î³ = 1)
Adaptive Lasso Selective Borrow
Conformal Selective Borrow (Î³^)
Figure S8: Comparison of CSB + FRT and ALSB + asymptotic inference when nE = 300.
60
Table S1: Summary statistics of the pre-processed data.
C9633 Treated
C9633 Controlled
NCDB Controlled
(n1 = 167)
(n0 = 168)
(nE = 335)
Sex
Male
109 (65.3%)
106 (63.1%)
219 (65.4%)
Female
58 (34.7%)
62 (36.9%)
116 (34.6%)
Age (years)
Mean (SD)
60.4 (10.2)
61.2 (9.28)
60.8 (9.69)
Median [Min, Max]
61.0 [34.0, 78.0]
62.0 [40.0, 81.0]
61.0 [34.0, 80.0]
Race
White
151 (90.4%)
148 (88.1%)
300 (89.6%)
Non-white
16 (9.6%)
20 (11.9%)
35 (10.4%)
Histology
Squamous
66 (39.5%)
65 (38.7%)
131 (39.1%)
Other
101 (60.5%)
103 (61.3%)
204 (60.9%)
Tumor Size (cm)
Mean (SD)
4.60 (2.04)
4.56 (2.05)
4.77 (1.42)
Median [Min, Max]
4.00 [1.00, 12.0]
4.00 [1.00, 12.0]
4.50 [3.10, 12.0]
Outcome: 3-year RMST*
Mean (SD)
2.77 (0.596)
2.64 (0.720)
2.43 (0.947)
Median [Min, Max]
3.00 [0.383, 3.00]
3.00 [0.181, 3.00]
3.00 [0.0242, 3.00]
*Pseudo-observations transformed from censored survival time.
C
More details about the real data
Pseudo-observations. Figure S9 shows the pseudo-observations versus censored times
for CALGB 9633 and NCDB, illustrating that: (i) all pseudo-observations are less than or
equal to the truncation time of 3 years; (ii) when an event occurs before 3 years, pseudo-
observations are generally equal to the event time; and (iii) when censoring occurs before
3 years, pseudo-observations are typically greater than the censored time.
Matching. Figure S10 shows that distributional balance for the five baseline covariates
and the estimated sampling score Ë†P(S = 1|X) improves significantly.
Pre-processing. Table S1 shows the summary statistics of the pre-processed data.
61
CALGB 9633
NCDB
0
5
10
0
1
2
3
0
1
2
3
Censored Time
Pseudoâˆ’observation
Censored
Yes
No
Figure S9: Pseudo-observation vs. Censored Time for CALGB 9633 and NCDB datasets.
62
Unmatched
Matched
0
1
0
1
0.0
0.2
0.4
0.6
Sex
Proportion
Unmatched
Matched
40 50 60 70 80
40 50 60 70 80
0.00
0.01
0.02
0.03
0.04
Age
Density
Unmatched
Matched
0
1
0
1
0.00
0.25
0.50
0.75
Race
Proportion
Unmatched
Matched
0
1
0
1
0.0
0.2
0.4
0.6
Histology
Proportion
Unmatched
Matched
2.5 5.0 7.510.012.5 2.5 5.0 7.510.012.5
0.0
0.1
0.2
0.3
0.4
Tumor Size
Density
Unmatched
Matched
0.0
0.1
0.2
0.0
0.1
0.2
0
5
10
15
20
25
Sampling Score
Density
Sample
NCDB (S = 0)
CALGB 9633 (S = 1)
Figure S10: Distributional balance (unmatched and matched) between CALGB 9633 (S = 1)
and NCDB (S = 0) for baseline covariates and the estimated sampling score Ë†P(S = 1|X).
63
