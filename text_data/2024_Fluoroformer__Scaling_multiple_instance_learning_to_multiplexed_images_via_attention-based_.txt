ML4H Findings Track Collection
Machine Learning for Health (ML4H) 2024
Fluoroformer: Scaling multiple instance learning to multiplexed
images via attention-based channel fusion
Marc Harary
marc@ds.dfci.harvard.edu
Dana-Farber Cancer Institute, Boston, MA, USA
Eliezer M. Van Allen
EliezerM VanAllen@dfci.harvard.edu
Dana-Farber Cancer Institute, Boston, MA, USA
William Lotter
lotterb@ds.dfci.harvard.edu
Dana-Farber Cancer Institute, Boston, MA, USA
Abstract
Though multiple instance learning (MIL) has
been a foundational strategy in computational
pathology for processing whole slide images
(WSIs), current approaches are designed for
traditional hematoxylin and eosin (H&E) slides
rather than emerging multiplexed technologies.
Here, we present an MIL strategy, the Fluo-
roformer module, that is specifically tailored
to multiplexed WSIs by leveraging scaled dot-
product attention (SDPA) to interpretably fuse
information across disparate channels. On a co-
hort of 434 non-small cell lung cancer (NSCLC)
samples, we show that the Fluoroformer both
obtains strong prognostic performance and re-
capitulates immuno-oncological hallmarks of
NSCLC. Our technique thereby provides a path
for adapting state-of-the-art AI techniques to
emerging spatial biology assays.
Keywords: computational pathology, multi-
plexed imaging, multiple instance learning
Data and Code Availability
The ImmunoPro-
file dataset (Lindsay et al., 2023) used in this
manuscript has not been IRB approved for public
release. Code is available at https://github.com/
lotterlab/fluoroformer.
Institutional Review Board (IRB)
All patients
in the ImmunoProfile cohort provided consent under
an institutional research protocol (DFCI 11-104, 17-
000, 20-000).
1. Introduction
Multiple instance learning (MIL) has emerged as the
de facto standard approach in computational pathol-
ogy for generating predictions from whole slide im-
ages (WSIs) (Ilse et al., 2018; Maron and Lozano-
P´erez, 1997; Carbonneau et al., 2018; Lu et al., 2021).
The typical MIL pipeline consists of 1) dividing the
WSI into smaller image patches, 2) extracting lower
dimensional embeddings for each patch from a pre-
trained neural network, 3) pooling embeddings across
patches to create a slide-level summary vector, and
4) generating slide-level predictions for the particu-
lar task at hand.
Compared to traditional strate-
gies such as training patch-level predictors that rely
exclusively on clinician-annotated regions of interest
(ROIs), MIL enables weakly-supervised training on
entire WSIs, thereby offering enhanced scalability, re-
duced sampling bias, and potentially superior perfor-
mance (Zhou, 2018).
Thus
far
in
computational
pathology,
MIL
pipelines have largely been confined to traditional
hematoxylin & eosin (H&E)-stained WSIs (Wilson
et al., 2021; Ghahremani et al., 2022). While H&E
staining can provide detailed morphological informa-
tion, it fails to explicitly capture important proteins
and other complex biomarkers that indicate cell phe-
notype and state (Lee et al., 2020; Peng et al., 2023;
Mu˜noz-Castro et al., 2022).
In contrast, emergent
techniques in spatial biology such as multiplex im-
munofluorescence (mIF) enable the imaging of many
biomarkers simultaneously in tissue samples while
preserving spatial context (Figure 1).
These tech-
niques result in rich, multi-channel (∼5-50) images
that have advanced our understanding of diseases
ranging from neurodegenerative disorders (Mu˜noz-
Castro et al., 2022) to cancer (Lee et al., 2020; Peng
et al., 2023). Conversely, mIF images are often an-
alyzed using hand-engineered features, such as the
counts of discrete biomarkers within clinician-defined
ROIs (Wilson et al., 2021). More recent efforts have
© 2024 .
arXiv:2411.08975v1  [eess.IV]  13 Nov 2024
Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion
Embedder (f)
hkm
×
×
×
Fluoroformer (gψ)
Ak×
×
×
Vk
^hk
×
ABMIL (pθ)
a ×
{^hk}
^hbag
Patch embedding
Marker attention
Patch attention
Logits
Layer
Module
Classifier (cϕ)
y
Figure 1: Overview of the Fluoroformer strategy for multiplexed imaging. Mathematical symbols are defined
in text.
pointed to the potential of using deep learning to im-
prove performance on downstream tasks, but these
efforts have also focused on ROIs rather than ex-
panding to WSIs (Hoebel et al., 2024; Sorin et al.,
2023; Wu et al., 2022). There is therefore a pressing
need to optimize MIL methods for mIF in order to
yield the benefits of both weakly-supervised training
and the rich information provided by spatial assays.
Doing so, however, presents several challenges. The
disparate channels must be somehow combined, and,
moreover, ideally would be done so flexibly given that
the number of channels can vary between mIF proto-
cols.
Here, we present the Fluoroformer, a Transformer-
like neural network module designed to interpretably
scale MIL to multiplex images.
Leveraging scaled
dot-product attention (SDPA) (Vaswani, 2017), it
fuses the information from disparate multiplexed
channels into a single summary vector for each patch,
enabling the subsequent pooling of the patch em-
beddings via standard attention-based MIL (ABMIL)
mechanisms.
Importantly, the Fluoroformer pro-
duces attention matrices for each patch that may offer
insights into cell-cell interactions and biological struc-
tures. Using a cohort of 434 non-small cell lung can-
cer (NSCLC) samples and their corresponding mIF
WSIs, we find that the Fluoroformer demonstrates
strong performance in predicting patient prognosis.
Analysis of the channel-wise attention matrices offers
insights into immune-tumor interactions that poten-
tially associate with prognosis. Our approach there-
fore bridges spatial biology techniques with state-of-
the-art artificial intelligence approaches to maximize
the potential of this emerging field.
2. Related work
2.1. Attention-based fusion strategies in
histopathology
Attention-based pooling has emerged as among the
most popular information aggregation strategies for
H&E histopathology slides. This includes attention-
based multiple instance learning (ABMIL), a bench-
mark MIL approach for H&E WSIs that consists of
a traditional gated attention mechanism (Ilse et al.,
2018) as further described below. Several works have
also applied scaled dot-product attention (SDPA)
and multihead attention (MHA) (Vaswani, 2017) to
H&E WSIs.
A prime example is TransMIL (Shao
et al., 2021), which leverages MHA rather than gated
attention to pool embeddings across the full slide. Be-
yond aggregating information across patches, atten-
tion mechanisms have also been used to fuse multiple
modalities. Recently, MCAT (Chen et al., 2021) has
leveraged SDPA to integrate genomic data and H&E
embeddings.
2.2. Deep learning for multiplexed pathology
images
Several recent studies have applied deep learning
to mIF. For instance, Sorin et al. (2023) applied a
ResNet-based (He et al., 2016) pipeline to the ROIs
in NSCLC samples and found improved prognostic
performance compared to models relying on tradi-
tional features. Wu et al. (2022) developed a graph
neural network approach based on point patterns
of cell phenotypes, also for mIF ROIs, and likewise
observed higher prognostic performance relative to
hand-engineered metrics. While these works demon-
2
Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion
Background
PD-1
PD-L1
DAPI
CD8
FOXP3
Autofluorescence
Cytokeratin
A
B
C
D
Figure 2: Heatmaps of the most highly attended markers in each patch of selected mIF images for the
Fluoroformer model with a ResNet50 embedder. Patterns are observed such as DAPI being a
highly attended marker for alveolar tissue (A, B) and CD8-attended regions appearing at tumor
margins and sporadically within the tumor (A, C, D).
strate the promise of deep learning applied to mul-
tiplexed images, they require human input to define
relevant regions, limiting scalability and underutiliz-
ing the full amount of data present in WSIs.
3. Methodology
Our Fluoroformer approach adapts MIL to multiplex
WSIs via an attention-based channel fusion mecha-
nism, inserted as an encapsulated module between
the typical patch embedding and slide-level aggrega-
tion stages. We first provide a preliminary summary
of MIL and ABMIL before describing our optimiza-
tions for multiplexing.
3.1. Preliminaries: MIL and ABMIL
Multiple instance learning (MIL) (Ilse et al., 2018;
Maron and Lozano-P´erez, 1997; Carbonneau et al.,
2018) is typically formulated as follows. Each sam-
ple consists of a set-based data structure X = {xk}
known as “bag” that contains, in a permutation-
invariant fashion, K separate “instances” xk, where
each instance xk ∈X and the bag X ∈X ∗. The task
is weakly supervised (Zhou, 2018), meaning that X
is associated with a global label y ∈Y.
MIL models consist of a pooling operation p that
aggregates all instances, paired with a learnable clas-
sifier cϕ (Ilse et al., 2018; Maron and Lozano-P´erez,
1997; Carbonneau et al., 2018). For biomedical im-
age processing, in which images may often be excep-
tionally large, instances consist of small patches of a
larger image (Sudharshan et al., 2019; Javed et al.,
2022; Chen et al., 2024; Xu et al., 2024). These are
embedded via a “featurizer” f : X →H into a la-
tent space H = Rdemb to produce an embedded bag
3
Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion
WSI
mIF + 
ResNet
mIF + 
UNI
H&E + 
ResNet
H&E + 
UNI
D
C
B
A
Figure 3: Heatmaps of patch attention for each com-
bination of imaging modality and neu-
ral embedder.
The mIF heatmaps often
demonstrate higher spatial continuity and
are concentrated towards regions adjacent
to the tumor mass (e.g., B, C), whereas
the H&E maps are often sparser and con-
centrate on inner tumor regions.
H ∈HK:
H = {hk = f (xk) | xk ∈X} .
(1)
Popular choices for f are ResNet50 (He et al., 2016)
trained on ImageNet or, more recently, specialized
foundation models like UNI (Chen et al., 2024) and
Gigapath (Xu et al., 2024) that have been trained
in a self-supervised fashion on large domain-specific
(H&E) datasets. Notably, f is frozen prior to training
of the pooling and classification operations in stan-
dard approaches.
In ABMIL, the pooling operation consists of a
learnable attention module pθ : HK →H that com-
putes a weighted sum of the embedded bag (Ilse et al.,
2018). Most popularly, including in CLAM (Lu et al.,
2021), a single- or double-gated attention mechanism
computes a weighted sum of the patch vectors via an
attention vector a ∈RK (Ilse et al., 2018):
hbag = pθ (H) =
X
k
akhk.
(2)
In the double-gated variant, we have
ak = softmax
 w⊤ tanh
 Vh⊤
k

⊙sigm
 Uh⊤
k

,
(3)
where w ∈Rdemb×1, V ∈Rdemb×demb, and U ∈
Rdemb×demb are learned parameters such that θ =
(w, V, U); ⊙denotes the Hadamard product; and
sigm the sigmoid non-linearity. Biases are implied.
The final module, cϕ, maps the aggregated embed-
dings hbag to the output space Y. Typically, both in
popular implementations and our own below, cϕ con-
sists of a single linear layer that returns the output
logits
y = cϕ(hbag) = w⊤hbag,
(4)
where ϕ = w (again omitting the bias term).
3.2. Fluoroformer: Leveraging MIL for
multiplexing
Multiplexed imaging adds another dimension along
which aggregation must be performed, namely the
large number (∼5-50) of disparate channels corre-
sponding to separate biomarkers. Rather than try-
ing to convert all of these channels into an RGB im-
age or developing an embedder that can directly pro-
cess many channels, we apply a pre-trained featur-
izer to each channel separately. To do so, each chan-
nel is first duplicated thrice along the RGB channel-
dimension to produce a gray-scale image that can be
processed by standard featurizers.
Given M chan-
nels, the global bag corresponding to a full sample
now consists of
X = {xkm} ,
where
xkm ∈X m,
(5)
or, equivalently,
H = {hkm} ,
where
hkm ∈Hm.
(6)
To leverage the benefits of multiplexing in com-
bining features across channels, we borrow insights
from natural language processing (NLP). The seman-
tic information contained in a sentence is not de-
termined by each of its constituent tokens indepen-
dently; rather, the tokens interact in pairwise depen-
dencies to collectively produce the semantic signif-
icance of the full sequence.
Likewise, multiplexing
is often employed to capture complex relationships
4
Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion
between each channel (e.g., tumor and immune cell
interactions), rather than to simply image several fea-
tures simultaneously per se.
We therefore propose fusing embeddings across
channels in each patch using SDPA, mirroring the
message-passing between tokens that is performed
by Transformers. A secondary advantage of such a
pairwise attention mechanism lies in explainability;
meaningful relationships between individual channels
can be captured in the attention matrix of each patch,
potentially identifying novel patterns while also re-
flecting the complex structure in the corresponding
region of the WSI.
3.2.1. Marker attention
Mathematically, the SDPA operation in the Fluoro-
former architecture thereby fills the role of a fourth,
learnable operation gψ : Hm →H to preliminarily
pool along the channel dimension:
ˆhk = gψ ({hkm}) .
(7)
Treating each kth patch as a “sentence” consisting of
M tokens in an demb-dimensional latent space (Otter
et al., 2020), we compute “query,” “key,” and “value”
embeddings Qk, Kk, Vk ∈RM×dhid via standard lin-
ear layers (Vaswani, 2017), then employ the following
formula:
akm = AkmVkm = softmax
QkmK⊤
km
√dhid

Vkm, (8)
where dhid is a hidden dimension and Akm is the
pairwise attention matrix.
Because we will almost always have demb ≫M, we
minimize computational overhead by adding a pre-
liminary bottleneck that contracts the embedding di-
mension demb to a hidden dimension dhid. We let ˜hkm
denote the contracted embedding.
3.2.2. Marker normalization
In keeping with the standard Transformer architec-
ture (Vaswani, 2017), we then employ two skip con-
nections (He et al., 2016) each followed by “marker
normalization” layers. Analogous to layer normaliza-
tion (Ba et al., 2016) in standard NLP models, these
have the motivation of both stabilizing training and
ensuring that no one channel dominates the patch
when performing mean pooling. Specifically, for each
kth patch and mth channel, the sum akm is updated
with its residual
akm ←akm + ˜hkm.
(9)
The resulting tensor is normalized by computing the
statistics
µ(SDPA)
km
=
1
dhid
dhid
X
i=1
akmi
(10)
σ(SDPA)
km
=
v
u
u
t 1
dhid
dhid
X
i=1

akmi −µ(SDPA)
km
2
+ ε, (11)
where ε is a small constant to prevent division by 0
(Ba et al., 2016). The layer then updates each chan-
nel via
akm ←akm −µ(SDPA)
km
σ(SDPA)
km
γ(SDPA) + β(SDPA),
(12)
where γ(SDPA) and β(SDPA) are learnable affine pa-
rameters.
Next, the bottleneck is inverted by a simple lin-
ear layer.
To prevent loss of information, a sec-
ond skip connection adds the original quantity hkm
back to akm followed by another round of patch nor-
malization with corresponding quantities µ(bottleneck)
km
and σ(bottleneck)
km
. GELU is used following each linear
transform (Hendrycks and Gimpel, 2016).
Finally, mean pooling is performed along the
marker dimension, creating a summary ˆhk of the
markers and their interactions within the kth patch:
ˆhk = 1
M
M
X
m=1
akm.
(13)
Having effectively eliminated the additional dimen-
sion, the pooled bag
n
ˆhk
o
becomes equivalent to a
non-multiplexed input such that any MIL aggrega-
tion strategy can be applied thereafter. In our case,
we pass the fused bag to a standard ABMIL double-
gated attention module pθ and linear classifier cϕ as
described above.
4. Experimental Details
We trained the Fluoroformer model to perform
survival prediction for non-small cell lung cancer
(NSCLC) WSIs.
For each sample in the utilized
cohort, both mIF and H&E pathology slides were
available, allowing us to directly compare the perfor-
mance of the Fluoroformer to state-of-the-art H&E
ABMIL approaches. For both, we consider two patch
5
Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion
embedders, namely ResNet50 (He et al., 2016) pre-
trained on ImageNet and UNI (Chen et al., 2024),
a histopathology foundation model consisting of a
vision transformer (ViT) (Dosovitskiy et al., 2020)
trained via the Dinov2 algorithm (Oquab et al., 2023)
on a large H&E dataset. As an additional baseline,
we compare to a Cox proportional hazards (CoxPH)
model (Cox, 1972) fit using the intratumoral cell den-
sities of the mIF biomarkers, as described below.
4.1. Dataset
The NSCLC dataset used consists of 434 primary-site
tumor samples from 414 patients and resulted from
the ImmunoProfile project (Lindsay et al., 2023), a
prospective mIF effort performed at the Dana-Farber
Cancer Institute from 2018-2022. The ImmunoProfile
assay stains for four immune markers (CD8, FOXP3,
PD-L1, PD-1), cytokeratin (Cyto) as a tumor marker,
and DAPI as a counterstain for nucleus detection.
Briefly, CD8 is a marker for cytotoxic T cells that
can attack tumor cells (Raskov et al., 2021). FOXP3
is a marker for regulatory T cells that can indicate im-
mune suppression (Rudensky, 2011). PD-1 and PD-
L1 are involved in immune inhibition and can be ex-
pressed by both immune and tumor cells (Han et al.,
2020). Along with these biomarkers, an autofluores-
cence channel is included in each mIF WSI in the
dataset.
The intratumoral density of cells positive
for each immune marker (CD8, FOXP3, PD-L1, and
PD-1) and the PD-L1 tumor proportion score (TPS)
have also been calculated for each sample based on
expert-annotated ROIs.
These cell density metrics
are commonly used in mIF studies (Lindsay et al.,
2023), where PD-L1 TPS quantifies the percent of
tumor cells that are positive for PD-L1.
For each sample, the H&E and mIF WSIs were ac-
quired from different tissue sections of the same tu-
mor sample and were not registered. Follow-up time
and survival status (deceased or censored) were also
recorded, meaning that each sample consists of the
tuple

X(i)
H&E, X(i)
mIF, t(i), c(i)
, where t(i) ∈R, and
c(i) ∈{0, 1}. As an unselected clinical population,
the dataset consists of tumors across different stages
(306 or 70.5% low-stage, 125 or 28.8% high stage, 3 or
0.7% unknown stage) and different treatment regimes
(97 or 22.4% receiving immunotherapy, 334 or 77.0%
receiving treatment other than immunotherapies, 3
or 0.7% with unknown treatment), representative of
a real-world clinical cohort. All data used in the ex-
periments are de-identified.
4.2. Preprocessing
For the H&E images, preprocessing consisted of first
identifying foreground patches and then embedding
each patch using a pre-trained embedder. For a given
WSI, foreground patches were identified by applying
Otsu’s algorithm (Otsu et al., 1975) to a grayscaled
version of the WSI after downsampling by 224. The
original RGB image patches corresponding to the
foreground were then used as input to the embedder
to create an embedding hk ∈Rdemb for each patch.
We perform experiments with two different embed-
ders: UNI (Chen et al., 2024) (demb = 1024) and
ResNet50 (He et al., 2016) (pre-trained on ImageNet;
demb = 2048).
For identification of foreground patches for mIF,
all seven gray-scale WSI channels were downsampled
and thresholded separately, which was followed by
a pixel-wise OR operation across each of the seven
binary masks to pool along the channel dimension.
For each foreground patch, each channel in the patch
was then repeated three times along an added color
dimension to create a gray RGB image patch and
embedded channel-wise to produce a matrix hk ∈
RM×demb for each kth patch.
4.3. Task and objective function
Pursuing a common strategy for prognostication in
deep learning, we train the Fluoroformer and stan-
dard ABMIL baseline models to regress the discrete
hazard and survival functions (Cox, 1972; Zadeh and
Schmid, 2020), given by
h (t | X) := P(T = t | T ≥t, X)
(14)
and
S (t | X) := P(T > t | X)
=
tY
s=1
(1 −h (s | X)) .
(15)
When the hazard function is discretized (Katzman
et al., 2018; Zadeh and Schmid, 2020), the hazard
ratio is predicted for Nbin intervals defined by cutoffs
{−∞, t1, t2, . . . , tNbin−1}. We use four bins based on
quartiles of event times in the dataset. The output
label for a network is correspondingly a logit vector
ˆy ∈[0, 1]Nbin such that ˆyi is equal to the probability
of the event occurring in the interval [ti−1, ti].
As
proposed by (Zadeh and Schmid, 2020), we then use
6
Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion
the log-likelihood objective given by
L (X, t, c) = −c log S (t | X)
−(1 −c) log S (t −1 | X)
−(1 −c) log h (t | X) .
(16)
4.4. Performance metrics
To evaluate the performance of each model, five-
fold cross-validation with stratification by patient was
performed. Each split involved using three folds for
training, a fourth for validation, and the fifth for test-
ing. For each test fold and each sample therein, a risk
score was computed via
r(i) :=
Nbin
X
j=1
S(i)
j ,
(17)
where S(i)
j
is the survival rate for the jth bin. The
concordance index (C-index) was then computed be-
tween the risk scores and the observed outcomes
(t(i), c(i)), where the C-index is a standard metric
in survival analysis and represents the probability of
correctly ranking pairs of samples. As is standard in
histopathology prognostication tasks, such as bench-
marks using TCGA, the models are trained solely
based on the WSIs and do not receive other patient or
tumor metadata as input (e.g., treatment, age). We
additionally compute the C-index for a CoxPH model
using the intratumoral cell densities (CD8, FOXP3,
PD-L1, PD-1) and PD-L1 TPS as covariates. The
same cross validation folds are used for fitting and
testing this baseline model as the MIL models.
4.5. Attention heatmap metrics
We assessed the patch-wise attention vectors (a) pro-
duced by the models both qualitatively and quanti-
tatively. For the latter, we consider the spatial au-
tocorrelation of the output attention heatmaps with
the following intuition: Neighboring patches in tis-
sue samples often contain similar features, meaning
that robust heatmaps should likely exhibit smoother
spatial variation (i.e., higher spatial autocorrelation).
Mathematically, spatial autocorrelation can be quan-
tified using Moran’s I (MI) (Moran, 1950), which
ranges from -1 (perfect negative correlation) to 1
(perfect positive correlation). The formula employed
was
I :=
N PN
i=1
PN
j=1 wij(xi −¯x)(xj −¯x)
PN
i=1
PN
j=1 wij
 PN
i=1(xi −¯x)2 ,
(18)
where x denotes the image matrix; i and j are patches
in x; ¯x is the mean of x; N the the total number of
units in x; and wij is the spatial weight between pixels
i and j, for which we follow the common definition
of wij = 1 if patches i and j are neighbors and 0
otherwise.
PD-1 PD-L1 DAPI
CD8 FOXP3 Auto
Cyto
PD-1
PD-L1
DAPI
CD8
FOXP3
Auto
Cyto
1.5
1.0
0.5
0.0
0.5
1.0
1.5
Figure 4: Average marker attention matrix (Ak)
across the cohort for the Fluoroformer with
ResNet embeddings. The displayed values
are z-scored, meaning a value of 1 indicates
that the mean attention value for that en-
try is one standard deviation higher than
the global mean across all markers.
The
x- and y-axes represent in- and outgoing
attention, respectively.
4.6. Training and implementation details
All experiments were conducted on NVIDIA A100
GPUs with 80Gb of VRAM using the PyTorch
(Paszke et al., 2019) software library.
Lightning
(Falcon, 2019) and Weights and Biases (Biewald,
2020) were employed to simplify training and logging.
The AdamW optimization algorithm (Loshchilov and
Hutter, 2017) with a learning rate of 1×10−4 was em-
ployed without a scheduler. All models were trained
for a total of 25 epochs, which was sufficient for model
convergence. The C-index was computed using the
Lifelines package (Davidson-Pilon, 2019) on the val-
idation fold at the end of each training epoch, with
model weights being checkpointed if a new maximum
was reached.
7
Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion
5. Results
Table 1: C-index and Moran’s I (MI) by image type
and embedding model
Image
Model
C-index ± STD
MI
mIF
ResNet
0.800 ± 0.053
0.501
UNI
0.807 ± 0.056
0.407
H&E
ResNet
0.771 ± 0.043
0.054
UNI
0.825 ± 0.077
0.353
5.1. Prognostic performance
The performance of the Fluoroformer approach is
summarized in Table 1. Averaging across all 5 folds,
the Fluoroformer achieves a C-index of 0.800 when
using a ResNet50 embedder, compared to 0.771 for
the H&E-ABMIL baseline using the ResNet50 em-
bedder.
UNI improves H&E performance as ex-
pected, with the Fluoroformer exhibiting a small in-
crease in performance to 0.807. For comparison, the
mIF-based CoxPH baseline based on commonly-used
cell density metrics achieved a C-index of 0.689 ±
0.056.
Thus, despite using off-the-shelf embedders
optimized for H&E and/or RGB images, the Fluoro-
former strategy exhibits strong absolute and relative
performance.
5.2. Marker-wise co-attention relationships
A core benefit of the Fluoroformer approach is the
generation of attention matrices (Ak) between the
different marker channels.
We computed an aver-
age marker attention matrix to obtain an aggregated
summary of the learned channel interactions. The av-
erage was computed by taking the 10% most highly
weighted patches for each WSI according to the vec-
tor a, and is displayed in Figure 2 for ResNet50 and
in the Appendix for UNI. Across both models, overall
higher attention is observed towards the PD-1, DAPI,
and cytokeratin channels.
Moreover, we visualized spatial variation in marker
attention across individual WSIs (Figure 3). Specifi-
cally, in each matrix Ak, we identified the marker re-
ceiving the most in-going attention by summing the
entries in each column, then locating the index of the
maximum value in the resulting 7-dimensional vector.
We then visualized the resulting “channel argmax
heatmaps” for each slide (Figure 3 for ResNet, Ap-
pendix Figure 7 for UNI). As expected based on the
analysis above, PD-1 was commonly the most at-
tended to channel.
Cytokeratin also received the
highest attention in regions of the tumor mass (Fig-
ure 3AC), while DAPI received the most in alveo-
lar structures (Figure 3AB). Patches high in atten-
tion to PD-L1 were also observed, commonly directly
adjacent to patches of high attention to cytokeratin
(Figure 3BC), with high levels of attention to CD8
and FOXP3 in regions that were often adjacent to
the tissue, potentially relating to immune infiltration
(Figure 3D).
5.3. Patch-wise attention heatmaps
While the marker attention matrices offer insights
into how the channels are combined per patch, the
patch attention heatmaps from ABMIL indicate how
the patches are combined into a WSI-level represen-
tation. Figure 4 contains exemplar patch attention
heatmaps for the Fluoroformer and H&E models,
with a higher resolution version also included as Fig-
ure 5 in the Appendix. As quantified by Moran’s I,
the mIF-based Fluoroformer models exhibit higher
spatial autocorrelation (i.e., smoothness) on aver-
age across the dataset (0.501 and 0.407 for Fluoro-
former with ResNet and UNI, respectively, compared
to 0.054 and 0.353 for the H&E models).
There
are also visible differences in the regions most at-
tended to by the different models. In the representa-
tive examples shown for instance, the Fluoroformer
model more highly attended to tumor margins (Fig-
ure 4BC), whereas the H&E attention maps were
largely concentrated on the tumor mass, indicating
possibly complementary prognostic features.
6. Discussion and Conclusions
In this work,
we develop the Fluoroformer,
a
Transformer-inspired
neural
network
architecture
emphasizing biological interpretability and designed
to scale attention-based multiple instance learning to
multiplexed images.
Using a dataset of 7-channel
mIF WSIs from 416 NSCLC patients, the approach
demonstrates strong performance in predicting pa-
tient prognosis. Importantly, the approach is flexible
in terms of number of channels and embedders, even
demonstrating similar performance to a H&E-based
model when using a H&E foundational model. We
expect even higher performance with mIF-optimized
8
Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion
embedders in the future, though the variability in
mIF assays presents challenges for the universality of
such embedders.
As such, we focused on develop-
ing a MIL strategy that can be applied to existing
embedders.
Beyond predictive performance, a key
motivation for the strategy is its marker-wise atten-
tion interpretability.
We highlight its potential for
investigating spatial patterns in the tumor immune
microenvironment, which is increasingly important
in the age of immunotherapies. This interpretability
is enhanced by the patch-level attention heatmaps,
for which we observe higher spatial smoothness than
H&E based models. Future important work will in-
volve further quantification and assessment of the ob-
served patterns and their biological significance. As
multiplexed, spatial biology techniques are increas-
ingly used, the Fluoroformer may therefore serve as
a general purpose method towards maximizing the
utility of these rich data.
Acknowledgments
We thank Scott Rodig, James Lindsay, Jennifer Al-
treuter, and Katharina Hoebel for fruitful discus-
sions and their support regarding the ImmunoProfile
dataset. WL acknowledges support from the Ellison
Foundation and the Wong Family Award in Transla-
tional Oncology.
References
Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E
Hinton.
Layer normalization.
arXiv preprint
arXiv:1607.06450, 2016.
Lukas Biewald.
Experiment tracking with weights
and biases, 2020. URL https://www.wandb.com/.
Software available from wandb.com.
Marc-Andr´e Carbonneau, Veronika Cheplygina, Eric
Granger, and Ghyslain Gagnon.
Multiple in-
stance learning: A survey of problem character-
istics and applications.
Pattern Recognition, 77:
329–353, 2018.
Richard J Chen, Ming Y Lu, Wei-Hung Weng,
Tiffany Y Chen, Drew FK Williamson, Trevor
Manz, Maha Shady, and Faisal Mahmood. Mul-
timodal co-attention transformer for survival pre-
diction in gigapixel whole slide images. In Proceed-
ings of the IEEE/CVF international conference on
computer vision, pages 4015–4025, 2021.
Richard J Chen, Tong Ding, Ming Y Lu, Drew FK
Williamson, Guillaume Jaume, Andrew H Song,
Bowen
Chen,
Andrew
Zhang,
Daniel
Shao,
Muhammad Shaban, et al.
Towards a general-
purpose
foundation
model
for
computational
pathology. Nature Medicine, 30(3):850–862, 2024.
David R Cox.
Regression models and life-tables.
Journal of the Royal Statistical Society: Series B
(Methodological), 34(2):187–202, 1972.
Cameron Davidson-Pilon. lifelines: survival analysis
in python. Journal of Open Source Software, 4(40):
1317, 2019. doi: 10.21105/joss.01317. URL https:
//doi.org/10.21105/joss.01317.
Alexey
Dosovitskiy,
Lucas
Beyer,
Alexander
Kolesnikov,
Dirk
Weissenborn,
Xiaohua
Zhai,
Thomas Unterthiner, Mostafa Dehghani, Matthias
Minderer, Georg Heigold, Sylvain Gelly, et al.
An image is worth 16x16 words:
Transformers
for image recognition at scale.
arXiv preprint
arXiv:2010.11929, 2020.
William Falcon.
Pytorch lightning. GitHub. Note:
https://github.com/PyTorchLightning/pytorch-
lightning, 2019.
Parmida Ghahremani, Yanyun Li, Arie Kaufman,
Rami Vanguri, Noah Greenwald, Michael Angelo,
Travis J Hollmann, and Saad Nadeem.
Deep
learning-inferred multiplex immunofluorescence for
immunohistochemical image quantification. Nature
machine intelligence, 4(4):401–412, 2022.
Yanyan Han, Dandan Liu, and Lianhong Li.
Pd-
1/pd-l1 pathway:
current researches in cancer.
American journal of cancer research, 10(3):727,
2020.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun. Deep residual learning for image recognition.
In Proceedings of the IEEE conference on com-
puter vision and pattern recognition, pages 770–
778, 2016.
Dan Hendrycks and Kevin Gimpel.
Gaussian
error
linear
units
(gelus).
arXiv
preprint
arXiv:1606.08415, 2016.
Katharina Viktoria Hoebel, James R Lindsay, Joao V
Alessi, Jason L Weirather, Ian D Dryg, Jennifer
Altreuter, Mark M Awad, Scott J Rodig, and
William E Lotter. Deep-learning model trained on
9
Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion
multiplex immunofluorescence-stained tissue sam-
ples predicts the survival of patients with non-small
cell lung cancer better than pd-l1 tps alone. Cancer
Research, 84(6 Supplement):6189–6189, 2024.
Maximilian Ilse, Jakub Tomczak, and Max Welling.
Attention-based deep multiple instance learning.
In International conference on machine learning,
pages 2127–2136. PMLR, 2018.
Syed Ashar Javed, Dinkar Juyal, Harshith Padi-
gela, Amaro Taylor-Weiner, Limin Yu, and Aa-
ditya Prakash.
Additive mil: Intrinsically inter-
pretable multiple instance learning for pathology.
Advances in Neural Information Processing Sys-
tems, 35:20689–20702, 2022.
Jared L Katzman, Uri Shaham, Alexander Cloninger,
Jonathan Bates, Tingting Jiang, and Yuval Kluger.
Deepsurv:
personalized treatment recommender
system using a cox proportional hazards deep neu-
ral network. BMC medical research methodology,
18:1–12, 2018.
Chung-Wein Lee, Yan J Ren, Mathieu Marella, Maria
Wang, James Hartke, and Suzana S Couto. Multi-
plex immunofluorescence staining and image analy-
sis assay for diffuse large b cell lymphoma. Journal
of immunological methods, 478:112714, 2020.
James Lindsay, Bijaya Sharma, Kristen D Felt, Anita
Giobbie-Hurder, Ian Dryg, Jason L Weirather, Jen-
nifer Altreuter, Tali Mazor, Priti Kumari, Joao V
Alessi,
et al.
Immunoprofile:
A prospective
implementation of clinically validated, quantita-
tive immune cell profiling test identifies tumor-
infiltrating cd8+ and pd-1+ cell densities as prog-
nostic biomarkers across a 2,023 patient pan-cancer
cohort treated with different therapies. Cancer Re-
search, 83(7 Supplement):5706–5706, 2023.
Ilya Loshchilov and Frank Hutter.
Decoupled
weight
decay
regularization.
arXiv
preprint
arXiv:1711.05101, 2017.
Ming Y Lu, Drew FK Williamson, Tiffany Y Chen,
Richard J Chen, Matteo Barbieri, and Faisal Mah-
mood. Data-efficient and weakly supervised com-
putational pathology on whole-slide images. Nature
biomedical engineering, 5(6):555–570, 2021.
Oded Maron and Tom´as Lozano-P´erez. A framework
for multiple-instance learning. Advances in neural
information processing systems, 10, 1997.
Patrick AP Moran. Notes on continuous stochastic
phenomena. Biometrika, 37(1/2):17–23, 1950.
Clara Mu˜noz-Castro, Ayush Noori, Colin G Mag-
damo, Zhaozhi Li, Jordan D Marks, Matthew P
Frosch, Sudeshna Das, Bradley T Hyman, and Al-
berto Serrano-Pozo.
Cyclic multiplex fluorescent
immunohistochemistry and machine learning re-
veal distinct states of astrocytes and microglia in
normal aging and alzheimer’s disease. Journal of
Neuroinflammation, 19(1):30, 2022.
Maxime Oquab, Timoth´ee Darcet, Th´eo Moutakanni,
Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre
Fernandez,
Daniel
Haziza,
Francisco
Massa,
Alaaeldin El-Nouby, et al. Dinov2: Learning robust
visual features without supervision. arXiv preprint
arXiv:2304.07193, 2023.
Nobuyuki Otsu et al. A threshold selection method
from gray-level histograms.
Automatica, 11(285-
296):23–27, 1975.
Daniel W Otter, Julian R Medina, and Jugal K
Kalita. A survey of the usages of deep learning for
natural language processing. IEEE transactions on
neural networks and learning systems, 32(2):604–
624, 2020.
Adam Paszke, Sam Gross, Francisco Massa, Adam
Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca
Antiga, et al. Pytorch: An imperative style, high-
performance deep learning library.
Advances in
neural information processing systems, 32, 2019.
Haoxin Peng, Xiangrong Wu, Shaopeng Liu, Miao
He, Chao Xie, Ran Zhong, Jun Liu, Chenshuo
Tang, Caichen Li, Shan Xiong, et al.
Multiplex
immunofluorescence and single-cell transcriptomic
profiling reveal the spatial cell interaction networks
in the non-small cell lung cancer microenviron-
ment. Clinical and Translational Medicine, 13(1):
e1155, 2023.
Hans Raskov, Adile Orhan, Jan Pravsgaard Chris-
tensen, and Ismail G¨ogenur. Cytotoxic cd8+ t cells
in cancer and cancer immunotherapy. British Jour-
nal of Cancer, 124:359–367, 2021.
Alexander Y. Rudensky. Regulatory t cells and foxp3.
Immunological Reviews, 241(1):260–268, 2011. doi:
https://doi.org/10.1111/j.1600-065X.2011.01018.
x.
URL https://onlinelibrary.wiley.com/
doi/abs/10.1111/j.1600-065X.2011.01018.x.
10
Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion
Zhuchen Shao, Hao Bian, Yang Chen, Yifeng Wang,
Jian Zhang, Xiangyang Ji, et al. Transmil: Trans-
former based correlated multiple instance learn-
ing for whole slide image classification. Advances
in neural information processing systems, 34:2136–
2147, 2021.
Mark Sorin, Elham Karimi, Morteza Rezanejad,
W Yu Miranda, Lysanne Desharnais, Sheri AC
McDowell, Samuel Dor´e, Azadeh Arabzadeh, Va-
lerie Breton, Benoit Fiset, et al. Single-cell spa-
tial landscape of immunotherapy response reveals
mechanisms of cxcl13 enhanced antitumor immu-
nity. Journal for Immunotherapy of Cancer, 11(2),
2023.
PJ Sudharshan, Caroline Petitjean, Fabio Spanhol,
Luiz Eduardo Oliveira, Laurent Heutte, and Paul
Honeine. Multiple instance learning for histopatho-
logical breast cancer image classification. Expert
Systems with Applications, 117:103–111, 2019.
Ashish Vaswani.
Attention is all you need.
arXiv
preprint arXiv:1706.03762, 2017.
Christopher M Wilson, Oscar E Ospina, Mary K
Townsend, Jonathan Nguyen, Carlos Moran Se-
gura, Joellen M Schildkraut, Shelley S Tworoger,
Lauren C Peres, and Brooke L Fridley. Challenges
and opportunities in the statistical analysis of mul-
tiplex immunofluorescence data. Cancers, 13(12):
3031, 2021.
Zhenqin Wu, Alexandro E Trevino, Eric Wu, Kyle
Swanson, Honesty J Kim, H Blaize D’Angio, Ryan
Preska, Gregory W Charville, Piero D Dalerba,
Ann Marie Egloff, et al. Graph deep learning for
the characterization of tumour microenvironments
from spatial protein profiles in tissue specimens.
Nature Biomedical Engineering, 6(12):1435–1448,
2022.
Hanwen Xu, Naoto Usuyama, Jaspreet Bagga, Sheng
Zhang, Rajesh Rao, Tristan Naumann, Cliff Wong,
Zelalem Gero, Javier Gonz´alez, Yu Gu, et al. A
whole-slide foundation model for digital pathology
from real-world data. Nature, pages 1–8, 2024.
Shekoufeh Gorgi Zadeh and Matthias Schmid. Bias in
cross-entropy-based training of deep survival net-
works. IEEE transactions on pattern analysis and
machine intelligence, 43(9):3126–3137, 2020.
Zhi-Hua Zhou. A brief introduction to weakly super-
vised learning. National science review, 5(1):44–53,
2018.
Appendix
Appendix figures are displayed in subsequent pages.
11
Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion
WSI
mIF + 
ResNet
mIF + 
UNI
H&E + 
ResNet
H&E + 
UNI
D
C
B
A
Figure 5: Heatmaps of patch attention for each combination of imaging modality and neural embedder. The
data is the same as displayed in the main text, but at high resolution.
12
Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion
Background
PD-1
PD-L1
DAPI
CD8
FOXP3
Autofluorescence
Cytokeratin
A
B
C
D
Figure 6: Heatmaps of the most highly attended markers in each patch of selected mIF images for the
Fluoroformer model with a UNI embedder.
13
Fluoroformer: Scaling multiple instance learning to multiplexed images via attention-based channel fusion
PD-1 PD-L1 DAPI
CD8 FOXP3 Auto
Cyto
PD-1
PD-L1
DAPI
CD8
FOXP3
Auto
Cyto
1.5
1.0
0.5
0.0
0.5
1.0
1.5
Figure 7: Average marker attention matrix (Ak) across the cohort for the Fluoroformer with UNI embed-
dings. The displayed values are z-scored, meaning a value of 1 indicates that the mean attention
value for that entry is one standard deviation higher than the global mean across all markers. The
x- and y-axes represent in- and outgoing attention, respectively.
14
