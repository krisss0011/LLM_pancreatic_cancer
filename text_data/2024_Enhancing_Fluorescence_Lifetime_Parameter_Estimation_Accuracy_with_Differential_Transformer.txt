Enhancing Fluorescence Lifetime Parameter
Estimation Accuracy with Differential
Transformer Based Deep Learning Model
Incorporating Pixelwise Instrument Response
Function
ISMAIL ERBAS,1,2,* VIKAS PANDEY,1,2 NAVID IBTEHAJ NIZAM,1,2
NANXUE YUAN,1,2 AMIT VERMA,3 MARGARIDA BAROSSO,3 XAVIER
INTES,1,2
1Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY 12180, USA
2Center for Modeling, Simulation, and Imaging in Medicine, Rensselaer Polytechnic Institute, Troy, NY
12180, USA
3Department of Molecular and Cellular Physiology, Albany Medical College, Albany, NY 12208, USA
*erbasi@rpi.edu
Abstract: Fluorescence lifetime imaging (FLI) is an important molecular imaging modality
that can provide unique information for biomedical applications. FLI is based on acquiring
and processing photon time of arrival histograms. The shape and temporal offset of these
histograms depends on many factors, such as the instrument response function (IRF), optical
properties, and the topographic profile of the sample. Several inverse solver analytical methods
have been developed to compute the underlying fluorescence lifetime parameters, but most of
them are computationally expensive and time-consuming. Thus, deep learning (DL) algorithms
have progressively replaced computation methods in fluorescence lifetime parameter estimation.
Often, DL models are trained with simple datasets either generated through simulation or a
simple experiment where the fluorophore surface profile is mostly flat; therefore, DL models
often do not perform well on samples with complex surface profiles such as ex-vivo organs or
in-vivo whole intact animals. Herein, we introduce a new DL architecture using state-of-the-art
Differential Transformer encoder-decoder architecture, MFliNet (Macroscopic FLI Network),
that takes an additional input of IRF together with TPSF, addressing discrepancies in the photon
time-of-arrival distribution. We demonstrate the modelâ€™s performance through carefully designed,
complex tissue-mimicking phantoms and preclinical in-vivo cancer xenograft experiments.
1.
Introduction
Fluorescence lifetime imaging (FLI) is a powerful molecular imaging technique with high
sensitivity and the ability to provide unique signatures with high specificity [1,2]. Fluorescence
lifetime and its associated parameters enable multiplexing studies [3â€“5] and can report on
numerous unique biological signatures, including micro-environmental parameters, protein
conformations, metabolic states, protein-protein interactions, and/or ligand-target engagement
[6â€“9]. FLI has known constant growth over the last three decades, with a significant acceleration
in its dissemination thanks to the availability of a user-friendly FLI microscope [10â€“12]. In
parallel, over the last two decades, FLI has found an increased utility in translational applications,
ranging from the mesoscopic (mFLI) [13] to the macroscopic regime (MFLI) [14â€“16]. Compared
to microscopic implementations, mFLI and MFLI are significantly more challenging due to
the requirement of using Near Infrared (NIR) fluorophores for deeper tissue penetration. As
fluorophores are red shifted, it is typical that their lifetimes are shorter (nanosecond (ns) or
sub-nanosecond compared to few nanoseconds in the visible) [16] whereas large-format detectors
exhibit low quantum efficiency (a few percent only) [17,18]. Hence, quantifying lifetime and
arXiv:2411.16896v1  [eess.IV]  25 Nov 2024
its associated parameters can be challenging due to very short fluorescence decays and/or low
photon counts [19â€“22]. Unlike microscopic imaging, where the sample preparation allows for
precise control over the imaging plane, mFLI, and MFLI samples can exhibit a large depth of
field (DOF). These lead to significant variations in the time of arrival of the acquired data, which
needs also be taken into account for accurate lifetime quantification. This is especially important
in clinical systems, such as endoscopic or fluorescence-guided surgical instruments in which the
tissue profiles can lead to DOF variations of a few centimeters.
To address these challenges, understanding the underlying methodology for estimating lifetime
parameters becomes important. In mFLI and MFLI, lifetime parameters can be estimated by
deconvolving the temporal point spread function (TPSF) and instrument response function (IRF).
TPSF is the temporal histogram of the acquired fluorescence photons exiting the surface of the
sample after a pulse excitation. The IRF represents the temporal response of the imaging system
to pulsed illumination [23]. Considering the complexity involved in estimating FLI parameters
across diverse imaging conditions, fast and advanced data processing techniques are necessary to
enhance both the precision and efficiency of these analyses. Recently, the field has seen a shift
toward rapid, fit-free deep learning (DL) methodologies to alleviate the computational burden
and reliance on user expertise, typically associated with methods such as nonlinear least squares
fitting (NLSF) for FLI parameter estimation [24,25]. This advancement makes real-time FLI a
possibility [26,27], driven by the development of novel DL methods that eliminate traditional
time-consuming computational approaches. FLI-Net, a DL model developed for FLI parameter
estimation [28], is used to analyze FLI data quickly, producing 2D quantitative images of the
lifetimes and corresponding parameters directly without requiring manual parameter adjustments,
outputting 2D quantitative images of the lifetime parameters directly. FLI-Net is versatile of
FLI experiments, including visible and near-infrared (NIR) imaging, making it adaptable to a
large range of biomedical applications. FLI-Net takes the TPSF as an input and outputs FLI
parameters. The experimental IRF was used in data generation of the training data; hence, it was
represented in the TPSFs. However, FLI-Net was not designed to analyze pixel-wise IRFs while
it predicts the lifetime parameters.
Despite the advancements in deep learning for FLI data analysis, the lack of pixel-wise IRF
considerations poses limitations. The IRF integrates both the excitation part (including the laser
source temporal profile) and detection (including the electronic limited reaction time) aspects
of the optical setup. The complex broadening or distortion of the intrinsic fluorescence decay
is caused by the detection part of the IRF from imaging system characteristics; however, the
temporal offset in the IRF is caused by the photon time-of-arrival delays caused by the distance
between the imager and sample surface [22]. Hence, topographic variations in the sample surface
can lead to variations in delays in photon arrival times per pixel. In such cases, it is important to
incorporate pixel-wise IRF in the FLI data processing pipeline. To address these limitations and
consider the essential role of the IRF in accurate FLI parameter estimation, we propose a novel
deep-learning approach tailored specifically for processing FLI data.
Following the developments in DL models, we leverage herein the ability of transformers
to handle sequential data. Generally, transformers have a natural ability to capture long-range
connections within data [29â€“32]. In the context of FLI, they can effectively identify and learn
the relationships between the TPSF and IRF for accurate lifetime estimation. Furthermore, the
self-attention mechanism in transformers allows them to focus on the most relevant parts of the
input data for making predictions [32]. In this study, we developed MFliNet to incorporate the
Differential Transformer (DIFF Transformer) [33], enhancing its ability to process sequential data
for accurate fluorescence lifetime parameter estimation. Our work introduces a novel decoder
layer design that integrates the DIFF Transformer for the first time in literature, improving the
modelâ€™s adaptability to account for shifts caused by variations in the DOF. The DIFF Transformer
employs a differential attention mechanism, which calculates attention scores as the difference
between two separate softmax attention maps, effectively canceling noise. This cancellation
mechanism encourages sparse attention patterns, intensifying the focus on relevant contextual data
while reducing distractions caused by irrelevant input. Analogous to noise-canceling systems, this
approach mitigates the problem of over-allocating attention to non-critical information, a common
issue with traditional transformers. DIFF Transformers outperform conventional transformers
across various domains, especially in long-context modeling, key information retrieval, and
robustness against variability in input structure. In the context of Time-Resolved FLI, these
characteristics enable the detection of critical patterns even in low signal-to-noise scenarios,
achieving higher accuracy and robustness compared to standard transformer architectures. These
advancements mark a significant progression in FLI methodologies, offering a more effective
tool for handling complex biological and imaging variability.
2.
Methods
2.1.
Imaging setup
All experimental data used in this work were captured on our MFLI system, where the detailed
information can be found in [34]. Briefly, the system uses a large-format Intensified Charge-
Coupled Device (ICCD) camera (Picostar HR, LaVision GmbH, Germany), for wide-field
detection over a 8 Ã— 6 cm2 in combination with a Digital micro-mirrors device (DMD), DLi
4110, Texas Instruments, TX, USA, for a wide-field illumination. As an excitation source, we
used a tunable Ti-Sapphire laser, Mai Tai HP, Spectra-Physics, CA, USA, which delivers 100
femtosecond pulses at 80 MHz. A gate width of 300 picoseconds (ps) and gate delay of 40 ps
were used for capturing time-resolved fluorescence decays (for in vivo and in vitro experiments)
with a total of 176 time points, which is referred to as a number of gates (G=176). An emission
filter at 740 Ã— 10 nm (FF01-740/13-25, Semrock, IL, Rochester, NY, USA) is used to capture the
TPSFs, with the laser set at a 700 nm wavelength, and Alexa Fluor 700 dye was used to obtain
the time-resolved fluorescence signals.
2.2.
Generation of training data and classical Fluorescence lifetime processing
Fluorescence Lifetime decay follows exponential decay. Depending on the number of components
present in the sample, the decay kinetics can be described by a combination of multi-exponential
functions. Most FLI imaging experiments involve up to two components, hence a bi-exponential
model is typically used. The two-component or bi-exponential model also includes mono-
exponential cases (where fractional amplitudes ğ´ğ‘…are one or zero). Mathematically, the TPSF is
the convolution of the IRF and the fluorescence decay associated with the lifetime parameters as
shown in Eq. 1, where lifetime decays are denoted as ğœ1, ğœ2, and ğ´ğ‘…is the amplitude fraction.
ğ‘‡ğ‘ƒğ‘†ğ¹(ğ‘¡) = ğ¼ğ‘…ğ¹(ğ‘¡) âˆ—

ğ´ğ‘…ğ‘’âˆ’ğ‘¡
ğœ1 + (1 âˆ’ğ´ğ‘…)ğ‘’âˆ’ğ‘¡
ğœ2

(1)
The in silico data used for training and validating the proposed model was generated using Eq.
1. Initially, time-resolved fluorescence lifetime images with dimensions of 28 Ã— 28 pixels were
generated by using the MNIST dataset. Fluorescence decays were generated for a range of lifetime
values commonly used in NIR applications: 0.2 ns to 0.8 ns for ğœ1 (short-lifetime component)
and 0.8 ns to 1.5 ns for ğœ2 (long-lifetime component). The range of the ğ´ğ‘…(fraction amplitude)
was set from 0% to 100%, respectively (both bound corresponding to mono-exponential cases).
To ensure that our simulated data accurately represents experimental applications, pixel-wise
IRFs were used. To capture experimental IRFs, a white diffused paper was placed on the imaging
table and illuminated using the DMD with an excitation wavelength of 700 nm. The reflected
light was captured using a neutral density (ND) filter. Subsequently, each TPSF was generated by
convolving randomly selected IRF from the dataset with simulated fluorescence decay profiles.
To approximate the noise characteristics of real-world measurements, system-derived noise,
including read-out noise, dark noise, etc., as explained in [34], was incorporated into the simulated
TPSFs. This approach ensures that the simulated data closely matches the noise dynamics
observed in the actual system.
To evaluate and compare the modelâ€™s performance in the absence of experimental ground truth,
we used the NLSF method, which is commonly used to estimate the FLI parameters described
in Eq. 1. Traditionally, FLI parameters are estimated from experimental data through iterative
fitting optimization methods such as the NLSF, which incorporates the Levenberg-Marquardt
algorithm [35], or center of mass (CMM) analysis [36]. For our NLSF analysis, we utilized
a software named AlliGator [37], allowing adjustments and constraints on fitting parameters,
including short and long lifetimes, fraction amplitudes, and offsets, depending on experimental
conditions. We selected between single and double exponential decay models according to the
complexity of our datasets. AlliGator also provides an option for offset correction when there is
a mismatch between the TPSF and IRF. We evaluated the importance of offset correction in our
NLSF analysis by comparing data with and without this feature in our phantom experiments.
Additionally, we benchmarked our results against those obtained using FLI-Net to provide a
comprehensive evaluation of our approach in the context of established methodologies.
2.3.
Deep learning network architecture
Fig. 1. Proposed transformer-based deep learning network architecture
MFliNet is a novel architecture designed for FLI parameter estimation, particularly effective
under varying IRFs. The model leverages a Differential Transformer framework, incorporating a
unique differential attention mechanism to enhance feature extraction while mitigating the effects
of noise. The theoretical background on the differential attention mechanism is detailed in [33].
At the core of MFliNet is the differential attention mechanism, which computes attention
scores by contrasting two separate multi-head attention outputs. Specifically, the mechanism
calculates the difference between two attention maps, scaled by a parameter ğœ†, to focus on relevant
patterns and suppress noise. The differential attention is defined as:
DiffAttn(ğ‘‹) =

softmax
ğ‘„1ğ¾âŠ¤
1
âˆšğ‘‘ğ‘˜

ğ‘‰1 âˆ’ğœ†Â· softmax
ğ‘„2ğ¾âŠ¤
2
âˆšğ‘‘ğ‘˜

ğ‘‰2

,
(2)
where:
â€¢ ğ‘„1, ğ¾1,ğ‘‰1 are the query, key, and value matrices for the first attention head, derived from
the input ğ‘‹using learned projections.
â€¢ ğ‘„2, ğ¾2,ğ‘‰2 are the query, key, and value matrices for the second attention head, also derived
from ğ‘‹.
â€¢ ğ‘‘ğ‘˜is the dimensionality of the key vectors.
â€¢ ğœ†is a learnable scalar parameter that balances the contributions of the two attention maps.
The queries, keys, and values are computed as:
ğ‘„ğ‘–= ğ‘‹ğ‘Šğ‘„
ğ‘–,
ğ¾ğ‘–= ğ‘‹ğ‘Šğ¾
ğ‘–,
ğ‘‰ğ‘–= ğ‘‹ğ‘Šğ‘‰
ğ‘–,
for ğ‘–= 1, 2,
(3)
where ğ‘Šğ‘„
ğ‘–, ğ‘Šğ¾
ğ‘–, and ğ‘Šğ‘‰
ğ‘–are the learned weight matrices for the ğ‘–-th attention head.
This differential attention mechanism enhances the modelâ€™s ability to focus on critical features
by emphasizing the differences between two attention outputs, effectively reducing the impact of
noise. The parameter ğœ†controls the degree to which the second attention output is subtracted
from the first.
Each input sequence passes through two stacked encoder blocks, each comprising a differential
attention layer, followed by layer normalization and a feed-forward network (FFN) with SwiGLU
activation. The encoder block operates as follows:
Attention Output = DiffAttn(ğ‘‹),
(4)
Add & Norm1 = LayerNorm(ğ‘‹+ Attention Output),
(5)
FFN Output = FFN(Add & Norm1),
(6)
Encoder Output = LayerNorm(Add & Norm1 + FFN Output),
(7)
where the feed-forward network is defined as:
FFN(ğ‘¥) = (Swish(ğ‘¥ğ‘Š1 + ğ‘1) âŠ™(ğ‘¥ğ‘Š2 + ğ‘2)) ğ‘Š3 + ğ‘3,
(8)
with ğ‘Š1, ğ‘Š2, ğ‘Š3 being learned weight matrices, ğ‘1, ğ‘2, ğ‘3 bias vectors, âŠ™representing element-
wise multiplication, and Swish being the activation function defined as Swish(ğ‘¥) = ğ‘¥Â· ğœ(ğ‘¥),
where ğœ(ğ‘¥) is the sigmoid function.
The decoder blocks incorporate both self-attention and cross-attention mechanisms. The
self-attention layer within the decoder uses the differential attention mechanism to capture
intra-sequence relationships. The cross-attention layer aligns the decoderâ€™s inputs with the
encoder outputs, integrating information from both inputs. The decoder block operates as:
Self-Attn Output = DiffAttn(ğ‘‹),
(9)
Add & Norm1 = LayerNorm(ğ‘‹+ Self-Attn Output),
(10)
Cross-Attn Output = Attention(Add & Norm1, ğ¸, ğ¸),
(11)
Add & Norm2 = LayerNorm(Add & Norm1 + Cross-Attn Output),
(12)
FFN Output = FFN(Add & Norm2),
(13)
Decoder Output = LayerNorm(Add & Norm2 + FFN Output),
(14)
where ğ¸represents the encoder outputs from the corresponding input sequence, and the
standard attention mechanism is defined as:
Attention(ğ‘„, ğ¾,ğ‘‰) = softmax
ğ‘„ğ¾âŠ¤
âˆšğ‘‘ğ‘˜

ğ‘‰.
(15)
MFliNetâ€™s architecture includes three parallel output pathways, each dedicated to predicting
one of the FLI parameters: short lifetime, long lifetime, and fractional amplitude. Each pathway
processes the decoder outputs through additional layers to refine the predictions.
The final outputs are obtained by reshaping the decoder outputs and applying a convolutional
layer with kernel size 1 Ã— 1, using the Exponential Linear Unit (ELU) activation function and L2
regularization to prevent overfitting:
Outputğ‘–= Conv2DELU(Reshape(Decoder Outputğ‘–)),
for ğ‘–= 1, 2, 3,
(16)
where Conv2DELU denotes a 2D convolutional layer with ELU activation and L2 regularization
applied to the reshaped decoder output corresponding to each parameter.
Training was conducted using the Adam optimizer with an adaptive learning rate starting
from 0.001. The loss function for each output branch was Mean Squared Error (MSE). The
dataset comprised 2,000 samples (totaling 1,568,000 generated time-resolved photon signals and
corresponding IRFs), with 10% reserved for validation. The modelâ€™s design allows it to capture
both local and global patterns in the data, effectively modeling variations in time-domain signals
and encoding the relationships between inputs and FLI parameters.
2.4.
Phantom preparation
For experimental validation, we designed a step ladder phantom to introduce variations in
sample-detector distance, as depicted in Figure 2(a). A 3D printable case was designed to
accommodate five discrete containers arranged at various heights: ground level, 5 mm, 10 mm, 15
mm, and 20 mm. Each container was crafted with dimensions of 40Ã—40Ã—10 mm to accommodate
tissue-mimicking phantoms. The phantoms were made with agar constituting 1% of the total
volume (80 cm3). To prepare the phantoms, agar was first dissolved in distilled water, heated
until fully integrated, and then allowed to cool slightly before further processing. The optical
properties of the phantoms (absorption coefficient (ğœ‡ğ‘) of 0.005 mmâˆ’1 and a reduced scattering
coefficient (ğœ‡â€²
ğ‘ ) of 1 mmâˆ’1) were controlled through the addition of India Ink and intralipid
solutions, to provide absorption and scattering contrasts respectively [38]. In each ladder step,
a specific area was designated for the placement of a cuboidal fluorescence embedding, with
dimensions of 5 Ã— 5 Ã— 40 mm. This embedding consisted of Alexa Fluor 700 dye dissolved in
phosphate-buffered saline to achieve a concentration of 20 ğœ‡M. The embeddings were placed at a
depth of 1 mm from the surface of each phantom.
To examine the offset variation across different heights on the phantom and in live intact
animals, we plotted the pixelwise IRFs for comparison as shown in Figure 2. For each specified
height in the step ladder phantom, we plotted the average IRFs in Figure 2 (a). Moreover, we
also illustrated the IRFs of various anatomical regions in live intact animals, including the liver,
urinary bladder (UB), and tumors, in Figure 2(b). Lastly, in Figure 2(c), we examined the
variability of the IRF within a single tumor. This plot contains IRFs on three points within a
tumor: the top, middle, and bottom. The top refers to an IRF from the upper region of the tumor,
the middle corresponds to an IRF from the central area in terms of height, and the bottom shows
an IRF from the lowest part of the tumor.
2.5.
In vivo experiment
For in vivo MFLI imaging experiments, we imaged HER2+ breast tumor xenografts HCC1954 in
athymic nude mice. The cell line was sourced from ATCC (Manassas, VA, USA) and maintained
in RPMI 1640 media enriched with 10% fetal bovine serum (ATCC) and 50 units/mL/ 50
Fig. 2. Illustration of designed 3D step ladder phantom and the IRF shifts as a result of
variations in height: (a) display of the 3D phantom (left) and plots of randomly selected
pixelwise IRFs from each height (right); (b) a side view of a mouse, highlighting height
differences between anatomical regions (left) and IRF plots of randomly selected pixels
on liver, urinary bladder (UB), tumors (right); (c) A distal ventral view of the mouse
highlighting the tumors and the liver (left) and the IRF plots of the randomly selected
pixels on the left tumor (right).
Âµg/mL penicillin/streptomycin from ThermoFisher Scientific (Waltham, MA, USA). We initiated
tumor xenografts by subcutaneously injecting 5 Ã— 106 HCC1954 cells suspended in PBS and
mixed in a 1 : 1 ratio with Cultrex BME (R&D Systems Inc, Minneapolis, MN, USA) into the
inguinal mammary fat pads of female athymic nude mice aged 4 weeks (CrTac: NCR-Foxn1nu,
Taconic Biosciences, Rensselaer, NY, USA). Tumors were monitored daily for 4 weeks. The
mouse was administered with a retro-orbital injection of AF700 conjugated with MDT-TZM
(MDT-TZM-AF700) at 20 Âµg and AF750 conjugated with MDT-TZM (MDT-TZM-AF750) at
40 Âµg in a 2 : 1 acceptor to donor ratio through staggered injection [9]. Donor injection was
performed 2 hours ahead of acceptor injection through the retro-orbital route. MFLI Imaging
was conducted 24 hours post-injection using the MFLI imaging setup. Throughout the imaging
process, the mouse was anesthetized with isoflurane, and the body temperature was maintained
with a Rodent Warmer X2 (Stoelting, IL, USA). All animal procedures were conducted with
the approval of the Institutional Animal Care and Use Committee (IACUC) at both Rensselaer
Polytechnic Institute and Albany Medical College. The animal facilities of both institutions have
been accredited by the American Association for Accreditation for Laboratory Animals Care
International.
3.
Results
We conducted the ladder phantom experiment designed to validate the MFliNet model under
controlled conditions that mimic biological tissues. Figure 3 shows the phantom experiment
results where the analysis was done using three methods: NLSF, FLI-Net, and MFliNet. To
compare the precision and stability of each method under varying conditions reflective of
real-world applications, results were evaluated across five different heights: ground, 5 mm, 10
mm, 15 mm, and 20 mm. A 160 ps shift in the IRF was observed from ground level to a height of
20 mm, with a shift of approximately 40 ps for each 5 mm increment in height. For simplicity in
Fig. 3. Phantom experiment results. a) Image overlay of the lifetime estimation results,
b) Violin plots of NLSF analysis, FLI-Net, and MFliNet
comparison, the amplitude-weighted average lifetime was calculated using Eq. 17, for all outputs.
ğœğ‘€= (ğ´ğ‘…ğœ1 + (1 âˆ’ğ´ğ‘…)ğœ2)
(17)
NLSF analysis using pixel-wise IRF showed consistency in lifetime estimation across all tested
heights. The mean fluorescence lifetime values obtained by NLSF were clustered around
1.01 Â± 0.02 ns. NLSF without offset correction results deteriorated with each increase in height.
At the ground level, NLSF without offset correction began with a mean value of 1.04 Â± 0.01
ns. However, as the height increased, a steady decline in lifetime estimation was observed,
reaching a mean value of 0.93 Â± 0.01 ns at 20 mm. FLI-Net, in contrast, demonstrated a wider
variation in estimated fluorescence lifetime values. At the ground level, it reported a mean value
of 0.96 Â± 0.01 ns, which was lower than the NLSF values. As the distance increased, FLI-Netâ€™s
estimations deviated further, peaking at 1.14 Â± 0.01 ns at 10 mm and estimating 20 mm with a
mean value of 1.10 Â± 0.02 ns. In contrast, MFliNet, showed closer results with NLSF, where
the mean values were within the same range as NLSF. Moreover, in terms of processing speed,
NLSF took approximately 6 hours to analyze 598 pixels (covering only the tumor area), whereas
MFliNet analyzed the entire dataset of 90,480 pixels in just 63 seconds.
Fig. 4. Comparison of in-vivo results for both NLSF and MFliNet a) Image overlays of
the short and long-lifetime results for both NLSF and MFliNet b) plot of means and
standard deviations of the predicted lifetime values of both methods
Following the phantom studies, in-vivo experiments were conducted using the HER2+ breast
tumor xenograft model in mice to evaluate the modelâ€™s performance in a more complex,
biologically variable environment. The experimental results, illustrated in Figure 4, demonstrate
the comparative analysis of the HCC1954 cell line using NLSF and MFliNet. For the smaller
tumor (HCC1954 (A)), the NLSF method reported a short fluorescence lifetime of 0.56 ns with
a standard deviation of 0.06 ns and a long lifetime of 1.17 Â± 0.03 ns. The MFliNet showed a
comparable short lifetime of 0.52 Â± 0.05 ns and a long lifetime of 1.19 Â± 0.02 ns. In the case
of the larger tumor (HCC1954 (B)),the NLSF method reported a short fluorescence lifetime of
0.55 ns with a standard deviation of 0.07 ns and MFliNet showed a comparable short lifetime
of 0.58 Â± 0.04 ns. For the long lifetime, both methods again yielded closely aligned values:
1.16 Â± 0.04 ns for NLSF and 1.18 Â± 0.03 ns for MFliNet.
4.
Discussion and Conclusion
In this study, we introduced MFliNet, a novel deep learning model based on the DIFF Transformer
architecture, to address the challenges of accurate FLI parameter estimation, particularly in
complex and variable biological environments. Our results, as illustrated in Figure 2, demonstrate
shifts in IRFs at varying heights, highlighting how each organâ€™s unique geometry and composition
contribute to IRF offsets. This variation in the IRF offset underscores the challenge of accurately
estimating the FLI parameters and the necessity for MFliNet, which can adapt to these complexities.
The integration of pixel-wise IRF analysis within MFliNet specifically addresses the effects of
surface irregularities on early photon arrival times, which is often overlooked in other DL models.
The differential attention mechanism within the DIFF Transformer enhances the modelâ€™s ability
to focus on relevant features while suppressing noise, leading to improved performance.
Comparative analysis indicates that MFliNet not only matches the accuracy of NLSF analysis
but also enhances processing speed. MFliNet eliminates the need for manual user dependency
and extensive user training, making it better suited for real-time applications. In addition, as
shown in the phantom experiment, an increasing trend in lifetime estimations from the FLI-Net
suggests a distance-related bias, which reflects an underlying limitation in the modelâ€™s ability
to account for variations in time-of-flight. The effect of the IRF offset on lifetime estimation
is further validated through NLSF analysis without using the offset correction, where lifetime
estimations result in noticeable declines, potentially leading to systematic underestimations of
fluorescence lifetimes and inaccuracies in diagnostics.
The significance of these improvements is particularly relevant in complex imaging environ-
ments such as fluorescence-guided surgery (FGS), where the understanding of these variables can
significantly impact the quality of imaging and, consequently, the surgical outcomes. Potential
integration of MFliNet with existing FGS systems can lead to the development of advanced
surgical guidance systems that offer real-time, precise imaging for cancer surgery [39]. Moreover,
the capabilities of MFliNet extend beyond clinical applications, offering potential benefits in
various research applications. In drug development, for instance, MFliNetâ€™s enhanced accuracy
could be used to determine drug-target interactions more precisely, thus accelerating the develop-
ment of therapeutics by providing clearer insights into molecular engagements. Additionally, in
biological research, the improved measurement accuracy of molecular interactions facilitated by
MFliNet could foster a deeper understanding of cellular functions and disease mechanisms. This
could open new avenues for exploring and developing targeted therapies. This work contributes
to the field by providing a robust and efficient tool for FLI parameter estimation, with potential
applications in clinical diagnostics, fluorescence-guided surgery, and various biomedical research
areas.
Funding.
Acknowledgment.
The authors thank Dr. Xavier Michalet for his support with the AlliGator software.
Disclosures.
The authors declare no conflicts of interest.
Data availability.
Data underlying the results presented in this paper are not publicly available at this time
but may be obtained from the authors upon reasonable request.
References
1.
W. Becker, â€œFluorescence lifetime imagingâ€“techniques and applications,â€ J. microscopy 247, 119â€“136 (2012).
2.
A. Verma, V. Pandey, C. Sherry, et al., â€œFluorescence lifetime imaging for quantification of targeted drug delivery in
varying tumor microenvironments,â€ bioRxiv .
3.
M. Ochoa, J. T. Smith, S. Gao, and X. Intes, â€œComputational macroscopic lifetime imaging and concentration
unmixing of autofluorescence,â€ J. biophotonics 15, e202200133 (2022).
4.
A. Rudkouskaya, N. Sinsuebphon, M. Ochoa, et al., â€œMultiplexed non-invasive tumor imaging of glucose metabolism
and receptor-ligand engagement using dark quencher fret acceptor,â€ Theranostics 10, 10309 (2020).
5.
A. T. Kumar, S. S. Hou, and W. L. Rice, â€œTomographic fluorescence lifetime multiplexing in the spatial frequency
domain,â€ Optica 5, 624â€“627 (2018).
6.
M. Wang, F. Tang, X. Pan, et al., â€œRapid diagnosis and intraoperative margin assessment of human lung cancer with
fluorescence lifetime imaging microscopy,â€ BBA clinical 8, 7â€“13 (2017).
7.
K. Suhling, L. M. Hirvonen, J. A. Levitt, et al., â€œFluorescence lifetime imaging (flim): Basic concepts and recent
applications,â€ Adv. Time-Correlated Single Photon Count. Appl. pp. 119â€“188 (2015).
8.
N. Yuan, V. Pandey, A. Verma, et al., â€œAntibody-target binding quantification in living tumors using macroscopy
fluorescence lifetime forster resonance energy transfer imaging (mfli fret),â€ in Visualizing and Quantifying Drug
Distribution in Tissue VIII, vol. 12821 (SPIE, 2024), pp. 17â€“20.
9.
A. Verma, C. Sherry, N. Yuan, et al., â€œUsing meditope-based antibody labeling to improve fluorescence lifetime fret
imaging,â€ in Multiphoton Microscopy in the Biomedical Sciences XXIV, (SPIE, 2024), p. PC128470S.
10. R. Datta, T. M. Heaster, J. T. Sharick, et al., â€œFluorescence lifetime imaging microscopy: fundamentals and advances
in instrumentation, analysis, and applications,â€ J. biomedical optics 25, 071203â€“071203 (2020).
11. R. I. Dmitriev, X. Intes, and M. M. Barroso, â€œLuminescence lifetime imaging of three-dimensional biological objects,â€
J. Cell Sci. 134, 1â€“17 (2021).
12. C. Sherry, A. Verma, J. Smith, et al., â€œNear infrared fluorescence lifetime fret microscopy to evaluate antibody drug
binding in various her2 positive cancer cell lines,â€ in Multiphoton Microscopy in the Biomedical Sciences XXIII, vol.
12384 (SPIE, 2023), pp. 162â€“167.
13. S. Gao, M. Li, J. T. Smith, and X. Intes, â€œDesign and characterization of a time-domain optical tomography platform
for mesoscopic lifetime imaging,â€ Biomed. Opt. Express 13, 4637â€“4651 (2022).
14. V. Venugopal, J. Chen, and X. Intes, â€œDevelopment of an optical imaging platform for functional imaging of small
animals using wide-field excitation,â€ Biomed. optics express 1, 143â€“156 (2010).
15. A. T. Kumar, â€œMacroscopic fluorescence imaging,â€ in Imaging from Cells to Animals In Vivo, (CRC Press, 2020), pp.
91â€“106.
16. M. Y. Berezin and S. Achilefu, â€œFluorescence lifetime measurements and biological imaging,â€ Chem. reviews 110,
2641â€“2684 (2010).
17. L. Chavez, S. Gao, and X. Intes, â€œCharacterization of fluorescence lifetime of organic fluorophores for molecular
imaging in the shortwave infrared window,â€ J. Biomed. Opt. 28, 094806â€“094806 (2023).
18. R. Nothdurft, P. Sarder, S. Bloch, et al., â€œFluorescence lifetime imaging microscopy using near-infrared contrast
agents,â€ J. microscopy 247, 202â€“207 (2012).
19. A. Rudkouskaya, J. T. Smith, X. Intes, and M. Barroso, â€œQuantification of trastuzumabâ€“her2 engagement in vitro and
in vivo,â€ Molecules 25, 5976 (2020).
20. A. Rudkouskaya, N. Sinsuebphon, J. Ward, et al., â€œQuantitative imaging of receptor-ligand engagement in intact live
animals,â€ J. controlled release 286, 451â€“459 (2018).
21. L. Marcu, â€œFluorescence lifetime techniques in medical applications,â€ Ann. biomedical engineering 40, 304â€“331
(2012).
22. N. Yuan, V. Pandey, X. Michalet, and X. Intes, â€œExperimental study of fluorescence lifetime uncertainty in time-
gated iccd-based macroscopic fluorescence lifetime imaging,â€ in Clinical and Translational Biophotonics, (Optica
Publishing Group, 2024), pp. TM5Bâ€“4.
23. S.-J. Chen, N. Sinsuebphon, A. Rudkouskaya, et al., â€œIn vitro and in vivo phasor analysis of stoichiometry and
pharmacokinetics using short-lifetime near-infrared dyes and time-gated imaging,â€ J. biophotonics 12, e201800185
(2019).
24. V. Pandey, I. Erbas, X. Michalet, et al., â€œDeep learning-based temporal deconvolution for photon time-of-flight
distribution retrieval,â€ Opt. Lett. 49, 6457â€“6460 (2024).
25. N. I. Nizam, V. Pandey, I. Erbas, et al., â€œA novel technique for fluorescence lifetime tomography,â€ bioRxiv (2024).
26. I. Erbas, V. Pandey, A. Amarnath, et al., â€œCompressing recurrent neural networks for fpga-accelerated implementation
in fluorescence lifetime imaging,â€ arXiv preprint arXiv:2410.00948 (2024).
27. I. Erbas, A. Amarnath, V. Pandey, et al., â€œUnlocking real-time fluorescence lifetime imaging: multi-pixel parallelism
for fpga-accelerated processing,â€ arXiv preprint arXiv:2410.07364 (2024).
28. J. T. Smith, R. Yao, N. Sinsuebphon, et al., â€œFast fit-free analysis of fluorescence lifetime imaging via deep learning,â€
Proc. National Acad. Sci. 116, 24019â€“24030 (2019).
29. Q. Wen, T. Zhou, C. Zhang, et al., â€œTransformers in time series: A survey,â€ arXiv preprint arXiv:2202.07125 (2022).
30. S. Khan, M. Naseer, M. Hayat, et al., â€œTransformers in vision: A survey,â€ ACM computing surveys (CSUR) 54, 1â€“41
(2022).
31. M. Zaheer, G. Guruganesh, K. A. Dubey, et al., â€œBig bird: Transformers for longer sequences,â€ Adv. neural
information processing systems 33, 17283â€“17297 (2020).
32. A. Vaswani, N. Shazeer, N. Parmar, et al., â€œAttention is all you need,â€ Adv. neural information processing systems 30
(2017).
33. T. Ye, L. Dong, Y. Xia, et al., â€œDifferential transformer,â€ arXiv (2024).
34. V. Venugopal, A small animal time-resolved optical tomography platform using wide-field excitation (Rensselaer
Polytechnic Institute, 2011).
35. J. Lakowicz, In Principles of Fluorescence Spectroscopy (Springer, US: Boston, MA, 2006).
36. D. D.-U. Li, J. Arlt, D. Tyndall, et al., â€œVideo-rate fluorescence lifetime imaging camera with cmos single-photon
avalanche diode arrays and high-speed imaging algorithm,â€ J. biomedical optics 16, 096012â€“096012 (2011).
37. S.-J. Chen, N. Sinsuebphon, M. Barroso, et al., â€œAlligator: A phasor computational platform for fast in vivo lifetime
analysis,â€ in Optical molecular probes, imaging and drug delivery, (Optica Publishing Group, 2017), pp. OmTu2Dâ€“2.
38. L. Chavez, S. Gao, V. Pandey, et al., â€œMultimodal fluorescence lifetime imaging and optical coherence elastography
for mesoscopic structural, biomechanical, and molecular imaging,â€ in Clinical and Translational Biophotonics,
(Optica Publishing Group, 2024), pp. TS3Bâ€“1.
39. M. I. Ochoa, A. Ruiz, E. LaRochelle, et al., â€œAssessment of open-field fluorescence guided surgery systems:
implementing a standardized method for characterization and comparison,â€ J. Biomed. Opt. 28, 096007â€“096007
(2023).
