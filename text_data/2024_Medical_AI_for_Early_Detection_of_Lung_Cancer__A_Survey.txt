Medical AI for Early Detection of Lung Cancer: A Survey
Guohui Caia, Ying Caia,∗, Zeyu Zhangb, Yuanzhouhan Caoc, Lin Wud, Daji Ergua, Zhibin
Liaoe and Yang Zhaof
aCollege of Computer Science and Artificial Intelligence, Southwest Minzu University, Chengdu, 610225, China
bThe Australian National University, Canberra ACT 2601, Australia
cSchool of Computer Science and Technology, Beijing Jiaotong University, Beijing, China
dHunan university of technology, Zhuzhou, 410072, China
eUniversity of Adelaide, Adelaide, South Australia 5005, Australia
fLa Trobe University, Melbourne, Victoria 3086, Australia
A R T I C L E I N F O
Keywords:
Lung cancer
Deep learning
Artificial intelligence (AI)
Pulmonary nodule detection
Computer-aided diagnosis (CAD)
Pulmonary nodule segmentation and
classification
A B S T R A C T
Lung cancer remains one of the leading causes of morbidity and mortality worldwide, making
early diagnosis critical for improving therapeutic outcomes and patient prognosis. Computer-
aided diagnosis (CAD) systems, which analyze CT images, have proven effective in detecting
and classifying pulmonary nodules, significantly enhancing the detection rate of early-stage lung
cancer. Although traditional machine learning algorithms have been valuable, they exhibit lim-
itations in handling complex sample data. The recent emergence of deep learning has revolu-
tionized medical image analysis, driving substantial advancements in this field. This review
focuses on recent progress in deep learning for pulmonary nodule detection, segmentation, and
classification. Traditional machine learning methods, such as SVM and KNN, have shown lim-
itations, paving the way for advanced approaches like Convolutional Neural Networks (CNN),
Recurrent Neural Networks (RNN), and Generative Adversarial Networks (GAN). The integra-
tion of ensemble models and novel techniques is also discussed, emphasizing the latest devel-
opments in lung cancer diagnosis. Deep learning algorithms, combined with various analytical
techniques, have markedly improved the accuracy and efficiency of pulmonary nodule analy-
sis, surpassing traditional methods, particularly in nodule classification. Although challenges
remain, continuous technological advancements are expected to further strengthen the role of
deep learning in medical diagnostics, especially for early lung cancer detection and diagno-
sis. A comprehensive list of lung cancer detection models reviewed in this work is available
at https://github.com/CaiGuoHui123/Awesome-Lung-Cancer-Detection.
1. Introduction
Lung cancer is one of the leading causes of both incidence and mortality worldwide. According to the latest
assessment by the International Agency for Research on Cancer (IARC) of the World Health Organization (WHO),
in 2022, there were approximately 19.96 million new cancer cases globally, with 2.48 million of them being lung
cancer, accounting for 12.4% of all cases, making it the most prevalent cancer worldwide Fig. 1 [3]. Due to the
subtlety of early-stage lung cancer symptoms, patients often miss the optimal treatment window. Early screening
and CT scans are essential for early diagnosis, as they allow for the detection of lesions before clinical symptoms
manifest, significantly increasing the rate of early lung cancer detection. Computer-aided diagnosis (CAD) systems
are designed to assist in medical image analysis by automating the detection of abnormalities, such as those in CT scans
∗Corresponding author: Ying Cai (E-mail: caiying34@yeah.net).
ORCID(s):
Cai et al.: Preprint submitted to Elsevier
Page 1 of 40
arXiv:2410.14769v1  [eess.IV]  18 Oct 2024
Medical AI for Early Detection of Lung Cancer: A Survey
Fig. 1: Pie chart showing the distribution of cases and deaths for the top five cancers for both sexes in 2022. The area of the pie
chart reflects the proportion of the total number of cases or deaths [3].
Fig. 2: Framework of this study and the basic steps of the pulmonary nodule CAD system.
[4]. These systems improve diagnostic accuracy and reduce the workload of radiologists. In lung cancer detection,
CAD systems are particularly effective in identifying and assessing pulmonary nodules. With advances in deep learning
and artificial intelligence, these systems have become increasingly accurate, fast, and reliable, supporting early lung
cancer diagnosis.
Pulmonary nodules are defined as round or irregular lesions with a diameter of less than 30 mm, typically appearing
on CT images as high-density areas with either well-defined or blurred margins. Nodules can be categorized into
Cai et al.: Preprint submitted to Elsevier
Page 2 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Fig. 3: This tree diagram illustrates the overall development of medical AI technologies in the early detection of lung cancer.
The diagram provides an overview of key advancements and techniques in the field, structured into three main sections: Tradi-
tional Machine Learning, Deep Learning, and Hybrid Methods. Each section is further divided into three core tasks—Detection,
Segmentation, and Classification—highlighting key techniques used in each. Traditional methods like Support Vector Machines
(SVM), Thresholding, and Decision Trees have been foundational, while deep learning methods such as CNN, U-Net, and ResNet
have significantly advanced the field, especially after the rise of deep learning in 2012. Hybrid methods, combining models from
both machine learning and deep learning, have become prominent since 2018, offering enhanced accuracy and robustness.
solid, subsolid, and ground-glass types based on their density and morphology. Among these, solid nodules generally
pose a lower risk of malignancy, whereas subsolid and ground-glass nodules, particularly those that are large and
irregular, are associated with a higher risk. Consequently, accurate identification and classification are critical for
clinical diagnosis [1, 2]. The application of computer-aided detection (CAD) technology in lung cancer diagnosis
began in the 1980s, initially focusing on assisting in the detection of abnormalities on chest X-rays. It later expanded
to high-resolution CT image analysis, evolving from simple image processing to sophisticated deep learning models
that significantly enhance both sensitivity and specificity. Today, CAD systems can autonomously detect and evaluate
pulmonary nodules, provide follow-up recommendations, and assist in decision-making, substantially improving the
accuracy and efficiency of early lung cancer screening.
Compared to traditional machine learning (ML) methods, deep learning, particularly convolutional neural networks
(CNNs), has demonstrated superior performance in pulmonary nodule CAD systems [5]. Traditional ML relies on
manually extracted features, which are limited by the quality of the features, whereas deep learning can automatically
learn complex image features, significantly improving detection accuracy and robustness. This advantage is especially
apparent in handling high-dimensional and large-scale data, where deep learning excels at capturing subtle changes
in pulmonary nodules, thereby enhancing diagnostic efficiency. The workflow of a pulmonary nodule CAD system
includes CT image preprocessing, automatic segmentation of nodule regions, feature extraction, and classification
analysis, ultimately generating diagnostic reports that assist clinicians in decision-making. The system aims to improve
detection accuracy and efficiency, contributing to early lung cancer diagnosis.
Recent reviews have summarized the application of AI in early lung cancer detection. The study by Kaulgud et
Cai et al.: Preprint submitted to Elsevier
Page 3 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
al. [6] primarily focuses on CT image detection methods and compares the performance of various techniques in
pulmonary nodule detection. Similarly, Kalkeseetharaman et al. [7] review studies based on X-ray and CT images,
highlighting the advantages of deep learning in CT image-based pulmonary nodule detection. However, these reviews
lack an in-depth exploration of the differences between traditional machine learning and deep learning algorithms,
particularly in terms of data sources and nodule segmentation methods, which is a significant oversight [6]. They also
provide insufficient descriptions of specific algorithms and model characteristics, lacking a unified review framework
[7].
To address these gaps, this review discusses the application of AI technologies in early lung cancer detection and
diagnosis, aiming to leverage AI for the rapid detection [8], segmentation [9], and classification of pulmonary nodules.
The research framework is illustrated in Fig. 2, and the overall development of medical AI technologies in lung cancer
detection is shown in Fig. 3.
The main contributions of this review are as follows:
• A comprehensive analysis of diverse data sources and a systematic literature retrieval and screening process,
identifying key studies and trends in lung cancer detection.
• A discussion of the structure, performance, and applicable scenarios of traditional machine learning and deep
learning algorithms for lung cancer analysis.
• An in-depth comparison of lung cancer detection, segmentation, and classification tasks across 131 reviewed
studies, highlighting their respective strengths, limitations, and future research directions.
• Practical insights into designing high-performance lung cancer analysis workflows, optimizing computational
complexity, and enhancing model interpretability, providing valuable guidance for researchers and radiologists.
2. Medical AI for Lung Cancer Detection
In recent years, the rapid advancement of artificial intelligence has brought unprecedented transformations across
various industries, particularly in the field of lung cancer detection and diagnosis. Traditional methods for detecting
pulmonary nodules often rely on the expertise of radiologists, are time-consuming, and are influenced by subjective
factors, which can compromise the accuracy of diagnostic results. However, with the progress of AI technology, the
healthcare sector has embraced new possibilities. AI enables machines and computer systems to emulate human intel-
ligence, encompassing capabilities such as language comprehension, natural language processing, decision-making,
and visual perception, as discussed by Messeri et al. [10]. The robust learning capabilities and high precision of AI
have led to its increasing application in lung cancer detection, particularly in the analysis of medical images. Through
deep learning algorithms, AI can automatically identify and analyze pulmonary nodules, significantly enhancing the
Cai et al.: Preprint submitted to Elsevier
Page 4 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Fig. 4: Algorithm structure schematic. (a) Random Forest (RF) incorporates multiple decision trees to evaluate different aspects of
the pulmonary nodule dataset, with a majority vote determining the final category of each nodule. (b) K-Nearest Neighbor (KNN)
classifies nodules by analyzing the closest training examples in the feature space, employing a specific number of neighbors (e.g.,
K=3) for voting. (c) Support Vector Machine (SVM) constructs a hyperplane to distinctly separate different types of nodules,
optimizing classification based on their features. Each method effectively leverages feature information along the X and Y axes to
distinguish between nodule types.
accuracy of early diagnosis and assisting physicians in making timely and effective decisions, ultimately improving
patient survival rates.
2.1. Statistical Learning Based
Machine learning is a methodology for implementing artificial intelligence that utilizes statistical learning algo-
rithms to enable computer systems to learn from experience and improve performance. In this process, manually
designed feature engineering is crucial for transforming data into a format suitable for shallow models. As illustrated
in Fig. 4, statistical learning-based algorithms include Support Vector Machines (SVM) [11], K-Nearest Neighbors
(KNN) [12], Extreme Learning Machines (ELM) [13], Decision Trees (DT), Random Forests (RF), and Naive Bayes
(NB). These methods have been widely applied in medical imaging analysis, particularly in the detection of pulmonary
nodules, significantly improving diagnostic accuracy and assisting physicians in identifying potential malignant lesions
in a timely manner.
Despite their commendable performance in this field, statistical learning-based methods have certain limitations.
They often rely on manual feature design and selection, which can be time-consuming and heavily influenced by do-
main knowledge; improper feature selection may adversely affect model performance. Additionally, these algorithms
face challenges in effectively handling nonlinearity, high-dimensional data, and complex data relationships, particu-
larly when dealing with unstructured data such as lung imaging, where capturing latent patterns and structures proves
difficult. However, the advent of deep learning methods offers effective solutions to these challenges. Deep learning
has significant advantages over statistical learning-based methods, with the main differences shown in Fig. 5a. Deep
learning models can autonomously learn feature representations from raw data, eliminating the need for tedious manual
Cai et al.: Preprint submitted to Elsevier
Page 5 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Fig. 5: (a) Main difference between statistical learning-based and deep learning. Statistical learning-based methods rely on manually
extracted features and employ simpler algorithms that often require human intervention for optimal performance. In contrast, deep
learning automates the feature extraction process, utilizing complex neural network architectures that learn directly from raw data.
This capability enables deep learning to handle more complex data structures and patterns, improving accuracy and efficiency in
tasks such as medical image analysis. (b) The deep neural network operation process.
feature engineering. The operation process of a deep neural network is illustrated in Fig. 5b.
2.2. Convolutional Neural Network (CNN)
Convolutional Neural Networks (CNNs) originated in the 1980s with the development of LeNet by Yann LeCun’s
team for handwritten digit recognition [14]. The rapid advancements in computational power and large-scale datasets
facilitated the widespread adoption of CNNs in the early 21st century, culminating in the success of AlexNet in the
2012 ImageNet competition, which marked a significant milestone [5]. Subsequent architectures like DenseNet and
ResNet further improved classification accuracy [15], significantly advancing both computer vision and medical image
analysis. Today, CNNs have become the cornerstone of modern medical image analysis, particularly in the detection
[16], segmentation [17, 18, 19], and classification of pulmonary nodules in CT scans. Designed to automatically
and adaptively learn spatial hierarchies of features from input images through multiple layers of convolutional filters,
CNNs capture intricate patterns and textures inherent in medical imaging data, making them exceptionally well-suited
for identifying subtle abnormalities such as pulmonary nodules. Fundamental architectures such as LeNet, AlexNet,
VGG, ResNet, and, more recently, specialized models like U-Net and DenseNet, have been extensively employed and
further refined to enhance the precision and efficiency of lung cancer detection systems. The basic structure of a CNN
is shown in Fig. 6b.
In addition to CNNs, Multilayer Perceptrons (MLPs) have historically served as foundational models in deep learn-
Cai et al.: Preprint submitted to Elsevier
Page 6 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
ing, consisting of an input layer, multiple hidden layers, and an output layer, as shown in Fig. 6a. While MLPs ex-
cel at capturing higher-order abstract features within data, their application to complex, high-dimensional tasks like
pulmonary nodule classification often leads to increased computational costs and challenges such as overfitting. To
overcome these limitations, researchers have integrated MLPs with CNN architectures, leveraging the strengths of both
models. For instance, Zhu et al. [20] enhanced nodule detection by combining convolutional layers with MLP compo-
nents in CM-Net, effectively capturing local dependencies in CT images while maintaining computational efficiency.
When comparing various CNN-based approaches for pulmonary nodule analysis, several studies demonstrate sig-
nificant advancements in both accuracy and computational efficiency. For instance, Kadhim et al. [21] developed a
high-efficiency CAD system using CNNs and stacked autoencoders, achieving an accuracy of 99.0% on the LIDC-IDRI
dataset. Similarly, Bhatt et al. [22] employed the YOLOv4 model, which attained 95% precision and 81% sensitiv-
ity, showcasing real-time detection capabilities. Mesquita et al. [23] introduced a Boolean equation-based method
integrated with CNNs, achieving 92.75% sensitivity with 8 false positives per scan. Additionally, Suzuki et al. [24]
enhanced a 3D U-Net model, reaching a CPM of 94.7% on the LIDC-IDRI dataset and 83.3% on a Japanese dataset,
demonstrating robust cross-dataset performance. These studies highlight the versatility and robustness of CNN archi-
tectures in diverse clinical settings, effectively handling different nodule types and minimizing false positives.
Furthermore, the integration of MLPs within CNN frameworks has led to the development of more sophisticated
models that combine feature extraction with complex classification tasks. For example, Fu et al. [37] introduced a
multimodal diagnostic model that integrates 3D lung CT images with serum biomarkers, achieving an average accuracy
of 90.6% on the LIDC-CISB dataset by fusing a multi-resolution 3D multi-class deep learning model (Mr-Mc) with
an MLP model based on lung tumor biomarkers (LTBs). This integration underscores the potential of hybrid models
in enhancing the accuracy and reliability of pulmonary nodule detection and classification.
In summary, CNNs are pivotal to modern computer-aided diagnosis (CAD) systems for lung cancer, offering un-
matched capabilities in feature extraction and pattern recognition. Models such as Kadhim et al.’s [21] CNN with
stacked autoencoders, Bhatt et al.’s [22] YOLOv4, de Mesquita et al.’s [23] Boolean equation-based CNN, Suzuki et
al.’s [24] enhanced 3D U-Net, and the MLP-integrated approaches by Zhu et al. [20] and Fu et al. [37] demonstrate
significant strides in improving the accuracy, sensitivity, and specificity of pulmonary nodule detection and classifi-
cation. These advancements not only facilitate early diagnosis and optimize treatment planning but also support the
seamless integration of CNN-based systems into routine clinical workflows, thereby elevating the standards of lung
cancer care. The typical CNN applications in this field in recent years are listed in Table 1.
Cai et al.: Preprint submitted to Elsevier
Page 7 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Table 1
Typical applications of CNN models in pulmonary nodule detection, segmentation, and classification on CT images.
Task
Type
Authors
Year
2D/3D
Technique/
Network Type
Validation/
Test Method
Nodules Types
Main Method
Model Performance
Kadhim et al.
[21]
2022
2D and
3D
CNN ; SAE
Accuracy, Sen-
sitivity
Multiple
appear-
ances and shapes
(size <10mm)
Pulmonary nodule
detection and diag-
nosis with CAD
Performance varies based on
dataset used, comparison of
CAD methods
Bhatt
et
al.
[22]
2022
2D
YOLOv4
Sensitivity
Various
nodule
types
YOLOv4 model
Sensitivity
with
FP/scan:
81%
Mesquita et al.
[23]
2022
3D
CNN
10-fold
cross-
validation
Nodules
larger
than 3 mm
Nodule
detection
using 16 filters and
Boolean logic
Sensitivity: 92.75%, 8 false
positives per exam with ma-
jority gold standard
Suzuki
et
al.
[24]
2022
3D
CNN;3D U-Net
Sensitivity
Nodules > 5 mm
Automated nodule
detection with 3D
U-Net
Internal CPM: 94.7%, Exter-
nal CPM: 83.3%
Det-
ection
Karrar
et
al.
[25]
2022
2D and
3D
SVM, DCNN
10-fold
cross-
validation
Solitary,
juxta-
pleural
CADx: segmenta-
tion, SVM, DCNN
SVM: 91.4%, DCNN: 95%
Bhaskar et al.
[26]
2023
3D
U-net, CNN
80:20 train-test
split
Cancerous or non-
cancerous
U-net for segmen-
tation,
CNN
for
classification
Sensitivity:
0.75 (before),
0.65 (after classification)
Jian et al. [27]
2024
3D
Dual-branch,
3D CNN
5-fold
cross-
validation
Lung parenchyma
and
chest
wall
nodules
Multi-task
dual-
branch 3D CNN,
attention fusion
Sensitivity: 91.33%, 0.125 to
8 FPs/scan
Zhao et al. [28]
2023
3D
3DCNN
10-fold
cross-
validation
Types,
shapes,
sizes: 3-30 mm
Adaptive 3D CNN
Sensitivity: 0.947, FP/s: 0.14
Ahmadyar
et
al. [29]
2024
2D and
3D
YOLOv5s,
3DCNN
Evaluated
on
LUNA16
Pulmonary
nod-
ules
Hierarchical
YOLOv5s,
3DCNN
Sensitivity:
97.8%,
confi-
dence: 0.3
Ma et al. [30]
2024
3D
Transformer,
CNN
10-fold
cross-
validation
Benign and malig-
nant
TiCNet,
Trans-
former,
attention,
multi-scale fusion
Sensitivity:
93%,
<11
FP/scan, CPM: 90.73%
Sweetline et al.
[31]
2024
2D
Multi-crop
CNN
Sensitivity
Various
nodule
types
Multi-crop
CNN,
boundary
refine-
ment, seg
DSC:LUNA16:0.978,
LIDC:0.982,
Sensitivity:
LUNA16:97.6%, LIDC:98%
Zhang
et
al.
[32]
2024
2D
DS-MSFF-Net
Sensitivity
Benign and malig-
nant
Dual-path: seman-
tic feature extrac-
tion
LIDC-IDRI:
85.39%,
LiTS2017
liver:
95.79%,
LiTS2017 tumor: 91.75%
Segme-
ntation
Suji et al. [33]
2024
2D
UNet,
FPN,
PSPNet
Sensitivity
Various
nodule
types
Pretrained
en-
coders: ResNet
DSC: IoU (UNet-efficientnet-
b3): 0.5922
Asiya
et
al.
[34]
2024
2D
Custom-VGG16
Sensitivity
Benign and malig-
nant
Custom-VGG16:
preprocessing
Precision: 90.87%
Tang et al. [35]
2023
2D
SM-RNet
Sensitivity
Benign and malig-
nant
SM-RNet:
Weighted-fusion
Precision: FUSCC: 89.774%,
LUNA16: 85.047%
Cai et al. [36]
2024
2D
MDFN
5-fold
cross-
validation
Various
nodule
types
MDFN:
Self-
calibrated
edge
enhancement
DSC: 89.19%;
Sensitivity:
88.89%
Fu et al. [37]
2021
3D
MLP ; Mr-Mc
5-fold
cross-
validation
Inflammation,
squamous
cell
carcinoma
Double modal fu-
sion of CT images
and LTBs
Mr-Mc Acc:
0.810, MLP
Acc:
0.887, Fusion model
Acc: 0.906
Zhan et al. [38]
2023
3D
3D CNN: SSL
5-fold
cross-
validation
Solitary
Pul-
monary
Nodules
(SPNs)
SSL with USC for
supervised training
Supervised:
Acc:
0.662,
USC
(confidence):
Acc:
0.702, Sensitivity: 0.707
Class-
ification
Rahouma et al.
[39]
2024
3D
3D CNN + GA
4-fold
cross-
validation
Benign or Malig-
nant
3D CNN with GA
for design
Acc:
95.98%,
Sensitivity:
98.80%, AUC: 0.985, Speci-
ficity: 93.40%
Lin et al. [40]
2024
3D
3D CNN
10-fold
cross-
validation
IA, MIA, AIS, and
AAH
AutoGluon-
Tabular for classifi-
cation
Task 1: Acc: 92.8%, Sensitiv-
ity: 89.43%, AUC: 96.17%,
Task 2.1: Acc: 74.76%
Drishti
et
al.
[41]
2024
2D
CNN - ConvNet
5-fold
cross-
validation
benign or Malig-
nant
Multi-scale, multi-
path for feature ex-
traction
Acc:
90.38%,
Sensitivity:
88.70%, AUC: 0.948, Speci-
ficity: 92.40%
2.3. Recurrent Neural Network (RNN)
Recurrent Neural Networks (RNNs), introduced by Rumelhart et al. in 1986 [42], are designed to handle sequential
data by maintaining an internal state that captures information from previous inputs. This makes RNNs particularly
effective for tasks involving temporal dependencies, such as language processing and the detection of pulmonary nod-
ules from continuous imaging datasets. Traditional RNNs, however, face challenges like vanishing and exploding
Cai et al.: Preprint submitted to Elsevier
Page 8 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Fig. 6: Various deep learning models and structures: (a) Multilayer Perceptron (MLP) performs complex function approximation,
vital for pattern recognition in data structures. (b) Convolutional Neural Network (CNN) excels in automatic feature extraction and
analyzing structural details in lung CT scans. (c) Generative Adversarial Network (GAN) synthesizes accurate medical images,
mitigating the lack of annotated samples and improving model robustness. (d) Recurrent Neural Network (RNN) analyzes temporal
patterns in sequential lung scans, crucial for accurate pulmonary nodule detection.
gradients, limiting their ability to learn long-term dependencies. To address these issues, architectures such as Long
Short-Term Memory (LSTM) networks and Gated Recurrent Units (GRUs) were developed [43], employing gating
mechanisms to control the flow of information and retain context over longer sequences. In pulmonary nodule detec-
tion, these models improve accuracy by learning inter-slice dependencies in CT images. Furthermore, Bidirectional
RNNs and attention mechanisms enhance the network’s ability to focus on important parts of the sequence, increasing
detection precision. With these advancements, RNNs and their variants have become essential tools in medical image
analysis, particularly in the early detection of lung cancer, as illustrated in Fig. 6d and Fig. 7a.
In the analysis of pulmonary nodules, RNNs, with their unique ability to process temporal sequences, are capable
of capturing sequential patterns in CT scan data, significantly improving classification tasks. For instance, Balannolla
et al. [44] combined RNNs with convolutional layers for pulmonary nodule classification, achieving a sensitivity of
96.4% using KNN classifiers. Similarly, Vijay et al. [45] employed an RNN model integrated with feature selection
algorithms for nodule classification, reaching a classification accuracy of 93.6% and a sensitivity of 96.39%. The ad-
vantage of RNNs in these medical imaging tasks lies in their ability to handle temporal dependencies within sequential
data, thereby effectively improving the robustness and accuracy of classification. However, the complexity and high
computational demands of RNNs remain challenges that need optimization, with researchers continuously exploring
Cai et al.: Preprint submitted to Elsevier
Page 9 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Fig. 7: Various deep learning models and structures: (a) Long Short-Term Memory (LSTM) structure is vital for sequence data
analysis in medical applications, utilizing forget, input, and output gates to manage information flow, thereby maintaining essential
temporal features critical for accurate diagnostic predictions. This mechanism proves especially effective in analyzing diagnostic
time-series data, capturing crucial changes over time. (b) The Attention Mechanism enhances neural network focus on significant
features within diagnostic images, facilitating precise detection and categorization of anomalies such as tumors and lesions by
adjusting the model’s focus to the most informative regions of the image data.
novel network architectures and optimization strategies to address these issues.
Although significant progress has been made in pulmonary nodule detection using convolutional neural networks
(CNNs) in recent years, RNNs, as a deep learning method capable of processing temporal information, continue to
show potential in enhancing performance when integrated with other network architectures. For example, some studies
have combined RNNs with CNNs to improve nodule detection, offering the dual advantage of handling both spatial
and temporal features. Additionally, methods such as the adaptive anchor box Faster R-CNN proposed by Nguyen
et al. [46], which integrates RNNs, and the dual-stage framework developed by Shimaa et al. [47], where RNN
modules enhance classification tasks, have made significant progress in improving detection sensitivity and reducing
false positives. These studies illustrate that the application of RNNs in medical imaging extends beyond classification
tasks, and when combined with other neural networks, can further enhance the recognition and handling of complex
data patterns, thereby advancing the field of pulmonary nodule detection.
2.4. Generative Adversarial Network (GAN)
Generative Adversarial Networks (GANs), introduced by Ian Goodfellow and colleagues in 2014 [48], consist of
two neural networks—the generator and the discriminator—that are trained simultaneously through an adversarial
process. The basic structure is shown in Fig. 6c. The generator aims to produce realistic data samples, while the
discriminator attempts to distinguish between genuine data and those generated by the generator. This competitive
dynamic drives the generator to produce increasingly realistic data, enhancing its capacity to model complex data
distributions. In medical imaging, GANs have been extensively applied to tasks such as image synthesis, restoration,
Cai et al.: Preprint submitted to Elsevier
Page 10 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
and super-resolution, significantly improving the accuracy and robustness of pulmonary nodule detection. Variants
of GANs, such as Conditional GANs, Generative Adversarial Autoencoders, and CycleGANs, provide specialized
solutions for specific challenges. For example, Conditional GANs generate images with specific pathological features,
increasing data diversity, while Generative Adversarial Autoencoders produce high-resolution images that assist in the
precise identification of nodules. CycleGANs, notably, can improve image quality without the need for paired datasets,
which is particularly beneficial in medical scenarios with limited annotated data. By generating high-fidelity synthetic
data for data augmentation, GANs help address issues of limited and imbalanced datasets, resulting in enhanced model
performance and generalization. Overall, GANs and their variants play a crucial role in enriching diagnostic data and
driving advancements in medical image analysis, especially for the early detection of pulmonary nodules.
In the realm of pulmonary nodule analysis, GANs have been employed to tackle challenges related to data scarcity
and class imbalance. For instance, Sengodan et al. [49] applied GANs to generate synthetic CT images of pulmonary
nodules, augmenting the training dataset and improving the robustness of detection models. In another study, Ling et
al. [50] incorporated GAN-based data augmentation into a dual-branch CNN framework, leading to improved segmen-
tation accuracy and reduced false positives. Furthermore, Gugulothu et al. [51] introduced a deep learning method that
integrates step deviation mean multi-level thresholding (SDMMT) and a novel CSDR-J-WHGAN classifier, achieving
impressive classification results with 97.11% detection accuracy on the LIDC-IDRI dataset. Zhu et al. [52] further
enhanced GAN-based approaches by developing the Functional Realistic GAN (FRGAN) architecture, which employs
TreeGAN to generate high-resolution images with accurate pathological features, significantly improving detection
sensitivity and accuracy, as demonstrated by its CPM score of 0.915 on the LUNA16 dataset.
Moreover, Tyagi et al. [53] proposed a 3D Conditional GAN (CSE-GAN) for pulmonary nodule segmentation,
integrating a U-Net-based generator with parallel compression and excitation modules. This approach effectively
reduced overfitting and improved segmentation performance, achieving a Dice coefficient of 80.74% on the LUNA16
dataset. These advanced GAN-based methods not only enhance training datasets with high-quality synthetic images
but also improve segmentation and classification accuracy, effectively addressing issues related to data scarcity and
class imbalance.
In summary, GANs provide innovative solutions for pulmonary nodule analysis by generating realistic synthetic
data that mitigates the challenges of data scarcity and class imbalance. Studies by Sengodan et al. [49], Ling et al. [50],
Gugulothu et al. [51], Zhu et al. [52], and Tyagi et al. [53] demonstrate the effectiveness of GAN-based augmentation
in enhancing the performance and robustness of detection and segmentation models. These findings underscore the
growing potential of GANs in clinical applications for pulmonary nodule detection, presenting a promising avenue
for improving diagnostic accuracy and reliability. As GAN technology continues to evolve, its remarkable ability to
generate high-quality synthetic data has attracted increasing attention, highlighting its critical role in the development
Cai et al.: Preprint submitted to Elsevier
Page 11 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
of next-generation CAD systems for early lung cancer detection and diagnosis.
2.5. Transformer Based Methods
Transformers, first introduced by Vaswani et al. [54] in 2017, have significantly advanced deep learning, par-
ticularly through the adoption of self-attention mechanisms [55]. Unlike traditional models that process input data
sequentially or focus on local features, Transformers can capture long-range dependencies and relationships across the
entire input sequence, which is crucial for tasks like medical imaging. The self-attention mechanism, a core component
of the Transformer, operates by calculating relationships between different parts of the input using three key matrices:
query, key, and value. This allows the network to focus on the most relevant features, enabling it to learn complex
patterns and improve performance in tasks such as image classification [56, 57], segmentation [58], and detection.
The basic structure is shown in Fig. 7b.
Building on this architecture, the Vision Transformer (ViT) adapts the Transformer model for image analysis by
dividing images into patches and treating them as a sequence. By leveraging self-attention, ViT effectively captures
both global and local image features, which is particularly beneficial in medical applications like pulmonary nodule
detection in CT scans. Recent studies, such as those by Hui Zhang et al. [59] and Chi et al. [60], have demonstrated
that incorporating Transformer-based models significantly improves detection sensitivity and reduces false positives.
Chi et al. showed that integrating Transformer layers into pulmonary nodule classification tasks resulted in higher
accuracy and better interpretability. Similarly, Han Yang et al. [61] explored the application of uncertainty-aware
attention in UGMCS-Net, further enhancing segmentation performance, particularly in complex nodule shapes and
low-confidence regions.
In addition to ViT, hybrid models like the Swin Transformer have been developed to handle high-resolution med-
ical images by introducing a hierarchical structure. This design allows the model to process images at multiple scales,
capturing detailed features across different levels of granularity. For instance, Jinjiang Liu et al. [62] incorporated 3D
coordinate attention and edge enhancement in SCA-VNet, achieving a high Dice coefficient by improving edge detec-
tion in pulmonary nodule segmentation. Similarly, Chenglong Wang et al. [63] utilized attention gating and multi-task
learning in ExPN-Net, improving both segmentation and classification with an AUC of 0.992. These Transformer-
based approaches, especially the Vision Transformer and its variants, have demonstrated significant potential in ad-
vancing the accuracy, sensitivity, and efficiency of early lung cancer detection and diagnosis.
2.6. Hybrid Deep Learning Methods
Hybrid deep learning methods combine different types of neural networks into a unified framework to tackle com-
plex tasks, such as pulmonary nodule detection, segmentation, and classification. By leveraging the unique strengths
of various models, including CNNs, RNNs, GANs, and attention mechanisms, these hybrid methods aim to enhance
Cai et al.: Preprint submitted to Elsevier
Page 12 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
overall performance, stability, and robustness. The primary advantage of hybrid models is their ability to address the
limitations of individual networks, providing better feature extraction, improving accuracy, reducing false positives,
and optimizing computational efficiency, particularly in challenging tasks like medical image analysis.
For example, Rashid et al. [64] developed a framework combining local binary patterns (LBP) with Histogram of
Oriented Surface Normal Vectors (HOSNV) features, achieving a sensitivity of 98.49% in detecting nodules. Cai et
al. [65] proposed MSDet, a model that combines ERD, PCAM, and TODB to capture richer contextual information
and reduce false positives caused by nodule occlusion through an extended receptive domain strategy, improving small
pulmonary nodule detection and achieving an 8.8% mAP improvement on the LUNA16 dataset. Siqi Liu et al. [66]
enhanced detection robustness by incorporating adversarial attacks into CNNs, improving the system’s ability to detect
rare nodules under noisy conditions. Similarly, Safta et al. [67] integrated 3D-LOP descriptors with 3D-CNN features,
achieving an accuracy of 97.84% and an AUC of 0.9912. As shown in Fig. 8a, Ling Ma et al. [30] introduced TiCNet,
combining Transformer and CNN architectures with multi-scale feature fusion, which achieved a CPM of 90.73% and
a sensitivity exceeding 93%, demonstrating its efficacy in reducing false positives. These hybrid approaches show that
combining diverse feature extraction and classification techniques significantly improves pulmonary nodule detection
and classification accuracy.
Other studies further highlight the versatility of hybrid deep learning methods. As shown in Fig. 8b, Jianning
Chi et al. [60] and Gonidakis et al. [68] demonstrated the effectiveness of combining local and global feature rep-
resentations using attention gates and hand-crafted features, respectively. Gonidakis et al.’s method notably reduced
the required training data by up to 43% while maintaining high performance. Additionally, Mao et al. [69] employed
a Hessian-MRLoG method to enhance contrast and reduce false positives, achieving a detection accuracy of 93.6%.
These strategies illustrate the benefits of integrating various deep learning techniques to enhance segmentation and
detection performance.
The successful applications of hybrid models, such as those proposed by Gugulothu et al. [51], Usman et al. [70],
and Pinheiro et al. [71], highlight the effectiveness of integrating advanced algorithms to improve detection accuracy,
reduce false positives, and enhance efficiency in lung cancer analysis. However, these hybrid models also introduce
challenges. Their complexity can lead to overfitting, requiring additional regularization or improved generalization
strategies. Furthermore, the combination of multiple components increases computational demands, leading to higher
costs and longer processing times. Effectively integrating different architectures and performing hyperparameter tuning
for such complex systems further adds to the difficulty. To address these challenges, more efficient model architectures,
advanced optimization techniques, larger datasets, and automated hyperparameter tuning methods could be explored
to improve performance and scalability.
Recently, Mamba models [72, 73] have gained prominence for their ability to effectively capture long-range depen-
Cai et al.: Preprint submitted to Elsevier
Page 13 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Fig. 8: Some structural examples of hybrid deep learning models: (a) Combination of 3D CNN, ACB, MSAI, TED, and dual
heads for NCD and FPR [30], which enhances multi-scale feature extraction and improves both classification and localization in
nodule detection. (b) Combination of CNN and Transformer branches with attention gates for local and global feature coupling
[60], allowing efficient integration of local and global features and guiding the decoding process for better feature reconstruction
and detection accuracy in medical images.
dencies [74, 75], significantly enhancing performance in dense prediction tasks like semantic segmentation. Studies by
Bian et al. [76] and Zhang et al. [77] have demonstrated the significant potential of the Mamba architecture in medical
image segmentation through the development of the MambaClinix model and VM-UNetV2 framework. MambaClinix
combines the Mamba architecture with Hierarchical Gated Convolutional Networks (HGCN), achieving an effective
balance between local and global features in 3D medical images. Its lower-level modules capture high-order spatial re-
lationships, while the higher-level modules utilize the Mamba architecture to extract long-range dependencies, resulting
in remarkable segmentation performance in datasets involving lung and liver tumors. Simultaneously, VM-UNetV2
introduces a Vision State Space (VSS) model and a Semantics and Detail Infusion (SDI) module, using linear computa-
tional complexity to efficiently capture contextual information. Compared to traditional CNNs and Transformer-based
Cai et al.: Preprint submitted to Elsevier
Page 14 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Fig. 9: (a) Number of publications in each database/platform from 2020 to 2024. (b) Number of publications on different pulmonary
nodule treatment tasks from 2020 to 2024.
models, VM-UNetV2 has demonstrated superior performance in medical segmentation tasks. This trend represents a
significant advancement in intelligent medicine, particularly in medical image analysis, where hybrid models incorpo-
rating the Mamba architecture [72, 73] are overcoming the limitations of traditional methods in terms of computational
efficiency and global feature extraction. As the volume of medical data continues to grow, models capable of efficiently
modeling long-range dependencies and handling complex contextual information will become increasingly essential.
These advancements not only enhance early disease detection and diagnosis but also lay a strong foundation for the
widespread adoption of intelligent medical systems.
In summary, hybrid deep learning models represent a rapidly growing trend, particularly in the field of pulmonary
nodule detection and classification, where these models are showing significant potential. With ongoing advancements
in deep learning technologies and the expansion of interdisciplinary research, even more innovative hybrid models are
expected to emerge. These models will likely address increasingly complex challenges, driving further progress in the
early detection and accurate diagnosis of lung cancer, ultimately improving clinical outcomes.
3. Literature Search and Screening
This review systematically retrieved relevant literature from multiple databases, including IEEE Xplore, Wiley
Online Library, Google Scholar, Web of Science, ACM, Science Direct, Springer Link, and Engineering Village,
covering the period from January 2020 to May 2024. The distribution of publications across these databases is shown
in Fig. 9a. Through rigorous screening, this review consolidates the applications of machine learning and deep learning
techniques in computer-aided diagnosis (CAD) of pulmonary nodules, with a particular focus on their implementation
in CT imaging. In addition to highlighting major research achievements, this review discusses the advantages and
limitations of current technologies and outlines future research directions, providing valuable insights for researchers
in the field.
Cai et al.: Preprint submitted to Elsevier
Page 15 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Fig. 10: The literature screening process adapted in this study. Screening criteria for step 2 include the following: time range
(2020.1 - 2024.5), journal publication, journal type, and language (English); screening criteria for step 3 include the exclusion of
methods that do not meet the criteria and conference papers. ’Others’ includes publications from Wiley, MDPI, Taylor and Francis,
and Hindawi.
During the retrieval process, 406 relevant articles were identified, covering different aspects of pulmonary nodule
analysis: 124 on detection, 155 on segmentation, and 127 on classification, as illustrated in Fig. 9b. After applying
stringent screening criteria, 131 articles were selected, with the selection process depicted in Fig. 10. The final
selection includes 56 articles on detection, 33 on segmentation, and 42 on classification. The subsequent sections
will discuss the technical approaches, research outcomes, and applications derived from these studies, providing a
comprehensive overview of the CAD landscape for pulmonary nodules and offering a thorough understanding of the
current research status and future trends in this evolving field.
4. Datasets and Benchmarks
The development of Computer-Aided Diagnosis (CAD) systems for pulmonary nodules relies heavily on high-
quality imaging data and robust evaluation metrics. Publicly available datasets serve as foundational resources for
training, testing, and validating deep learning algorithms, facilitating standardized comparisons across different meth-
ods. These datasets vary in size, annotation quality, and imaging techniques, making them critical for different stages
of research and clinical applications. In addition to datasets, benchmarks play a key role in evaluating the performance
of CAD systems, providing objective metrics such as accuracy, sensitivity, and specificity to assess algorithm effec-
tiveness. This section provides an overview of the key datasets widely used in CAD research for pulmonary nodules
and discusses the most commonly employed benchmarks and evaluation metrics. As shown in Table 2, these datasets
provide essential resources for advancing research in pulmonary nodule detection and diagnosis.
The LIDC-IDRI dataset [78] is one of the most comprehensive publicly available lung CT datasets, jointly created
by the National Cancer Institute (NCI) and the American College of Radiology (ACR). It contains over 1,000 lung CT
cases, annotated by four experienced thoracic radiologists through a multi-phase, consensus-based evaluation. Each
scan is annotated with regions of interest, specifically focusing on pulmonary nodules of varying sizes, and includes
both nodule and non-nodule cases. The diversity of imaging protocols and scanning devices makes this dataset widely
Cai et al.: Preprint submitted to Elsevier
Page 16 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Table 2
Overview of Datasets Commonly Adapted in Pulmonary Nodule Computer-Aided Diagnosis (CAD) Research.
Dataset
No. of Scans
Focus Area
Use Case
Annotations
LIDC-IDRI
1,018
Pulmonary nodule Detection
Detection, Classification, Segmentation
✓
LUNA16
888
Nodule Detection (Nodules >3mm)
Detection Benchmark
✓
ELCAP
50
Early Lung Cancer Screening
Early Detection
✓
NSCLC
422
Non-Small Cell Lung Cancer
Personalized Treatment, Prognosis
✓
ANODE09
55
Nodule Detection (Various types)
Benchmarking Detection Algorithms
✓
applicable for CAD system development. Furthermore, its comprehensive annotations from different radiologists allow
for the exploration of inter-observer variability, a key challenge in medical image analysis.
The LUNA16 dataset [79] is derived from LIDC-IDRI but focuses specifically on pulmonary nodule detection. It
includes 888 high-quality CT scans with detailed annotations of nodules larger than 3 mm in diameter. LUNA16 also
provides a standardized evaluation framework, making it a widely adopted benchmark for comparing nodule detection
algorithms. The dataset includes annotations that highlight the location and size of each nodule, offering a valuable
resource for both segmentation and detection tasks. The nodule cases are categorized based on their risk levels, helping
researchers more effectively distinguish between benign and malignant nodules.
The ELCAP dataset [80] is part of the Early Lung Cancer Action Project and consists of low-dose CT (LDCT)
scans, primarily targeting high-risk populations, such as heavy smokers. ELCAP emphasizes early-stage lung cancer
screening and includes a large number of small nodules, making it an essential resource for early detection studies. The
dataset includes detailed clinical and demographic information, such as patient age, smoking history, and risk factors.
Although only part of this dataset is publicly available, its focus on high-risk groups makes it valuable for developing
screening algorithms aimed at detecting lung cancer in its earliest stages.
The NSCLC-Radiomics dataset [81] focuses on non-small cell lung cancer (NSCLC) and includes not only CT
scans but also extensive clinical and molecular data. This dataset contains over 400 CT scans from patients with
NSCLC, annotated with tumor regions, genomic information, and treatment outcomes. Its richness in clinical context
makes it particularly valuable for research into personalized treatment strategies and prognostic modeling. The dataset
also supports the study of radiomics, which involves extracting a large number of features from medical images to
uncover disease characteristics that are not visible to the naked eye, providing a bridge between medical imaging and
molecular biology.
The ANODE09 dataset [82] was developed for an international competition on automatic pulmonary nodule de-
tection and consists of 55 CT scans that cover a wide range of nodule types, sizes, and shapes. This dataset focuses
on providing a controlled environment for evaluating detection algorithms. The standardized evaluation metrics, such
as sensitivity and false positive rates, facilitate direct comparisons between different methods. Although smaller in
Cai et al.: Preprint submitted to Elsevier
Page 17 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
size compared to other datasets, ANODE09 is highly structured and provides clear, well-defined cases that are ideal
for benchmarking new detection techniques. The diversity of nodule types, including solid, subsolid, and ground-
glass opacities, presents an additional challenge for algorithm development, making this dataset particularly useful for
testing algorithm robustness.
In terms of evaluating the effectiveness of CAD systems, several standardized benchmarks and evaluation metrics
are employed. One widely adopted benchmark for nodule detection is the Competition Performance Metric (CPM),
based on the Free-Response Receiver Operating Characteristic (FROC) curve. CPM evaluates an algorithm’s sensitiv-
ity at predefined false positive rates, typically ranging from 1/8 to 8 false positives per scan. By averaging sensitivity
at these rates, CPM provides a robust measure of how well a model balances sensitivity and false positives. The FROC
curve, which plots the true positive rate (sensitivity) against the average number of false positives per scan, is a key
tool in CAD research. The area under the FROC curve (AUC) indicates overall performance, with higher AUC values
(ranging from 0.5 to 1) reflecting better discrimination between positive and negative cases.
For segmentation tasks, the Dice Similarity Coefficient (DSC) is commonly employed to assess how accurately
an algorithm delineates nodule boundaries, with higher DSC values indicating better overlap between predicted and
actual segmentations. In classification tasks, key metrics include sensitivity (the ability to correctly identify nodules),
specificity (the ability to correctly identify non-nodules), and accuracy, which measures the overall correctness of
the model’s predictions. These metrics—sensitivity, AUC, specificity, and DSC—are critical for balancing nodule
detection and minimizing false positives, ultimately guiding the development of reliable CAD systems for clinical
practice.
5. Discussion: Key Techniques and Breakthroughs in Lung Cancer Detection,
Segmentation, and Classification
In recent years, AI-driven advancements in computer-aided diagnosis (CAD) systems for pulmonary nodules have
transformed the field of lung cancer detection, segmentation, and classification. These innovations, bolstered by high-
quality datasets such as LIDC-IDRI and LUNA16, have not only accelerated technological progress but also fostered
international research collaboration. In detection, the integration of deep learning models, especially multi-task convo-
lutional neural networks, has significantly enhanced the sensitivity and accuracy of identifying nodules from CT scans.
In segmentation, advanced models like UNet, 3D CNNs, and GANs have greatly improved precision in delineating
nodule boundaries, a critical factor in evaluating nodule size and growth. For classification, the combination of deep
learning techniques and texture-based features has refined the differentiation between benign and malignant nodules,
thus improving diagnostic reliability. Together, these innovations have optimized CAD systems, paving the way for
broader clinical applications and improved patient outcomes through earlier and more accurate lung cancer diagnoses.
Cai et al.: Preprint submitted to Elsevier
Page 18 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
The following sections will examine recent progress in detection, segmentation, and classification, highlighting the
key techniques and breakthroughs in each area and providing a critical analysis of their clinical relevance and future
directions.
5.1. Discussion on AI-Driven Advances in Lung Cancer Detection
Detecting pulmonary nodules is essential for early lung cancer diagnosis and treatment, enabling timely interven-
tion. Pulmonary nodule detection generally involves two stages: screening potential nodules in CT scans and classi-
fying malignancy likelihood, which guides clinical decisions. Recent advancements in AI, particularly deep learning
models like multi-task CNNs, YOLOv4, UNet, and GANs, have significantly improved detection sensitivity and accu-
racy, enhancing CAD systems. High-quality datasets such as LIDC-IDRI and LUNA16 have facilitated these advances
by providing annotated data for effective model training. Table 3 summarizes 19 recent studies (2020-2024) utilizing
the LIDC-IDRI dataset, highlighting their strengths, limitations, and clinical relevance.
Key Innovations and Performance Comparisons: Over the past several years, significant advancements have been
made in AI-driven pulmonary nodule detection, contributing uniquely to the evolution of the field. In 2020, Masud
et al. [90] developed a lightweight deep learning model achieving 97.9% accuracy, showcasing the potential for AI
deployment in resource-constrained environments, such as mobile devices in clinics with limited computational power.
In 2022, Bhatt et al. [22] demonstrated the utility of YOLOv4 for real-time detection with 95% precision, emphasizing
the practical application of AI in rapid diagnostics. Fu et al. [37] integrated 3D CT imaging with serum biomark-
ers, highlighting a multimodal approach that combines diverse data sources to enhance diagnostic precision. In 2023,
Gugulothu et al. [51] introduced a hybrid deep learning approach, and by 2024, Gautam et al. [88] combined ResNet,
DenseNet, and EfficientNet to achieve a sensitivity of 98.6%, significantly reducing false negatives. Furthermore,
Usman et al. [70] developed MEDS-Net, which achieved a CPM score of 93.6% by reducing false positives, thus min-
imizing unnecessary invasive procedures and enhancing diagnostic reliability. These innovations collectively advance
the clinical applicability of AI for lung cancer detection by improving both accuracy and efficiency.
Model Adoption and Clinical Implications: The discussed studies highlight a range of technical approaches fo-
cusing on improving sensitivity, computational efficiency, and real-time applicability. Models such as YOLOv4 and
MEDS-Net illustrate the potential of AI to be integrated into practical, real-time clinical workflows, whereas the mul-
timodal diagnostic model by Fu et al. [37] underscores the value of combining multiple data sources for a more
comprehensive diagnostic approach. A crucial factor in clinical adoption is the computational complexity of these
models. While high accuracy is desirable, the scalability of complex models like Mask R-CNN and GANs is often
limited due to their heavy computational requirements. For instance, Zhu et al.’s [52] GAN-based approach effectively
addresses data imbalance but at the cost of significant computational demands, potentially hindering scalability in less
Cai et al.: Preprint submitted to Elsevier
Page 19 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Table 3
Pulmonary nodule detection methods and their performance in CT images from the LIDC-IDRI dataset.
Authors
Year
2D/3D
Technique/
Network Type
Training/
Validation/
Testing Set
Software/
Hardware
Utilized
Main
Method
Nodules
Types
Validation/
Test Method
Model
Performance
Veronica et al.
[83]
2020
2D and
3D
ANN, Fuzzy C-
Means
LIDC-IDRI,
ELCAP
MATLAB, 4GB
RAM
FCM,ANN with
OALO
Benign, malig-
nant
Sensitivity:
96.10%
Bhatt
et
al.
[22]
2022
2D
YOLOv4
Tra
70%,
Val
20%, Test 10%
TensorFlow
RTX 2070
YOLOv4 model
Various nodule
types and sizes
YOLOv4: 81.00%
Harsono et al.
[84]
2022
3D
I3DR-Net
LIDC: 605 tra,
202 val, 202 tes
Pytorch,
Tesla
P100 16GB
Inflated
3D
ConvNet (I3D)
Solid and non-
solid nodules
Sensitivity:
94.60%
Nair et al. [85]
2022
2D
RWI segmenta-
tion, RF, KNN
534
training,
150 testing
MATLAB
2018a
Random Walker
with
Random
Forest, k-NN
Benign and ma-
lignant nodules
RWI-RF: 99.99%;
RWI-k-NN:
98.9919%
Jain et al. [86]
2023
3D
Two-stage
CNN, U-net
LIDC-IDRI:
5023tra/val
Python,
Tesla
P100
Two-stage
CNN, U-net
Pulmonary nod-
ules ≥3 mm
Train-
Validation-
Test Split
Sensitivity:
83.55%
Gugulothu
et
al. [51]
2023
2D
CSDR-J-
WHGAN
Training
80%,
Testing 20%
Python
SDMMT, MD-
HHOA, CSDR-
J-WHGAN
Nodule
and
non-nodule
Sensitivity:
96.98%
Rashid
et
al.
[64]
2024
2D and
3D
HOSNV,
LBP,
XGBoost
LIDC-IDRI
-
XGBoost
Vessel, isolated,
juxtapleural
XGBoost:
98.49%
Agnes
et
al.
[87]
2024
2D
Wavelet
U-
Net++
LIDC-IDRI:
1018 scans
Python
Keras,
GPU
U-Net++,
hy-
brid loss
Small, irregular
nodules
DSC:
93.70%;
IoU: 87.80%
Gautam et al.
[88]
2024
2D
ResNet-152,
EfficientNet-B7
LIDC-IDRI
-
Weighted aver-
age ensemble
Benign and ma-
lignant
Sensitivity:
98.60%
Gugulothu
et
al. [45]
2024
2D
Hybrid
DL
(HDE-NN)
LIDC-IDRI
-
Hybrid differen-
tial
evolution-
based NN
Benign and ma-
lignant
Sensitivity:
95.25%
Halder
et
al.
[89]
2020
2D
Segmentation
(AMST)
LIDC/IDRI,
private dataset
-
Morphological
filter with SVM
Solid, subsolid,
GGO
Sensitivity:
94.88%
Masud
et
al.
[90]
2020
2D
CNN
LIDC 1279 im-
ages
Nvidia
GTX1050,12GB
Light CNN
Normal,
Be-
nign, malignant
Accuracy:
97.90%
Farhangia et al.
[91]
2021
2D and
3D
Unified CNN
888 CT exams
CT volume: 12
min
Dilated 1D con-
volutions
Solid, subsolid,
large nodules
10-fold cross-
validation
Sensitivity:
>96.00%
Zheng
et
al.
[92]
2021
3D
U-net++,
Efficient-Net
LIDC:888scans,
1186 nodules
-
Multiscale
dense CNNs
Small
nodules
(<6 mm)
Sensitivity:
94.20%
Chen
et
al.
[93]
2022
3D
F-Net,
MSS-
Net
Training
70%,
Validation 20%,
Test 10%
-
F-Net,
MSS-
Net
Solitary,
vary-
ing sizes (3-30
mm)
0.971 (1 FP/scan);
0.978 (2 FPs/scan)
Usman et al.
[70]
2024
3D
Multi-encoder,
Self-distillation
Training
80%,
Validation 10%
Python
3Dsub-
volumes,
self-distillation
Nodules
≥
3
mm
20.27 Fps/scan
Fu et al. [37]
2021
3D
Multi-DL, MLP
3:1
train-
ing/validation
Keras,
GTX1080ti
Fusion
of
3D
lung CT images
Squamous
cell
carcinoma
Specificity:
90.60%
Majidpourkhoei
et al. [94]
2021
3D
CNN
LIDC,1415 test
images
Python,
8GB
RAM
CNN with 3D
convolutions
Nodule sizes (1-
5 mm)
5-fold
cross-
validation
Specificity:
91.70%
Hung
et
al.
[95]
2023
3D
HSNet
Original:
4252
images, split 3:1
TensorFlow 2.7,
NVIDIA
RTX
3060, 32GB
3D hierarchical
semantic
CNN
(HSNet)
Subtlety,
tex-
ture, sphericity,
malignancy
Cal:
98.73%;
Margin:
92.07%;
Subtlety: 90.26%
resource-rich environments. In contrast, Wu et al.’s [96] enhancement of YOLOv7 presents a more efficient model
that balances performance and computational load, making it more practical for broader clinical implementation.
Comparisons Across Benchmark Datasets: Compared to the LIDC-IDRI dataset, LUNA16 employs CPM (Compe-
tition Performance Metric) as a benchmark, providing a standardized measure for comparing CAD system performance.
Cai et al.: Preprint submitted to Elsevier
Page 20 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Table 4
Pulmonary nodule detection methods and their performance in CT images from the LUNA16 dataset.
Authors
Year
2D/3D
Technique/
Network Type
Training/
Validation/
Testing Set
Software/
Hardware
Utilized
Main
Method
Nodules
Types
Validation/
Test Method
Model
Performance
Cai
et
al.
[97]
2020
3D
Mask R-CNN
LUNA16, Ali
TianChi
Quadro
P6000
GPU
Mask
R-CNN,
ResNet50, FPN,
RPN
Benign and
malignant
88.1% at 1 FP/scan;
88.7% at 4 FP/scan ;
AP@50: 88.2%
Song et al.
[98]
2020
3D
3D CPM-Net
LUNA16
(888 scans)
SenseCare Plat-
form
Anchor-free, 3D
context
Benign and
malignant
91.2% at 1 FP/scan;
92.4% at 2 FP/scan
Yuan et al.
[99]
2021
3D
Multi-path
3D
CNN
LUNA16,
split 8:1:1
TensorFlow,
RTX2080
TI
GPU
Multi-path
3D
CNN,
feature
fusion
Various
sizes
0.952 at 4 FP/scan;
0.962 at 8 FP/scan ;
CPM: 0.881
Agnes et al.
[100]
2022
2D and
3D
Two-stage Pul-
monary nodule
detection
23,720
CT,
80%
Train,
20% Test
Keras,
GTX
1060 (6 GB)
Atrous UNet+,
PD-CLSTM
Small
nodules(5-9
mm)
0.544-0.986 at differ-
ent FP levels ; CPM:
0.93
Zhao et al.
[101]
2022
2D and
3D
Faster R-CNN
LUNA16
Platform - Co-
lab;
Ubuntu;
K80 GPU
Multiscale
fu-
sion
Small nod-
ules
Train-
Validation-
Test Split
0.905 at 4 FP/scan ;
CPM: 0.829
Gonidakis
et al. [68]
2023
3D
Handcrafted
features + CNN
70%
Train,
10% Val, 20%
Test
Keras
with
TensorFlow,
2080 RX
Handcrafted
+
CNN
Benign and
malignant
0.5 mean FP/scan ;
Fusion: 94.3%
Hendrix
et
al. [102]
2023
2D and
3D
AI system
500 CT (Hos-
pital A), 888
(LUNA16)
-
AI,
multi-view
ResNet50,
FROC
Actionable
benign
nodules
Internal: 90.9%; Ex-
ternal:
92.4%;
Be-
nign: 94.3%
Wu
et
al.
[96]
2024
2D
YOLO-MSRF
LUNA16
-
YOLO-MSRF
Benign and
malignant
Sensitivity:
94.02%;
mAP: 95.26%
Zhang et al.
[103]
2024
3D
S-Net,
U-
shaped
LUNA16
-
S-Net,
hybrid
loss
Different
shapes
S-Net(R): 0.914;
S-
Net(S): 0.915
Budati et al.
[104]
2024
2D
SbYSF, Sailfish
+ YOLO
LUNA16
Python in Win-
dows 10
Sailfish-based
YOLO (SbYSF)
Lung
can-
cer nodules
CPM: 99.75%
Cao et al.
[105]
2020
3D
Two-Stage
CNN
LUNA16,
10%
valida-
tion
Ubuntu
14.04,
Python
3.6.4,
GTX-1080Ti
TSCNN: UNet,
3D CNN
Calcific,
cavitary
DenseNet:
0.768;
SeResNet:
0.730;
IncepNet: 0.686
Zhu et al.
[52]
2021
3D
FRGAN
543
images,
augmented to
0.22M
Adam
opti-
mizer, learning
rate 1.0 × 10−4
GAN
augmen-
tation, 3D-CNN
Solid, sub-
solid, large
nodules
CPM: 0.915
Shi
et
al.
[106]
2021
3D
3D Res-I, Faster
R-CNN
Fold
1-9
Train, Fold 0
Test
Ubuntu
16.04,
PyTorch,
GTX
1080Ti
U-Net-Like net-
work, Faster R-
CNN
Solid, semi-
solid
Sensitivity:
96.37%;
FROC: 83.75%
Zhang et al.
[59]
2022
3D
3D
MSA,
3D
Faster R-CNN
LUNA16,
TianChi
-
Multiscale
at-
tention
Various
sizes
10-fold cross-
validation
0.945 at 1 FP/scan ;
CPM: 0.927
Zhang et al.
[107]
2023
3D
LungSeek,
3D
SK-ResNet
LUNA16:
9
Train subsets
(800 CT)
PyTorch,
GTX
1080,
16
GB
RAM
LungSeek,
3D
SK-ResNet
Benign and
malignant
SK-ResNet:
95.78%;
Res18: 95.53%; DPN:
94.32%
Gao et al.
[108]
2024
3D
FULFIL, GCN
LUNA:
140
scans
PyTorch
1.1.0,
RTX 3090
FULFIL, GCN,
Teacher–Student
Benign and
malignant
0.574 at 0.125 FP/scan
Lin
et
al.
[109]
2024
3D
3D RPN
LUNA16,
LNOP, LNHE
PyTorch,
RTX
2070,
24GB
RAM
Modified
3D
RPN,
CSP-
ResNeXt, FPN
Different
solid
96.6% at 8 FP/scan
for LUNA16 ; CPM:
90.10%
This allows for a clearer evaluation of different models’ strengths and applicability in various clinical scenarios. Table
4 compiles key metrics such as author, year, technique type, validation method, and CPM score, offering a compre-
hensive view of advancements between 2020 and 2024. Studies employing deep learning techniques that integrate 3D
contextual information and multi-scale feature fusion, such as Mask R-CNN and 3D CPM-Net, exhibit outstanding
performance, improving detection accuracy while minimizing false positives.
Cai et al.: Preprint submitted to Elsevier
Page 21 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Future Directions and Clinical Potential: The development and adoption of AI-driven CAD systems for pulmonary
nodule detection must prioritize clinical integration and adaptability. Future research should focus on reducing com-
putational complexity to make these models suitable for environments with limited resources, further developing
lightweight and real-time applications to expand access, and integrating multimodal data, such as combining imag-
ing with biomarkers, to improve diagnostic precision. In conclusion, advancements in AI-driven pulmonary nodule
detection have significantly enhanced detection sensitivity, reduced false positives, and improved clinical applicabil-
ity, paving the way for broader adoption. Successful integration into clinical practice, with a continued emphasis on
balancing efficiency and accuracy, is essential for realizing the full impact of these systems on patient care.
5.2. Discussion on AI-Driven Advances in Lung Cancer Segmentation
Pulmonary nodule segmentation is vital for early lung cancer diagnosis, involving the precise identification of
nodules in CT images for volumetric analysis, growth rate estimation, and characterization—critical for treatment
strategies. Segmentation quality directly impacts clinical decisions, making it essential for CAD systems. Recent AI
advancements, particularly in deep learning models like UNet, GANs, and 3D CNNs, have enhanced segmentation
accuracy, supported by datasets such as LIDC-IDRI and LUNA16. Table 5 summarizes recent studies, detailing
model performance, datasets, and validation methods, helping identify suitable models for clinical use. Ultimately,
improved segmentation accuracy supports early diagnosis, treatment planning, and better patient outcomes.
Key Innovations and Performance Comparisons: Recent AI-driven advancements in pulmonary nodule segmenta-
tion have significantly enhanced both accuracy and clinical utility. In 2020, Chen et al. [118] introduced the LDDNet
model, achieving over 99% segmentation accuracy on the LIDC-IDRI dataset, showing strong potential for reducing
manual workload and improving consistency in clinical nodule identification. Khanna et al. [123] similarly demon-
strated the robustness of deep learning approaches with their deep residual U-Net, reaching a Dice Similarity Coeffi-
cient (DSC) of over 98% on the LUNA16 dataset. In 2021, Dutande et al. [110] and Kadia et al. [111] presented a
2D-3D cascaded CNN and the R2U3D model, respectively, emphasizing the benefits of using multiple dimensionalities
for capturing diverse features in nodule segmentation. In 2022, Zhang et al. [120] introduced the I-3D DenseUNet,
excelling in segmenting complex tumor shapes, while Tyagi et al. [53] leveraged a CSE-GAN to overcome chal-
lenges posed by data scarcity, a common issue in medical imaging. Recent models have also focused on hybrid and
multi-modal approaches: in 2023, Youssef et al. [122] combined deep learning with stochastic models for enhanced
robustness, while Nguyen et al. [46] used a multi-branch attention mechanism to improve segmentation accuracy. In
2024, Bbosa et al. [115] and Sweetline et al. [31] developed MRUNet-3D and a multi-crop CNN, respectively, both
demonstrating strong performance in segmenting small nodules—critical for the early detection necessary for effective
lung cancer treatment.
Cai et al.: Preprint submitted to Elsevier
Page 22 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Table 5
Methods and their performance in pulmonary nodule segmentation on CT images.
Authors
Year
Dataset
Technique/
Network Type
Main
Method
Software/
Hardware
Utilized
Validation/
Test Method
Model
Performance
Dutande et al.
[110]
2021
LIDC-IDRI,
LNDb, ILCID
2D-3D
cas-
caded CNN
SquExUNet:
Seg-
mentation
Keras,
NVIDIA
P100 16GB
Segmentation:
80.00% ; Detec-
tion: 90.01%
Kadia
et
al.
[111]
2021
LUNA16, VES-
SEL12
R2U3D
R2U3D
with
3D
convolution.
Keras,
NVIDIA
RTX 2080 Ti
Soft-DSC: 0.9920
Liu et al. [62]
2024
LIDC-IDRI
SCA-VNet
Residual edge en-
hancement
PyTorch 1.12.1
DSC:
87.50%
;
Sensitivity:
86.80% ; Precision: 88.32%
Agnes
et
al.
[87]
2024
LIDC-IDRI
Wavelet
U-
Net++
U-Net++
with
wavelet pooling
Python
Keras,
GPU
DSC: 93.7% ± 0.14
Cai et al. [97]
2020
LUNA16,
TianChi
Mask R-CNN
Mask
R-CNN,
resnet50 backbone
Quadro
p6000
(1.08GB)
88.1% at 1 false positive/scan;
88.7% at 4 false positives/scan
Osadebey et al.
[112]
2021
LIDC-IDRI,
3DIRCAD,
ILD, PHTM
CNNs and U-
net
Preprocessing:
CNN
classifier;
Processing: U-net
MATLAB,
Win-
dows
10,
Intel
i7-8650U
Train-
Validation-
Test Split
3DIRCAD: 0.76-0.95; ILD: 0.81-
0.95
Zhu et al. [50]
2021
LUNA16
HR-MPF
HR-MPF with PDM
PyTorch, Intel i7-
10700, GTX 2070
DSC: 0.9373 ; Sensitivity: 0.9377
; Precision: 0.9427
Tyagi et al. [53]
2022
LUNA16,
ILND
3D GAN
CSE-GAN with U-
Net
TensorFlow,
NVIDIA P100
LUNA: 80.74%, ILND: 76.36% ;
LUNA: 85.46%, ILND: 82.56%
Tang
et
al.
[113]
2023
LUNA16
NoduleNet
AI-based CT nod-
ule diagnosis, Lung-
RADS, PCA.
PyTorch,
Nvidia
GTX 1060 6GB
non-solid:
0.86; partially solid:
0.68; solid: 0.94; Class 1: 0.84,
Class 3: 0.29, Class 5: 0.99
Luo et al. [114]
2024
LUNA16
RkcU-Net
Improved
residual
block
PyTorch, Python,
NVIDIA P100
DSC:
89.25%
;
Sensitivity:
88.48% ; Precision: 90.04%
Bbosa
et
al.
[115]
2024
LUNA16
MRUNet-3D
MRUNet-3D:
Multi-stride
PyTorch,
NVIDIA 3060
DSC:
83.47%
;
Sensitivity:
83.39% ; Precision: 86.04%
Qiu et al. [116]
2023
LIDC-IDRI,
LUNA16
Dual-task 3D
U-Net
Dual-task
region-
boundary
PyTorch,NVIDIA
RTX 3090
LIDC-IDRI:
82.48
±
8.17;
LUNA16: 71.61 ± 14.17
Thangavel et al.
[117]
2024
LIDC-IDRI,
LUNA16
T-Net, NAS-
Net
T-Net,
CenterNet,
NASNet for seg
Keras,
NVIDIA
930 mx
LIDC-IDRI:
99.07;
LUNA16:
98.97
Chen
et
al.
[118]
2020
LIDC-IDRI
LDDNet
LDDNet:
Uses
dense block, BN
PYDICOM, CV2
(OpenCV); 32GB
Accuracy: Over 99% ; High seg-
mentation accuracy and robustness
Ni et al. [119]
2022
LIDC-IDRI
Two-stage
multitask
U-Net
Coarse-to-fine
2-stage
with
3D
U-Net, MSU-Net.
PyTorch,3
NVIDIA
GTX-
1080 GPUs
Malignancy:
83.4%;
Margin:
81.4%;
Calcification:
92.4% ;
Accuracy 77.8%; AUC 84.3%
Zhang
et
al.
[120]
2022
LIDC-
IDRI,TCIA,
SHATMU
I-3D
Dense-
UNet
Nested dense skip
connection,
TPS
augmentation.
Keras/
Tensor-
Flow,
Linux,
6
NVIDIA 12GB
TCIA/LIDC: 0.8316, SHATMU:
0.8167 ;
TCIA/LIDC: 0.9278,
SHATMU: 0.9015
Usman
et
al.
[121]
2023
LIDC-IDRI
MESAHA-
Net
Multi-encoder
structure
TensorFlow
2.0,
NVIDIA
5-fold
cross-
validation
88.27% ± 7.42% ; 92.88% ± 9.54%
; 86.95% ± 11.29%
Youssef et al.
[122]
2023
LIDC-IDRI
3D U-Net
MGRF model; 3D
U-net
for
precise
ROI segmentation.
PyTorch,
Tesla
V100
GPU
(16GB)
Dice score:
93.64% ± 5.20% ;
93.30% ± 07.72%
Khanna et al.
[123]
2020
LUNA16,
VESSEL12,
HUG-ILD
Deep
Resid-
ual U-Net
Residual
U-Net,
false-positive
re-
moval.
Keras/
Tensor-
flow,
Intel
i7,
GTX 1060 (6GB)
LUNA16:
98.63%; VESSEL12:
99.62%; HUG-ILD: 98.68%
Nguyen et al.
[46]
2023
LIDC-IDRI,
LUNA16
3D UNet
UNet-based
back-
bone, multi-branch
attention.
NVIDIA
Tesla
P100 (16GB)
Consensus 3: 82.74 ± 8.11; Con-
sensus 4: 83.61 ± 7.01 ; FROC
sensitivity: 88.11%
Halder
et
al.
[89]
2020
LIDC-IDRI
AMST
ASE:
Adaptive
filter, reduces false
positives.
Siemens
So-
matom
Spirit
scanner
Min 0.9433; Max 0.9919; Avg
0.9872 ; 8-9 mm: 92.90%, 9-10
mm: 93.55%, 10-20 mm: 95.83%
Bhattacharyya
et al. [124]
2023
LUNA16
DB-NET
DB-NET: Mish acti-
vation
PyTorch,
NVIDIA GPU
10-fold cross-
validation
DSC:
88.89%
;
Sensitivity:
90.24% ; Precision: 77.92%
Ma et al. [125]
2024
LUNA16,
LNDb
Dig-CS-VNet
Dig-CS-VNet: Pixel
threshold
PyTorch
1.7.0,
RTX A5000x2
LUNA16: 94.9%, LNDb: 81.1% ;
LUNA16: 92.7%, LNDb: 76.9%
Performance Evaluation via Dice Similarity Coefficient (DSC): Recent studies indicate significant progress in deep
learning-based pulmonary nodule segmentation, particularly regarding the Dice Similarity Coefficient (DSC). Halder
et al. [89] achieved a sensitivity of 94.88% on the LIDC-IDRI dataset. Chen et al. [118] introduced LDDNet, which
recorded over 99% accuracy in lung parenchyma segmentation. Zhang et al. [120] reported an 83.16% DSC with their
Cai et al.: Preprint submitted to Elsevier
Page 23 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
I-3D DenseUNet on the LIDC dataset, while Liu et al. [62] reached a DSC of 87.50% with their SCA-VNet on the
LIDC-IDRI dataset. Sweetline et al. [31] developed a multi-crop CNN that achieved accuracies of 98.3% and 98.5%
on the LUNA16 and LIDC-IDRI datasets, respectively. These advances, primarily based on U-Net variants, CNNs,
and attention mechanisms, have significantly improved segmentation accuracy and reliability.
Model Adoption and Clinical Implications: The successful adoption of AI-driven segmentation models in clinical
settings hinges on balancing accuracy with computational efficiency. While high-performing models like LDDNet
and deep residual U-Net show great promise due to their high accuracy, they also present computational challenges
that can hinder scalability, especially in resource-limited healthcare facilities. For instance, Zhang et al.’s [120] I-3D
DenseUNet demonstrated excellent segmentation accuracy but may not be feasible for smaller healthcare centers due
to its high computational demands. In contrast, Liu et al.’s [62] SCA-VNet offers a more balanced approach, achieving
a DSC of 87.5% while minimizing computational overhead, making it a more practical candidate for widespread clin-
ical adoption. Additionally, reducing false positives remains a critical aspect of clinical deployment, as minimizing
unnecessary procedures is vital for patient safety and healthcare efficiency. Approaches like attention mechanisms and
ensemble learning, utilized in models such as MANet and SCA-VNet, enhance precision and sensitivity, ultimately
making these models more reliable and suitable for real-world clinical use.
Future Directions and Clinical Potential: Future research in AI-driven pulmonary nodule segmentation should
prioritize developing lightweight, computationally efficient models suitable for real-time use, especially in resource-
limited settings. Such advancements could support integration into mobile devices or clinical workflows, improving
access to diagnostic tools in underserved areas. Moreover, integrating segmentation models with other modalities,
such as imaging, biomarkers, or genomic data, could enhance diagnostic accuracy and provide a comprehensive un-
derstanding of patient conditions. In conclusion, strides in AI-driven segmentation have improved accuracy and early
lung cancer detection. Successful clinical integration will require balancing performance with practical deployment,
focusing on efficiency, accessibility, and multimodal data to maximize impact on patient outcomes.
5.3. Discussion on AI-Driven Advances in Lung Cancer Classification
Pulmonary nodule classification aims to distinguish between benign and malignant nodules and differentiate true
nodules from imaging artifacts, which is crucial for guiding clinical decisions and reducing unnecessary interventions.
Recent advancements in AI have significantly improved classification accuracy, enhancing patient care and resource
utilization. To summarize these advancements, we reviewed 32 studies from 2020 to 2024, encompassing machine
learning, deep learning, and hybrid approaches using datasets like LIDC-IDRI and LUNA16. Table 6 highlights these
studies, emphasizing their methodologies, strengths, limitations, and clinical relevance.
Key Innovations and Performance Comparisons: Recent studies in pulmonary nodule classification have made
Cai et al.: Preprint submitted to Elsevier
Page 24 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Table 6
Methods and their performance in pulmonary nodule classification on CT images.
Authors
Year
Dataset
Classification
Technique/
Network Type
Main
Method
Software/
Hardware
Utilized
Validation/
Test Method
Model
Performance
Savitha et al.
[126]
2020
LIDC-
IDRI
Nodule
or
non-nodule
DCNN +CRF
DCNN + CRF
for extraction and
classification
i5-7300-HQ,
16GB,
GTX
1050
ACC: Without CRF: 83%; With
CRF: 89.48%
Naqi
et
al.
[127]
2020
LIDC-
IDRI
Nodule
or
non-nodule
FODPSO;
Geometric fit
Four phases: ex-
traction, cla
MATLAB,
Xeon 3.5 GHz
ACC: 96.90% ; SEN: 95.60% ;
SPE: 97.00%
Pinheiro et al.
[71]
2020
LIDC-
IDRI
Nodule
or
non-nodule
CNNs
Swarm
AI
for
CNN training
-
ACC: 93.71% ; SEN: 92.96% ;
SPE: 98.52%
Wang
et
al.
[128]
2021
LIDC-
IDRI
Nodule
or
non-nodule
CS-LBP,
ORT-EOH;
H-SVMs
3D
feature
extraction:
CS-
LBP, ORT-EOH
MATLAB,
Xeon 3.5 GHz
Average1: 96.04% ; Average2:
95.69% ; Average3: 96.95%
Naveen et al.
[129]
2023
LIDC-
IDRI
Nodule
or
non-nodule
DS,
RF,
BPNN
DS, RF, BPNN
for classification
-
solid:
98.00%;
part-solid:
93.68%; non-solid: 97.20%
Gugulothu
et
al. [51]
2023
LIDC-
IDRI
Nodule
or
non-nodule
SDMMT; U-
Net;LTrP
Clas:
CSDR-J-
WHGAN
Python
CSDR-J-WHGAN:
97.11%;
GAN: 95.56%; DCNN: 91.54%
Chen
et
al.
[130]
2021
LUNA16;
Kaggle
DSB
Nodule
or
non-nodule
LDNNET:
Dense-Block,
BN, Dropout
LDNNET,
Dense-Block:
classification
32GB RAM, 2.5
GHz CPU, GT
640M
LUNA16:
98.84%;
Kaggle
DSB 2017: 99.95%
Halder
et
al.
[131]
2023
LIDC-
IDRI
benign
or
Malignant
Atrous CNN:
ATCNN1P,
ATCNN2PR
VGG-like struc-
ture:
classifica-
tion
GPU in Google
Colab Pro
ATCNN2PR-1:
95.97%
;
ATCNN2PR-2:
95.84%
;
ATCNN2PR-3: 96.89%
Sengodan et al.
[49]
2023
LIDC-
IDRI
benign
or
Malignant
RCNN,
En-
semble SVM
Ensemble SVM:
classification
MATLAB, i7, 4
GB GPU
Train-
Validation-
Test Split
ACC: 98.53% ; SEN: 99.30% ;
AUC: 0.98 ; SPE: 98.03%
Guo
et
al.
[132]
2023
LUNA16
benign
or
Malignant
3D SAACNet
+ GBM
SAACNet
+
GBM: extraction
and classification
PyTorch,
4
GTX 2080Ti
ACC: 95.18%; SEN: 97.35%;
AUC: 97.70%; SPE: 90.43%
Sivakumar
et
al. [133]
2024
LUNA16,
Kaggle
DSB
benign
or
Malignant
ADBN,
LightGBM
LightGBM: clas-
sification
TensorFlow,
16GB RAM
ACC: 99.87% ; SEN: 99.75% ;
SPE: 99.42%
Zhang
et
al.
[134]
2021
Internal:
532pts
benign
or
Malignant
3D CNN, SE-
ResNet
3D CNN: NSNs
classification
TensorFlow, TI-
TAN XP
AIS
vs
MIA-IAC:
81.9%
(CNN), 86.4% (CNN + radio)
Harsono et al.
[84]
2022
LIDC-
IDRI;
Moscow
benign
or
Malignant
I3DR-Net
Transfer
learn-
ing:
I3D back-
bone, RetinaNet
PyTorch,
Win-
dows,
Tesla
P100
Public-1:
94.12%, Private-1:
65.90%;
Public-2:
81.84%,
Private-2: 70.36%
Zhang
et
al.
[135]
2022
LIDC-
IDRI
Both
VGG16
Seg: RW; Class:
VGG16 + fused
features
-
single VGG16:
0.930; multi
VGG16:
0.975; multi-feature
VGG16: 0.9681
Cai et al. [136]
2023
LIDC-
IDRI; HB;
XZ
Both
3D
MaskR-
CNN,
ResNet18-3D
Baseline models
fine-tuned
with
local datasets
-
LIDC baseline:
0.846;
HB:
0.813; XZ: 0.696 ; LIDC base-
line: 0.837; HB: 0.849
Gugulothu
et
al. [45]
2024
LIDC-
IDRI
Both
CBSO;
IFB;
HDE-NN
Seg:
CBSO;
Classification:
HDE-NN
Keras,
32 GB
RAM, i5
HDE-NN:
96.39%;
SVM:
91.68%; ELM: 94.57% ; HDE-
NN: 95.25%; SVM: 88.38%
Raza
et
al.
[137]
2023
IQ-OTH /
NCCD
Both
EfficientNetB1
Transfer
learn-
ing:
Efficient-
Net: class
Keras,
Tensor-
Flow; Tesla T4
No
augmentation:
98.64%;
With augmentation: 99.10%
Dodia
et
al.
[138]
2022
LUNA16
Nodule
or
non-nodule
RFR
V-Net;
NCNet
RFR V-Net: seg;
NCNet: clas
Keras;
HPC
setup
NCNet 3D: 98.21%; NCNet 3D:
98.38%; NCNet 3D: 98.33%
Lei et al. [139]
2020
LIDC-
IDRI
benign
or
Malignant
CNN,
SAM,
HESAM
SAM for shape &
margin analysis
PyTorch;
2
GTX 1080 Ti
HESAM:
99.13%;
SAM:
98.25%; CAM: 96.51%
significant strides in both model performance and clinical applicability. In the nodule versus non-nodule classification
task, Savitha et al. [126] used a Deep Convolutional Neural Network (DCNN) combined with Conditional Random
Fields (CRF) to reduce false positives, achieving a mean Intersection over Union (MIoU) of 0.911 and pixel accuracy of
89.48% on the LIDC-IDRI dataset, with precision and recall of 0.95 each. Similarly, Naqi et al. [127] utilized geometric
Cai et al.: Preprint submitted to Elsevier
Page 25 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Table 6: (continued)
Authors
Year
Dataset
Classification
Technique/
Network Type
Main
Method
Software/
Hardware
Utilized
Validation/
Test Method
Model
Performance
Blanc
et
al.
[140]
2020
SFR Data
Challenge
2019
Nodule
or
non-nodule
3D
U-NET;
3D
Retina-
UNET;SVM
SVM: classifica-
tion
IBM
Power
AC922,
Volta
V100 GPU
(95% CI: 84.83% – 91.03%);
AUROC: 0.9058
Fu et al. [37]
2021
LIDC-
CISB
benign
or
Malignant
3D
multi-
classification;
MLP
Mr-Mc and MLP
for
pathological
types
Keras;
Dual
GTX1080ti
(11GB)
Mr-Mc: 0.810; MLP: 0.887;
Fusion: 0.906 ; Mr-Mc: 0.876;
MLP: 0.980; Fusion: 0.950
Amini
et
al.
[141]
2024
LIDC-
IDRI;
SPIE
benign
or
Malignant
FIG method
FIG for classifi-
cation
-
Sub-band D2:
67.11%;
8-
orientation Gabor: 70.22%
Wang
et
al.
[63]
2024
LIDC-
IDRI;
Nanjing
Univ.
benign
or
Malignant
Multi-task
DL;3D
nnU-
Net;
AAG
and SAM
3D
nnU-Net:
seg;
ExPN-Net,
AAG,
SAM:
classification
PyTorch, GPU
5-fold
cross-
validation
LIDC:
95.5%;
In-house:
90.1% ;
LIDC: 100%;
In-
house: 90.9% ; LIDC: 0.992;
In-house: 0.923
Muzammil
et
al. [142]
2021
LUNA16
benign
or
Malignant
DCNN
+
SVM + Ad-
aBoostM2
Fusion: AlexNet,
VGG-16, VGG-
19
MATLAB,
i7-8550U, 8GB
RAM
SVM + deep:
95.59% ±
0.27%; AdaBoostM2 + deep:
95.25%
Wang
et
al.
[143]
2020
LIDC-
IDRI,
LNUTCM
benign
or
Malignant
EOH,
MSPLBP,
NNCS
Seg:EOH,
MSPLBP; DLSR
(Class)
MATLAB,
i7,
8GB RAM
ACC: 95.88% ; AUC: 0.8149
(PR curves)
Wu et al. [144]
2023
LIDC-
IDRI;
CQUCH
benign
or
Malignant
STLF-VA, 3D
CNN
STLF-VA
with
self-supervised
learning
Keras, Ubuntu,
RTX TITAN
ACC: 85.30% ; SEN: 86.80% ;
AUC: 0.9042 ; SPE: 83.90%
Lin et al. [145]
2020
LIDC-
IDRI;
UCLA
Both
RetinaNet,
ResNet
34,
HSCNN
RetinaNet for de-
tection; HSCNN
for classification
PyTorch, Tesla
V100
Diameter, consistency, mar-
gin: 0.59, 0.74, 0.75 ; Mean
AUC for malignancy: 0.89
Zhang
et
al.
[146]
2022
LIDC-
IDRI
Nodule
or
non-nodule
Radiomics;
ML
Various models:
classification
Python,
CPU,
GT 640M
RF + RFE: 0.9580 ; Best clas-
sifier (RF + RFE): 0.9893
Suresh
et
al.
[147]
2022
LIDC-
IDRI
benign
or
Malignant
DCNN
Non-cancerous,
malignant classi-
fication
MATLAB
2018b;
GTX
960, 8 GB
ACC: 97.80% ; SEN: 97.10% ;
AUC: 0.9956 ; SPE: 97.20%
Gupta
et
al.
[148]
2024
LIDC-
IDRI
benign
or
Malignant
SVM;
LDA,
KNN
Feature
extrac-
tion: radiomics
MATLAB
10-fold cross-
validation
ACC: 91.3% ; SEN: 90.0% ;
AUC: 0.96 ; SPE: 92.0%
Zhai
et
al.
[149]
2020
LIDC-
IDRI,
LUNA16
benign
or
Malignant
Multi-task
CNN
(MT-
CNN)
MT-CNN
for
classification and
reconstruction
PyTorch
1.3,
Tesla
V100,
Python 3.7
LUNA-16:
97.3%;
LIDC-
IDRI: 95.59%
Siddiqui et al.
[150]
2023
LIDC,
LUNA16
benign
or
Malignant
DBN, Gabor
Gabor filters with
enhanced DBN
TensorFlow, 16
GB RAM
GF-DBN-SVM:
97.877%;
IGF-EDBN-SVM: 99.424%
fitting combined with deep learning, which reduced false positives to 2.8 with a sensitivity of 95.6%, showcasing
effective false positive control. Pinheiro et al. [71] integrated swarm intelligence algorithms with CNNs to achieve
93.71% accuracy on the LIDC-IDRI dataset, reducing training time by 25%. Wang et al. [128] improved multi-
class nodule detection using 3D texture and edge features, reaching a sensitivity of 95.69% and specificity of 96.95%.
Dodia et al.’s [138] NCNet, combining V-Net and SqueezeNet, further enhanced sensitivity to 98.38% while effectively
managing false positives. These advancements highlight the diverse innovations targeting both high classification
accuracy and the reduction of false positives, enhancing clinical decision-making capabilities.
In the benign versus malignant classification task, several methodologies have also emerged. Lei et al. [139]
utilized SAM and HESAM methods for shape and edge analysis to reduce false positives. Amini et al. [141] leveraged
fuzzy information and texture features, achieving high accuracy, though with slightly lower sensitivity. Suresh et
Cai et al.: Preprint submitted to Elsevier
Page 26 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
al. [147] achieved 97.8% accuracy using a DCNN while managing false positives effectively, and Gupta et al. [148]
demonstrated that SVM models achieved 91.3% accuracy on the LIDC-IDRI dataset. Zhai et al. [149] used a Multi-task
Convolutional Neural Network (MT-CNN) to reach an AUC of 97.3% on the LUNA16 dataset, successfully reducing
false positives. Similarly, Rahouma et al. [39] designed a genetic algorithm to optimize a 3D CNN, achieving 95.977%
accuracy, while Sivakumar et al. [133] demonstrated the potential of optimization algorithms with an accuracy of
99.87%. These studies indicate progress in handling the complexities of benign versus malignant nodule classification,
focusing on balancing sensitivity and false positive control.
For models that combine both nodule versus non-nodule and benign versus malignant classification, innovations
in hybrid and transfer learning techniques have been instrumental. Lin et al. [145] developed EDICNet, integrating
RetinaNet with hierarchical convolutional networks, achieving an AUC of 0.89 for malignant prediction. Cai et al.
[136] enhanced classification performance through localized fine-tuning across multiple datasets, while Gugulothu et
al. [45] combined chaotic bird optimization with an improved fish-swarm algorithm to boost accuracy and sensitivity.
Raza et al. [137] demonstrated the effectiveness of Lung-EffNet, achieving 99.10% accuracy on the IQ-OTH/NCCD
dataset, addressing class imbalance with data augmentation techniques. These innovations highlight the critical role
of advanced optimization and hybrid learning in achieving high accuracy across multiple classification tasks.
Regarding Computational Complexity: Recent studies indicate that improvements in pulmonary nodule classifi-
cation often come with increased computational demands. Chen et al. [130] reported higher complexity for their
DenseNet model despite improved accuracy. Naqi et al. [127] and Dodia et al. [138] both enhanced model sensi-
tivity but at the cost of increased computational burden. Lei et al. [139] similarly found their SAM and HESAM
methods added significant complexity. In contrast, Suresh et al. [147] achieved high accuracy with relatively low
computational overhead, emphasizing efficiency-focused design. These findings suggest that balancing performance
with computational efficiency is key to making AI models viable for clinical use.
Model Adoption and Clinical Implications: The adoption of AI-driven classification models in clinical workflows
requires balancing model performance with computational efficiency. High-performing models like DenseNet, em-
ployed by Chen et al. [130], improve performance but add computational complexity. Similarly, Naqi et al.’s [127]
FODPSO-based method successfully reduced false positives but at the cost of increased computational requirements.
Conversely, Suresh et al. [147] employed a DCNN that maintained high accuracy with lower computational costs,
making it more feasible for clinical integration. These examples illustrate the ongoing challenge of achieving high
accuracy while maintaining computational feasibility, which is essential for broader clinical adoption, particularly in
resource-limited settings.
Future Directions and Clinical Potential: Future research should focus on the development of computation-
ally efficient models suitable for deployment in real-time clinical settings, particularly those with limited resources.
Cai et al.: Preprint submitted to Elsevier
Page 27 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Fig. 11: Timeline of AI-driven advancements in lung cancer detection, segmentation, and classification (2020–2024). Colors
represent application areas: Segmentation + Classification (yellow), Detection + Segmentation (pink), Detection + Classification
(green), Other Applications (orange), Detection (blue), Segmentation (red), and Classification (purple). Each node represents a
key model or method with performance metrics, highlighting major breakthroughs. Superscript numbers next to models indicate
their corresponding references: 1-3 [98, 118, 126], 4-9 [134, 112, 37, 130, 142, 50], 10-16 [147, 138, 120, 119, 84, 59, 137], 17-25
[124, 107, 136, 121, 129, 144, 136, 86, 122], 26-35 [117, 151, 63, 87, 96, 62, 45, 145, 40, 115].
Lightweight models capable of functioning on mobile devices could dramatically improve accessibility to high-quality
diagnostic tools, especially in underserved areas. Moreover, the integration of imaging data with other modalities, such
as genomic and biomarker information, presents a promising direction for enhancing diagnostic precision and provid-
ing a more comprehensive understanding of the patient’s condition. Ultimately, AI-driven classification models have
made significant progress in distinguishing between benign and malignant nodules, enhancing early detection and re-
ducing unnecessary interventions. To fully realize their clinical potential, continued focus on optimizing computational
efficiency, accuracy, and data integration will be key to ensuring these tools benefit diverse healthcare environments.
Through an in-depth analysis of the aforementioned studies on lung cancer detection, segmentation, and classi-
fication, Fig. 11 summarizes and presents the significant advancements made in these areas from 2020 to 2024. It
comprehensively reflects the applications and performance improvements of deep learning models in pulmonary nod-
ule analysis. The figure covers the evolution of single-task models (e.g., DCNN, 3D U-Net) and multi-task fusion
models (e.g., ResNet18-3D, STLF-VA), clearly illustrating the trend of continuous optimization and integration of
these technologies. With the introduction of advanced approaches such as YOLO-MSRF, I3DR-Net, and Wavelet
Cai et al.: Preprint submitted to Elsevier
Page 28 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
U-Net++, AI-driven computer-aided diagnosis (CAD) systems have significantly enhanced detection sensitivity, seg-
mentation precision, and classification accuracy. These systems demonstrate considerable potential, particularly in
multi-task processing and complex network architectures. Notably, these models have achieved breakthroughs not
only in improving early diagnosis and reducing misdiagnosis rates but also in providing robust support for real-world
clinical applications. The developments outlined in Fig. 11 indicate that future trends will focus on multi-modal inte-
gration, automated feature extraction, and improving model generalization, thereby laying a solid technical foundation
for early detection and accurate diagnosis of pulmonary nodules.
6. Challenges and Future Prospects
AI-driven advancements in lung cancer detection, segmentation, and classification have shown significant potential
in improving diagnostic accuracy and efficiency. However, several challenges remain that hinder the full deployment
and adoption of these technologies in clinical settings.
Data. A major challenge lies in the availability and quality of data. Although datasets like LIDC-IDRI and LUNA16
have been instrumental in advancing AI-based models for lung cancer analysis, these datasets are limited in scope and
may not represent the full diversity of clinical cases. Furthermore, high-quality, annotated datasets are essential for
training robust models, yet current datasets often suffer from annotation inconsistencies and a lack of standardization
across institutions. The quality of CT images, including issues such as noise, motion artifacts, and variations in acqui-
sition protocols, further complicates model training. These data challenges limit the generalizability of AI models and
their robustness in real-world applications.
Algorithms. Selecting the appropriate algorithm for different tasks, such as detection, segmentation, and classifi-
cation, remains a complex issue. Deep learning algorithms like CNNs, U-Net, and their variants have demonstrated
strong performance, but they also present challenges in terms of model interpretability and computational cost. Many
models function as "black boxes," making it difficult for clinicians to understand the decision-making process behind
a model’s predictions, potentially limiting clinical adoption. Moreover, there is a need for algorithms that are not only
accurate but also computationally efficient to enable real-time diagnosis in resource-constrained environments.
Tasks. Current lung cancer CAD systems predominantly focus on well-defined tasks such as nodule detection,
segmentation, and binary classification (benign vs. malignant). However, these tasks may not fully capture the com-
plexity of lung cancer diagnosis. More nuanced tasks, such as predicting tumor growth or treatment response, require
further exploration. Additionally, while most models focus on 2D image data from CT scans, there is an increasing
need to integrate 3D data, multi-modal inputs (such as PET-CT), and even temporal data (such as follow-up scans) to
better characterize the progression of lung cancer. This broader scope of tasks will require more sophisticated models
capable of handling diverse and complex data types.
Cai et al.: Preprint submitted to Elsevier
Page 29 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Tools. Although AI models have demonstrated impressive capabilities, there is still a significant gap in provid-
ing accessible tools for non-expert users, such as radiologists and clinicians, who may lack extensive programming
knowledge. The development of user-friendly platforms that integrate classical machine learning and deep learning
algorithms, offering ready-to-use tools for model training, evaluation, and interpretation, is crucial. Such platforms
should allow clinicians to apply advanced AI models without needing to write complex code, thus reducing the time
and technical barriers to AI adoption in clinical practice.
Generalizability and Validation. One of the major hurdles in implementing AI-driven CAD systems in real-world
clinical settings is ensuring that models generalize well across different institutions and populations. Models trained
on a specific dataset may not perform as expected when applied to data from a different hospital or region due to
variations in imaging protocols, equipment, and patient demographics. Rigorous external validation across diverse
datasets is required to address this issue. Additionally, cross-platform compatibility should be emphasized, ensuring
that AI models can be effectively deployed across a range of hardware configurations, from high-performance servers
to mobile devices.
In summary, AI-driven lung cancer diagnosis faces multiple challenges related to data, algorithms, tasks, tools,
and generalizability, requiring reliable solutions to fully harness the potential of these technologies. Future research
directions should focus on the following areas:
1. Building large, diverse datasets: Expanding publicly available datasets with a broader range of imaging modal-
ities (e.g., CT, PET, MRI) and clinical contexts (e.g., early-stage vs. late-stage lung cancer) to improve model
robustness and generalizability.
2. Data augmentation and synthetic data: Leveraging deep learning-based techniques such as GANs, to augment
existing datasets and generate synthetic data, addressing issues of data scarcity and overfitting during model
training.
3. Developing interpretable AI models: Enhancing model transparency by integrating explainability methods,
such as attention mechanisms or post-hoc interpretability tools, to help clinicians better understand AI predic-
tions.
4. Creating efficient algorithms for real-time applications: Designing lightweight, high-performance models
that can be deployed in real-time diagnostic scenarios, particularly in resource-constrained environments such
as rural clinics or mobile devices.
5. Expanding task scope: Incorporating more complex tasks, such as longitudinal tumor tracking and multi-modal
data integration, to provide a more comprehensive diagnostic tool for lung cancer management.
6. Building user-friendly AI platforms: Developing zero-code or low-code platforms that allow clinicians to
easily apply AI models, assess model performance, and generate predictions without requiring programming
Cai et al.: Preprint submitted to Elsevier
Page 30 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
expertise.
7. Enhancing cross-institution generalizability: Promoting external validation and cross-platform compatibility
to ensure that AI models can generalize effectively across different clinical settings and patient populations.
These future directions will be essential in overcoming the current challenges in AI-driven lung cancer diagnosis,
making these technologies more accessible and reliable for clinical applications.
7. Conclusion
Deep learning has revolutionized medical image analysis, particularly in the early detection of lung cancer, where
it surpasses traditional statistical methods in handling complex data. Despite notable advances in pulmonary nodule
detection, segmentation, and classification using CNNs, RNNs, and GANs, challenges such as data scarcity and the in-
terpretability of models remain. The reliance on large, annotated datasets limits the widespread clinical application of
these models, while their "black box" nature raises concerns about transparency in medical decision-making. Future
research should focus on enhancing model interpretability through explainable AI (XAI) techniques and overcom-
ing data limitations with innovative solutions like GAN-based augmentation. Furthermore, integrating multimodal
data—such as genomic and clinical information—into CAD systems and exploring hybrid models that combine deep
learning with traditional machine learning could significantly improve diagnostic accuracy and clinical utility. By ad-
dressing these challenges, deep learning holds immense potential to further transform early lung cancer detection and
patient outcomes. This review aims to provide valuable insights to guide future research in this evolving field.
CRediT authorship contribution statement
Guohui Cai: Conceptualization, Investigation, Methodology, Writing – original draft. Ying Cai: Investigation,
Validation, Writing – original draft. Zeyu Zhang: Writing – original draft. Yuanzhouhan Cao: Methodology, Writ-
ing – review & editing. Lin Wu: Investigation, Methodology. Daji Ergu: Supervision. Zhibin Liao: Investigation,
Methodology. Yang Zhao: Investigation, Supervision.
Declaration of competing interest
The authors declare that they have no known competing financial interests or personal relationships that could have
appeared to influence the work reported in this paper.
Data availability
No data was used for the research described in the article.
Cai et al.: Preprint submitted to Elsevier
Page 31 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
Acknowledgment
This research has been supported by the National Natural Science Foundation of China (Grant No. 72174172) and
the Scientific and Technological Innovation Team for Qinghai-Tibetan Plateau Research at Southwest Minzu University
(Grant No. 2024CXTD20). We sincerely appreciate their valuable support, which made this work possible.
References
[1] Z. Zhang, K. A. Ahmed, M. R. Hasan, T. Gedeon, M. Z. Hossain, A deep learning approach to diabetes diagnosis, in: Asian Conference on
Intelligent Information and Database Systems, Springer, 2024, pp. 87–99.
[2] A. D. Hiwase, C. D. Ovenden, L. M. Kaukas, M. Finnis, Z. Zhang, S. O’Connor, N. Foo, B. Reddi, A. J. Wells, D. Y. Ellis, Can rotational
thromboelastometry rapidly identify theragnostic targets in isolated traumatic brain injury?, Emergency Medicine Australasia (2024).
[3] F. Bray, M. Laversanne, H. Sung, J. Ferlay, R. L. Siegel, I. Soerjomataram, A. Jemal, Global cancer statistics 2022: Globocan estimates of
incidence and mortality worldwide for 36 cancers in 185 countries, CA: a cancer journal for clinicians 74 (3) (2024) 229–263.
[4] H. Jin, C. Yu, Z. Gong, R. Zheng, Y. Zhao, Q. Fu, Machine learning techniques for pulmonary nodule computer-aided diagnosis using ct
images: A systematic review, Biomedical Signal Processing and Control 79 (2023) 104104.
[5] A. Krizhevsky, I. Sutskever, G. E. Hinton, Imagenet classification with deep convolutional neural networks, Advances in neural information
processing systems 25 (2012).
[6] R. V. Kaulgud, A. Patil, Analysis based on machine and deep learning techniques for the accurate detection of lung nodules from ct images,
Biomedical Signal Processing and Control 85 (2023) 105055.
[7] P. Kalkeseetharaman, S. T. George, A bird’s eye view approach on the usage of deep learning methods in lung cancer detection and future
directions using x-ray and ct images, Archives of Computational Methods in Engineering (2024) 1–21.
[8] Y. Zhao, Z. Liao, Y. Liu, K. O. Nijhuis, B. Barvelink, J. Prijs, J. Colaris, M. Wijffels, M. Reijman, Z. Zhang, et al., A landmark-based
approach for instability prediction in distal radius fractures, in: 2024 IEEE International Symposium on Biomedical Imaging (ISBI), IEEE,
2024, pp. 1–5.
[9] J. Ge, Z. Zhang, M. H. Phan, B. Zhang, A. Liu, Y. Zhao, Esa: Annotation-efficient active learning for semantic segmentation, arXiv preprint
arXiv:2408.13491 (2024).
[10] R. E. Bawack, S. Fosso Wamba, K. D. A. Carillo, A framework for understanding artificial intelligence research: insights from practice,
Journal of Enterprise Information Management 34 (2) (2021) 645–678.
[11] C. Cortes, V. Vapnik, Support-vector networks, Machine learning 20 (1995) 273–297.
[12] T. Cover, P. Hart, Nearest neighbor pattern classification, IEEE transactions on information theory 13 (1) (1967) 21–27.
[13] G.-B. Huang, Q.-Y. Zhu, C.-K. Siew, Extreme learning machine: theory and applications, Neurocomputing 70 (1-3) (2006) 489–501.
[14] Y. LeCun, L. Bottou, Y. Bengio, P. Haffner, Gradient-based learning applied to document recognition, Proceedings of the IEEE 86 (11)
(1998) 2278–2324.
[15] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, in: Proceedings of the IEEE conference on computer vision
and pattern recognition, 2016, pp. 770–778.
[16] Z. Zhang, N. Yi, S. Tan, Y. Cai, Y. Yang, L. Xu, Q. Li, Z. Yi, D. Ergu, Y. Zhao, Meddet: Generative adversarial distillation for efficient
cervical disc herniation detection, arXiv preprint arXiv:2409.00204 (2024).
[17] B. Wu, Y. Xie, Z. Zhang, J. Ge, K. Yaxley, S. Bahadir, Q. Wu, Y. Liu, M.-S. To, Bhsd: A 3d multi-class brain hemorrhage segmentation
Cai et al.: Preprint submitted to Elsevier
Page 32 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
dataset, in: International Workshop on Machine Learning in Medical Imaging, Springer, 2023, pp. 147–156.
[18] Z. Zhang, X. Qi, B. Zhang, B. Wu, H. Le, B. Jeong, Z. Liao, Y. Liu, J. Verjans, M.-S. To, et al., Segreg: Segmenting oars by registering mr
images and ct annotations, in: 2024 IEEE International Symposium on Biomedical Imaging (ISBI), IEEE, 2024, pp. 1–5.
[19] Z. Zhang, B. Zhang, A. Hiwase, C. Barras, F. Chen, B. Wu, A. J. Wells, D. Y. Ellis, B. Reddi, A. W. Burgan, M.-S. To, I. Reid, R. Hartley,
Thin-thick adapter: Segmenting thin scans using thick annotations, OpenReview (2023).
[20] W. Zhu, C. Liu, W. Fan, X. Xie, Deeplung: Deep 3d dual path nets for automated pulmonary nodule detection and classification, in: 2018
IEEE winter conference on applications of computer vision (WACV), IEEE, 2018, pp. 673–681.
[21] O. R. Kadhim, H. J. Motlak, K. K. Abdalla, Computer-aided diagnostic system kinds and pulmonary nodule detection efficacy, International
Journal of Electrical and Computer Engineering (IJECE) 12 (5) (2022) 4734–4745.
[22] S. D. Bhatt, H. B. Soni, T. D. Pawar, H. R. Kher, Diagnosis of pulmonary nodules on ct images using yolov4., International Journal of Online
& Biomedical Engineering 18 (5) (2022).
[23] V. A. de Mesquita, P. C. Cortez, A. B. Ribeiro, V. H. C. de Albuquerque, A novel method for lung nodule detection in computed tomography
scans based on boolean equations and vector of filters techniques, Computers and Electrical Engineering 100 (2022) 107911.
[24] K. Suzuki, Y. Otsuka, Y. Nomura, K. K. Kumamaru, R. Kuwatsuru, S. Aoki, Development and validation of a modified three-dimensional
u-net deep-learning model for automated detection of lung nodules on chest ct images from the lung image database consortium and japanese
datasets, Academic Radiology 29 (2022) S11–S17.
[25] A. Karrar, M. S. Mabrouk, M. Abdel Wahed, A. Y. Sayed, Auto diagnostic system for detecting solitary and juxtapleural pulmonary nodules
in computed tomography images using machine learning, Neural Computing and Applications 35 (2) (2023) 1645–1659.
[26] N. Bhaskar, T. S. Ganashree, R. K. Patra, Pulmonary lung nodule detection and classification through image enhancement and deep learning,
International Journal of Biometrics 15 (3-4) (2023) 291–313.
[27] M. Jian, H. Jin, L. Zhang, B. Wei, H. Yu, Dbpndnet: dual-branch networks using 3dcnn toward pulmonary nodule detection, Medical &
Biological Engineering & Computing 62 (2) (2024) 563–573.
[28] D. Zhao, Y. Liu, H. Yin, Z. Wang, An attentive and adaptive 3d cnn for automatic pulmonary nodule detection in ct image, Expert Systems
with Applications 211 (2023) 118672.
[29] Y. Ahmadyar, A. Kamali-Asl, H. Arabi, R. Samimi, H. Zaidi, Hierarchical approach for pulmonary-nodule identification from ct images
using yolo model and a 3d neural network classifier, Radiological physics and technology 17 (1) (2024) 124–134.
[30] L. Ma, G. Li, X. Feng, Q. Fan, L. Liu, Ticnet: Transformer in convolutional neural network for pulmonary nodule detection on ct images,
Journal of Imaging Informatics in Medicine 37 (1) (2024) 196–208.
[31] B. C. Sweetline, C. Vijayakumaran, A. Samydurai, Overcoming the challenge of accurate segmentation of lung nodules: A multi-crop cnn
approach, Journal of Imaging Informatics in Medicine (2024) 1–20.
[32] X. Zhang, L. Pu, L. Wan, X. Wang, Y. Zhou, Ds-msff-net: Dual-path self-attention multi-scale feature fusion network for ct image segmen-
tation, Applied Intelligence 54 (6) (2024) 4490–4506.
[33] R. J. Suji, W. W. Godfrey, J. Dhar, Exploring pretrained encoders for lung nodule segmentation task using lidc-idri dataset, Multimedia Tools
and Applications 83 (4) (2024) 9685–9708.
[34] S. Asiya, N. Sugitha, Automatically segmenting and classifying the lung nodules from ct images, International Journal of Intelligent Systems
and Applications in Engineering 12 (1s) (2024) 271–281.
[35] T. Tang, R. Zhang, K. Lin, F. Li, X. Xia, Sm-rnet: A scale-aware-based multi-attention guided reverse network for pulmonary nodules
segmentation, IEEE Transactions on Instrumentation and Measurement (2023).
Cai et al.: Preprint submitted to Elsevier
Page 33 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
[36] Y. Cai, Z. Liu, Y. Zhang, Z. Yang, Mdfn: A multi-level dynamic fusion network with self-calibrated edge enhancement for lung nodule
segmentation, Biomedical Signal Processing and Control 87 (2024) 105507.
[37] Y. Fu, P. Xue, N. Li, P. Zhao, Z. Xu, H. Ji, Z. Zhang, W. Cui, E. Dong, Fusion of 3d lung ct and serum biomarkers for diagnosis of multiple
pathological types on pulmonary nodules, Computer Methods and Programs in Biomedicine 210 (2021) 106381.
[38] K. Zhan, Y. Wang, Y. Zhuo, Y. Zhan, Q. Yan, F. Shan, L. Zhou, X. Chen, L. Liu, An uncertainty-aware self-training framework with
consistency regularization for the multilabel classification of common computed tomography signs in lung nodules, Quantitative Imaging in
Medicine and Surgery 13 (9) (2023) 5536.
[39] K. H. Rahouma, S. M. Mabrouk, M. Aouf, Automated 3d convolutional neural network architecture design using genetic algorithm for
pulmonary nodule classification, Bulletin of Electrical Engineering and Informatics 13 (3) (2024) 2009–2018.
[40] C.-Y. Lin, S.-M. Guo, J.-J. J. Lien, W.-T. Lin, Y.-S. Liu, C.-H. Lai, I.-L. Hsu, C.-C. Chang, Y.-L. Tseng, Combined model integrating deep
learning, radiomics, and clinical data to classify lung nodules at chest ct, La radiologia medica 129 (1) (2024) 56–69.
[41] Drishti, J. Singh, Novel algorithm for pulmonary nodule classification using cnn on ct scans, International Journal of Intelligent Systems and
Applications in Engineering 12 (2) (2024) 144–152.
[42] D. E. Rumelhart, G. E. Hinton, R. J. Williams, Learning representations by back-propagating errors, nature 323 (6088) (1986) 533–536.
[43] S. Hochreiter, J. Schmidhuber, Long short-term memory, Neural computation 9 (8) (1997) 1735–1780.
[44] S. Balannolla, A. K. Nikhath, S. Yeruva, Detection and classification of lung carcinoma using ct scans, in: Journal of Physics: Conference
Series, Vol. 2286, IOP Publishing, 2022, p. 012011.
[45] V. K. Gugulothu, S. Balaji, An early prediction and classification of lung nodule diagnosis on ct images based on hybrid deep learning
techniques, Multimedia Tools and Applications 83 (1) (2024) 1041–1061.
[46] T.-C. Nguyen, T.-P. Nguyen, T. Cao, T. T. P. Dao, T.-N. Ho, T. V. Nguyen, M.-T. Tran, Manet: Multi-branch attention auxiliary learning for
lung nodule detection and segmentation, Computer Methods and Programs in Biomedicine 241 (2023) 107748.
[47] S. El-Bana, A. Al-Kabbany, M. Sharkas, A two-stage framework for automated malignant pulmonary nodule detection in ct scans, Diagnostics
10 (3) (2020) 131.
[48] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, Y. Bengio, Generative adversarial nets, Advances
in neural information processing systems 27 (2014).
[49] P. Sengodan, K. Srinivasan, R. Pichamuthu, S. Matheswaran, Early detection and classification of malignant lung nodules from ct images:
An optimal ensemble learning, Expert Systems with Applications 229 (2023) 120361.
[50] L. Zhu, H. Zhu, S. Yang, P. Wang, Y. Yu, Hr-mpf: high-resolution representation network with multi-scale progressive fusion for pulmonary
nodule segmentation and classification, EURASIP Journal on Image and Video Processing 2021 (2021) 1–26.
[51] V. K. Gugulothu, S. Balaji, A novel deep learning approach for the detection and classification of lung nodules from ct images, Multimedia
tools and applications 82 (30) (2023) 47611–47634.
[52] H. Zhu, G. Han, Y. Peng, W. Zhang, C. Lin, H. Zhao, Functional-realistic ct image super-resolution for early-stage pulmonary nodule
detection, Future Generation Computer Systems 115 (2021) 475–485.
[53] S. Tyagi, S. N. Talbar, Cse-gan: A 3d conditional generative adversarial network with concurrent squeeze-and-excitation blocks for lung
nodule segmentation, Computers in Biology and Medicine 147 (2022) 105781.
[54] A. Vaswani, Attention is all you need, Advances in Neural Information Processing Systems (2017).
[55] Y. Ji, H. Saratchandran, C. Gordon, Z. Zhang, S. Lucey, Sine activated low-rank matrices for parameter efficient learning, arXiv preprint
arXiv:2403.19243 (2024).
Cai et al.: Preprint submitted to Elsevier
Page 34 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
[56] Z. Zhang, X. Qi, M. Chen, G. Li, R. Pham, A. Qassim, E. Berry, Z. Liao, O. Siggs, R. Mclaughlin, et al., Jointvit: Modeling oxygen saturation
levels with joint supervision on long-tailed octa, in: Annual Conference on Medical Image Understanding and Analysis, Springer, 2024, pp.
158–172.
[57] B. Wu, Y. Xie, Z. Zhang, M. H. Phan, Q. Chen, L. Chen, Q. Wu, Xlip: Cross-modal attention masked modelling for medical language-image
pre-training, arXiv preprint arXiv:2407.19546 (2024).
[58] S. Tan, Z. Zhang, Y. Cai, D. Ergu, L. Wu, B. Hu, P. Yu, Y. Zhao, Segstitch: Multidimensional transformer for robust and efficient medical
imaging segmentation, arXiv preprint arXiv:2408.00496 (2024).
[59] H. Zhang, Y. Peng, Y. Guo, Pulmonary nodules detection based on multi-scale attention networks, Scientific Reports 12 (1) (2022) 1466.
[60] J. Chi, J. Zhao, S. Wang, X. Yu, C. Wu, Lgdnet: local feature coupling global representations network for pulmonary nodules detection,
Medical & Biological Engineering & Computing (2024) 1–14.
[61] H. Yang, Q. Wang, Y. Zhang, Z. An, L. Chen, X. Zhang, S. K. Zhou, Lung nodule segmentation and uncertain region prediction with an
uncertainty-aware attention mechanism, IEEE Transactions on Medical Imaging (2023).
[62] J. Liu, Y. Li, W. Li, Z. Li, Y. Lan, Multiscale lung nodule segmentation based on 3d coordinate attention and edge enhancement, Electronic
Research Archive 32 (5) (2024) 3016–3037.
[63] C. Wang, Y. Liu, F. Wang, C. Zhang, Y. Wang, M. Yuan, G. Yang, Towards reliable and explainable ai model for pulmonary nodule diagnosis,
Biomedical Signal Processing and Control 88 (2024) 105646.
[64] U. Rashid, A. Jaffar, M. Rashid, M. S. Alshuhri, S. Akram, Nodule detection using local binary pattern features to enhance diagnostic
decisions., Computers, Materials & Continua 78 (3) (2024).
[65] G. Cai, Y. Cai, Z. Zhang, D. Ergu, Y. Cao, B. Hu, Z. Liao, Y. Zhao, Msdet: Receptive field enhanced multiscale detection for tiny pulmonary
nodule, arXiv preprint arXiv:2409.14028 (2024).
[66] S. Liu, A. A. A. Setio, F. C. Ghesu, E. Gibson, S. Grbic, B. Georgescu, D. Comaniciu, No surprises: Training robust lung nodule detection
for low-dose ct scans by augmenting with adversarial attacks, IEEE Transactions on Medical Imaging 40 (1) (2020) 335–345.
[67] W. Safta, A. Shaffie, Advancing pulmonary nodule diagnosis by integrating engineered and deep features extracted from ct scans, Algorithms
17 (4) (2024) 161.
[68] P. Gonidakis, A. Sóñora-Mengana, B. Jansen, J. Vandemeulebroucke, Handcrafted features can boost performance and data-efficiency for
deep detection of lung nodules from ct imaging, IEEE Access 11 (2023) 126221–126231.
[69] Q. Mao, S. Zhao, D. Tong, S. Su, Z. Li, X. Cheng, Hessian-mrlog: Hessian information and multi-scale reverse log filter for pulmonary
nodule detection, Computers in Biology and Medicine 131 (2021) 104272.
[70] M. Usman, A. Rehman, A. Shahid, S. Latif, Y.-G. Shin, Meds-net: Multi-encoder based self-distilled network with bidirectional maximum
intensity projections fusion for lung nodule detection, Engineering Applications of Artificial Intelligence 129 (2024) 107597.
[71] C. A. de Pinho Pinheiro, N. Nedjah, L. de Macedo Mourelle, Detection and classification of pulmonary nodules using deep learning and
swarm intelligence, Multimedia Tools and Applications 79 (21) (2020) 15437–15465.
[72] A. Gu, T. Dao, Mamba: Linear-time sequence modeling with selective state spaces, arXiv preprint arXiv:2312.00752 (2023).
[73] T. Dao, A. Gu, Transformers are ssms: Generalized models and efficient algorithms through structured state space duality, arXiv preprint
arXiv:2405.21060 (2024).
[74] Z. Zhang, A. Liu, I. Reid, R. Hartley, B. Zhuang, H. Tang, Motion mamba: Efficient and long sequence motion generation with hierarchical
and bidirectional selective ssm, arXiv preprint arXiv:2403.07487 (2024).
[75] Z. Zhang, A. Liu, Q. Chen, F. Chen, I. Reid, R. Hartley, B. Zhuang, H. Tang, Infinimotion: Mamba boosts memory in transformer for
Cai et al.: Preprint submitted to Elsevier
Page 35 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
arbitrary long motion generation, arXiv preprint arXiv:2407.10061 (2024).
[76] C. Bian, N. Xia, X. Yang, F. Wang, F. Wang, B. Wei, Q. Dong, Mambaclinix: Hierarchical gated convolution and mamba-based u-net for
enhanced 3d medical image segmentation, arXiv preprint arXiv:2409.12533 (2024).
[77] M. Zhang, Y. Yu, S. Jin, L. Gu, T. Ling, X. Tao, Vm-unet-v2: rethinking vision mamba unet for medical image segmentation, in: International
Symposium on Bioinformatics Research and Applications, Springer, 2024, pp. 335–346.
[78] S. G. Armato III, G. McLennan, L. Bidaut, M. F. McNitt-Gray, C. R. Meyer, A. P. Reeves, B. Zhao, D. R. Aberle, C. I. Henschke, E. A.
Hoffman, et al., The lung image database consortium (lidc) and image database resource initiative (idri): a completed reference database of
lung nodules on ct scans, Medical physics 38 (2) (2011) 915–931.
[79] A. A. A. Setio, A. Traverso, T. De Bel, M. S. Berens, C. Van Den Bogaard, P. Cerello, H. Chen, Q. Dou, M. E. Fantacci, B. Geurts, et al.,
Validation, comparison, and combination of algorithms for automatic detection of pulmonary nodules in computed tomography images: the
luna16 challenge, Medical image analysis 42 (2017) 1–13.
[80] C. I. Henschke, D. I. McCauley, D. F. Yankelevitz, D. P. Naidich, G. McGuinness, O. S. Miettinen, D. Libby, M. Pasmantier, J. Koizumi,
N. Altorki, et al., Early lung cancer action project: a summary of the findings on baseline screening, The oncologist 6 (2) (2001) 147–152.
[81] H. J. Aerts, E. R. Velazquez, R. T. Leijenaar, C. Parmar, P. Grossmann, S. Carvalho, J. Bussink, R. Monshouwer, B. Haibe-Kains, D. Rietveld,
et al., Decoding tumour phenotype by noninvasive imaging using a quantitative radiomics approach, Nature communications 5 (1) (2014)
4006.
[82] B. Van Ginneken, S. G. Armato III, B. de Hoop, S. van Amelsvoort-van de Vorst, T. Duindam, M. Niemeijer, K. Murphy, A. Schilham,
A. Retico, M. E. Fantacci, et al., Comparing and combining algorithms for computer-aided detection of pulmonary nodules in computed
tomography scans: the anode09 study, Medical image analysis 14 (6) (2010) 707–722.
[83] B. K. Veronica, An effective neural network model for lung nodule detection in ct images with optimal fuzzy model, Multimedia Tools and
Applications 79 (19) (2020) 14291–14311.
[84] I. W. Harsono, S. Liawatimena, T. W. Cenggoro, Lung nodule detection and classification from thorax ct-scan using retinanet with transfer
learning, Journal of King Saud University-Computer and Information Sciences 34 (3) (2022) 567–577.
[85] S. S. Nair, D. V. M. Devi, D. S. Bhasi, Prediction and classification of ct images for early detection of lung cancer using various segmentation
models, IJEER 10 (4) (2022) 1027–1035.
[86] S. Jain, P. Choudhari, M. Gour, Pulmonary lung nodule detection from computed tomography images using two-stage convolutional neural
network, The Computer Journal 66 (4) (2023) 785–795.
[87] S. A. Agnes, A. A. Solomon, K. Karthick, Wavelet u-net++ for accurate lung nodule segmentation in ct scans: Improving early detection
and diagnosis of lung cancer, Biomedical Signal Processing and Control 87 (2024) 105509.
[88] N. Gautam, A. Basu, R. Sarkar, Lung cancer detection from thoracic ct scans using an ensemble of deep learning models, Neural Computing
and Applications 36 (5) (2024) 2459–2477.
[89] A. Halder, S. Chatterjee, D. Dey, S. Kole, S. Munshi, An adaptive morphology based segmentation technique for lung nodule detection in
thoracic ct image, Computer Methods and Programs in Biomedicine 197 (2020) 105720.
[90] M. Masud, G. Muhammad, M. S. Hossain, H. Alhumyani, S. S. Alshamrani, O. Cheikhrouhou, S. Ibrahim, Light deep model for pulmonary
nodule detection from ct scan images for mobile devices, Wireless Communications and Mobile Computing 2020 (1) (2020) 8893494.
[91] M. M. Farhangi, B. Sahiner, N. Petrick, A. Pezeshk, Automatic lung nodule detection in thoracic ct scans using dilated slice-wise convolutions,
Medical Physics 48 (7) (2021) 3741–3751.
[92] S. Zheng, L. J. Cornelissen, X. Cui, X. Jing, R. N. Veldhuis, M. Oudkerk, P. M. van Ooijen, Deep convolutional neural networks for multi-
Cai et al.: Preprint submitted to Elsevier
Page 36 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
planar lung nodule detection: Improvement in small nodule identification, Medical physics 48 (2) (2021) 733–744.
[93] Y. Chen, X. Hou, Y. Yang, Q. Ge, Y. Zhou, S. Nie, A novel deep learning model based on multi-scale and multi-view for detection of
pulmonary nodules, Journal of Digital Imaging 36 (2) (2023) 688–699.
[94] R. Majidpourkhoei, M. Alilou, K. Majidzadeh, A. Babazadehsangar, A novel deep learning framework for lung nodule detection in 3d ct
images, Multimedia Tools and Applications 80 (20) (2021) 30539–30555.
[95] S.-C. Hung, Y.-T. Wang, M.-H. Tseng, An interpretable three-dimensional artificial intelligence model for computer-aided diagnosis of lung
nodules in computed tomography images, Cancers 15 (18) (2023) 4655.
[96] X. Wu, H. Zhang, J. Sun, S. Wang, Y. Zhang, Yolo-msrf for lung nodule detection, Biomedical Signal Processing and Control 94 (2024)
106318.
[97] L. Cai, T. Long, Y. Dai, Y. Huang, Mask r-cnn-based detection and segmentation for pulmonary nodule 3d visualization diagnosis, Ieee
Access 8 (2020) 44400–44409.
[98] T. Song, J. Chen, X. Luo, Y. Huang, X. Liu, N. Huang, Y. Chen, Z. Ye, H. Sheng, S. Zhang, et al., Cpm-net: A 3d center-points matching
network for pulmonary nodule detection in ct scans, in: International Conference on Medical Image Computing and Computer-Assisted
Intervention, Springer, 2020, pp. 550–559.
[99] H. Yuan, Z. Fan, Y. Wu, J. Cheng, An efficient multi-path 3d convolutional neural network for false-positive reduction of pulmonary nodule
detection, International journal of computer assisted radiology and surgery 16 (12) (2021) 2269–2277.
[100] S. A. Agnes, J. Anitha, A. A. Solomon, Two-stage lung nodule detection framework using enhanced unet and convolutional lstm networks
in ct images, Computers in Biology and Medicine 149 (2022) 106059.
[101] Y. Zhao, Z. Wang, X. Liu, Q. Chen, C. Li, H. Zhao, Z. Wang, Pulmonary nodule detection based on multiscale feature fusion, Computational
And Mathematical Methods In Medicine 2022 (1) (2022) 8903037.
[102] W. Hendrix, N. Hendrix, E. T. Scholten, M. Mourits, J. Trap-de Jong, S. Schalekamp, M. Korst, M. van Leuken, B. van Ginneken, M. Prokop,
et al., Deep learning for the detection of benign and malignant pulmonary nodules in non-screening chest ct scans, Communications Medicine
3 (1) (2023) 156.
[103] J. Zhang, W. Zou, N. Hu, B. Zhang, J. Wang, S-net: an s-shaped network for nodule detection in 3d ct images, Physics in Medicine & Biology
69 (7) (2024) 075013.
[104] M. Budati, R. Karumuri, An intelligent lung nodule segmentation framework for early detection of lung cancer using an optimized deep
neural system, Multimedia Tools and Applications 83 (12) (2024) 34153–34174.
[105] H. Cao, H. Liu, E. Song, G. Ma, X. Xu, R. Jin, T. Liu, C.-C. Hung, A two-stage convolutional neural networks for lung nodule detection,
IEEE journal of biomedical and health informatics 24 (7) (2020) 2006–2015.
[106] L. Shi, H. Ma, J. Zhang, Automatic detection of pulmonary nodules in ct images based on 3d res-i network, The Visual Computer 37 (2021)
1343–1356.
[107] H. Zhang, H. Zhang, Lungseek: 3d selective kernel residual network for pulmonary nodule diagnosis, The Visual Computer 39 (2) (2023)
679–692.
[108] Z. Gao, Y. Guo, G. Wang, X. Chen, X. Cao, C. Zhang, S. An, F. Xu, Robust deep learning from incomplete annotation for accurate lung
nodule detection, Computers in Biology and Medicine 173 (2024) 108361.
[109] C.-Y. Lin, S.-M. Guo, J.-J. J. Lien, T.-Y. Tsai, Y.-S. Liu, C.-H. Lai, I.-L. Hsu, C.-C. Chang, Y.-L. Tseng, Development of a modified 3d region
proposal network for lung nodule detection in computed tomography scans: a secondary analysis of lung nodule datasets, Cancer Imaging
24 (1) (2024) 40.
Cai et al.: Preprint submitted to Elsevier
Page 37 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
[110] P. Dutande, U. Baid, S. Talbar, Lncds: A 2d-3d cascaded cnn approach for lung nodule classification, detection and segmentation, Biomedical
signal processing and control 67 (2021) 102527.
[111] D. D. Kadia, M. Z. Alom, R. Burada, T. V. Nguyen, V. K. Asari, R 2 u3d: Recurrent residual 3d u-net for lung segmentation, Ieee Access 9
(2021) 88835–88843.
[112] M. Osadebey, H. K. Andersen, D. Waaler, K. Fossaa, A. C. Martinsen, M. Pedersen, Three-stage segmentation of lung region from ct images
using deep neural networks, BMC Medical Imaging 21 (2021) 1–19.
[113] T.-W. Tang, W.-Y. Lin, J.-D. Liang, K.-M. Li, Artificial intelligence aided diagnosis of pulmonary nodules segmentation and feature extrac-
tion, Clinical Radiology 78 (6) (2023) 437–443.
[114] Y. Luo, M. Cao, X. Chang, Pulmonary nodule segmentation network based on res select kernel contextual u-net, Journal of Engineering and
Science in Medical Diagnostics and Therapy 7 (4) (2024) 041004.
[115] R. Bbosa, H. Gui, F. Luo, F. Liu, K. Efio-Akolly, Y.-P. P. Chen, Mrunet-3d: A multi-stride residual 3d unet for lung nodule segmentation,
Methods 226 (2024) 89–101.
[116] J. Qiu, B. Li, R. Liao, H. Mo, L. Tian, A dual-task region-boundary aware neural network for accurate pulmonary nodule segmentation,
Journal of Visual Communication and Image Representation 96 (2023) 103909.
[117] C. Thangavel, J. Palanichamy, Effective deep learning approach for segmentation of pulmonary cancer in thoracic ct image, Biomedical
Signal Processing and Control 89 (2024) 105804.
[118] Y. Chen, Y. Wang, F. Hu, D. Wang, A lung dense deep convolution neural network for robust lung parenchyma segmentation, IEEE Access
8 (2020) 93527–93547.
[119] Y. Ni, Z. Xie, D. Zheng, Y. Yang, W. Wang, Two-stage multitask u-net construction for pulmonary nodule segmentation and malignancy risk
prediction, Quantitative Imaging in Medicine and Surgery 12 (1) (2022) 292.
[120] G. Zhang, Z. Yang, S. Jiang, Automatic lung tumor segmentation from ct images using improved 3d densely connected unet, Medical &
Biological Engineering & Computing 60 (11) (2022) 3311–3323.
[121] M. Usman, A. Rehman, A. Shahid, S. Latif, S. S. Byon, S. H. Kim, T. M. Khan, Y. G. Shin, Mesaha-net: Multi-encoders based self-adaptive
hard attention network with maximum intensity projections for lung nodule segmentation in ct scan, arXiv preprint arXiv:2304.01576 (2023).
[122] B. Youssef, A. Alksas, A. Shalaby, A. Mahmoud, E. Van Bogaert, N. S. Alghamdi, A. Neubacher, S. Contractor, M. Ghazal, A. ElMaghraby,
et al., Integrated deep learning and stochastic models for accurate segmentation of lung nodules from computed tomography images: a novel
framework, IEEE Access (2023).
[123] A. Khanna, N. D. Londhe, S. Gupta, A. Semwal, A deep residual u-net convolutional neural network for automated lung segmentation in
computed tomography images, Biocybernetics and Biomedical Engineering 40 (3) (2020) 1314–1327.
[124] D. Bhattacharyya, N. Thirupathi Rao, E. S. N. Joshua, Y.-C. Hu, A bi-directional deep learning architecture for lung nodule semantic seg-
mentation, The Visual Computer 39 (11) (2023) 5245–5261.
[125] X. Ma, H. Song, X. Jia, Z. Wang, An improved v-net lung nodule segmentation model based on pixel threshold separation and attention
mechanism, Scientific Reports 14 (1) (2024) 4743.
[126] G. Savitha, P. Jidesh, A holistic deep learning approach for identification and classification of sub-solid lung nodules in computed tomographic
scans, Computers & Electrical Engineering 84 (2020) 106626.
[127] S. M. Naqi, M. Sharif, A. Jaffar, Lung nodule detection and classification based on geometric fit in parametric form and deep learning, Neural
Computing and Applications 32 (9) (2020) 4629–4647.
[128] B. Wang, S. Si, H. Zhao, H. Zhu, S. Dou, False positive reduction in pulmonary nodule classification using 3d texture and edge feature in ct
Cai et al.: Preprint submitted to Elsevier
Page 38 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
images, Technology and Health Care 29 (6) (2021) 1071–1088.
[129] H. Naveen, C. Naveena, M. A. VN, An approach for classification of lung nodules, Tumor Discovery 2 (1) (2023) 317–317.
[130] Y. Chen, Y. Wang, F. Hu, L. Feng, T. Zhou, C. Zheng, Ldnnet: towards robust classification of lung nodule and cancer using lung dense
neural network, IEEE Access 9 (2021) 50301–50320.
[131] A. Halder, D. Dey, Atrous convolution aided integrated framework for lung nodule segmentation and classification, Biomedical Signal
Processing and Control 82 (2023) 104527.
[132] Z. Guo, J. Yang, L. Zhao, J. Yuan, H. Yu, 3d saacnet with gbm for the classification of benign and malignant lung nodules, Computers in
Biology and Medicine 153 (2023) 106532.
[133] M. Sivakumar, S. Chinnasamy, M. Thanabal, An efficient combined intelligent system for segmentation and classification of lung cancer
computed tomography images, PeerJ Computer Science 10 (2024) e1802.
[134] T. Zhang, Y. Wang, Y. Sun, M. Yuan, Y. Zhong, H. Li, T. Yu, J. Wang, High-resolution ct image analysis based on 3d convolutional
neural network can enhance the classification performance of radiologists in classifying pulmonary non-solid nodules, European Journal of
Radiology 141 (2021) 109810.
[135] Y. Zhang, L. Meng, Study on identification method of pulmonary nodules: Improved random walk pulmonary parenchyma segmentation
and fusion multi-feature vgg16 nodule classification, Frontiers in Oncology 12 (2022) 822827.
[136] J. Cai, L. Guo, L. Zhu, L. Xia, L. Qian, Y.-M. F. Lure, X. Yin, Impact of localized fine tuning in the performance of segmentation and
classification of lung nodules from computed tomography scans using deep learning, Frontiers in Oncology 13 (2023) 1140635.
[137] R. Raza, F. Zulfiqar, M. O. Khan, M. Arif, A. Alvi, M. A. Iftikhar, T. Alam, Lung-effnet: Lung cancer classification using efficientnet from
ct-scan images, Engineering Applications of Artificial Intelligence 126 (2023) 106902.
[138] S. Dodia, A. Basava, M. Padukudru Anand, A novel receptive field-regularized v-net and nodule classification network for lung nodule
detection, International Journal of Imaging Systems and Technology 32 (1) (2022) 88–101.
[139] Y. Lei, Y. Tian, H. Shan, J. Zhang, G. Wang, M. K. Kalra, Shape and margin-aware lung nodule classification in low-dose ct images via soft
activation mapping, Medical Image Analysis 60 (2020) 101628.
[140] D. Blanc, V. Racine, A. Khalil, M. Deloche, J.-A. Broyelle, I. Hammouamri, E. Sinitambirivoutin, M. Fiammante, E. Verdier, T. Besson,
et al., Artificial intelligence solution to classify pulmonary nodules on ct, Diagnostic and Interventional Imaging 101 (12) (2020) 803–810.
[141] F. Amini, R. Amjadifard, A. Mansouri, Fuzzy information granulation towards benign and malignant lung nodules classification, Computer
Methods and Programs in Biomedicine Update 5 (2024) 100153.
[142] M. Muzammil, I. Ali, I. U. Haq, M. Amir, S. Abdullah, Pulmonary nodule classification using feature and ensemble learning-based fusion
techniques, IEEE Access 9 (2021) 113415–113427.
[143] B. Wang, S. Si, E. Cui, H. Zhao, D. Yang, S. Dou, J. Zhu, A fast and efficient cad system for improving the performance of malignancy level
classification on lung nodules, IEEE Access 8 (2020) 40151–40170.
[144] R. Wu, C. Liang, Y. Li, X. Shi, J. Zhang, H. Huang, Self-supervised transfer learning framework driven by visual attention for benign–
malignant lung nodule classification on chest ct, Expert Systems with Applications 215 (2023) 119339.
[145] Y. Lin, L. Wei, S. X. Han, D. R. Aberle, W. Hsu, Edicnet: An end-to-end detection and interpretable malignancy classification network for
pulmonary nodules in computed tomography, in: Medical Imaging 2020: Computer-Aided Diagnosis, Vol. 11314, SPIE, 2020, pp. 344–355.
[146] X. Zhang, B. Zhang, X. Liu, J. Dong, S. Zhao, S. Li, Accurate classification of nodules and non-nodules from computed tomography images
based on radiomics and machine learning algorithms, International Journal of Imaging Systems and Technology 32 (3) (2022) 956–968.
[147] S. Suresh, S. Mohan, Nroi based feature learning for automated tumor stage classification of pulmonary lung nodules using deep convolutional
Cai et al.: Preprint submitted to Elsevier
Page 39 of 40
Medical AI for Early Detection of Lung Cancer: A Survey
neural networks, Journal of King Saud University-Computer and Information Sciences 34 (5) (2022) 1706–1717.
[148] H. Gupta, H. Singh, A. Kumar, Texture and radiomics inspired data-driven cancerous lung nodules severity classification, Biomedical Signal
Processing and Control 88 (2024) 105543.
[149] P. Zhai, Y. Tao, H. Chen, T. Cai, J. Li, Multi-task learning for lung nodule classification on chest ct, IEEE access 8 (2020) 180317–180327.
[150] E. A. Siddiqui, V. Chaurasia, M. Shandilya, Detection and classification of lung cancer computed tomography images using a novel improved
deep belief network with gabor filters, Chemometrics and Intelligent Laboratory Systems 235 (2023) 104763.
[151] S. U. Atiya, N. Ramesh, B. N. K. Reddy, Classification of non-small cell lung cancers using deep convolutional neural networks, Multimedia
Tools and Applications 83 (5) (2024) 13261–13290.
Cai et al.: Preprint submitted to Elsevier
Page 40 of 40
