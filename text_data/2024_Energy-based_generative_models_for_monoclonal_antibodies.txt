Energy-based generative models for monoclonal antibodies
Paul Pereira,1, 2 Herve Minoux,2 Aleksandra M. Walczak,1, ∗and Thierry Mora1, ∗
1Laboratoire de physique de l’´Ecole normale sup´erieure, CNRS, PSL University,
Sorbonne Universit´e, and Universit´e de Paris, 75005 Paris, France
2Sanofi Vitry-sur-Seine, France
Since the approval of the first antibody drug in 1986, a total of 162 antibodies have been approved
for a wide range of therapeutic areas, including cancer, autoimmune, infectious, or cardiovascular
diseases. Despite advances in biotechnology that accelerated the development of antibody drugs,
the drug discovery process for this modality remains lengthy and costly, requiring multiple rounds
of optimizations before a drug candidate can progress to preclinical and clinical trials. This multi-
optimization problem involves increasing the affinity of the antibody to the target antigen while
refining additional biophysical properties that are essential to drug development such as solubility,
thermostability or aggregation propensity. Additionally, antibodies that resemble natural human
antibodies are particularly desirable, as they are likely to offer improved profiles in terms of safety,
efficacy, and reduced immunogenicity, further supporting their therapeutic potential. In this article,
we explore the use of energy-based generative models to optimize a candidate monoclonal antibody.
We identify tradeoffs when optimizing for multiple properties, concentrating on solubility, humanness
and affinity and use the generative model we develop to generate candidate antibodies that lie on
an optimal Pareto front that satisfies these constraints.
I.
INTRODUCTION
Monoclonal antibodies are an important type of bio-
logical drug, with 162 therapeutic antibodies currently
approved used to treat a variety of diseases for differ-
ent therapeutic areas such as cancer or inflammation.
Their development however is costly, time consuming and
prone to failure. Antibodies are Y-shaped proteins that
specifically bind to an antigen. The number of possible
antibodies that can be designed is too large to search ex-
haustively when trying to find an antibody that will bind
sufficiently strongly to a target antigen. In addition to
affinity, there are a number of other desirable properties
that the candidate antibody must have in order to func-
tion properly as a drug. For example, it is desirable for
the antibody not to have exposed hydrophobic patches
that could cause aggregation issues and to be soluble.
The antigenicity of the candidate antibody must also be
as low as possible in order to avoid an immune reaction
in the patient. These constraints further reduce the num-
ber of drug candidates and must be taken into account
as early as possible in the development process.
We focus on the development of energy-based gener-
ative models for monoclonal antibodies. Our work falls
within a broad range of methods utilizing wet-lab experi-
ments and machine learning models to optimize antibod-
ies for drug development.
In-vitro assays can be used
today to characterize antibodies and filter-out ones with
poor affinity to the target antigen or poor developability
properties [1]. The development of high-throughput as-
says has made it possible to characterize large numbers
of sequences in batches. Methods like phage or yeast dis-
play [2, 3] can be used to identify a few antibodies that
∗Corresponding authors. These authors contributed equally.
bind to a target antigen out of a large library of diverse
antibodies, or to optimize such candidates by comparing
many different mutants of the same wild type sequence
[4]. However, high throughput methods tend to provide
less accurate information than lower-throughput meth-
ods such as surface plasmon resonance [5] and can still
take a long time to run compared to in-silico methods.
Machine learning models can been trained on the data
generated by these wet-lab experiments [6]. These mod-
els can then be used to evaluate the properties of large
libraries of antibodies in order to filter-out poor drug can-
didates and reduce the list of candidates to be tested us-
ing wet-lab experiments. This process may lowers the ex-
perimental cost, allowing for the use of lower-throughput
methods when possible. For example Ref. [7] used affin-
ity information about 1 × 104 variants of the clinical an-
tibody trastuzumab binding to Her2 to train a machine
learning model that was then used to predict the affin-
ity of 1 × 108 trastuzumab variants and to identify top
binders. The top predicted binders were further tested
using in-silico models for viscosity, clearance, solubility
and immunogenicity to end up with a few thousands
highly optimized antibodies.
While this approach has
demonstrated its efficacy, its success relies on optimal
candidates being already presents in the library of can-
didates. This is not guaranteed and depends on the way
the library is designed.
Alternatively, generative algorithms directly generate
optimized candidate antibodies. Biswas et al [8] success-
fully combined a predictive model for the fluorescence
of green fluorescent proteins and energy based sampling
methods to generate new amino sequences of GFP from
Aequorea victoria with increased fluorescence.
Jain et
al [9] demonstrated the ability of autoregressive mod-
els to learn to generate amino acid sequences optimized
with respect to the output of a proxy predictive model
for 3 different tasks (anti-microbial peptide, TFBind 8
arXiv:2411.13390v1  [q-bio.BM]  20 Nov 2024
2
and GFP). More recently Bennet et al [10] demonstrated
the ability of their structure generative method to design
de-novo single domain VHH that bind to target antigens
for which the epitope is specified.
We develop and analyze a method for single round op-
timization of monoclonal antibodies.
We start from a
wild type (WT) sequence of the variable part of an an-
tibody that binds to a target antigen. While this WT
antibody is functional (i.e. binds to the target antigen),
we want to improve some of its properties: further in-
crease its affinity to the target antigen or increase its
solubility. Furthermore, we want to improve these prop-
erties by performing a small number of mutations, in or-
der to prevent the loss of functionality. Finally, in order
to decrease the antigenicity of the antibody, we aim to
generate antibodies that are as human-like as possible.
In short, we explore the tradeoffs generative models need
to consider to produce candidate antibodies that satisfy
properties needed in practical antibody discovery: solu-
bility, lack of antigenicity and strong affinity.
II.
RESULTS
A.
Multiple objective optimization
Each antibody is made of 2 copies of a heterodimer
each composed of a heavy chain and a light chain. The
variable regions of the antibodies contain the complemen-
tarity determining regions (CDR), flexible loop struc-
tures that make up a large part of the paratopes (the sec-
tion of the antibody that is in contact with the antigen).
The heavy chain and light chain each contain 3 CDR re-
gions: CDRH1, CDRH2 and CDRH3 for the heavy chain
and CDRL1, CDRL2 and CDRL3 for the light chain. In
this work, we will restrict the optimization to the heavy
chain sequence for simplicity although our method can
easily be modified to include the light chain.
We use a multiple objective optimization approach.
We consider a set of biophysical properties fp(x), as-
sumed to be a function of the antibody sequence x, which
we wish to maximize all at once. We expect trade-offs
to emerge since optimizing some properties may come at
the cost of others. We look for Pareto optimal solutions,
defined as sequences which cannot be improved in any
property without being degraded in another one. Com-
binations of biophysical properties achieved by Pareto-
optimal sequences form the Pareto front.
We do not have access to the functions fp directly for
arbitrary sequences x. Instead, we will exploit predictive
machine learning models ˆfp trained on large datasets to
generate sequences that are close to the Pareto front. We
are interested in the single-round setting: we assume that
once our generative method has selected candidates for
us to test, we will be able to validate those candidates
using wet-lab experiments only once, with a fixed bud-
get of B sequences to be tested. Since we do not expect
the models ˆfp to perfectly reproduce the desired proper-
ties, we wish to generate a diverse set of B candidates
to maximize the probability that at least one them will
pass validation. We further require that these sequences
be different from the ones included in the datasets used
to train the models.
In the following, we will focus on two main biophysical
properties: solubility (sol) and affinity (aff). Our gen-
erative process incorporates the humanness of sequences
through the distribution of natural antibodies pHUM(x),
as given by an auto-regressive transformer previously
trained on 558 million human heavy chain sequences from
the OAS database [11] [12]. We define p(x) for our gen-
erative model to be as close as possible to pHUM (as mea-
sured by the Kullback-Leibler divergence) while maxi-
mizing the mean values of fsol and faff. This gives us the
explicit expression:
p(x) = 1
Z pHUM(x)e−E(x)/T
(1)
E(x) = −w ˆfaff(x) −(1 −w) ˆfsol(x),
(2)
where Z is a normalization, T may be interpreted as a
temperature controling to cloneness to the Pareto front,
and 0 ≤w ≤1 is a weight controling the importance of
affinity versus solubility in the optimization.
We then use two energy-based generative methods to
sample new heavy chain sequences from p(x) (Figure 1):
Metropolis Hastings (MCMC) and the amortized Monte
Carlo method GFlowNet [13, 14]. GFlowNet has been
shown to generate a better and more diverse set of amino
acid sequences on multiple tasks such as generating new
anti-microbial peptides [9]. Details of these procedures
are given in the Methods section.
Below we apply this approach to generate optimized
binders to a HR2 region of the SARS-CoV-2 spike protein
peptide (CB-119) whose amino acid sequence is PDVDL-
GDISGINAS.
B.
Affinity model
Antibody-antigen affinity is often defined in terms of
the dissociation constant (Kd) between an antibody and
its antigen.
High affinity means low Kd, so we define
faff = log(1 nM/Kd). In order to train our affinity pre-
diction model, we use the dataset from Engelhart and al.
[15]. A library of variants was built by first identifying
a pair of heavy and light chain that produce an anti-
body (Ab-14) that binds to CB-119. The heavy chain
of Ab-14 has 33 CDR amino acids that were modified to
generate 22000 mutants: 594 single mutants were gener-
ated by doing a saturated deep mutational scan over the
CDRH1, CDRH2 and CDRH3. In addition 3,671 dou-
ble mutants and 22,188 triple mutants were generated
by performing random substitutions in the CDRs. The
affinity of each sequence was measured 3 times using the
AlphaSeq assay to compute their Kd with respect to the
CB-119 SARS-CoV-2 peptide. Of the 26453 sequences,
3
A
B
C
FIG. 1: Overview of the generative process. A. Our generative model generates the heavy chain sequence of an antibody
undergoing lead optimization. The goal is to find a small number of mutations in the CDRs to improve affinity and solubility.
B. For humaness, our predictive model is IGLM, an autoregressive transformer which outputs a log probability estimate of the
input heavy chain being human. For solubility we use a convolutional neural network that estimates the per-residue SASA
and combines these estimates with hydrophobicity weights. For the affinity we use a Gaussian Process in combination with a
protein language model encoder. C Energy based sampling is used to generate mutants of the wild-type sequence with up to
dlim mutations. The closest sequences to the pareto front are selected for wet-lab validation
only 13921 sequences had affinity measurements. We ap-
proximate their true Kd as the average over replicates
and removed the sequences for which there are no mea-
surements.
For our affinity prediction method, we use a Gaus-
sian Process. The Gaussian process assumes that out-
puts (affinities) are drawn from a multivariate Gaussian
distribution whose covariance between two outputs de-
pends on the distance between their input sequences x,
and uses Gaussian integration rules to predict the poste-
rior for the affinity of any sequence x as a function of the
training data:
faff(x) ∼N(µaff(x; D), σ2
aff(x; D)),
(3)
where D = (xi, faff(xi))i is the training dataset.
We define multiple models using different embeddings
for the amino acid sequences and used a Radial Basis
Function (RBF) as our kernel function (see Methods).
The parameters of the kernel function (δ and λ) are
fitted by minimizing the marginal likelihood loss function
(see Eq. 14) for 600 steps using a learning rate of 10−3
(see Methods for details). We utilized the gpytorch [16]
framework to implement the Gaussian Process and fit the
parameters.
To score sequences, we define 4 different versions of the
affinity function to be used in the multiple objective opti-
mization: ˆfaff(x; β) = µ(x) + βσ(x), with β = −1, 0, 1, 2.
When β is positive we get back the Upper Confidence
Bound (UCB) acquisition function [17] which gives pri-
ority to sequences with high uncertainty and encourages
exploration of the sequence space. When β is negative,
we obtain the Lower Confidence Bound (LCB) acquisi-
tion function, a pessimistic estimate of the affinity of the
sequence. Using LCB encourages the model to generate
sequences close to the ones in the training set
We split the dataset into a training and a validation
set. We refer to the training set as the set of sequences
that are used to fit the parameters of the kernel function
and to make a prediction. In order to test the ability
of the Gaussian process to correctly predict the affinity
to CB-119, we first built a training set of 80% of D and
validate the model on the remaining 20%. The Pearson
correlation score between the log of the measured associ-
ation constant faff and the predicted affinity µaff on the
validation set for the best choice of embedding and when
training on 80% of the data is 0.58 (Figure 2A) showing
that the model is able to discriminate between high and
low affinity sequences.
Using the protein language model (PLM) ESM2 [18]
for the embeddings gives a modest improvement over the
simpler one-hot vector encoding of the sequences (Fig. 2
B). We observe no differences between using a smaller
version of ESM (ESM-T6) versus a larger network (ESM-
T30). Using an antibody specific protein language model
(Antiberty) [19] gives worse results than a more general
PLM (Fig. 2). We asked whether reducing the amount
of training data significantly decreases the performance
of the model. When we reduce the size of the training
4
set to only 30% of the data, the Pearson correlation co-
efficient decreases by only 0.02 when using the ESM-T6
PLM to compute the embedding. Since the running time
for the prediction of a Gaussian Process is quadratic in
the number of sequences in the training set, evaluating
new sequences during the generative processes we use the
ESM-T6 embeddings and train the Gaussian Process on
30% of the dataset to limit the computational cost.
C.
Solubility model
The solubility of a monoclonal antibody is related to a
different factors that can impact the efficacy of the drug.
Antibodies can aggregate when stored in an aqueous so-
lution which will result in a painful reaction when the
drug is administered to the patient. In addition, aggre-
gates can become a target for the immune system and
increase the antigenicity of the drug. Hydrophobic in-
teraction chromatography (HIC) estimates the solubility
of antibodies by measuring the time time it takes the
antibody to cross a buffer. Stronger hydrophobic amino
acids result in longer times.
We use a method developed by Jain and al. [20] to
estimate the solubility of an antibody based on its se-
quence.
Given a sequence of amino acid of length L:
x = x1, x2, ..., xL, the solubility score of the sequence is
defined as
fsol(x) = −
L
X
j=1
SASA(j, xj)HW(xj) + const,
(4)
where SASA(i, Si) is the residue solvent accessible sur-
face area of amino acid ai at position i, and HW(xi) is
one of 20 hydrophobic weights describing the hydropho-
bicity of the amino acid xi. We use the solubility weights
provided in Jain et al [20] and train a convolutional neu-
ral network to predict the per-residue SASA score of each
amino acid in an antibody heavy chain sequence (see Sec-
tion Methods B).
Since the per-residue SASA score is not available from
the sequence alone, Jain and al. compute the per residue
SASA for 902 antibody structures identified from the
RCSB using the Shrake-Rupley algorithm [21] and train a
random forest regressor to predict the per residue SASA
of residues in the variable region from the sequence alone.
They then use a private dataset of 5000 antibody se-
quences for which the HIC retention time (RT) was mea-
sured to learn the HW weights using logistic regression.
We re-implemented their method but replaced the ran-
dom forest regressor with a deep convolutional neural
network NanoNet [22], a structure prediction method for
antibodies, and included more structures taken from the
SAbDab database [23].
Since this architecture is able
to accurately predict the structure of antibodies, we hy-
pothesized it may predict the per-residue SASA score.
We modified the last layer of the network to output a
single value corresponding to the SASA score for each
residue instead of the 15 values corresponding to the co-
ordinates of the backbone residues (see section IV A).
We use a dataset containing 137 clinical stage antibod-
ies for which the HIC RT was computed [1]. We used the
Thera-SAbDab database [23] to identify the antibodies
in this dataset whose structures were used to train the
SASA prediction model and excluded them, leaving us
with 83 clinical stage antibodies. The Spearman corre-
lation coefficient between the HIC RT and the predicted
solubility score on the 83 clinical stage antibodies is 0.40.
(Fig. 2 C). We compare the performance of our solubility
model to other models used to evaluate the solubility of
antibodies (Fig. 5 D). Removing the SASA in the pre-
dictive models leads to a drop in the Pearson correlation
score to 0.3. The SASA model we use is comparable in
performance to the commonly used CamSol [24] [25], a se-
quence based model that returns a hydrophobicity score
for every amino acid in the sequence that can be averaged
to produce an overall score. Augmenting Camsol with
our SASA prediction model only provides a marginal im-
provement (0.4 vs 0.38). Finally, our method performs
much better than the Gravy biopython score [26] (0.39
vs 0.18).
D.
Pareto optimal binders to CB-119 peptide
To generate a diverse set of antibodies binding the
CB-119 peptide and optimized for solubility, we gen-
erate 20 sets of sequences with 5 different weights
w = 0.85, 0.875, 0.9, 0.95, 1.0 and the 4 choices of β =
−1, 0, 1, 2.
We restrict ourselves to sequences at most
6 mutations away from the wildtype (WT) AB-14 (see
Discussion).
We define the distance to the Pareto front as:
dP(x) = min
x′∈PO
(faff(x) −faff(x′))2
σ2
aff
+ (fsol(x) −fsol(x′)2
σ2
sol
,
(5)
where σ2
aff and σ2
sol are the variances of the affinities and
solubilities of the generated sequences.
Top sequences
are defined as the B sequences with smallest dP, where
B is the number of sequences we wish to generate and
generally corresponds to a budget of sequences that can
be experimentally validated following the generation pro-
cess.
Fig. 3 A and B show the empirical Pareto fronts
from the generative process for an inverse temperature
of T −1 = 20 and a β = 0. The Pareto fronts for β = 2.0,
β = 1 and β = -1 are included in SI Fig. S4.
The
Pareto fronts generated by Metropolis-Hastings sampling
and the GflowNet are similar for β = 0 and β = −1,
suggesting neither method is better than the other one
at finding optimal sequences.
For β = 1 and β = 2,
Metropolis-Hastings sampling generates sequences with
higher affinity and solubility than the GFlowNet. Addi-
tional training of the GFlowNet could possibly improve
5
A
C
B
D
FIG. 2:
A. Density plot showing results from predicting KD using Gaussian Process B. Pearson’s correlation coefficient for
different choices of embedding C. Scatter plot comparing HIC RT to Solubility score for 83 monoclonal antibodies D. Pearson’s
correlation score for different solubility methods. HW + SASA refers to the method we retain for the generative process, HW
is similar to HW + SASA except the predicted SASA for each residue is set to 1. Camsol refers to the Camsol method [24]
and Gravy refers to the biopython hydrophobicity score function.
its performance, for example by doubling the number
of training steps from 8000 to 16000.
For β = 0, the
generated sequences that have the highest affinity have
a solubility score of around 2.5 while the generated se-
quences that have the highest solubility have an affinity of
10−1.4 ≈0.04 nM. As a point of comparison, the 83 ther-
apeutic antibodies on which we evaluated our solubility
prediction method have an average solubility score ˆfsol
of ≈0.7. The shape of the Pareto fronts show a trade off
between the solubility and the affinity score. The Pareto
front obtained using the predictive models suggests that
increasing the solubility score from 2 to 6, a solubility
score higher than any of the therapeutic antibodies used
to validate the model, decreases the affinity by one order
of magnitude.
To evaluate the novelty and diversity of a set of gener-
ated sequences Dgen, we follow Jain et al [9] and define
a diversity index given by the mean Hamming distance
within the generated dataset:
Diversity(Dgen) =
1
Ngen(Ngen −1)
X
(x,x′)∈Dgen
dH(x, x′),
(6)
where dH(x, x′) is the Hamming distance between x and
x′, and Ngen = |Dgen|. Novelty is defined as the mean
distance to the original dataset:
Novelty(Dgen) =
1
Ngen
X
x∈Dgen
min
x′∈Daff d(x, x′),
(7)
where Daff is the dataset of sequences for which affinity
was measured. Figure 3 C and D shows the diversity and
novelty of the sequences generated for both methods and
the three choices of β.
The average mean pairwise Hamming distance of gen-
erated sequences is between 4.5 and 5 depending on the
6
C
D
A
B
FIG. 3: A. Density plots of 1000 sequences sub-sampled from the set generated by Metropolis-Hastings at inverse temperature
T −1 = 20 and β = 0.0. B. Density plots of 1000 sequences sub-sampled from the set generated by the GFlowNet at inverse
temperature T −1 = 20 and β = 0.0. C. Comparison of diversity based on generative method and choice of β. D. Comparison
of novelty based on generative method and choice of β
.
choice of β and sampling method (Figure 3 C), compared
to the maximum possible value of 12 since the exploration
is limited to the space of sequences that are at most 6
amino acid away from the wildtype sequence. Novelty
shows an expected dependence on the exploration param-
eter β: it ranges from ∼2.5 for a pessimistic acquisition
function β = −1 to ∼4 for an exploratory acquisition
function β = 1. Both MCMC and GFlownet sampling
methods generate a diverse and novel set of sequences.
In addition, the continuity of the cloud of points shows
that the methods can generate points all along the Pareto
front from which we can pick the sequences with the de-
sirable trade-off between affinity and solubility.
The inverse temperature parameter T −1 provides a
balance between diversity and optimality. A low value
will lead to more diversity in the generated set but may
prevent the method from generating sequences in or near
the Pareto optimal set. To verify that T −1 is sufficiently
high to generate Pareto optimal sequences, we generated
30 new sets of sequences with T −1 = 25 and T −1 = 30 us-
ing MCMC sampling for each choice of β and w. We then
combined all sequences generated for different choices of
w into a single set and identified the Pareto optimal set
shown in SI Fig S1.
Decreasing the temperature does
not generate more optimal sequences, suggesting that an
inverse temperature of 20 is sufficient to generate the
Pareto optimal set.
We evaluated the sequences generated using two other
developability scores reported in previous work to evalu-
ate generative methods [26, 27]: the average charge and
7
instability. For the instability measure, we use the insta-
bility index() Biopython package function, which takes
as input an amino acid sequence and returns a real value
instability score [28]. A protein is considered unstable if
the instability score is less than −40. To estimate the
charge of the antibody, we sum the contributions from
all amino acids in the heavy chain sequence, adding +1
for positively charged amino acids R and K, +0.1 for all
H and −1 for negatively charged amino acids D and E. A
good candidate antibody should have a charge score to
be between −2 and 2. The results for T −1 = 20.0 and all
choices of β are shown in supplementary information fig-
ure S3. The sequences generated by our method have an
average charge score within the desired range, with 1.25
for β = −1 and 0.5 for β = 1. The standard deviation is
approximately 1 for all choices of β and we observe that a
small fraction of the sequences have a charge score higher
than the limit of 2. This is likely due to the fact that pos-
itively charged amino acid are more hydrophilic and the
generative model can generate more soluble antibodies
by adding positively charged amino acids to the antibody
sequence. In addition, we observe that for all choices of
β, the instability score remains on average slightly below
30 with a standard deviation of 3, with the vast ma-
jority of sequences having an instability score below the
threshold of 40. In conclusion, these results suggests that
our method is able to generate functional proteins, even
when evaluated on methods that were not included in the
multi-objective optimization function.
E.
Validation on synthetic dataset
We have demonstrated the ability of energy based gen-
erative methods to generate Pareto optimal sequences
with respect to the proxy functions ˆfaff and ˆfsol. How-
ever, we are not able to experimentally evaluate the Kd
of HIC of the sequences to verify that the sequences gen-
erated are actually functional. To circumvent this limi-
tation and test the validity of the method, we designed a
synthetic dataset Dsyn on which to test our approach.
We define an epistatic affinity model as:
faff(x) = faff(xWT) +
L
X
i=1
hi(xi) +
X
i<j
Jij(xi, xj),
(8)
where xWT is a wild type sequence, hi(i) is the change
in log(1/Kd) after mutating the amino acid at position i
to xi away from its wildtype value, and hi(xi)+hj(xj)+
Jij(xi, xj) is the change caused by mutating two amino
acids at position i and j to xi and xj away from the
wildtype. This epistasis model was previously used to
estimate the affinity of antibodies to fluorescein based on
a dataset similar in composition to the CB-119 peptide
dataset studied above [29] and fits within the broader
class of epistatic model decomposed by order of interac-
tion, here truncated at second order—check Phillips et
al. [30] and Ranganathan review [31] on epistasis.
Using this framework, we define two synthetic affinity
models in which hi(xi) and Jij(xi, xj) are sampled from
a Gaussian distribution. The first model, referred to as
the simple epistasis model has H(i, Si) = N(−0.5, 0.5)
and J(i, j, Si, Sj) = N(0.0, 0.5).
The second ”hard”
model has H(i, Si) = N(0.0, 0.5) and J(i, j, Si, Sj) =
N(−0.5, 0.5). The probability that a random mutation
will be deleterious is higher in the hard case than in the
simple case due to the larger impact of the J terms com-
pared to the H terms, which motivates the hard/simple
terminology.
To generate our synthetic dataset, we use the same
wildtype sequences as in the SARS-CoV-2 affinity
dataset, and compute the affinities (Eq 8) of 14660 ran-
dom variants containing all 660 single mutants, 2100 dou-
ble mutants and 11900 triple mutants, comparable to the
affinity Engelhart dataset [15]. Each mutant was gener-
ated by starting from the wildtype sequence AB-14, ran-
domly selecting a number of positions that we want to
mutate and performing a random substitution at each
of these positions. We further add some random noise
∼N(0, 1) to each measurement to mimic experimental
error. We use this data to train a Gaussian Process as the
new predictive affinity model ˆfaff, and generate sequences
optimized for that objective as well as ˆfsol. For each of
the two tasks, we set the inverse temperature T −1 = 10
and generate 6 sets of sequences with w ∈{0.85, 1.0}
and β ∈{−1.0, 0.0, 1.0, 2.0}.
We initially tried an in-
verse temperature of T −1 = 20, however we found that
value to be too high and the process failed to generate
diverse sequences. We lowered the inverse temperature
to 10 to more closely match the behavior we observed
when generating binders to CB-119.
Figures 4 A, B and C show the 1, 000 sequences clos-
est to the empirical Pareto front for the simple task,
using MCMC sampling to generate new sequences for
the 3 choices of β.
We observe that for all choices of
β, the method is able to generate a diverse set of se-
quences along the empirical Pareto front. We observe a
clear trade-off between the solubility score and the affin-
ity score, especially for β = 0, 1 and 2. However, similarly
as for the CB-119 task, for β = −1 the method has more
difficulty generating many sequences very close to the em-
pirical Pareto front. This result stems from the fact that
β = −1 limits the search space to sequences similar to the
ones in Dsyn, decreasing the probability of the generative
method to find the most optimal sequences according to
ˆfaff and ˆfsol. Furthermore, we observe that the gener-
ated sequences are slightly more diverse and novel when
w = 0.85, for all choices of β (Figure 4 D). The results
for the hard epistasis model are shown in supplementary
figure S5. The results for the hard task are similar to
the simple task, except for β = −1.0 for which the meth-
ods fails to generate many diverse solutions. Instead we
generate only 17 unique sequences. One possible reason,
is the small number of high affinity sequences in Dsyn
with 2 or 3 mutations (since the hard task penalizes the
J epistasis terms) (Figure S6 C). This in turn may make
8
E
F
A
B
C
D
FIG. 4: A. Density plots of 1000 sequences sub-sampled from the set generated by Metropolis-Hastings at inverse temperature
T −1 = 10 and β = −1.0 on the simple synthetic task. B. Density plots of 1000 sequences sub-sampled from the set generated
by Metropolis-Hastings at inverse temperature T −1 = 10 and β = 0.0 on the simple synthetic task. C. Density plots of 1000
sequences sub-sampled from the set generated by Metropolis-Hastings at inverse temperature T −1 = 10 and β = 1.0 on the
simple synthetic task. D. Density plots of 1000 sequences sub-sampled from the set generated by Metropolis-Hastings at inverse
temperature T −1 = 10 and β = 2.0 on the simple synthetic task. E,F. Comparison of diversity and novelty for different choices
of β and w.
9
it difficult for the Gaussian process to predict with high
certainty that sequences with more mutations have a high
affinity. The generative process then produces many sin-
gle mutants which are subsequently removed from our
results since all single mutants are already included in
Dsyn. From this result, we learn that on tasks where im-
proving the affinity is difficult, i.e. there are not many
beneficial mutations, it is especially important to use an
optimistic approach to find novel candidates to test.
In order to investigate the usefulness of our method
for antibody lead optimization, we consider the task of
generating antibodies with predicted solubility score ˆfsol
greater than a threshold f min
sol
and with a synthetic affin-
ity faff(x) greater than a threshold f min
aff . For each choice
of β and w, we take the set of generated sequences using
MCMC sampling and select the ones with ˆfsol > f min
sol .
We rank the selected sequences by ˆfaff and keep the top
B sequences, where B is the budget of sequences that can
be validated with wet lab experiments. For every thresh-
old f min
aff
we count the number of sequences, out of the
B sequences generated and selected, with synthetic affin-
ity ˆfaff > f min
aff . We choose thresholds f min
sol
= −∞(no
solubility threshold) and f min
sol
= 4.0 to explore the differ-
ences when optimizing for both affinity and solubility vs
simply affinity, and a budget of B = 500. f min
sol
= 4.0 is
sufficiently high to demonstrate a difference not having a
solubility threshold while still generating valid sequences.
Using the synthetic dataset we investigate the most ap-
propriate choice of β for lead optimization. We observe
that for three of the tasks: simple with and without a
solubility threshold and hard without a solubility thresh-
old, the best choice of β out of the ones we tested is 1.0.
In the case where we have no solubility threshold (Fig-
ure 5 A,C), the best choice is for w = 1.0 whereas in
the simple case with f min
sol
= 4.0, w = 0.85 (Figure 5 B).
These results suggests that using an optimistic choice of
β helps to discover more optimal sequences rather than a
pessimistic choice of β = −1.0. In fact, in the considered
scenarios, using β = −1.0 consistently performs worse
than the other choices.
In addition, we observe that being too optimistic can
be detrimental as β = 2.0 can perform worse than
β = 1.0.
For the hard task with no solubility thresh-
old using β = 1.0 yields approximately twice as many
valid sequences for all affinity thresholds. However, for
the simple task β = 2.0 and β = 1.0 perform approxi-
mately the same, since in the hard task finding a bene-
ficial mutant randomly is less likely than in the simple
task. Furthermore, we observe that for the most diffi-
cult case, the hard task with a solubility threshold, using
β = 1.0 is also the best choice, except for f min
aff
> 1, when
β = 2.0 and w = 1.0 is best. We found that using an
optimistic choice for β yields consistently better results
than a pessimistic choice of β, even on the hard task. In
fact, the more difficult the task, the better it is to use
β = 2.0 rather than β = 1.0. This suggests that in order
to find the few sequences that are optimized for solubility
and affinity, it is necessary to take more risks during the
exploration process.
To explore the consequences of small budgets, we con-
sidered B = 20 (Fig S7) and found for the hard task
with f min
sol
= 4.0, the best choice is to use β = 0 and
w = 0.85. This suggests that when having a limited bud-
get and optimizing for a difficult task, it may be better
to use a more conservative choice for β and generate high
confidence sequences.
Comparison to other methods
We can use the synthetic dataset to compare the per-
formance of our approach to previous methods against
the ground truth.
Khan et al
[26] define the multi-
objective optimization of antibodies as a constrained
affinity optimization problem. They use a local search
algorithm similar to hill climbing as the inner loop of
an active learning framework to optimize the CDRH3
of antibody heavy chain in order to increase their affin-
ity according to a synthetic affinity function computed
with the software Absolut! [32], as well as three devel-
opability properties (net charge, repetition of amino acids
and presence of a glycosylation motif). For each devel-
opability property, the algorithm requires an interval of
valid values to be specified. Sequences that fall outside of
these developable regions are automatically rejected by
the search algorithm.
In order to compare the local search algorithm from
antBO to our approach, we implemented their method
and ran it using two different sets of developability re-
strictions. In the first case we limit the exploration to
sequences with Hamming distance less than 6 to the wild
type. In the second case, we add the additional restric-
tion that the sequences must have a solubility predicted
score ˆfsol ≥4. For both cases, we ran the local search
algorithm 800 times in parallel for 200 steps and kept
the last sequences of each run as the set of generated
sequences.
In addition, as a negative control, we also compared
our method to a set of 500 randomly generated sequences
Drnd.
We generated these sequences by starting with
the best mutant in Dsyn.
We then randomly select 3
positions that have no yet been mutated. For each of
these positions, we perform an amino acid substitution
with an amino acid uniformly drawn from the 19 other
amino acids.
We compared the initial mutants Dsyn, the randomly
generated mutants Drnd, and the sequences generated
with the local search of antBO to sequences gener-
ated with our method using MCMC sampling and the
GflowNet (Fig. 6). For both MCMC and the GflowNet,
for each choice of β we combined all the sequences gener-
ated for both choices of the affinity weight w into a sin-
gle set. For each set of generated sequences, we remove
all sequences with f sol
θ (x) < f min
sol
for f min
sol
= −∞and
f min
sol
= 4.0. Then we select the top 500 sequences accord-
ing to the acquisition function used during the generation
10
C
D
Simple Epistasis Model
A
B
Hard Epistasis Model
FIG. 5:
Figure A. shows the number of sequences out the top 500 selected from the set of generated sequences with Metropolis
Hastings when trying to optimize the simple epistasis model with an affinity above a certain thresholds for different choices of
β and w. We compare those results to the set of sequences in the training set, indicated as initial. B shows the percentage
of sequences that are above a certain threshold and also have a predicted solubility score above 3. Figure C. and D. show the
results when trying to optimize the hard epistasis model.
process. We then compute the percentage of sequences
with a synthetic affinity faff higher than a chosen thresh-
old f min
aff .
For the simple task with no solubility threshold,
MCMC sampling with β = 1 and β = 2 are the best
choices of parameters and outperform the antBO local
search (Fig. 6 A). However, we observe that the random
sequences contain more optimized sequences than any
of the sequences generated by our method.
This sug-
gests that the task is quite easy.
For the simple task
with f min
sol
= 4.0, MCMC sampling with β = 0, β = 1.0
and β = 2.0 outperforms the antBO local search (Fig. 6
B). In addition, MCMC sampling performs better than
GFlowNet for similar values of β except for β = −1.0
where the results are similar. All of the methods do bet-
ter than the random baseline and the initial dataset. For
the simple task, regardless of solubility thresholds, we ob-
serve that using a positive β is more beneficial although if
β is too high, the performance starts to decrease a little.
For the hard task with no solubility threshold, the best
method is MCMC sampling with β = 1.0 (Fig. 6 C).
In this case, using β = 2.0 leads to significantly worse
performance. In addition MCMC sampling with β = 1.0
outperforms the GflowNet, except for β = 0.0 for which
they give similar results. Finally both MCMC sampling
and Gflownet outperform the local search of antBO, the
initial dataset and the random baseline for f min
aff
> −0.3.
Finally, on the hard task with f min
sol
= 4.0, we find that for
11
Hard Epistasis Model
C
D
A
B
Simple Epistasis Model
FIG. 6:
Figure A shows the number of sequences out the top 500 selected from the set of sequences generated for different
choices of β and generative method (Metropolis Hastings and GFlowNet). We compare those results to the set of sequences
generated by the local search procedure of antBO and the set of sequences used to train the Gaussian Process affinity predictor,
indicated as initial, as well as a set of randomly generated sequences in the neighborhood of the best sequence in Drnd indicated
as random. B shows the percentage of sequences that are above a certain threshold and also have a predicted solubility score
above 3. Figure C and D show the results when trying to optimize the hard epistasis model.
an affinity threshold f min
aff
> 0, the GFlowNet with β =
2.0 generates the highest number of valid sequences. This
is the first setting where the GFlowNet performs better
than MCMC sampling. Overall, both MCMC sampling
and the GFlowNet outperform the local search of antBO,
the initial dataset and the random baseline.
Comparing the methods for a limited budget of B = 20
(Fig. S8), we find the most significant differences for the
hard task with f min
sol
= 4.0, where using β = 0 greatly
outperforms using β = 2. This result suggests conserva-
tive choices of β for limited budgets. Furthermore, on all
tasks except the simple one with no solubility threshold,
our energy based method outperforms the local search of
antBO. On the simple task with no solubility threshold,
even antBO performs worse than random.
These results serve to demonstrate that our energy
based sampling method performs better than constrained
optimization in a variety of settings. In particular, we
find that the local search algorithm has more difficulty
when generating sequences optimized for the hard epista-
sis affinity function than for the simple epistasis affinity
function.
III.
DISCUSSION
Data limitations and choice of models
We made many design choices when developing this
method. First and foremost, data limitations are inher-
ent to the task of antibody optimization. In this paper,
we use a dataset that contains 105 sequences. While this
number may vary depending on the available resources,
that number is usually a tiny fraction of the space of
sequences we wish to explore. Even limiting the search
to sequences 6 amino acids away from the WT, leaves
12
7.088 × 1013 possible candidates. Given the complexity
of the task of predicting the affinity of an antibody to
a target antigen based on sequence information alone,
training a model on the dataset that generalizes well to
the entire search space is hard. For this reason, we chose
to use a Gaussian Process as this method allows us to
directly estimate the epistemic uncertainty of our predic-
tion. Furthermore, due to the limited training set size,
when using a protein language model to compute the
embeddings of sequences, we chose not to do any fine-
tunning of the model to avoid potential over-fitting due
to the large number of parameters these models use.
For the solubility model, in absence of a large ex-
ploitable dataset for machine learning, we opted to reuse
the method developed by [20]. Since their method relies
on first training a SASA prediction method on publicly
available structures of antibodies, we were able to imple-
ment our own SASA prediction model and then reuse the
20 hydrophobicity weights learned by [20] on their private
dataset containing 5000 pairs of antibody sequences and
their HIC RT.
Review of prior approaches
A number of methods for the generation of optimized
antibody sequences have previously been proposed. Like
our method, AntB0 [26] performs multi-objective opti-
mization by modifying the heavy chain of antibodies.
They seek to optimize the affinity estimate given by Ab-
solut! as well as three developability properties. Another
similar approach [33]. also performs multi-objective opti-
mization and optimizes both affinity and thermostability.
Our approach to multi-objective optimization is different
from Ref.
[33] and Ref.
[26].
Both of these methods
define hard constraints for the developability properties.
For example, antBO requires the charge of the gener-
ated sequences to be between -2 and 2. The method in
Ref. [33] requires the predicted melting temperature to
be above 60 or 65 ◦C. We do not use hard constraints but
instead use an energy function made up of a linear combi-
nation of the predicted properties and sampled from the
Boltzmann distribution defined by this energy function.
The advantage of this approach is that it does not require
prior knowledge of constraints for each property. In the
case of the solubility prediction for example, the HIC
RT can depend on experimental conditions and defining
a precise threshold for which antibodies are soluble or
not is often not simple. Ref. [34] developed an active
learning loop procedure to optimize the affinity of anti-
bodies based on the predicted free energy of the antibody
antigen complex using the Schr¨odinger software, using a
standard multi-round active learning framework without
constraining the search space. Unlike us, they do not per-
form multi-objective optimization but they use a gaus-
sian process as a predictive model for the Schr¨odinger
∆∆G prediction similar to our methods and [33] and
Ref. [26]. These three methods [26, 33, 34] use the ex-
pected improvement acquisition function to select which
sequence to test.
In contrast, we use the UCB/ LCB
acquisition function in order to study the effect of be-
ing optimistic vs pessimistic in a single round of opti-
mization.
Another key difference is that, we utilize a
pretrained autoregressive protein language model to reg-
ularize our generative process.
Of these methods, Ref
[33] is the most similar to us in scope as it is designed
to perform offline single round multi-objective optimiza-
tion, although it optimizes thermostability whereas we
optimize solubility. In addition, the idea of performing
the exploration in the latent space of the auto-encoder in
order to amortize the exploration cost of the search space
is similar to our use of the GflowNet. antBO and Ref.
[34] on the other hand were designed for multi-round on-
line active learning. Both methods use in-silico affinity
prediction methods as faff, allowing them to bypass the
more expensive and time-consuming wet lab experiments.
In addition, [27] trained a GP on the dataset of [15]
and generated new sequences using Monte Carlo Markov
chain and the expected improvement acquisition func-
tion. They demonstrated that this approach is able to
generate new mutants with higher affinity to the CB-119
peptide than in the initial dataset. Unlike us however
they do not perform multi-objective optimization.
Motivation behind investigating the choice of
acquisition function
Our motivation to investigate the use of different
choices of β for the acquisition function came from the
fact that we have a limited dataset and the need to con-
strain the space of sequences on which the exploration
is performed, both to facilitate the generative process
and limit the search to sequences on which our predic-
tive models are confident. By varying β, we can choose to
let the generative model generate sequences farther away
from the original dataset or to remain close. In [33] [26],
a trust region is used to achieve a similar goal. The trust
region limits the exploration and is dynamically updated
at the end of each optimization round based on whether
a new best solution has been found. It is not possible to
use the same approach in the context of a single round
as the trust region is only modified at the end of each
round. In our case however, trying out different choices
for β is a principled way of restricting the search space.
We took inspiration from recent papers in offline rein-
forcement learning to try both optimistic and pessimistic
values of β [35][36]. The setting of offline reinforcement
learning is identical to single round antibody optimiza-
tion, wherein we do not have the ability to further query
the environment or run more wet lab experiments. In
this setting, multiple papers have pointed out that it may
be useful to penalize uncertainty, i.e. choose a negative
value for β [37][38].
The advantage of being pessimistic is that it forces
the generative model to generate sequences on which it
13
is more confident that its prediction is accurate. This
is particularly important if the number of sequences that
can be tested is small and if there are few good sequences
(with a high affinity) within the trust region.
Instead
of being optimistic and generating a large variety of se-
quences for which we have no guarantee that they will
work, we chose to generate sequences closer to the ones in
our dataset, but for which we have more accurate affinity
predictions, and therefore stronger guarantees that they
will bind to the target antigen.
However, we found that risk was often necessary to
find new mutations. The only exception was when using
a limited budget on the most difficult task(Fig S7). Yet
even in that case, β = 0 yielded better candidates than
β = −1.
Limitations of our method and future research
directions
There are several limitations to our study. We only
consider the case of optimizing over both affinity and sol-
ubility, although there are several other important prop-
erties of interest, such as thermostability. It will be in-
teresting to test this method when there are multiple
properties to optimize over.
Our solubility predictive model only outputs a pre-
dictive score but no uncertainty estimate.
It remains
a possible research direction to build a SASA prediction
model that includes uncertainty estimates. In addition,
since the model outputs a prediction for every amino acid
residue, it would also need to output an uncertainty esti-
mate for every residue. It would therefore also be inter-
esting to investigate how to combine each estimate into
a single uncertainty score that could be included in the
acquisition function.
Overall, our approach demonstrates the possibility to
optimize several antibody properties in parallel. As real-
life pharmaceutical projects aims at optimizing more
than only 2 protein properties (affinity ans solubility)
before identifying a drug candidate, a direct application
of this work would be to apply this approach to the opti-
mization of 5 or more properties with experimental evalu-
ations of the resulting sequences. By providing sequences
fulfilling the drug developability criteria, the method de-
scribed in this paper can help scientists to accelerate drug
discovery projects
IV.
METHODS
A.
Solubility predictor
In order to select the structures from which to build
the training dataset for the solubility predictor, we took
all the structures available in SabDab [23] and clustered
them by 98% similarity of the heavy chain sequence us-
ing CD-HIT [39]. From each cluster, we selected the an-
tibody with the longest heavy chain sequence, giving us
2648 distinct heavy chain structures. We use the Shrake-
Rupley algorithm [21] to compute the SASA of every
residue in the heavy chains. We divided each computed
SASA value by the maximum exposed side-chain SASA
in the Ala-X-Ala peptides (where X is the amino acid for
which the SASA was computed) as determined by [40].
We use the convolutional neural network architecture
used for NanoNet [22] with an additional embedding layer
added at the beginning. This layer takes as input a one-
hot vector encoding of dimension L × 22. The first 20
values are used to determine which amino acid is present
at position i and the last two values contain the distance
to the first amino acid i and the distance to the last amino
acid L−i [? ]. We found that providing both the forward
and backward positioning information helps the network
deal with sequences of different lengths. The output of
the encoding layer is a matrix of dimension L × h with
h = 64.
The network was trained using stochastic gradient de-
scent for 10 epochs and using a mini-batch size of 16. We
use the MSE loss function:
Lθ = 1
L
L
X
i=1
(SASA(j, xj; θ) −SASAstruct(j, xj; θ))2, (9)
where SASA(j, xj; θ) is the predicted SASA of the residue
at position i in the sequence x and SASAstruct(j, xj; θ) is
its true value.
B.
Gaussian Process
The Gaussian process assumes that the output func-
tion f(x) was initially drawn at random, but in a way
that similar x have similar f(x). The distribution f(x)
for all x is assumed to be a multivariate Gaussian of con-
stant mean C and covariance k(x, x′), where k is called
the kernel function and determines how similar the out-
puts of x and x′ should be.
Let X ∈Rn×m be the set of training data and Y ∈Rn
associated affinity values. We assume that the data is
noisy so that y(x) = f(x) + ϵ(x) with ϵ(x) ∼N(0, σ2
n).
Call z is a new sequence for which we aim to make a
prediction for f(z).
The joint distribution for the training data and
the new sequence is also a multivariate Gaussian:
p(Y, f(z)|X, z) ∼N(µ, Σ) with:
µ =



C
C
...
C


, Σ =

k(X, X) + σ2
nIn k(z, X)
k(z, X)T
k(z, z)

.
(10)
k(X, X) a matrix of dimensions n × n where the (i, j)
entry is k(xi, xj). k(z, X) a vector of dimension n where
the ith entry is equal to k(z, xi) and In is the identity
matrix of dimension n.
14
We seek the posterior distribution:
p(f(z)|X, Y, z) = p(Y, f(z)|X, z)
p(Y |X)
(11)
which is Gaussian with mean:
µ(f(z)|X, Y ) = C+k(z, X)T (K+σ2
nIn)−1(Y −C), (12)
and variance
σ2(f(z)|X, Y, z) = k(z, z)+k(z, X)T (K+σ2
nIn)−1k(z, X).
(13)
The posterior distribution for the noisy prediction y(z) =
f(z) + ϵ(z) has an additional σ2
n term in its variance.
The model provides both an estimate for the affinity
of a new sequence as well as an uncertainty estimate.
This uncertainty σ only depends on the training data
X and can be reduced by adding more training exam-
ples. Therefore it captures the “epistemic” uncertainty
of the error. On the other hand σn is independent of the
training set and z, therefore it captures the “aleatoric”
uncertainty.
We use the common radial basis function (RBF) Ker-
nel:
k(x, x′) = δ exp(−∥x −x′∥2
2λ2
).
(14)
The RBF kernel [41] encodes the bias that sequences close
to one another in embedding space have similar affinities
to the target antigen.
The norm ∥x−x′∥is defined as the Euclidian distance
in the embedding space. We tested the following embed-
ding choices:
◦One-hot vector embedding of the amino acid se-
quences. For a sequence of length L, this a vector
of length L × 20.
◦Embeddings computed by the protein language
model ESM2 [42]. ESM2 is a BERT [43] style trans-
former that was trained using the masked language
task on general proteins. We compared the versions
with 8M, 150M and 650M parameters.
◦Embeddings computed by Antiberty [19], a bert
style transformer, similar to ESM2, but trained
uniquely on human antibody heavy chain se-
quences.
The parameters λ and δ of the Kernel k(x, x′), as well
as σn, are learned by minimizing the log marginal likeli-
hood of the training data:
ln p(Y |X) = −1
2Y T (K+σ2
nI)−1Y −1
2 ln 2π|K+σ2
nI|.
(15)
C.
Humaness Model
To
model
humaness
parameter
pHUM,
we
use
IGLM [11], an auto-regressive transformer trained on
558M human heavy chain sequences from the OAS
database [12]. Given the amino acid sequence from posi-
tion 1 to i −1 denoted x<i, the model returns a discrete
probability distribution over the set of the 20 amino acids
pIGLM(xi|x<i) and adds the next amino acid. For each
sequence of amino acids pHUM is the probability that
IGLM generates that particular sequence (obtained us-
ing the likelihood method of IGLM)
pHUM(x) =
n
Y
i=1
pIGLM(xi|x<i),
(16)
which guarantees that only amino acid sequences that
resemble human heavy chain sequences will have a high
probability of being generated. Shuai and al [11] showed
that sequences generated with IGLM have on average
good developability properties when looking at solubility,
aggregation and CDRH3 length.
D.
Energy based model
We sample sequences using Energy based models
(EBMs) by assigning an energy score E(x) to each amino
acid sequence x where E(x) is low for desirable x. We
would like to sample x from a probability distribution
that is as close as possible to the distribution of natural
antibodies, pHUM, while minimizing the mean of E(x):
p = arg max
π∈Π
(
X
x
π(x)E(x) + TDKL(π||pHUM),
(17)
where DKL is the Kullback-Leibler divergence The solu-
tion of this minimization is given by the Boltzmann law,
Eq. 1.
In the particular case where pHUM is replaced
by the uniform distribution, DKL becomes the negative
entropy of π, and the problem reduces to the maximum
entropy principle, where T plays the role of an inverse
Lagrange parameter enforcing the mean value of E(x).
The temperature T sets the trade-off between the ob-
jectives of minimizing the quantity of interest E(x), and
remaining as close to the basal distribution of antibod-
ies. While T = 0 reduces to finding the best sequences,
T > 0 ensures a higher diversity of antibodies that look
like natural ones.
The energy function E(x) is chosen as a linear combi-
nation of multiple properties which we wish to minimize,
called linear scalarization:
E(x) =
X
i
wi fi(x) s.t
X
i
wi = 1.
(18)
Varying the weights wi make it possible to explore the
Pareto front in the T = 0 limit, when that front is convex.
For T > 0, the vicinity of the front is explored while also
ensuring that antibodies still look like natural ones drawn
from pHUM.
15
E.
MCMC sampling
To perform MCMC sampling of Eq. 1, we start from
the WT sequence ’GFTLNSYGISIYSDGRRTFYGDSV-
GRAAGTFDS’,
the
concatenation
of
the
CDRH1,
CDRH2 and CDRH3 of the AB-14 sequence from the
CB-119 dataset. The same wild type sequence was also
use to generated the synthetic datasets for the simple
and hard synthetic affinity task. We set this sequence to
be the first sequence x0. At time k, we randomly sam-
ple a mutant sequence x′ from the neighborhood of xk.
The neighborhood of xk is defined as the set of sequences
that are at most 1 mutation away from xk and at most 6
mutations away from x0. For each sequence with prob-
ability min(1, p(x′)/p(xk)), we accept the mutation and
set xk+1 = x′, or otherwise we reject the mutation and
set xk+1 = xk.
We ran this process in parallel 8 times.
Each time
we performed MCMC sampling for a period of 20000
time steps. To add a burn-in period, we removed all the
sequences x1, x2, ...xb from the 8 chains and computed
the Gelman-Rubin statistic. The Gelman-Rubin statistic
checks the convergence of multiple Markov Chain Monte
Carlo (MCMC) chains by computing the ratio between
the variance within each chain to the variance between
chains, with values close to 1 indicating convergence. We
then selected an initial timestep b such that the Gelman-
Rubin statistic was as close to 1 as possible. If we could
not find a timestep b such that the Gelman-Rubin statis-
tic was lower than 1.1, we ran the sampling for 20000
additional steps and repeated the process until conver-
gence.
F.
GFlowNet sampling
For the autoregressive model used in our implementa-
tion of the GFlowNet, we used a ByteNet [44] [45] archi-
tecture. The network starts with an encoding layer that
feeds into 4 ByteNet blocks.
Each block uses masked
convolutional layers with no dilution and a kernel size of
17. The output of these 4 blocks is a matrix of dimen-
sion L × H where L is the maximum sequence length
and H is a hyper parameter representing the size of the
encoding which we choose to be 16. We then feed to a
decoder the ith column of this matrix to which we append
two values, i and n, where i is the position of the amino
acid we are currently sampling and n is the Levenshtein
distance between the sequence generated so far and the
prefix of length i −1 of the WT sequence. We provide i
to the decoder to simplify the learning process and n in
order for the network to be able to learn to only generate
sequences with at most 6 mutations from the wild type
sequence.
The decoder consists of a 2 layer multi-layer percep-
tron with a normalizing layer and ReLu activation layer
between the first and second linear layer. The output of
the second layer is vector of dimension 20 containing the
logits for each of the 20 amino acids.
For each GflowNet trained, we use a starting learning
rate for the parameters of the network of 10−3, except
for the learning rate of Zθ which is set to 10−2 (an or-
der of magnitude higher per the recommendation of the
GflowNet paper). We train each network for 8000 train-
ing steps, halve the learning rate after 4000 steps and use
a replay buffer with a max size of 20000. We initialize
to contain the sequences in the COVID dataset for the
COVID task and the synthetic dataset for the simple and
hard synthetic tasks. At each step, we first generate 16
sequences using the generative model and compute their
energy E. We then sample 16 more sequences and their
score from the replay buffer and update the parameters
of the model using stochastic gradient descent on the set
of 32 sequences. The 16 generated sequences are then
added to the replay buffer and the process is repeated.
Unlike for the MCMC, there is no principled way to
check that the training of the neural network has con-
verged to a local optimum. In order to verify that the
network is learning to properly generate sequences with a
probability proportional to their reward, we take inspira-
tion from Ref. [46] Using a separate dataset of sequences
from the sequences used to initiate the replay buffer, we
periodically, during the training process compute the log
probability of the sequences being generated. We com-
pute the SpearmanR correlation score between the scores
and the log probability of generated sequences.
While this method has its flaws, we found it was a
simple method to verify that the generative model was
correctly learning for each choice of β, w and inverse
temperature T −1 (SI Fig. S2).
Data availibility
The code and data supporting the findings of this
study are available at the following GitHub repository:
https://github.com/statbiophys/ABGen
Acknowledgements
This work was supported by Sanofi, the European
Research Council consolidator grant no 724208 (AMW,
TM), and the Agence Nationale de la Recherche grant
no ANR-19-CE45-0018 “RESP-REP” (AMW, TM, PP).
PP and HM are Sanofi employees and may hold shares
and/or stock options in the company. The authors de-
clare that this study received funding from Sanofi. The
funder collaborated directly in the study and was in-
volved in the study design, analysis, and interpretation
of data, the writing of this article, and the decision to
submit it for publication.
16
[1] Jain T, et al. (2017) Biophysical properties of the clinical-
stage antibody landscape.
Proceedings of the National
Academy of Sciences 114:944–949.
[2] McMahon C, et al.
(2018) Yeast surface display plat-
form for rapid discovery of conformationally selective
nanobodies.
Nature structural & molecular biology
25:289–296.
[3] Ledsgaard L, Kilstrup M, Karatt-Vellatt A, McCafferty
J, Laustsen AH (2018) Basics of antibody phage display
technology. Toxins 10:236.
[4] Ye W, et al. (2022) Improving antibody affinity through
in vitro mutagenesis in complementarity determining re-
gions. Journal of Biomedical Research 36:155.
[5] Hearty S, Leonard P, O’Kennedy R (2012) Measuring
antibody–antigen binding kinetics using surface plasmon
resonance.
Antibody Engineering: Methods and Proto-
cols, Second Edition pp 411–442.
[6] Khetan R, et al. (2022) Current advances in biopharma-
ceutical informatics: guidelines, impact and challenges in
the computational developability assessment of antibody
therapeutics (Taylor & Francis), Vol. 14, p 2020082.
[7] Mason DM, et al. (2021) Optimization of therapeutic an-
tibodies by predicting antigen specificity from antibody
sequence via deep learning. Nature Biomedical Engineer-
ing 5:600–612.
[8] Biswas S, Khimulya G, Alley EC, Esvelt KM, Church
GM (2021) Low-n protein engineering with data-efficient
deep learning. Nature methods 18:389–396.
[9] Jain M, et al.
(2022) Biological sequence design with
gflownets (PMLR), pp 9786–9801.
[10] Bennett NR, et al. (2024) Atomically accurate de novo
design of single-domain antibodies. bioRxiv.
[11] Shuai RW, Ruffolo JA, Gray JJ (2021) Generative lan-
guage modeling for antibody design. BioRxiv pp 2021–
12.
[12] Olsen TH, Boyles F, Deane CM (2022) Observed anti-
body space: A diverse database of cleaned, annotated,
and translated unpaired and paired antibody sequences.
Protein Science 31:141–146.
[13] Haarnoja T, Tang H, Abbeel P, Levine S (2017) Rein-
forcement learning with deep energy-based policies. pp
1352–1361.
[14] Bengio Y, et al.
(2023) Gflownet foundations
(JML-
RORG), Vol. 24, pp 10006–10060.
[15] Engelhart E, et al. (2022) A dataset comprised of binding
interactions for 104,972 antibodies against a sars-cov-2
peptide. Scientific Data 9:653.
[16] Gardner J, Pleiss G, Weinberger KQ, Bindel D, Wilson
AG (2018) Gpytorch: Blackbox matrix-matrix gaussian
process inference with gpu acceleration. Advances in neu-
ral information processing systems 31.
[17] Auer P
(2002) Finite-time analysis of the multiarmed
bandit problem.
[18] Lin Z, et al.
(2023) Evolutionary-scale prediction of
atomic-level protein structure with a language model.
Science 379:1123–1130.
[19] Ruffolo JA, Gray JJ, Sulam J
(2021) Decipher-
ing antibody affinity maturation with language mod-
els and weakly supervised learning.
arXiv preprint
arXiv:2112.07782.
[20] Jain T, et al. (2017) Prediction of delayed retention of
antibodies in hydrophobic interaction chromatography
from sequence using machine learning.
Bioinformatics
33:3758–3766.
[21] Shrake A, Rupley JA (1973) Environment and exposure
to solvent of protein atoms. lysozyme and insulin. Jour-
nal of molecular biology 79:351–371.
[22] Cohen T, Halfon M, Schneidman-Duhovny D
(2022)
Nanonet:
Rapid and accurate end-to-end nanobody
modeling by deep learning.
Frontiers in immunology
13:958584.
[23] Dunbar J, et al. (2014) Sabdab: the structural antibody
database. Nucleic acids research 42:D1140–D1146.
[24] Sormanni P, Aprile FA, Vendruscolo M (2015) The cam-
sol method of rational design of protein mutants with en-
hanced solubility. Journal of molecular biology 427:478–
490.
[25] Sormanni P, Amery L, Ekizoglou S, Vendruscolo M,
Popovic B (2017) Rapid and accurate in silico solubil-
ity screening of a monoclonal antibody library. Scientific
reports 7:8200.
[26] Khan A, et al. (2022) Antbo: Towards real-world auto-
mated antibody design with combinatorial bayesian op-
timisation. arXiv preprint arXiv:2201.12570.
[27] Li L, et al.
(2023) Machine learning optimization of
candidate antibody yields highly diverse sub-nanomolar
affinity antibody libraries.
Nature Communications
14:3454.
[28] Guruprasad K, Reddy BB, Pandit MW (1990) Corre-
lation between stability of a protein and its dipeptide
composition: a novel approach for predicting in vivo sta-
bility of a protein from its primary sequence.
Protein
Engineering, Design and Selection 4:155–161.
[29] Adams RM, Kinney JB, Walczak AM, Mora T (2019)
Epistasis in a fitness landscape defined by antibody-
antigen binding free energy. Cell systems 8:86–93.
[30] Phillips AM, et al.
(2021) Binding affinity landscapes
constrain the evolution of broadly neutralizing anti-
influenza antibodies. eLife 10:e71393.
[31] Poelwijk FJ, Krishna V, Ranganathan R
(2016) The
context-dependence of mutations:
a linkage of for-
malisms. PLoS computational biology 12:e1004771.
[32] Robert PA, et al.
(2022) Unconstrained generation of
synthetic antibody–antigen structures to guide machine
learning methodology for antibody specificity prediction.
Nature Computational Science 2:845–865.
[33] Zeng Y, et al. (year?) Antibody Design with Constrained
Bayesian Optimization.
[34] Gessner A, Ober SW, Vickery O, Ogli´c D, U¸car T (2024)
Active learning for affinity prediction of antibodies. arXiv
preprint arXiv:2406.07263.
[35] Moskovitz T, Parker-Holder J, Pacchiano A, Arbel M,
Jordan M (2021) Tactical optimism and pessimism for
deep reinforcement learning. Advances in Neural Infor-
mation Processing Systems 34:12849–12863.
[36] Xie T, Cheng CA, Jiang N, Mineiro P, Agarwal A (2021)
Bellman-consistent Pessimism for Offline Reinforcement
Learning eds Ranzato M, Beygelzimer A, Dauphin Y,
Liang P, Vaughan JW (Curran Associates, Inc.), Vol. 34,
pp 6683–6694.
[37] Shi L, Li G, Wei Y, Chen Y, Chi Y (2022) Pessimistic q-
learning for offline reinforcement learning: Towards op-
17
timal sample complexity (PMLR), pp 19967–20025.
[38] Koppel A, et al. (2024) Information-Directed Pessimism
for Offline Reinforcement Learning.
[39] Fu L, Niu B, Zhu Z, Wu S, Li W (2012) Cd-hit: acceler-
ated for clustering the next-generation sequencing data.
Bioinformatics 28:3150–3152.
[40] Chennamsetty N, Voynov V, Kayser V, Helk B, Trout
BL
(2010) Prediction of aggregation prone regions of
therapeutic proteins. The Journal of Physical Chemistry
B 114:6614–6624.
[41] Williams CK, Rasmussen CE (2006) Gaussian processes
for machine learning (MIT press Cambridge, MA) Vol. 2.
[42] Lin Z, et al. (2022) Language models of protein sequences
at the scale of evolution enable accurate structure pre-
diction. bioRxiv.
[43] Devlin J (2018) Bert: Pre-training of deep bidirectional
transformers for language understanding. arXiv preprint
arXiv:1810.04805.
[44] Kalchbrenner N, et al. (2016) Neural machine translation
in linear time. arXiv preprint arXiv:1610.10099.
[45] Yang KK, Fusi N, Lu AX (2024) Convolutions are com-
petitive with transformers for protein sequence pretrain-
ing. Cell Systems 15:286–294.
[46] Madan K, et al. (2023) Learning gflownets from partial
episodes for improved convergence and stability (PMLR),
pp 23467–23483.
18
Supplementary information
This section provides supplementary figures that support the main findings described in the document.
B
C
D
A
FIG. S1: A. Empirical Pareto Front on the Sars-Cov-2 task for β = −1 and T −1 ∈[20.0, 25.0, 30.0] B. Empirical Pareto Front
on the Sars-Cov-2 task for β = 0 and T −1 ∈[20.0, 25.0, 30.0] C. Empirical Pareto Front on the Sars-Cov-2 task for β = 1 and
T −1 ∈[20.0, 25.0, 30.0] D. Empirical Pareto Front on the Sars-Cov-2 task for β = 2 and T −1 ∈[20.0, 25.0, 30.0]
A
B
C
FIG. S2: During the training of the GflowNet, for each task (Sars-Cov-2/Simple/Hard) and hyper-parameter choice (β /
w / T −1, we randomly selected 128 sequences generated by Metropolis Hastings on the same task and for the same hyper-
parameter choices and computed the spearman correlation score between the log probability of the sequences being generated
and their score R(x) = ln pHUM −E(x). A. Shows the results on the Sars-Cov-2 task for T −1 = 20.0, w ∈[0.85, 1.0] and
β ∈[−1.0, 0.0, 1.0, 2.0], B. Shows the results on the simple task for T −1 = 10.0, w ∈[0.85, 1.0] and β ∈[−1.0, 0.0, 1.0, 2.0] and
C. shows the results on the hard task for for T −1 = 10.0, w ∈[0.85, 1.0] and β ∈[−1.0, 0.0, 1.0, 2.0]. We can observe that the
Gflownet training converges faster for lower values of β
19
A
B
FIG. S3: Figure A. shows the average and the standard deviation of the charge of the heavy chain sequences generated by
Metropolis Hastings and the GFlowNet for different choices of β. A net charge between -2 and 2 is considered desirable.Figure
B. shows the average and the standard deviation of the instability scores of the heavy chain sequences generated by Metropolis
Hastings and the GFlowNet for different choices of β. An instability score lower than 40 is desirable.
20
E
F
A
B
C
D
FIG. S4: A. Density plots of 1000 sequences sub-sampled from the set generated by Metropolis-Hastings at inverse temperature
T −1 = 20 and β = −1.0. B. Density plots of 1000 sequences sub-sampled from the set generated by the GFlowNet at inverse
temperature T −1 = 20 and β = −1.0 C. Density plots of 1000 sequences sub-sampled from the set generated by Metropolis-
Hastings at inverse temperature T −1 = 20 and β = 1.0. D. Density plots of 1000 sequences sub-sampled from the set generated
by the GFlowNet at inverse temperature T −1 = 20 and β = 1.0, E. Density plots of 1000 sequences sub-sampled from the
set generated by the Metropolis Hastings at inverse temperature T −1 = 20 and β = 2.0, F. Density plots of 1000 sequences
sub-sampled from the set generated by the GFlowNet at inverse temperature T −1 = 20 and β = 2.0
21
C
D
E
F
A
B
FIG. S5: A. Density plots of all distinct sequences sub-sampled from the set generated by Metropolis-Hastings at inverse
temperature T −1 = 10 and β = −1.0 on the hard synthetic task. B. Density plots of 1000 sequences sub-sampled from the set
generated by Metropolis-Hastings at inverse temperature T −1 = 10 and β = 0.0 on the simple synthetic task. C. Density plots
of 1000 sequences sub-sampled from the set generated by Metropolis-Hastings at inverse temperature T −1 = 10 and β = 1.0 on
the simple synthetic task. D. Density plots of 1000 sequences sub-sampled from the set generated by Metropolis-Hastings at
inverse temperature T −1 = 10 and β = 2.0 on the simple synthetic task. E F. Comparison of diversity and novelty for different
choices of β and w.
22
A.
B.
C.
FIG. S6: A. Box plot showing the distribution of KA from the CB-119 binder dataset. B. Box plot showing the distribution of
synthetic affinity faff for the dataset used to train the gaussian process. In addition, we generated 14000 random mutants from
the wild type with 1 to 6 mutations and computed their synthetic affinity faff to estimate the distribution of faff conditioned
on the number of mutations a mutant has. We show the box plots of the empirical distribution. C. Same as B. but for the
hard synthetic task.
23
C
D
Simple Epistasis Model
A
B
Hard Epistasis Model
FIG. S7:
Figure A. shows the number of sequences out the top 20 selected from the set of generated sequences with Metropolis
Hastings when trying to optimize the simple epistasis model with an affinity above a certain thresholds for different choices of
β and w. We compare those results to the set of sequences in the training set, indicated as initial. B shows the percentage
of sequences that are above a certain threshold and also have a predicted solubility score above 3. Figure C. and D. show the
results when trying to optimize the hard epistasis model.
24
Hard Epistasis Model
C
D
A
B
Simple Epistasis Model
FIG. S8:
Figure A shows the number of sequences out the top 20 selected from the set of sequences generated for different
choices of β and generative method (Metropolis Hastings and GFlowNet). We compare those results to the set of sequences
generated by the local search procedure of antBO and the set of sequences used to train the Gaussian Process affinity predictor,
indicated as initial. B shows the percentage of sequences that are above a certain threshold and also have a predicted solubility
score above 3. Figure C and D show the results when trying to optimize the hard epistasis model.
