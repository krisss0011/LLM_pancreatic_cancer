Multi-Tiered Self-Contrastive Learning for Medical Microwave
Radiometry (MWR) Breast Cancer Detection
Christoforos Galazis1, Huiyi Wu2, and Igor Goryanin3,4,5,*
1Department of Computing, Imperial College London, London, United Kingdom
2National Heart & Lung Institute, Imperial College London, London, United
Kingdom
3School of Informatics, University of Edinburgh, Edinburgh, United Kingdom
4Okinawa Institute Science and Technology, Okinawa, Japan
5MMWR LTD, United Kingdom
*igor.goryanin@ed.ac.uk
Abstract
The pursuit of enhanced breast cancer detection and monitoring techniques is a paramount
healthcare objective, driving the need for innovative imaging technologies and diagnostic ap-
proaches. This study introduces a novel multi-tiered self-contrastive model tailored for the ap-
plication of microwave radiometry (MWR) breast cancer detection. Our approach encompasses
three distinct models: Local-MWR (L-MWR), Regional-MWR (R-MWR), and Global-MWR
(G-MWR), each engineered to analyze varying sub-regional comparisons within the breasts.
These models are cohesively integrated through the Joint-MWR (J-MWR) network, which
leverages the self-contrastive data generated at each analytical level to enhance detection ca-
pabilities. Employing a dataset comprising 4,932 cases of female patients, our research show-
cases the effectiveness of our proposed models. Notably, the J-MWR model distinguishes it-
self by achieving a Matthews correlation coefficient of 0.74 ± 0.018, surpassing existing MWR
neural networks and contrastive methods. These results highlight the significant potential of
self-contrastive learning techniques in improving both the diagnostic accuracy and generaliz-
ability of MWR-based breast cancer detection processes. Such advancements hold consider-
able promise for further investigative and clinical endeavors. The source code is available at:
https://github.com/cgalaz01/self_contrastive_mwr
Keywords
Self-contrastive learning; Hierarchical neural networks; Medical microwave radiom-
etry; Point-of-care testing; Breast cancer detection
1
Introduction
Breast cancer, marked by the uncontrolled and rapid growth of cells due to genetic mutations,
significantly impacts global health, as it records one of the highest incidence rates of cancer. In 2020
alone, it was estimated to account for 2.3 million new cases, becoming the primary cause of death
among women with nearly 700,000 deaths [1]. Disturbingly, future forecasts suggest a continued rise
in both the occurrence and death rates associated with breast cancer [2].
The pivotal role of early detection in reducing mortality rates and reducing the healthcare load
cannot be overstated.
In this context, Microwave Radiometry (MWR) emerges as a promising
imaging modality that passively captures the natural microwave emissions of human tissues [3]. Its
utility spans a broad spectrum of clinical areas, including but not limited to, the breasts [3, 4, 5, 6],
brain [7, 8], lungs [9], veins [10], and musculoskeletal structures [11]. Within the domain of breast
cancer screening, MWR leverages the fact that cancerous tissues, due to their increased metabolic
rate, emit more heat than normal tissue [4]. Its advantages and manifold, offering non-invasive, safe,
mobile, and economical options for diagnosis. However, the relatively novel integration of MWR
into breast cancer diagnostics introduces challenges, particularly in data interpretation and the
integration of this technology into existing medical workflows. Overcoming these hurdles necessitates
the deployment of artificial intelligence (AI) models to refine and streamline the application of MWR
in a clinical setting.
1
arXiv:2410.04636v1  [eess.IV]  6 Oct 2024
In the landscape of algorithmic advancements, the last few years have witnessed a surge in ef-
forts to refine MWR breast cancer diagnostic accuracy through various machine-learning models
and neural networks.
Studies from [12, 13, 14] have shed light on the potency of conventional
machine learning strategies, including support vector machines (SVM), random forest algorithms,
and Bayesian classifiers, in enhancing diagnostic precision.
Parallel to these conventional meth-
ods, a range of neural networks have been evaluated and found to deliver promising outcomes, as
documented in [12, 13, 15, 16].
Taking a step further, research from [17] proposed a learnable architecture designed not only to
bolster diagnostic accuracy but also to pave the way for more efficient, lightweight neural network
structures for MWR. This approach underscores a pivotal shift towards creating more resource-
efficient models without compromising performance.
Furthermore, [6] combined Kohonen’s self-
organizing maps with machine learning algorithms, marking a noteworthy stride towards improving
the efficacy of these systems. Additionally, the domain of fuzzy analysis has not been left untapped,
with studies [18, 19] delving into its applicability and effectiveness.
Before data-driven methods were utilized, a set of hand-engineered features had been proposed
[20, 21, 5] based on prior knowledge to identify temperature disparities within the breast. These
features, aimed at mammary gland analysis, can be categorized into five groups: 1) temperature
asymmetry between the two glands; 2) increased temperature dispersion within a single gland;
3) detection of abnormally high temperatures in the nipple compared to other gland areas; 4)
relationship between surface and depth temperature measurements; and 5) features derived from
comparing the two glands.
On the other hand, in supervised learning the emphasis lies in comparing across samples of the
dataset [22] rather than within the sample itself. This approach is termed supervised contrastive
learning, where the learned embedding representation of the data ensures that instances with the
same label are brought closer together, while those with different labels are pushed further apart.
Research in this domain has predominately focused on how to sample the pair to compare against
within the batch. The simplest form is the contrastive loss [23], in which a random negative sample
is taken.
This has been extended to a triplet loss [24, 25], in which a positive and negative is
sampled. A further extension is an N-pair loss [26] where one positive is taken and N −1 negative
samples. One of the advantages of employing this learning strategy is the enhanced performance
and generalizability of the resulting models [22].
However, despite notable advancements in developing models for MWR breast cancer detection,
a critical challenge persists in the seamless integration of data-driven methodologies with existing
knowledge, including hand-engineered features [20, 21]. The incorporation of such prior knowledge
into the models is pivotal to improving the performance and generalizability. Such advancements
are paramount for MWR’s application in the clinical setting amidst varying and evolving conditions.
In this paper, we introduce a novel supervised neural network known as the Joint-MWR (J-
MWR), which embodies hierarchical self-contrastive models. Unlike traditional approaches, it learns
by comparing different regions within itself rather than across different cases. This innovative model
aims to enhance the analysis of sub-regions across both breasts through a unified structure. Our
methodology employs a tri-tiered comparative analysis strategy to enhance the detection capabilities
of the MWR breast cancer detection system. We demonstrate that the J-MWR surpasses both the
state-of-the-art MWR model and widely used batch-wise contrastive learning methods, highlighting
its superior performance.
At the initial stage, the Local-MWR (L-MWR) comparison occurs, where each point within the
breast undergoes comparison against every other point, enabling a detailed analysis. The next tier,
Regional-MWR (R-MWR), focuses on comparing corresponding points between the two breasts,
aiming to identify symmetry or anomalies between them. Finally, at the Global-MWR (G-MWR)
tier, each breast undergoes mirroring, swapping roles to contrast and compare, thereby revealing
subtle variations and collective patterns.
This layered approach replicates traditional comparison techniques utilized in hand-engineered
feature extraction within a data-centric framework.
Consequently, it enriches the MWR breast
cancer detection system with enhanced robustness and adaptability, rendering it a more versatile
tool in combating breast cancer.
In summary, our contributions are twofold: 1) We introduce a novel supervised multi-tiered self-
contrastive framework, enabling comparison of regions within itself, and 2) We evaluate, for the first
time, the performance of batch-wise contrastive learning on a large MWR dataset.
2
2
Materials and Methods
2.1
Data
The data for this study was gathered using the point-of-care MWR-2020 dual-band device manu-
factured by MMWR Ltd1. This device monitors both infrared (skin temperature) and microwave
(internal tissue temperature) emissions. Operating within a microwave frequency range of 3.5 to
4.2 GHz, it can penetrate tissues to depths ranging from 3 to 7 cm. The acquisition accuracy for
temperature measurements obtained from the infrared and microwave antennas is within ±0.2◦C.
Each case in the study involved the measurement of 22 locations, which can be seen in Figure 1.
Specifically, for each breast, eight points were measured equidistantly around the nipple, including
the nipple itself. Additionally, a single point was measured in the left and right axillary reference
regions. Two additional points were recorded under the chest to serve as reference points. At each
of these 22 locations, both skin and internal temperatures were recorded, resulting in a total of 44
temperature readings per case, which serve as the models’ input.
Figure 1: An illustration of the skin and internal acquisition points on the breasts. Point 0 is on the
nipple, points 1-8 are equidistantly around the nipple, point 9 is on the axillary region, and points
T1 and T2 are under the chest.
The data was collected with ethical approval, and consent from participants and fully anonymized.
In total, the dataset comprises measurements from 4,932 female cases across multiple clinical centers.
Among these cases, 4,384 were deemed healthy by clinical experts, while the remaining 548 were
classified as cancerous, with an example of each can be seen in Figure 2. The data was randomly
class-balanced split into training, validation, and testing sets, constituting 60%, 20%, and 20% of
the entire dataset, respectively. Model evaluation was conducted on the test set, with test results
generated upon completion of the development and experimentation phases.
Figure 2: Comparison of internal breast temperature profiles between a healthy (Panel A) and
high growth rate cancerous (Panel B) case. In the healthy instance, no significant temperature
asymmetries are evident. However, in the cancerous case, notably elevated temperatures are observed
in regions 1 and 8 of the left-hand side gland.
1https://www.mmwr.co.uk/
3
2.2
Models
We standardized the model settings utilized across all presented models. Initialization of model
weights employed Glorot uniform initialization [27], with initial biases set to 0. Weight optimization
utilized the Adam optimizer [28] with an initial learning rate of 0.0001, and the remaining param-
eters, β1, and β2 set to 0.9 and 0.999, respectively. The learning rate was reduced by a factor of
0.1 if the validation loss did not decrease after 5 epochs. A batch size of 4 was determined to be
suitable for all evaluated models. The weights were updated based on the class-balanced binary
cross-entropy loss.
2.3
Base Model
To streamline our approach, we introduce a fundamental building block called the MWR-Block,
which is a residual fully connected (FC) component outlined in Figure 3A. Each MWR-Block consists
of an FC layer, layer normalization, a Rectified Linear Unit (ReLU) activation function [29], another
FC layer, layer normalization, ReLU, and addition with the block’s input.
Our baseline model, hereafter defined as the ”base model”, is the neural network proposed in
[12]. However, to accommodate the larger dataset under evaluation, we made adjustments to the
base model’s parameters. Specifically, it now comprises 4 MWR-Blocks, each FC layer containing
256 units. The output FC layer of unit size 1 uses a sigmoid activation function.
2.4
Self-Contrastive MWR Neural Networks
Inward learning, not outward wandering Our proposed models utilize self-contrastive learning
to optimize the embedding space for distinguishing between healthy and cancerous samples. The
embedding space of healthy and cancerous cases is pushed to distinct clusters. Unlike traditional
contrastive learning methods, our approach focuses on features within individual cases rather than
across samples.
Figure 3: Overview of the proposed multi-tiered self-contrastive MWR models for breast cancer
detection. A) The common residual block used in all networks, MWR-Block. B) L-MWR network
that compares all individual points between them. C) R-MWR network that compares between the
left and right breasts. D) G-MWR network that compares both breasts with their positional inverse
self. E) J-MWR network that combines all previous models to obtain a new prediction.
2.4.1
L-MWR Neural Network
The Local-MWR (L-MWR) network processes each temperature point individually, excluding ref-
erence measurements, resulting in 18 inputs, each consisting of skin and internal values (see Figure
4
3B). The network is structured into feature extraction and feature comparison. Feature extraction
involves 4 MWR-Blocks, followed by a single unit FC layer with ReLU activation, in which the
weights are shared. Small activations below a learnable threshold are filtered to 0. Feature com-
parison computes the mean absolute feature differences between pairwise inputs. The prediction is
obtained through a single unit FC layer with the tanh activation function, as the activations are
already bound below to 0.
2.4.2
R-MWR Neural Network
The Regional-MWR (R-MWR) network compares left and right breasts as self-contrastive regions
(see Figure 3C), with 2 inputs of vector size 24 each, including respective breast and reference points.
Shared feature extraction includes 4 MWR-Blocks with 256 units, followed by an FC layer with
ReLU activation, and l2 normalization. Element-wise absolute differences are computed, filtered,
and summed for comparison. Prediction is generated via a single unit FC layer with tanh activation.
2.4.3
G-MWR Neural Network
The Global-MWR (G-MWR) network utilizes features from both breasts (see Figure 3D). However,
to perform self-contrastive learning, we use as the second input the inverse positions, in which the
values of the left breast are used as the right and vice versa. Thus, G-MWR takes two pairs of input,
each of size 44, and uses the same architecture as R-MWR, described in section 2.4.2.
2.4.4
J-MWR Neural Network
The Joint-MWR (J-MWR) network combines the L-MWR (section 2.4.1), R-MWR (section 2.4.2),
and G-MWR (section 2.4.3) pre-trained models to leverage their complementary features (see Figure
3E). Weighted outputs from each sub-network, using individual FC layers, are concatenated and
passed through a final single unit FC layer with tanh activation. As we are only fine-tuning the
weights of the sub-networks, the learning rate was reduced to 1e−7.
2.5
Experiments
In our experiments, we conducted three model executions with different initialization seeds, and the
reported results represent the average across these three seeds on the test set. The model evaluation
is based on the Matthews correlation coefficient (MCC) to assess the performance of imbalanced
data when we consider both positive and negative cases equally important [30]. We also assessed
the accuracy and receiver operating characteristic (ROC) area under the curve (AUC) for the main
results as a reference. Our analysis involved comparing our proposed self-contrastive models with
commonly used batch-wise contrastive losses, both individually and in combination.
Specifically, we utilized contrastive loss [23], triplet hard loss [24], triplet semi-hard loss [25], and
N-pairs loss [26], where N is the number of negatives in the batch. The weight assigned to the batch-
wise contrastive losses was experimentally determined to be 0.1, while the weight for cross-entropy
classification remained at 1.0.
3
Results
3.1
Model Evaluation
Our proposed J-MWR model has the highest predictive capabilities in correctly identifying breast
cancer from MWR data. It obtains an MCC score of 0.74 ± 0.018, a 0.08 margin from the second-
best performing model, R-MWR. This translates to an accuracy of 0.95 ± 0.003 and an ROC AUC
of 0.96 ± 0.001. In comparison, the base model obtains an MCC score of 0.58 ± 0.004, an accuracy
of 0.88 ± 0.003, and an ROC AUC of 0.93 ± 0.006. The results for all models can be seen in Table
1.
We can consider J-MWR as a meta-classifier of the sub-networks. In this case, when we compare
individual models, we can observe that both R-MWR and G-MWR outperform the base model with
an MCC of 0.66 ± 0.012 and 0.61 ± 0.045, respectively. L-MWR is the only model that performs
substantially worse than the base model, with an MCC score of 0.43 ± 0.002. This is expected as
the model only learns features from a single point.
5
Table 1: The mean and standard deviation of accuracy, MCC, and ROC AUC for the base model,
and the proposed models L-MWR, R-MWR, G-MWR, and J-MWR.
Model
Accuracy
MCC
ROC AUC
Base
0.88 ± 0.003
0.58 ± 0.004
0.93 ± 0.006
L-MWR
0.82 ± 0.002
0.43 ± 0.002
0.89 ± 0.001
R-MWR
0.92 ± 0.003
0.66 ± 0.012
0.95 ± 0.006
G-MWR
0.90 ± 0.021
0.61 ± 0.045
0.94 ± 0.016
J-MWR
0.95 ± 0.003
0.74 ± 0.018
0.96 ± 0.001
3.2
Batch-wise Contrastive Loss Evaluation
When employing batch-wise contrastive loss, J-MWR with triplet hard loss achieves the highest per-
formance, as illustrated in Table 2, with an MCC score of 0.74 ± 0.03. Overall, J-MWR consistently
achieves the highest MCC score compared to other models, regardless of the batch-wise contrastive
loss used.
However, none of the configurations surpass J-MWR without batch-wise contrastive
learning.
Interestingly, both R-MWR and J-MWR experience a reduction in MCC score when utilizing
batch-wise contrastive learning. On the other hand, L-MWR shows a slight improvement of 0.01,
while G-MWR demonstrates an improvement ranging from 0.03 to 0.06. The base model also benefits
from contrastive and N-pairs losses, with an MCC score increase of 0.02 for both configurations.
Table 2: The mean and standard deviation MCC results of each model when trained using a batch-
wise contrastive loss (contrastive, N-pairs, triplet hard, and triplet semi-hard). MCC values in bold
indicate an improvement over their non-batch-wise loss counterparts.
Model
MCC
Contrastive
N-pairs
Triplet hard
Triplet semi-hard
Base
0.60 ± 0.024
0.60 ± 0.035
0.57 ± 0.016
0.51 ± 0.149
L-MWR
0.44 ± 0.003
0.44 ± 0.001
0.44 ± 0.004
0.44 ± 0.008
R-MWR
0.63 ± 0.060
0.59 ± 0.019
0.60 ± 0.026
0.64 ± 0.025
G-MWR
0.65 ± 0.005
0.64 ± 0.012
0.64 ± 0.022
0.67 ± 0.017
J-MWR
0.71 ± 0.000
0.71 ± 0.029
0.74 ± 0.030
0.70 ± 0.081
3.3
Embedding Space
In this analysis, we explore the properties and characteristics of the embedding space generated by
the L-MWR, R-MWR, G-MWR, and base contrastive models. The 2D projections of the embedding
spaces can be observed in Figure 4. Our findings reveal that the base contrastive model, in com-
parison to our proposed models, excels at delineating a clearer boundary between the healthy and
cancerous groups, with a mean between-class distance of 6.57 ± 3.71. This result is expected, given
its explicit training for this task. However, notable disparities within the groups emerge, as reflected
by a mean within-class distance of 4.53 ± 2.85, contributing to its relatively lower performance.
Our proposed models, despite being trained on comparing features within themselves, we observe
that cancerous cases tend to have similar embedding properties across cases. However, these cases
are more intertwined with the healthy cases, making it challenging to discern a clear boundary
between them. For instance, R-MWR demonstrates a mean within-class distance of 2.93 ± 1.46
and a mean between-class distance of 3.94 ± 1.17. This close proximity of each group sufficiently
mitigates the lack of a clear boundary, thereby improving performance.
These findings suggest the potential for the two methods, self-contrastive and batch-wise con-
trastive, to complement each other and further enhance performance.
3.4
Data Constraint Training
We retrained the models using randomly selected subsets of the training set at 75%, 50%, and 25%.
This approach allows us to gauge how the models perform when trained with limited data, offering
insights into their scalability as more data becomes available. The performance of the models is
summarized in Figure 5a. J-MWR consistently demonstrates the highest MCC across all subsets,
6
(a)
(b)
(c)
(d)
Figure 4: Uniform Manifold Approximation and Projection (UMAP) [31] embedding visualizations
of (a) L-MWR, (b) R-MWR, (c) G-MWR, and (d) base contrastive are presented. In each figure,
a blue circle indicates a correct healthy prediction, a yellow square signifies a correct cancerous
prediction and a red cross overlaid on the previous cases indicates a respective incorrect prediction.
(a)
(b)
Figure 5: (a) MCC scores of each of the models as the training size is reduced to 75%, 50%, and
25% of the original size. (b) MCC scores of the models as the batch size changes from 1 to 128.
obtaining its lowest value of 0.59±0.001 at 25%. In contrast, the base contrastive model exhibits its
lowest performance at 50% and 25% training percentages but notably improves at 75%. Remarkably,
L-MWR maintains a consistent level of performance regardless of the reduction in training data
size. Between 75% to 100% of the training data, R-MWR shows the highest performance gain of 0.1
MCC, highlighting its effective utilization of additional data, which also reflects upon J-MWR. The
7
performance of the remaining models appears to plateau as more training data is added.
3.5
Batch Size Dependency
In our investigation into the impact of batch size on performance, we analyzed values ranging from
1 to 128. J-MWR consistently outperforms other models, achieving its peak MCC at a batch size of
4 with a value of 0.74 ± 0.018, followed by a gradual decline, as shown in Figure 5b. Notably, while
most models experienced a decline in performance with increasing batch size, the base contrastive
model maintained near-consistent performance levels, a trend we anticipate extending to larger batch
sizes.
This suggests that, for self-contrastive models, smaller batch sizes are preferable, although this
comes with a trade-off between training speed and accuracy.
Smaller batches may yield higher
accuracy but result in longer training times. In contrast, batch-wise contrastive losses for MWR are
less influenced by batch size.
3.6
Generalizability
(a)
(b)
(c)
(d)
Figure 6: MCC scores of the models as we add increasing amounts of Gaussian noise (a), randomly
set points to the mean of the remaining (b), shift all the temperatures by a given amount (c) and
rotate the points around the nipple of each breast (d).
To assess the generalizability of our trained models, we subjected them to an augmented test
set comprising various out-of-distribution transformations. These transformations included adding
Gaussian noise (Figure 6a), applying dropout to the temperature points and setting their value to
the mean of the remaining points (Figure 6b), adjusting the temperature of all values (Figure 6c),
and rotating the breast points around the nipple (Figure 6d).
As depicted in Figure 6, J-MWR consistently demonstrated better generalization performance,
evidenced by its higher MCC score compared to other models, both in the presence of data corrup-
tions (Figures 6a and 6b) and data drifts (Figures 6c and 6d). However, when subjected to large
Gaussian noise (σ > 0.25), R-MWR showed greater resilience. This decline in J-MWR’s perfor-
mance can be attributed to the poorer performance of G-MWR under noisy conditions. We note
that while L-MWR shows the smallest changes across the different transformations its performance
8
remains low at around 0.43 MCC. However, under some conditions (see Figure 6) it can outperform
the base, base contrastive, and/or G-MWR models.
Overall, these findings underscore the robustness of J-MWR in handling various forms of data
perturbations, albeit with some sensitivity to specific types of noise. Comparing regions within the
individual case rather than across samples allows it to better generalize to unknown distributions.
3.7
Ensemble Methods
In the J-MWR network, each sub-network contributes almost equally to the final prediction. Specif-
ically, the L-MWR, with a weight of 0.998, holds comparable significance to both the R-MWR and
G-MWR networks, each possessing weights close to 1.0. Moreover, their biases are all approximately
0. From Figure 7, it is apparent that J-MWR surpasses other ensemble techniques, including aver-
aging and majority voting, as well as meta-classifiers such as logistic regression, SVM, and decision
tree. While J-MWR bears a resemblance to averaging voting, the fine-tuning step applied to the
sub-networks enables substantial enhancement in MCC performance.
When averaging the predictions of L-MWR, R-MWR, and G-MWR, the second-best MCC value
of 0.66 ± 0.02 is achieved, which is comparable to that obtained from R-MWR alone. Following
closely is the majority voting approach. Notably, despite best efforts, the remaining meta-classifiers
exhibited overfitting to the training data, leading to a large decline in MCC performance on the test
set.
Figure 7: MCC scores on different ensemble methods using the pre-trained L-MWR, R-MWR, and
G-MWR models.
4
Discussion
In this study, we have demonstrated the successful adaptation of self-contrastive learning to tackle
MWR breast cancer detection.
Our proposed architectures, namely L-MWR, R-MWR, and G-
MWR, offer a novel approach to integrating hand-engineered features capturing thermal asymmetries
alongside data-driven methods. Our combined model, J-MWR, achieves an MCC score of 0.74±0.018
surpassing all existing models, showcasing its efficacy in detecting breast cancer with high accuracy
and generalizability. This underscores the potential of self-contrastive learning in enhancing the
performance of breast cancer detection systems.
The final layer of J-MWR acts as an ensemble averaging due to the weights of each sub-network
being near 1. However, J-MWR gains an improvement of 0.08 MCC compared to the traditional
ensemble averaging.
This improvement is attributed to the fact that J-MWR serves as a fine-
tuning meta-classifier. Specifically, it enables the indirect sharing of information between each self-
contrastive tier, thereby enhancing performance. However, it’s important to note that this benefit
comes at the cost of increased model complexity.
Furthermore, batch-wise contrastive learning, while it only contributed to minor improvements,
we see potential in its use.
It presents a minimally disruptive enhancement to existing MWR
models. Our future efforts will focus on refining positive and negative sampling strategies tailored
to physiological characteristics, thus advancing beyond mere classification considerations. Its current
subpar performance can be attributed to the inherent variability in breast temperature readings,
influenced by factors such as age and menstrual cycle phase [3].
9
Furthermore, while batch-wise contrastive learning only resulted in minor improvements, we
recognize its potential value. It offers a minimally disruptive enhancement to existing MWR models.
Our future efforts will concentrate on refining positive and negative sampling strategies tailored to the
physiological characteristics of the breasts, thus advancing beyond mere classification considerations.
The current subpar performance of batch-wise contrastive learning can be attributed to the inherent
variability in breast temperature readings, influenced by factors such as age and menstrual cycle
phase [3].
5
Conclusion
Our research presents promising advancements in MWR breast cancer detection, offering potential
clinical benefits and avenues for future exploration. Moving forward, further refinement through
NAS and tailored sampling strategies holds promise for further enhancing diagnostic accuracy. Ad-
ditionally, evaluating our proposed model across various anatomical locations and under different
physiological conditions will be crucial for expanding its applicability and effectiveness in diverse
clinical settings. To further improve breast cancer predictions, we aim to adapt our proposed self-
contrastive learning approach by including mammogram, gene expression, miRNA and other multi-
omics data.
References
[1] H. Sung, J. Ferlay, R. L. Siegel, M. Laversanne, I. Soerjomataram, A. Jemal, and F. Bray,
“Global cancer statistics 2020: Globocan estimates of incidence and mortality worldwide for 36
cancers in 185 countries,” CA: a cancer journal for clinicians, vol. 71, no. 3, pp. 209–249, 2021.
[2] M. Arnold, E. Morgan, H. Rumgay, A. Mafra, D. Singh, M. Laversanne, J. Vignat, J. R. Gralow,
F. Cardoso, S. Siesling, and I. Soerjomataram, “Current and future burden of breast cancer:
Global statistics for 2020 and 2040,” The Breast, vol. 66, pp. 15–23, 2022.
[3] I. Goryanin, S. Karbainov, O. Shevelev, A. Tarakanov, K. Redpath, S. Vesnin, and Y. Ivanov,
“Passive microwave radiometry in biomedical studies,” Drug Discovery Today, vol. 25, no. 4,
pp. 757–763, 2020.
[4] S. Vesnin, A. K. Turnbull, J. M. Dixon, and I. Goryanin, “Modern microwave thermometry for
breast cancer,” J. Mol. Imaging Dyn, vol. 7, no. 2, p. 1000136, 2017.
[5] L. Fisher, O. Fisher, D. Chebanov, S. Vesnin, A. Goltsov, A. Turnbull, M. Dixon, I. Ku-
daibergenova, B. Osmonov, S. Karbainov, L. Popov, A. Losev, and I. Goryanin, “Passive mi-
crowave radiometry and microrna detection for breast cancer diagnostics,” Diagnostics, vol. 13,
no. 1, p. 118, 2022.
[6] A. V. Khoperskov and M. V. Polyakov, “Improving the efficiency of oncological diagnosis of the
breast based on the combined use of simulation modeling and artificial intelligence algorithms,”
Algorithms, vol. 15, no. 8, p. 292, 2022.
[7] O. Shevelev, M. Petrova, A. Smolensky, B. Osmonov, S. Toimatov, T. Kharybina, S. Karbainov,
L. Ovchinnikov, S. Vesnin, A. Tarakanov, and I. Goryanin, “Using medical microwave radiom-
etry for brain temperature measurements,” Drug discovery today, vol. 27, no. 3, pp. 881–889,
2022.
[8] O. A. Shevelev, M. V. Petrova, E. M. Mengistu, M. Y. Yuriev, I. Z. Kostenkova, S. G. Vesnin,
M. M. Kanarskii, M. A. Zhdanova, and I. Goryanin, “Correction of local brain temperature after
severe brain injury using hypothermia and medical microwave radiometry (mwr) as companion
diagnostics,” Diagnostics, vol. 13, no. 6, p. 1159, 2023.
[9] B. Osmonov, L. Ovchinnikov, C. Galazis, B. Emilov, M. Karaibragimov, M. Seitov, S. Vesnin,
A. Losev, V. Levshinskii, I. Popov, C. Mustafin, T. Kasymbekov, and I. Goryanin, “Passive
microwave radiometry for the diagnosis of coronavirus disease 2019 lung complications in kyr-
gyzstan,” Diagnostics, vol. 11, no. 2, p. 259, 2021.
[10] V. Levshinskii, C. Galazis, A. Losev, T. Zamechnik, T. Kharybina, S. Vesnin, and I. Goryanin,
“Using ai and passive medical radiometry for diagnostics (mwr) of venous diseases,” Computer
Methods and Programs in Biomedicine, vol. 215, p. 106611, 2022.
10
[11] A. V. Tarakanov, E. S. Ladanova, A. A. Lebedenko, T. D. Tarakanova, S. G. Vesnin, T. Khary-
bina, and I. I. Goryanin, “Passive microwave radiometry as a component of imaging diagnostics
in juvenile idiopathic arthritis,” Rheumato, vol. 2, no. 3, pp. 55–68, 2022.
[12] V. Levshinskii, C. Galazis, L. Ovchinnikov, S. Vesnin, A. Losev, and I. Goryanin, “Application of
data mining and machine learning in microwave radiometry (mwr),” in Biomedical Engineering
Systems and Technologies: 12th International Joint Conference, BIOSTEC 2019, Prague, Czech
Republic, February 22–24, 2019, Revised Selected Papers 12.
Springer, 2020, pp. 265–288.
[13] C. Galazis, S. Vesnin, and I. Goryanin, “Application of artificial intelligence in microwave
radiometry (mwr).” in Bioinformatics, 2019, pp. 112–122.
[14] A. Losev, I. Popov, A. Y. Petrenko, A. Gudkov, S. Vesnin, and S. Chizhikov, “Some methods
for substantiating diagnostic decisions made using machine learning algorithms,” Biomedical
Engineering, vol. 55, no. 6, p. 442, 2022.
[15] A. G. Losev, D. A. Medevedev, and A. V. Svetlov, “Neural networks in diagnosis of breast
cancer,” in ”Smart Technologies” for Society, State and Economy 13.
Springer, 2021, pp.
220–227.
[16] A. G. Losev and A. V. Svetlov, “Artificial intelligence algorithms in diagnosis of breast can-
cer,” in New Technology for Inclusive and Sustainable Growth: Perception, Challenges and
Opportunities.
Springer, 2022, pp. 175–182.
[17] J. Li, C. Galazis, L. Popov, L. Ovchinnikov, T. Kharybina, S. Vesnin, A. Losev, and I. Goryanin,
“Dynamic weight agnostic neural networks and medical microwave radiometry (mwr) for breast
cancer diagnostics,” Diagnostics, vol. 12, no. 9, p. 2037, 2022.
[18] I. Germashev, V. Dubovskaya, A. Losev, and I. Popov, “Fuzzy inference of the effectiveness
factors of the computational model for the diagnosis of breast cancer,” in 2021 3rd International
Conference on Control Systems, Mathematical Modeling, Automation and Energy Efficiency
(SUMMA).
IEEE, 2021, pp. 528–533.
[19] I. Germashev, V. Dubovskaya, and A. Losev, “Hierarchical fuzzy inference of adequacy of highly
informative diagnostic signs of breast cancer,” in Society 5.0: Cyber-Solutions for Human-
Centric Technologies.
Springer, 2023, pp. 31–41.
[20] A. Zenovich, V. Glazunov, A. Oparin, and F. Primachenko, “Algoritmy prinyatiya resheniy v
konsultativnoy intellektualnoy sisteme diagnostiki molochnykh zhelez [algorithms of decision-
making in intelligent advisory system for diagnostics of the mammary glands],” Vestnik Vol-
gogradskogo gosudarstvennogo universiteta. Seriya 1, Matematika. Fizika, pp. 129–142, 2016.
[21] A. Losev and V. Levshinskiy, “Intellektualnyy analiz termometricheskikh dannykh v diagnostike
molochnykh zhelez [the thermometry data mining in the diagnostics of mammary glands],”
Upravlenie bolshimi sistemami, no. 70, pp. 113–135, 2017.
[22] P. Khosla, P. Teterwak, C. Wang, A. Sarna, Y. Tian, P. Isola, A. Maschinot, C. Liu, and
D. Krishnan, “Supervised contrastive learning,” Advances in neural information processing
systems, vol. 33, pp. 18 661–18 673, 2020.
[23] R. Hadsell, S. Chopra, and Y. LeCun, “Dimensionality reduction by learning an invariant
mapping,” in 2006 IEEE computer society conference on computer vision and pattern recognition
(CVPR’06), vol. 2.
IEEE, 2006, pp. 1735–1742.
[24] A. Hermans, L. Beyer, and B. Leibe, “In defense of the triplet loss for person re-identification,”
arXiv preprint arXiv:1703.07737, 2017.
[25] F. Schroff, D. Kalenichenko, and J. Philbin, “Facenet: A unified embedding for face recogni-
tion and clustering,” in Proceedings of the IEEE conference on computer vision and pattern
recognition, 2015, pp. 815–823.
[26] K. Sohn, “Improved deep metric learning with multi-class n-pair loss objective,” Advances in
neural information processing systems, vol. 29, 2016.
[27] X. Glorot and Y. Bengio, “Understanding the difficulty of training deep feedforward neural
networks,” in Proceedings of the thirteenth international conference on artificial intelligence
and statistics.
JMLR Workshop and Conference Proceedings, 2010, pp. 249–256.
11
[28] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” arXiv preprint
arXiv:1412.6980, 2014.
[29] V. Nair and G. E. Hinton, “Rectified linear units improve restricted boltzmann machines,”
in Proceedings of the 27th international conference on machine learning (ICML-10), 2010, pp.
807–814.
[30] D. Chicco and G. Jurman, “The advantages of the matthews correlation coefficient (mcc) over
f1 score and accuracy in binary classification evaluation,” BMC genomics, vol. 21, pp. 1–13,
2020.
[31] L. McInnes, J. Healy, and J. Melville, “Umap: Uniform manifold approximation and projection
for dimension reduction,” arXiv preprint arXiv:1802.03426, 2018.
12
