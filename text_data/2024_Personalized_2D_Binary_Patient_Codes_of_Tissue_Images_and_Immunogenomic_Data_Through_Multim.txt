Personalized 2D Binary Patient Codes of Tissue
Images and Immunogenomic Data Through
Multimodal Self-Supervised Fusion
Areej Alsaafin†, Abubakr Shafique†, Saghir Alfasly†,
H.R.Tizhoosh†*
† KIMIA Lab, Dept. of Artificial Intelligence & Informatics,
Mayo Clinic, Rochester, MN, USA.
* Corresponding author: tizhoosh.hamid@mayo.edu.
Abstract
The field of medical diagnostics has witnessed a transformative convergence of
artificial intelligence (AI) and healthcare data, offering promising avenues for
enhancing patient care and disease comprehension. However, this integration
of multimodal data, specifically histopathology whole slide images (WSIs) and
genetic sequencing data, presents unique challenges due to modality dispari-
ties and the need for scalable computational solutions. This paper addresses
the scarcity of multimodal solutions, primarily centered around unimodal data
solutions, thus limiting the realization of the rich insights that can be derived
from integrating images and genomic data. Here, we introduce MarbliX “Mul-
timodal Association and Retrieval with Binary Latent Indexed matriX,” an
innovative multimodal framework that integrates histopathology images with
immunogenomic sequencing data, encapsulating them into a concise binary
patient code, referred to as “monogram.” This binary representation facilitates
the establishment of a comprehensive archive, enabling clinicians to match similar
cases. The experimental results demonstrate the potential of MarbliX to empower
healthcare professionals with in-depth insights, leading to more precise diagnoses,
reduced variability, and expanded personalized treatment options, particularly in
the context of cancer.
1
arXiv:2409.13115v1  [eess.IV]  19 Sep 2024
1 Introduction
The traditional diagnosis of cancer primarily relies on the microscopic examination
of tissue slides. However, over recent decades, the diagnostic process has undergone
a transformation with the integration of molecular tests. This evolution has led to
more precise grading and prognosis for cancer patients. While molecular assays have
made remarkable strides in various aspects, the intricate task of assessing tissue mor-
phology still falls within the realm of skilled pathologists. The landscape of cancer
diagnosis is currently experiencing a rapid shift, largely driven by the advent of dig-
ital pathology. Machine learning techniques have the potential to revolutionize the
clinical workflow. While traditional approaches may focus solely on morphological fea-
tures in histopathology whole slide images (WSIs) when studying tumors in a given
sample case, recent advancements in machine learning techniques have expanded our
ability to extract valuable insights from complex molecular data. Generally, relying
solely on morphological features to understand cancer may provide an incomplete pic-
ture. However, with the advent of deep learning, researchers have gained the ability
to delve deeper into the molecular and genetic aspects of cancer. For instance, deep
learning models can analyze extensive biological sequence databases, uncovering intri-
cate patterns and associations that might have been overlooked using conventional
methods.
In the domain of cancer immunogenomics, the adaptive immune system has demon-
strated its remarkable ability to detect tumor antigens at an early stage, initiating a
defense against cancer cells [1, 2]. This immune response involves the proliferation of
tumor antigen-specific T lymphocytes (T cells) and B lymphocytes (B cells), which
play pivotal roles in the fight against cancer [3]. Similarities found in both T cell
receptor (TCR) and B cell receptor (BCR) sequences, which are protein complexes
located on the surface of T cells and B cells, signify shared antigen specificity among
receptors, offering a promising avenue for the discovery of novel therapeutic targets [3–
5]. The quantifiable measures of the adaptive immune system’s diversity, as provided
by immunogenomic data, contribute to the improved categorization of patients who
would derive optimal benefits from specific treatments [3, 6]. This addresses the
prevalent observation that patients sharing the same clinical diagnosis or symptoms
often respond differently to identical treatments [7, 8]. The analysis of immune cell
sequencing data holds promise in predicting the effectiveness of treatments on specific
cancerous cells, thereby curbing costs and enhancing the sustainability and efficiency
of healthcare systems[9]. Recent research underscores the capacity of deep neural
networks to glean meaningful insights from complex immunogenomic data patterns.
This encompasses tasks such as outcome prediction or clustering of TCR and BCR
sequences to uncover their underlying similarities [4, 10–12].
The integration of diverse data streams derived from various sources provides
pathologists and clinicians with a holistic perspective on cancer’s complex manifesta-
tions. Each modality illuminates unique facets of tumor biology, collectively offering
crucial insights into a patient’s prognosis and treatment options. However, the inher-
ently high-dimensional nature of some of most of the clinical data modalities poses
a formidable challenge for manual interpretation, making it arduous for clinicians to
extract meaningful information from these multimodal biomedical datasets in order
2
Fig. 1 Diagram illustrating MarbliX framework for multimodal data fusion. MarbliX integrates
histopathology images and immunogenomic data into a concise binary patient code coined as “mono-
gram.” The workflow encompasses unimodal transformation, multimodal latent association, and the
generation of the monogram representation.
3
to guide treatment decisions and estimate prognosis. Patient heterogeneity further
underscores the need for personalized tumor characterization to optimize treatment
strategies [13]. Leveraging machine learning and deep learning tools to uncover hid-
den patterns within multimodal data is pivotal in constructing robust models capable
of more accurately gauging tumor aggressiveness and predicting treatment outcomes.
Despite the availability of multimodal data, their integration into a cohesive com-
puterized framework remains rare; most current automated solutions are tailored to
a single data modality. This underscores the untapped potential for harnessing the
synergy of diverse data sources in cancer diagnosis and treatment planning.
In this paper, we introduce a novel multimodal framework known as Multimodal
Association and Retrieval with Binary Latent Indexed matriX (MarbliX). The absence
of any pre-existing multimodal AI solutions that incorporate both histopathology
and immunogenomic data serves as a compelling incentive to introduce MarbliX
to unveiling the underlying latent correlations between these complex yet informa-
tive modalities. MarbliX (1) is an innovative framework harnesses the capabilities
of deep learning to merge histopathology whole slide images (WSIs) with immune
cell sequencing data, condensing them into a concise binary patient code referred to
as “monogram.” This compact binary representation encapsulates the intricate pat-
terns found within extensive multimodal data files, encompassing both histopathology
images and genomic data. Moreover, MarbliX serves as an efficient similarity search
tool for establishing a comprehensive “monogram”-based archive. It enables the match-
ing and retrieval of similar cases to a given query case, thus empowering clinicians
and pathologists with an in-depth comprehension of cases. Current search solutions
for histopathology entirely focus on whole slides images and their patches [14–16].This
facilitates more precise and timely diagnoses, reduces variability in assessments, and
augments personalized treatment options.
2 Results
MarbliX framework is designed with the purpose of fusing the subtle morphological
characteristics found in histopathology images with the intricate immune response pat-
terns within immune cell sequencing profiles. The underlying rationale for this choice is
deeply rooted in the profound clinical implications of these modalities. Histopathology
data, with its potentials to unveil the subtleties of tissue structures, and immune cell
sequencing data, capable of unraveling the molecular nuances of immune responses.
MarbliX was implemented and evaluated using datasets obtained from The Cancer
Genome Atlas (TCGA), which included histopathology images and genomic data.
Specifically, cases from two primary sites, lung and kidney, were sourced from TCGA.
Only cases featuring both WSI and genomic profiles were considered. This resulted in
a dataset comprising 535 lung adenocarcinoma (LUAD) cases and 510 lung squamous
cell carcinoma (LUSC) cases for the lung primary site. For the kidney primary site, the
dataset consisted of three classes: 508 kidney renal clear cell carcinoma (KIRC) cases,
248 kidney renal papillary cell carcinoma (KIRP) cases, and 38 kidney chromophobe
(KICH) cases. MarbliX was evaluated using 5-fold cross validation for lung dataset
while 2-fold cross validation was used to evaluate kidney dataset due to the limited
4
number of cases in the KICH subtype as enough cases from every subtype is needed
for meaningful training.
MarbliX Training Evaluation
Different experiments were conducted to evaluate the quality of the patient repre-
sentation. An experiment was performed to analyze the quality of the multimodal
latent association applied through the hybrid autoencoders to map histopathology
features to immunogenomic features, and vice versa. As shown in Figure 2, the cosine
similarity was calculated between every histopathology and immunogenomic embed-
ding extracted by the pretrained model with the reconstructed histopathology and
immunogenomic, respectively, embeddings by the trained hybrid autoencoders. The
violin plots in Figure 2 show the distribution of the cosine similarities between the
original embedding and the reconstructed embedding of every case in the test sets of
(a) lung dataset and (b) kidney dataset. The median cosine similarities of 0.95 for lung
histopathology and 0.91 for kidney histopathology indicate a strong overall resem-
blance between the original and reconstructed embeddings, suggesting effective feature
retention. Similarly, in the immunogenomic distribution, with median cosine similari-
ties of 0.93 for lung and 0.94 for kidney, the model maintains a high degree of similarity
on average during the reconstruction process. The tightly packed quartiles in both
lung and kidney histopathology plots imply consistent performance across the major-
ity of cases. However, the wider spread in the upper quartile of the immunogenomic
kidney plot suggests challenges in accurately reconstructing complex patterns, poten-
tially attributed to the limited representation of the KICH subtype in the training set.
This limitation may lead to deviations in reconstructions when confronted with new,
less familiar patterns in the test set.
In Figure 2, the accompanying bar plot provides a quantitative assessment of the
reconstruction quality by illustrating the average mean squared error (MSE) between
the original embeddings and their reconstructed counterparts for both lung and kidney
datasets. Remarkably, the MSE values exhibit consistency across both histopathol-
ogy and immunogenomics reconstructions, ranging between 0.020 and 0.030 for both
datasets. The MSE values indicate that the model performs well in minimizing the
squared differences between the original and reconstructed embeddings, reaffirming the
reliability of the reconstruction process for both histopathological and immunogenomic
features in the lung and kidney datasets.
The training curves shown in Figure 2 (c) provide an overview of the learning
curves of the final MarbliX models trained on triplet loss, aiming to learn monogram
representations for lung and kidney cases. The curves represent the evolution of the
loss function over training epochs for each model. Initially, both models exhibit a
sharp decrease in the loss, indicative of effective learning and convergence tendency.
However, as the epochs progress, subtle differences emerge. The model trained on the
kidney dataset demonstrates a slightly more gradual decline in the loss compared to its
lung counterpart. This might suggest that the kidney dataset poses greater complexity
or variability, requiring the model to adapt more cautiously.
The binary monograms generated by MarbliX were analyzed to assess both inter
and intra-dissimilarity between the representations. To address the limited number of
5
11/6/23, 2:33 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/lung_plots_final/lung_reconstruction_mse.html
immunogenomics
histopathology
11/6/23, 2:27 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/kidney_plots_final/reconstruction_cosine_similarity.html
11/6/23, 2:27 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/kidney_plots_final/reconstruction_cosine_similarity.html
11/6/23, 2:33 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/lung_plots_final/lung_reconstruction_cosine_similarity.html
histopathology
immunogenomics
Cosine Similarity
11/6/23, 2:33 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/lung_plots_final/lung_reconstruction_cosine_similarity.html
Reconstructed Lung Features
11/6/23, 2:27 
Page 1 o
file:///Users/M282500/Desktop/multimodality/kidney_plots_final/reconstruction_cosine_similarity.html
11/6/23, 2:27 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/kidney_plots_final/reconstruction_cosine_similarity.html
11/6/23, 2:33 
Page 1 o
file:///Users/M282500/Desktop/multimodality/lung_plots_final/lung_reconstruction_cosine_similarity.html
11/6/23, 9:10 P
Page 1 of
file:///Users/M282500/Desktop/multimodality/kidney_plots_final/reconstruction_mse.html
immunogenomics
histopathology
histopathology
immunogenomics
Cosine Similarity
Reconstructed Kidney Features
(a)
(b)
Mean Squared Error (MSE)
Mean Squared Error (MSE)
11/6/23, 9:10 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/kidney_plots_final/reconstruction_mse.html
(a)
(b)
a
b
c
d
Fig. 2 a-b Analysis of reconstructed features from multimodal association learning through hybrid
autoencoders trained using histopathology images and immunogenomic data of lung and kidney
datasets. The violin plot illustrates the distribution of cosine similarity values between the original and
reconstructed embeddings by the hybrid autoencoders, with the dashed line indicating the median.
The accompanying bar plot provide a comprehensive overview of the mean squared error (MSE)
across all original embeddings and their corresponding reconstructed counterparts. c The triplet
loss during the training of MarbliX to learn a multimodal patient code referred to as “monogram,”
of cases within each of lung and kidney datasets. d A heatmap illustrating the distinctions in the
generated monogram representations among cases with various subtypes of lung and kidney cancers.
The dissimilarity is expressed as the XOR of each monogram with every other monogram in the
datasets.
6
KICH cases, a set of 19 random cases was selected from the test set of each subtype.
Quantifying the dissimilarity between matrices involved performing a bitwise XOR
operation to identify differing bits between any two matrices. The resulting heatmap,
displaying calculated dissimilarities, is presented in 2 (d). Notably, the heatmap’s
diagonal reflects the smallest dissimilarity, indicating that MarbliX generates sim-
ilar representations for patients with shared diagnoses. However, intra-dissimilarity
among patient representations within LUAD, LUSC, and KIRC was observed to
be lower compared to the intra-dissimilarity within KIRP and KICH. This can be
attributed to the limited number of cases in the latter two subtypes, leading to con-
strained coverage of subtype features during the training process. Furthermore, the
heatmap illustrates that KIRP and KICH shows a lower degree of dissimilarity in their
representations than the dissimilarity observed between either of them and KIRC.
This could stem from more common patterns between KIRP and KICH or, alter-
natively, the limited available cases belonging to KIRP and KICH during training.
The dissimilarity between lung monograms (LUAD and LUSC) was smaller than the
dissimilarity between lung monograms and kidney monograms (KIRC, KIRP, and
KICH). Similarly, the dissimilarity between representations of kidney cases was smaller
than the dissimilarity between kidney and lung cases. Additionally, the dissimilarity
between representations of kidney subtypes was higher than the dissimilarity between
representations of lung subtypes.
MarbliX Generates Discriminative Patient Representations
In assessing the efficacy of MarbliX in generating high quality multimodal patient
representations, an experiment was conducted, comparing them to unimodal represen-
tations derived from histopathology and immunogenomics data. PCA transformation
was applied to extract the top 64 components from each embedding in the lung and
kidney test sets, using folds not employed during training. These components were
then projected into a high-dimensional space, forming the t-SNE maps presented in
Figure 3. The maps provide comprehensive insights into feature properties, highlight-
ing distinctions among various subtype classes. In Figure 3 (a), lung histopathology
image embeddings of LUAD and LUSC are intermixed, lacking a clear discriminative
pattern. Figure 3 (b) demonstrates a more discriminative pattern in immunogenomic
embeddings, although some LUSC features intertwine with LUAD features. Merg-
ing histopathology and immunogenomics features into a monogram using MarbliX
enhances distribution in Figure 3 (c) and (d), showcasing real and binary features.
Notably, the t-SNE maps reveal improved separation of LUAD and LUSC, particu-
larly using binary monogram representations. Transitioning to kidney maps, Figure 3
(e) shows two well-separated clusters of mixed cased from the three kidney subtypes
in the histopathology t-SNE map. Analysis reveals that this separation is influenced
by different hospitals, indicating the dominance of WSI technical properties in the
embeddings. Immunogenomic t-SNE map (Figure 3 (f)) exhibits a more meaningful
distribution than histopathology, with KIRC being the most discriminated class due to
the available number of cases during training compared to KIRP and KICH. Despite
this, MarbliX application refines the distribution of patient representations (Figure 3
7
(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
Fig. 3 The t-SNE map depicting the distribution of modalities within a high-dimensional space.
The visual representation showcases embeddings post-PCA transformation, specifically retaining the
initial 64 components. The maps shows the relationship between cancer subtypes within lung (first
row) and kidney (second row) datasets. The distributions of uni-modal embeddings are presented in
(a) and (e) for the image modality, while (b) and (f) illustrate the immunogenomics modality. Maps
(c) and (g) show the distribution of real-value monogram representations, while (d) and (h) display
binary monograms, both generated by MarbliX.
(g) and (h)), creating distinct groups for the three kidney cancer subtypes, highlight-
ing the ability of MarbliX to derive compact yet discriminative representations from
diverse modalities.
Efficient Multimodal Similarity Search
MarbliX demonstrated its primary utility through the application of the mono-
gram representation for conducting efficient multimodal search and retrieval (Figure
4. The monogram, a condensed representation, integrates diverse features extracted
from multimodal data, thereby streamlining the process of multimodal search and
retrieval. MarbliX was employed to fuse each patient’s histopathology image and
immunogenomic data into a monogram. To assess MarbliX’s performance, “leave-one-
out” validation was performed, utilizing monograms generated by MarbliX for cases in
the test folds of lung and kidney datasets. Cases in the test folds were not part of the
training set. The evaluation involved searching for similar cases within the monograms
archive, treating each case as a query case by excluding it from the search process.
The majority vote criterion was applied for top-3 (MV@3), top-5 (MV@5), and top-10
(MV@10) retrievals, requiring at least n/2 + 1 of the top-n retrieved cases to belong
to the same diagnosis class as the query case.
8
Fig. 4 The pipeline for utilizing MarbliX in a multimodal pathology search, aiming to identify
similar cases to a given query case—exemplified here with a liver cancer patient. The process begins
with specimen collection for histopathology staining and genomics analysis. In the second stage,
the tissue slide is digitized, and RNA sequencing is conducted to obtain the patient’s whole slide
image and genomics profile, respectively. In the third stage, following unimodal transformations of
the histopathology image and genomics profile, MarbliX integrates the two modalities into a binary
multimodal representation, referred to as “monogram”. The final stage involves a multimodal search
using the generated monogram as a query to identify the top n (in this case, n=3) similar matrices in
the archive. The search is performed through Hamming distance comparison. The retrieved matrices
can be utilized to identify the similar patients’ medical information, including histopathology images,
genomics data, treatment history, and risk stratification.
Figure 5 presents the mean and standard deviation of macro average F1-score
and accuracy for the test folds. The results of MarbliX representations, real and
binary monograms are compared against unimodal representations of histopathol-
ogy and immunogenomics. Analyzing the lung dataset results in Figure 5 (a and c),
multimodal search using monogram yields more accurate and similar retrieved cases
compared to unimodal searches. MarbliX consistently achieves performance between
85% and 89% across all criteria from top-1 to MV@10, surpassing the 69%-71% and
73%-76% ranges of histopathology and immunogenomics, respectively. The integration
9
of distinctive patterns from both modalities into a compact multimodal representa-
tion notably enhances the quality of retrieved cases. Analyzing the performance on
the kidney dataset shown in Figure 5 (b and d), MarbliX representation also out-
performs unimodal representations. The best performance was achieved using real
monograms, with F1-score ranging between 80% and 83%, and accuracy between 87%
and 90%. However, employing binary monograms results in a slight decrease in the F1-
score range (78%-82%). Immunogenomic representations outperform histopathology
representations in terms of F-score (70%-76% vs. 60%-70%), while accuracy remains
comparable. Notably, all kidney representations exhibit lower macro average F1-score
values compared to accuracy values, reflecting dataset imbalance.
In Figure 5, the precision and recall results are illustrated for the same search eval-
uation on the lung and kidney datasets. The mean precision and mean recall of the
folds are represented with the diamond shape, while the standard deviation of each
mean value is shown as a horizontal bar. As shown in the figure, MarbliX representa-
tion maintains more stable results across the folds (different test sets) compared to the
unimodal representations. This is evident from the generally shorter standard devia-
tion bars for both lung and kidney results, indicating a more consistent performance.
Furthermore, MarbliX maintains higher precision and recall compared to both lung
histopathology and immunogenomic representations. For the kidney dataset, although
the histopathology representation achieved the highest precision when a top-5 and
top-10 majority vote was applied (90%-91%), it also achieved the lowest recall for the
same measures (56%-59%). Binary MarbliX representation resulted in approximately
the same recall as immunogenomics over the top-1 measure but demonstrated higher
precision. Overall, MarbliX consistently maintained precision and recall above 78%
for top-1, MV@3, MV@5, and MV@10 measures.
In summary, MarbliX demonstrates robust performance in multimodal search
and matching, leveraging monograms to fuse histopathology and immunogenomic
data effectively. Overall, MarbliX maintained more accurate and stable performance
compared to unimodal representations.
MarbliX Monogram Binary Representation Analysis
The primary goal of MarbliX is to generate multimodal monogram representations
that are similar for patients with similar characteristics and distinct for those with
different attributes. In this study, similarity is defined based on a shared diagnosis,
specifically the commonality of cancer subtypes. Figure 6 illustrates MarbliX’s efficacy
in achieving this objective. The figure presents four LUAD monograms and four LUSC
monograms generated for randomly selected samples from each class (refer to Figure2
(d) for a quantified monogram difference). It is evident that matrices from patients
with the same subtype exhibit a consistent pattern (intra-similarity).
To highlight this intra-similarity and inter-dissimilarity, the figure displays the
result of applying bitwise XOR on each LUAD matrix with every other matrix within
the LUAD set. The same process was applied to the LUSC set, resulting in {LUSCset−
LUSCset}. Additionally, the set of LUAD was XORed with the set of LUSC to identify
the differences between each LUAD matrix and every LUSC matrix in the sets. Yellow
pixels represent values turning from 0 to 1, while purple indicates the shift from
10
11/7/23, 1:16 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/lung_plots_final/precision_recall.html
11/7/23, 1:16 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/lung_plots_final/precision_recall.html
11/7/23, 1:16 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/lung_plots_final/precision_recall.html
(a)
(b)
(c)
(d)
11/7/23, 1:16 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/lung_plots_final/precision_recall.html
11/7/23, 1:16 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/lung_plots_final/precision_recall.html
11/7/23, 1:16 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/lung_plots_final/precision_recall.html
file:///Users/M282500/Desktop/multimodality/kidney_plots_final/precision_recall.html
file:///Users/M282500/Desktop/multimodality/kidney_plots_final/precision_recall.html
11/7/23, 1:16 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/lung_plots_final/precision_recall.html
11/7/23, 1:16 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/lung_plots_final/precision_recall.html
11/7/23, 1:16 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/lung_plots_final/precision_recall.html
(a)
(b)
(c)
(d)
11/7/23, 1:16 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/lung_plots_final/precision_recall.html
11/7/23, 1:16 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/lung_plots_final/precision_recall.html
11/7/23, 1:16 PM
Page 1 of 1
file:///Users/M282500/Desktop/multimodality/lung_plots_final/precision_recall.html
file:///Users/M282500/Desktop/multimodality/kidney_plots_final/precision_recall.html
file:///Users/M282500/Desktop/multimodality/kidney_plots_final/precision_recall.html
Lung Retrieval Precision
Kidney Retrieval Precision
Lung Retrieval Recall
Kidney Retrieval Recall
(a)
(b)
(c)
(d)
Lung Retrieval F1-Score
Kidney Retrieval F1-Score
Lung Retrieval Accuracy
Kidney Retrieval Accuracy
a
b
c
d
e
f
g
h
Fig. 5 a-d Comparative analysis of multimodal search performance - MarbliX versus unimodal
representations of histopathology images and immunogenomic data. Mean and standard deviation
of macro average F1-score and accuracy for lung and kidney test folds. Leave-one-out and majority
vote criteria are applied to retrieve top-1, MV@3, MV@5, and MV@10 for cases in the test folds. e-h
Multimodal search performance of real and binary MarbliX representations compared to unimodal
representations of histopathology images and immunogenomic data. Diamond-shaped points represent
the mean of macro-average precision and recall for lung and kidney test folds. Horizontal bars denote
the standard deviation range. Leave-one-out and majority vote (MV) criteria are applied to retrieve
top-1, MV@3, MV@5, and MV@10 for cases in the test folds.
11
Fig. 6 Monogram representations generated using MarbliX, for randomly selected patients with
Lung Adenocarcinoma (LUAD) and Lung Squamous Cell Carcinoma (LUSC). The figure presents
matrix bitwise XOR results: the left side illustrates {LUADset⊕LUADset}, the right side {LUSCset⊕
LUSCset}, and the middle {LUADset ⊕LUSCset}. Yellow pixels highlight features transitioning from
0 to 1, while purple pixels indicate the shift from 1 to 0. This color scheme serves to distinguish
the presence or absence of features. In the context of {LUADset ⊕LUSCset}, yellow pixels signify
features unique to LUAD matrices, absent in LUSC, and purple pixels denote features specific to
LUSC matrices, absent in LUAD.
1 to 0. This color scheme is particularly informative when analyzing the results of
{LUADset −LUSCset}, where yellow pixels signify features present in LUAD matrices
but absent in LUSC matrices, and purple denotes features present in LUSC matrices
but absent in LUAD matrices.
As shown in Figure 6, the dissimilarity within LUAD or LUSC matrices is notably
lower than the dissimilarity resulting from XORing the two sets. This is evident from
the greater number of white empty areas in the intra-XOR results, as opposed to the
more densely colored squares in the {LUADset −LUSCset} difference.
12
3 Discussion
The motivation for this research work stems from the significant challenges and unex-
plored opportunities that arise due to the conspicuous scarcity of multimodal solutions
adept at merging histopathology images with genetic sequencing data in general, and
with immunogenomic data in particular. Furthermore, as far as knowledge extends,
the fusion of histopathology images with immunogenomic data remains an untapped
area. By fusing these data modalities within the MarbliX framework, the objective
is to effectively bridge critical research gaps and contribute to a more comprehensive
understanding of cancer cases, while also unlocking new avenues for potential research
in this domain. The work at hand brings forth four substantial contributions to the
burgeoning field of multimodal research.
First and foremost, MarbliX introduces a novel approach that condenses diverse
data modalities into a concise representation, referred to as monogram. This innovative
concept enables the generation of monogram for each individual patient, serving as a
tangible representation of their multimodal data. This representation encapsulates the
intricate patterns unearthed from various data sources, thereby affording each patient
a highly informative imprint or signature. This approach empowers researchers and
medical practitioners to extract rich insights from a patient’s multimodal clinical data,
facilitating personalized and data-driven healthcare.
The second contribution of MarbliX lies in its ability to create a binary barcode
of multimodal patient data, which often comprises voluminous files like histopathol-
ogy whole slide images (WSIs) and genetic sequencing data. This compactness holds
profound implications for time efficiency, computational complexity, and storage
requirements. Employing monograms in diverse downstream tasks such as search and
retrieval not only streamlines these operations but also unlocks a powerful tool that
can handle data in varying formats, sizes, complexities, and sources.
Furthermore, the third significant contribution of MarbliX is its backbone inde-
pendence, a feature that distinguishes it as a versatile multimodal AI framework. The
capability to map different modalities within a latent space not only contributes to
the model’s training efficiency but also enables the extraction of associated patterns
from data modalities originating from diverse sources within the medical field. This
adaptability is paramount for addressing the heterogeneous nature of medical data.
Lastly, but no less important, MarbliX serves as a valuable asset in facilitating
multimodal search, a crucial task in medical research and diagnosis. With the ability
to construct a monogram-indexed archives, MarbliX empowers practitioners with an
interactive tool to multimodal search for cases similar to a given query. This process
involves generating a monogram for the query case and then scouring the archive to
retrieve the most analogous monograms that share similar patterns with the query.
This feature enhances the discoverability of relevant cases and expedites the decision-
making process in healthcare.
The evaluation of MarbliX has demonstrated its remarkable success in captur-
ing multimodal patient representations by integrating histopathology images and
immunogenomic data to generate monogram representations. These monograms serve
as condensed binary representations of patients’ multimodal features, achieved through
unimodal processing and transformation, multimodal latent association by training
13
hybrid autoencoders, and self-supervised training with triplet loss. The assessment of
patient representation demonstrated the efficacy of MarbliX in capturing distinctive
features from both histopathology and immunogenomics modalities.
The similarity analysis of generated monograms showed intra-similarity for patients
with the same primary diagnosis and inter-dissimilarity between those with differ-
ent primary diagnoses. Both visual and statistical analyses underscored MarbliX’s
capability to generate meaningful compact binary barcodes, effectively discriminating
between patients with distinct primary diagnoses. Furthermore, the evaluation of Mar-
bliX in multimodal search and retrieval demonstrated its superiority over unimodal
representations. Monograms consistently resulted in accurate and similar retrieved
cases across various criteria, highlighting the model’s capability in capturing informa-
tive patterns from both histopathology and immunogenomic data. The t-SNE maps
provided visual insights into MarbliX’s ability to create discriminative representations,
notably enhancing the separation of cancer subtypes.
In summary, MarbliX has effectively achieved its objectives by generating infor-
mative multimodal monograms that capture and represent the complex features
of patients with different cancer subtypes. Beyond demonstrating its robustness in
patient representation through multimodal search, MarbliX emerges as a versatile
framework with applications extending beyond search and retrieval. Its capability to
efficiently integrate and encapsulate distinct data modalities, each inherently pos-
sessing large sizes and complexity, into a compact binary matrix is remarkable. This
resulting binary matrix serves as a powerful bridge between different modalities, with
each entry encoding whether specific features from one modality align with or cor-
respond to certain features in the other. The binary nature of the representations
simplifies storage requirements and computational complexity needed for various appli-
cations. Multimodal data fusion through MarbliX paves the way for more informed
and data-driven decision-making in complex biomedical analyses.
4 Methods
This section describes the details of MarbliX’s design and the intricate process involved
in generating a unique monogram representation. An overview of MarbliX is illustrated
in Figure 1. The design of MarbliX involves three main phases: unimodal transfor-
mation, multimodal latent association, and monogram representation. The details of
every phase is described below.
Unimodal Transformation
The integration of histopathology images and immune cell sequencing data into a
shared computational framework requires an alignment step to transform them into
a common format. This enables joint manipulation and integration within a unified
model. Hence, as a first stage, each modality, is processed and transformed into a single
feature vector or embedding. For simplicity, in the context of the notation (I , S), I
represents the histopathology image, while S represents the immunogenomic data (a
set of immune cell sequences) of a given case.
14
Image processing: to represent the WSIs, SPLICE [17] was employed to select rep-
resentative patches, forming a collage for image I after segmenting the tissue region
from the background using Otsu thresholding. This collage is a condensed represen-
tation, composed of a select set of representative patches extracted from I , capturing
the crucial tissue characteristics that define the image. The collage was generated by
setting the similarity threshold to the 30th percentile, striking a balance between per-
formance and computational/storage requirements. Once the collage is generated for
I , the next step involves extracting deep features from the individual patches that
compose the collage. This process is achieved by leveraging a pre-trained deep neural
network F, here we used DINO ViT [18], which possesses the ability to extract pat-
terns and meaningful information within these patches. As a result of this indexing, a
feature vector f i of patch Pi within the collage is generated by applying f i = F(Pi),
where f i ∈Rl×1.
To craft an all-encompassing feature vector that encapsulates the entirety of image
I and effectively represents its rich content, a widely adopted practice involves com-
puting the average of the patch-level feature vectors [19], resulting in a single feature
vector f ∈Rl×1 that serves as a holistic representation of the entire image I . As we
used DINO ViT, this resulted in a 768-dimensional embedding for the entire WSI.
Sequencing data processing: for the immunogenomic data, raw RNA-seq files
from TCGA were utilized to reconstruct the immune repertoire of every patient.
TRUST4 [20] was employed to obtain the TCR and BCR sequences of each patient
from their RNA-seq profiles. Rare sequences and artifacts were filtered out by exclud-
ing those that were not common to a sufficient proportion of patients within each
subtype class. Through experimentation, for the lung dataset, sequences that were not
common to at least 30% of the patients within the subtype class were excluded, while a
lower threshold of 15% was applied to kidney cases due to the limited number of sam-
ples. Before we encode the sequencing data into a dense vector, we applied Seqwash [21]
method to preprocess the sequencing profiles and prepare them for feature extrac-
tion. Seqwash is a “harmonization” approach tailored to genetic sequencing data and
serves as a crucial preprocessing step, aimed at preparing these sequences for analysis
using deep models designed for textual data by overcoming the impact of the vari-
ability among patients in terms of sequence lengths and unregulated sequence orders.
Therefore, Seqwash was used to unify the patient profiles by aligning them into a stan-
dardized representation before proceeding with deep feature extraction. The ultimate
goal is to create a single, coherent embedding that encapsulates vital information while
negating the effects of varying sequence orders within each patient’s profile. Applying
Seqwash on sequencing profile S results in a harmonized set Sh. A pre-trained deep
learning model G is then employed to distill features from the sequences by applying
g = G(Sh), where g ∈Rl×1 represents a feature vector extracted from the harmo-
nized sequences set Sh. Here, we employed BERT which resulted in a 768-dimensional
embedding.
Multimodal Latent Association
Following the transformation of each modality, histopathology image I into embedding
f and immune cell sequence profile S into embedding g, the association between these
15
Algorithm 1 Multimodal Latent Association
1: Input:
2:
Histopathology image embedding f
3:
Immune cell sequence profile embedding g
4: Training Stage:
5:
Initialize AI (Autoencoder for Histopathology):
6:
while not converged do:
7:
Forward pass: f →EI(f ) →DI(EI(f ))
8:
Compute loss: lI = MSE(g, DI(EI(f )))
9:
Backpropagate and update weights
10:
Initialize AS (Autoencoder for Immune Cell Sequences):
11:
while not converged do:
12:
Forward pass: g →ES(g) →DS(ES(g))
13:
Compute loss: lS = MSE(f , DS(ES(g)))
14:
Backpropagate and update weights
15: Latent Representation:
16:
Encode using the encoder of AI:
17:
u ←EI(f )
18:
Encode using the encoder of AS:
19:
v ←ES(g)
20: return u, v
embeddings is learned. However, as these embeddings come from different models,
they have different ranges. Therefore, min-max rescaling was performed to bring the
embeddings to a common scale before learning the association between them. After
normalization, association learning was performed by projecting the two embeddings
into a shared latent space. In this shared space, the embeddings from both modalities
coalesce to form a concise patient representation. This step addresses the issue of non-
relevant features that may exist in the uni-modal data obtained from a pretrained
network. By merging these embeddings into an encoded representation, we want to
extract and consolidate the pertinent features from each modality, enhancing their
combined synergy and informative value in subsequent analyses.
To accomplish this, as shown in Algorithm 1, two deep neural networks with an
encoder-decoder (autoencoder) architecture are employed, each tailored to empha-
size the salient features from its corresponding modality while suppressing extraneous
information. This step addresses the issue of non-relevant features that may exist in
the uni-modal data obtained from a pretrained network. By merging these embeddings
into an encoded representation, we want to extract and consolidate the pertinent fea-
tures from each modality, enhancing their combined synergy and informative value in
subsequent analyses. This is achieved by training the two hybrid models to generate
an encoded latent representation, highlighting the relevant features. Specifically, each
autoencoder model is designed to take one modality and reconstruct the other, result-
ing in a latent representation that embodies the dominant features of its respective
modality.
16
In the first stage (illustrated in Algorithm 1, Lines 4-9), an autoencoder denoted
as AI is designed, where it takes the histopathology image embedding f as input, and
reconstructs the immune cell sequence profile embedding g. During training, AI learns
to focus on critical features present in histopathology images that offer insights into
immune cell sequence patterns. These features are encapsulated within the bottleneck
layer, situated just before the first decoder layer of model AI.
Conversely, in the second stage (described in Algorithm 1, Lines 10-14), another
autoencoder, denoted as AS, is employed, which takes the immune cell sequence profile
embedding g as input and reconstructs the histopathology image embedding f . This
design empowers the model to emphasize essential characteristics inherent to immune
cell sequence data that are relevant to the histopathological context, also embedded
within the bottleneck layer of model AS.
Both hybrid autoencoders AI and AS comprised an encoder with two dense layers
of size 512 and 256, followed by a bottleneck layer of size 128, and finally, a decoder with
two dense layers of size 256 and 512. All autoencoders were trained using the Adam
optimizer and mean square error (MSE) as the loss function. The image-genomics
autoencoder was trained for 150 epochs with a learning rate of 1 × 10−5, while the
genomics-image autoencoder was trained for 50 epochs with a learning rate of 1×10−4.
Following the training of AI and AS, the encoder from each hybrid autoencoder is
employed to generate an encoded latent for each sample, resulting in two encoded vec-
tors: image features-enriched latent and genomic features-enriched latent (Algorithm 1,
Lines 15-20). For instance, u, characterized by a strong emphasis on histopathological
features, is derived through the application of u = EI(f ), where u ∈Rl×1. Likewise,
v, accentuating immune cell characteristics, is derived as v = ES(g), where v ∈Rl×1.
The resulting compact representation (size 128) not only reduces dimensionality but
also encapsulates critical aspects of both modalities. This representation serves as
a powerful encoding of joint information extracted from histopathology images and
immune cell sequences, facilitating profound integration in the subsequent phase.
MarbliX Monogram
After generating the two latent representations u and v, the next crucial step within
the MarbliX framework is the projection and indexing of these representations into a
2D binary matrix, referred to as “monogram.” This matrix serves as an effective repre-
sentation for capturing the intricate relationships and correlations that exist between
the two modalities. The process of learning the monogram representation is the core of
the MarbliX framework, enabling a comprehensive exploration of the joint information
encoded within u and v.
To accomplish this task, a deep neural network, denoted as Q, is designed to
uncover the correlations between histopathology and immunogenomic features based
on diagnosis. This process aims to unveil the underlying structure that interlinks
histopathological characteristics with immune cell behavior among cases within the
same diagnostic class. In other words, the model is engineered to capture the common-
ality in multimodal relationships among cases that share similar diagnoses, embedding
these features within their respective monograms. Simultaneously, it strives to dis-
cern the distinctions between cases of different diagnostic classes and accentuate these
17
disparities within their corresponding monograms. This is achieved by employing self-
supervised training using triplet loss to minimize the distance between patients with
the same primary diagnosis and maximize the distance between patients with different
primary diagnoses.
As described in Algorithm 2, The Q model comprises three branches with shared
weights, each taking a pair of latent representations, u and v. Thus, the model is
provided with triplet pairs as input Q({u, v}, {u+, v +}, {u−, v −}), consisting of an
anchor pair (u, v), a positive pair (u+, v +), and a negative pair (u−, v −). The anchor
case serves as the reference for which the model endeavors to generate a representa-
tive monogram. The positive case shares the same diagnosis as the anchor, reinforcing
common features. In contrast, the negative case differs in diagnosis from the anchor,
shedding light on the discrepancies between diagnostic classes. The positive and neg-
ative samples were selected for each anchor sample by calculating pairwise Euclidean
distances and identifying the farthest positive sample and the closest negative sample
for each anchor. This approach was implemented to ensure robust training by intro-
ducing hard triplets to the model, guiding toward learning the similarities between
samples belonging to the same class, despite eventual dissimilarity between them.
Analogously, this approach guides the model to generate different representations for
cases that share common features in their data but belong to different classes.
Algorithm 2 Learning Multimodal Monogram Representation
1: Input:
2:
u: image latent representation
3:
v: sequencing latent representation
4: Training Stage:
5:
Initialize Q model with three branches T1, T2, T3
6:
T1, T2, T3 ←shared weights
7:
for each triplet T1(u, v), T2(u+, v +), T3(u−, v −) do:
8:
M ←u ⊗v
9:
¯
M ←T (M) ←M
10:
¯
Mbinary ←{if w > 0.5 then 1 else 0 for each w in ¯
M}
11:
Calculate triplet loss:
12:
d(a, p) ←distance( ¯
M, ¯
M +)
13:
d(a, n) ←distance( ¯
M, ¯
M −)
14:
Ltriplet ←max{(d(a, p) −d(a, n)) + α, 0}
15:
T1, T2, T3 ←update weights using gradient descent
Within each branch (Algorithm 2, Lines 11-15), the pair of u and v is projected
into a matrix through the computation of the outer product between their respective
layers. This tensor is then flattened and passed through three consecutive dense layers
of size 1024, 256, and 64 to learn the deep multimodal relationship. The last layer
of the model has a binary branch that generates a binary representation of the last
layer. This is crucial as it enables the generation of compact binary representations,
highly efficient for subsequent indexing and storage. As the tanh function results in
18
values within the range of [−1, 1], the binary dense layer sets positive values to 1 and
negative values to 0.
The triplet loss function (Equation 1) calculates the distances between the anchor’s
predicted matrix and both the positive and negative matrices.
Ltriplet(a, p, n) = max{d(a, p) −d(a, n) + α, 0}
(1)
In Equation 1, a represents the anchor case, p signifies a positive case (sharing the
same diagnosis as the anchor), and n denotes a negative case (with a different diagnosis
from the anchor). d(a, p) calculates the distance between the anchor and positive case
matrices, while d(a, n) computes the distance between the anchor and negative case
matrices. The margin parameter α ensures a minimum separation between the positive
and negative cases.
Model Q was trained for 150 epochs using the tanh activation function and Adam
optimizer with a learning rate of 1×10−5. After training the Q model, it was utilized to
generate binary monogram representations for new cases. This was done by applying
monogram = Q({u, v}), where monogram represents an 8 × 8 binary matrix (with
encoding capability to cover 264 = 1.8 × 1019 combinations) derived from the latent
representations u and v of the histopathology image and immune cell sequences,
respectively.
Competing Interests
The Authors declare no Competing Financial.
Data Availability
The data used in this work is publicly available in The Cancer Genome Atlas (TCGA)
(URL: https://portal.gdc.cancer.gov/).
Author Contributions
AA implemented the approach, run all experiments and wrote the first draft of the
paper. AS and SA contributed to implementation and experiments. HRT conceptually
designed the approach, supervised the implementation and experiments, and wrote
and rewrote large parts of the paper.
References
[1] Gun, S.Y., Lee, S.W.L., Sieow, J.L., Wong, S.C.: Targeting immune cells for
cancer therapy. Redox biology 25, 101174 (2019)
[2] Beausang, J.F., Wheeler, A.J., Chan, N.H., Hanft, V.R., Dirbas, F.M., Jeffrey,
S.S., Quake, S.R.: T cell receptor sequencing of early-stage breast cancer tumors
identifies altered clonal structure of the t cell repertoire. Proceedings of the
National Academy of Sciences 114(48), 10409–10417 (2017)
19
[3] Pogorelyy, M.V., Fedorova, A.D., McLaren, J.E., Ladell, K., Bagaev, D.V.,
Eliseev, A.V., Mikelov, A.I., Koneva, A.E., Zvyagin, I.V., Price, D.A., et al.:
Exploring the pre-immune landscape of antigen-specific t cells. Genome medicine
10(1), 1–14 (2018)
[4] Sidhom, J.-W., Larman, H.B., Pardoll, D.M., Baras, A.S.: Deeptcr is a deep learn-
ing framework for revealing sequence concepts within t-cell repertoires. Nature
communications 12(1), 1–12 (2021)
[5] Medzhitov, R., Janeway Jr, C.A.: Innate immunity: impact on the adaptive
immune response. Current opinion in immunology 9(1), 4–9 (1997)
[6] Jung, D., Alt, F.W.: Unraveling v (d) j recombination: insights into gene
regulation. Cell 116(2), 299–311 (2004)
[7] Fridman, W.H., Saut`es-Fridman, C., Galon, J., et al.: The immune contexture
in human tumours: impact on clinical outcome. Nature Reviews Cancer 12(4),
298–306 (2012)
[8] Leone, R.D., Powell, J.D.: Metabolism of immune cells in cancer. Nature reviews
cancer 20(9), 516–531 (2020)
[9] Alsaafin, A., Babaie, M., Tizhoosh, H.: Deep modality association learning using
histopathology images and immune cell sequencing data. In: Medical Imaging
2023: Digital and Computational Pathology, vol. 12471, pp. 354–361 (2023). SPIE
[10] Beshnova, D., Ye, J., Onabolu, O., Moon, B., Zheng, W., Fu, Y.-X., Brugarolas,
J., Lea, J., Li, B.: De novo prediction of cancer-associated t cell receptors for
noninvasive cancer detection. Science translational medicine 12(557) (2020)
[11] Burger, J.A., Wiestner, A.: Targeting b cell receptor signalling in cancer:
preclinical and clinical advances. Nature Reviews Cancer 18(3), 148–167 (2018)
[12] Fischer, D.S., Wu, Y., Schubert, B., Theis, F.J.: Predicting antigen specificity of
single t cells based on tcr cdr 3 regions. Molecular systems biology 16(8), 9416
(2020)
[13] Alizadeh, A.A., Aranda, V., Bardelli, A., Blanpain, C., Bock, C., Borowski, C.,
Caldas, C., Califano, A., Doherty, M., Elsner, M., et al.: Toward understanding
and exploiting tumor heterogeneity. Nature medicine 21(8), 846–853 (2015)
[14] Kalra, S., Tizhoosh, H.R., Choi, C., Shah, S., Diamandis, P., Campbell, C.J., Pan-
tanowitz, L.: Yottixel–an image search engine for large archives of histopathology
whole slide images. Medical Image Analysis 65, 101757 (2020)
[15] Lahr, I., Alfasly, S., Nejat, P., Khan, J., Kottom, L., Kumbhar, V., Alsaafin,
A., Shafique, A., Hemati, S., Alabtah, G., Comfere, N., Murphree, D., Mangold,
20
A., Yasir, S., Meroueh, C., Boardman, L., Shah, V.H., Garcia, J.J., Tizhoosh,
H.R.: Analysis and validation of image search engines in histopathology. IEEE
Reviews in Biomedical Engineering, 1–19 (2024) https://doi.org/10.1109/RBME.
2024.3425769
[16] Tizhoosh, H.R., Pantanowitz, L.: On image search in histopathology. Journal of
Pathology Informatics, 100375 (2024)
[17] Alsaafin, A., Nejat, P., Shafique, A., Khan, J., Alfasly, S., Alabtah, G., Tizhoosh,
H.R.: Splice: Streamlining digital pathology image processing. The American
journal of pathology (2024)
[18] Caron, M., Touvron, H., Misra, I., J´egou, H., Mairal, J., Bojanowski, P., Joulin,
A.: Emerging properties in self-supervised vision transformers. In: Proceedings
of the IEEE/CVF International Conference on Computer Vision, pp. 9650–9660
(2021)
[19] Vale-Silva, L.A., Rohr, K.: Long-term cancer survival prediction using multimodal
deep learning. Scientific Reports 11(1), 1–12 (2021)
[20] Song, L., Cohen, D., Ouyang, Z., Cao, Y., Hu, X., Liu, X.S.: Trust4: immune
repertoire reconstruction from bulk and single-cell rna-seq data. Nature Methods
18(6), 627–630 (2021)
[21] Alsaafin, A., Tizhoosh, H.R.: Harmonizing immune cell sequences for computa-
tional analysis with large language models. Biology Methods and Protocols, 055
(2024)
21
