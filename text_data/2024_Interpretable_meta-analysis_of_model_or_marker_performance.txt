Interpretable meta-analysis of model or marker performance
Jon A. Steingrimsson1, Lan Wen2,3, Sarah Voter1, and Issa J. Dahabreh3-5
1Department of Biostatistics, Brown University School of Public Health, Providence, RI
2 Department of Statistics and Actuarial Science, University of Waterloo, Waterloo, Ontario, Canada
3CAUSALab, Harvard T.H. Chan School of Public Health, Boston, MA
4Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, MA
5Department of Biostatistics, Harvard T.H. Chan School of Public Health, Boston, MA
Monday 23rd September, 2024
1
arXiv:2409.13458v1  [stat.ME]  20 Sep 2024
Abstract
Conventional meta analysis of model performance conducted using datasources from different
underlying populations often result in estimates that cannot be interpreted in the context of
a well defined target population. In this manuscript we develop methods for meta-analysis of
several measures of model performance that are interpretable in the context of a well defined
target population when the populations underlying the datasources used in the meta analysis
are heterogeneous. This includes developing identifiablity conditions, inverse-weighting, outcome
model, and doubly robust estimator. We illustrate the methods using simulations and data from
two large lung cancer screening trials.
2
1
Introduction
Users of prediction models are often interested in using model derived predictions in a target popula-
tion of substantive interest. When multiple studies evaluate the performance of the same prediction
model (or biomarker), stakeholders are often interested in synthesizing evidence across the studies
to learn about model performance in a target population of substantive interest (i.e. performing
meta analysis). Commonly used databases for meta analysis of model development and evaluation
are randomized controlled trials, observational cohort studies, and electronic health records. But
the populations underlying each datasource likely differ and they are usually not a random sample
of the target population. For example, participants who agree to participate in clinical research
are often younger [1], healthier [2], and less diverse [3] than the population that meet the eligibility
criteria for participation, and observational cohort studies and administrative databases are often
limited to specific healthcare systems or geographic regions.
Meta analysis of measures of model performance is usually conducted using weighted averages
of study specific estimators of model performance or by modeling the distribution of measures of
model performance across studies [4, 5]. But when prediction error modifiers, that is, variables
that are associated with prediction error for a given measure of model performance and prediction
model [6], are differentially distributed across the studies or between the target population and
the study populations, estimates of measures of model performance obtained from standard meta
analysis methods are not reflective of measures of model performance in the target population
(and usually don’t have a clear interpretation outside of the population underlying the pooled
sample from the studies). The analogous problem occurs for meta-analysis of treatment effects and
methods have been developed for synthesizing data from multiple randomized controlled trials that
have a causal interpretation in a target population [7,8].
Several methods have been developed for transporting or generalizing both loss-based measures
of model performance [9–15] and estimators of area under the curve from a single study to a target
population [16]. The related literature on multi-source domain adaptation [17–22] usually focuses
on risk estimation using samples from multiple source populations that perform well in a target
population or are robust to distributional shifts between the source populations and the target
3
population.
In this manuscript we develop identifiability results and propose novel estimators for measures
of model performance in a target population, using data from multiple studies. We refer to this
approach as interpretable meta analysis of model performance. The measures of model performance
we consider are risk-based measures, sensitivity, specificity, negative predictive value, positive pre-
dictive value, and the area under the curve. We derive asymptotic properties of the estimators and
evaluate finite sample properties of the estimators using simulations and apply them to analyzing
data on lung cancer screening.
2
Data and target parameters
We assume that we have data from K studies that we refer to as the source studies. For each
source study participant, we assume that information is available on which study they come from
S = 1, . . . , K, covariate information X, and outcome information Y , where the outcome can be
binary, count, or continuous. That is, the observed data from study s is
{(Xi, Si = s, Yi), 1, . . . , ns},
where ns is the number of observations in study s ∈{1, . . . , K}. We also assume that we have
covariate information, but no outcome information, on a sample from the target population. Let
S = 0 denote an observation being from the target population and n0 be the number of observations
available from the target population. We denote O as the combined dataset from all the studies
and the target population with n = PK
k=0 nk representing the total number of observations in the
combined dataset. We assume that the observations are independent and identically distributed
random variables, and define R = I(S ̸= 0) as an indicator of whether an observation comes from
one of the studies (R = 1) or the target population (R = S = 0).
Throughout, we make the following two assumptions:
A1 Conditional exchangeability between datasources. We assume that Y ⊥⊥R|X.
A2 Positivity of participation in the collection of data sources: Pr[R = 1|X = x] > 0 for all x
4
such that f(x|S = 0) > 0.
The positivity assumption A2 states that all covariate patterns that can occur in the target popu-
lation have a positive probability of occurring in at least one of the studies. Hence, the methods
developed can draw conclusions about a target population that has a broader spectrum than each
of the individual studies.
Let h(X, bβ) be a prediction model indexed through a parameter β and let h(X, bβ) be the
estimated model where the parameter bβ is an estimator for β. Throughout we do not make the
assumption that the model is correctly specified. As such, the results presented in the rest of this
paper apply to both correctly specified and misspecified models. We are interested in estimating
performance of the model h(X, bβ) on a dataset that is independent of the data used for model
building (i.e., the data used to calculate bβ).
For a binary outcome, common measures of model performance, especially when estimating
diagnostic accuracy, are sensitivity and specificity.
For a cut-point c, sensitivity in the target
population is defined as
Pr[h(X, bβ) > c|Y = 1, S = 0]
and specificity in the target population is defined as
Pr[h(X, bβ) ≤c|Y = 0, S = 0].
That is, sensitivity in the target population is the proportion of the target population that have
the disease (Y = 1) that the model classifies as having the disease (h(X, bβ) > c). And, specificity
is the proportion of the target population that are disease free (Y = 0) that the model classifies as
disease free (h(X, bβ) ≤c).
Both sensitivity and specificity condition on true disease status while positive predictive value
and negative predictive value condition on the model derived classification. The positive predictive
value in the target population is defined as Pr[Y = 1|I(h(X, bβ) > c), S = 0] and the negative
predictive value in the target population is defined as Pr[Y = 0|I(h(X, bβ) ≤c), S = 0].
Plotting sensitivity vs 1−specificity when varying the threshold c gives the receiver operating
5
characteristic (ROC) curve. The area under the ROC curve (AUC) provides a summary of sen-
sitivity and specificity across thresholds. The AUC can be interpreted as the probability that a
randomly selected observation that has the disease (Y = 1) will have a higher model derived risk
than a randomly selected observation without the disease (Y = 0). Mathematically, the AUC in
the target population is defined as
E[I(h(Xi, bβ) > h(Xj, bβ))|Yi = 1, Yj = 0, Si = 0, Sj = 0]
where the indices i and j denote random observations from the target population with Y = 1 and
with Y = 0, respectively.
Loss-based measures of model performance such as the mean squared error, absolute loss, and
the Brier score [23] are another class of commonly used measures. A loss function L(Y, h(X, bβ))
measures the discrepancy between the outcome (Y ) and the model derived predictions (h(X, bβ)).
The risk (expected loss) in the target population is defined by E[L(Y, h(X, bβ))|S = 0]. In the main
part of the manuscript we focus on estimating sensitivity and AUC and mostly present results for
specificity, negative predictive value, positive predictive value, and loss-based measures of model
performance in the Supplementary Web Appendix.
3
Identifiability of measures of model performance
The following theorem shows that the sensitivity in the target population is identifiable using the
observable data O. A proof is given in Supplementary Web Appendix A.
Theorem 1. If assumptions A1 and A2 hold and E[Pr[Y = 1|X, R = 1]|S = 0] > 0, then the
sensitivity in the target population is identifiable using the observed data through the observed data
functional
E[I(h(X, bβ) > c) Pr[Y = 1|X, R = 1]|S = 0]
E[Pr[Y = 1|X, R = 1]S = 0]
(1)
6
or equivalently using the weighting representation
E
h
Pr[R=0|X]
Pr[R=1|X]I(h(X, bβ) > c, Y = 1, R = 1)
i
E
h
Pr[R=0|X]
Pr[R=1|X]I(Y = 1, R = 1)
i
.
(2)
In Supplementary Web Appendix A we prove the following identifiability result for the AUC.
Theorem 2. Assume that assumptions A1 and A2 hold and E[Pr[Y = 1|Xi, R = 1](1 −Pr[Y =
1|Xj, R = 1])|Si = 0, Sj = 0] > 0, where i is a random observation from the target population with
Y = 1 and j is a random observation from the target population with Y = 0. Then the AUC in the
target population is identifiable using the observed data functional
E[Pr[Yk = 1|Rk = 1, Xk] Pr[Yl = 0|Rl = 1, Xl]I(h(Xk, bβ) > h(Xl, bβ))|Sk = 0, Sl = 0]
E[Pr[Yk = 1|Rk = 1, Xk] Pr[Yl = 0|Rl = 1, Xl]|Sk = 0, Sl = 0]
,
(3)
or equivalently using the weighting representation
E
h
Pr[R=0|Xk]
Pr[R=1|Xk]
Pr[R=0|Xl]
Pr[R=1|Xl]I(h(Xk, bβ) > h(Xl, bβ), Yk = 1, Yl = 0, Rk = 1, Rl = 1)
i
E
h
Pr[R=0|Xk]
Pr[R=1|Xk]
Pr[R=0|Xl]
Pr[R=1|Xl]I(Yk = 1, Yl = 0, Rk = 1, Rl = 1)
i
.
(4)
Here, k is a random observation from the target population with Y = 1 and l is a random observation
from the target population with Y = 0.
In Supplementary Web Appendix D we provide identifiability results and estimators for loss-
based measures of model performance, specificity, and negative and positive predictive value.
4
Sampling framework
We adopt the sampling framework from causally interpretable meta-analysis for treatment effects
[8]. That is, we assume that there is a single population stratified by S and we assume that the
data from each of the K studies can be modeled as being a sample from some superpopulation
that can be potentially ill-defined and hard to characterize. We also assume that we have access
to a random sample from a well defined target population. We allow the sampling fractions for
the studies and the target population to be unknown and potentially unequal. More specifically,
7
we assume there are two sampling models i) a population sampling model which assumes we have
a random sample from the single superpopulation and ii) a biased sampling model where the
sampling is done stratified on S. If we denote densities from the population sampling model using
p(·) and densities from the biased sampling model using q(·), then the assumptions made imply
p(y|x, r = 1) = q(y|x, r = 1) and p(x|r = 0) = q(x|r = 0).
And as the probabilities in the
identifiability expressions (1) and (3) only rely on the densities p(y|x, r = 1) and p(x|r = 0), they
can be interpreted as being derived from the biased sampling model, with the expectations and
probabilities integrated with respect to densities from the biased sampling model. As the biased
sampling model is a more realistic representation of how the data is collected, we will work under
the biased sampling setting.
5
Estimation of measures of model performance in the target pop-
ulation
Sample analogs of expression (1) give the following outcome (or g-formula like [24]) estimator for
sensitivity in the target population:
bψsens,out =
Pn
i=1 I(Ri = 0)I(h(Xi, bβ) > c) bm(Xi)
Pn
i=1 I(Ri = 0) bm(Xi)
,
(5)
where bm(X) is an estimator for Pr[Y = 1|X, R = 1].
The sample analogs of expression (2) gives the following weighting estimator:
bψsens,w =
Pn
i=1 I(h(Xi, bβ) > c, Yi = 1, Ri = 1) bw(Xi)
Pn
i=1 I(Yi = 1, Ri = 1) bw(Xi)
,
(6)
where bw(X) is an estimator for Pr[R=0|X]
Pr[R=1|X]. In Supplementary Web Appendix B we derive the non-
parametric influence function for sensitivity in the target population. This influence function based
“doubly robust” estimator is given by
bψsens,dr =
Pn
i=1

I(Si = 0)I(h(Xi, bβ) > c) bm(Xi) + bw(Xi)I(Ri = 1)I(h(Xi, bβ) > c)

I(Yi = 1) −bm(Xi)
	
Pn
i=1
 I(Si = 0) bm(Xi) + bw(Xi)I(Ri = 1)

I(Yi = 1) −bm(Xi)
	
8
In Supplementary Web Appendix C we proof the following theorem.
Theorem 3. If either bm(X)
P
−→Pr[Y = 1|X, R = 1] or bw(X)
P
−→Pr[R=0|X]
Pr[R=1|X], then bψsens,dr is
consistent (i.e., bψsens,dr
P
−→ψsens).
So far we have assumed that the cut-point c is provided, but it is often data-dependent. For
example, the Youden index [25] is a way to select cut-points by maximizing the sum of sensitivity
and specificity. Using the methods developed, the Youden index can easily be extended to perform
cut-point selection in the target population. Let bψspec,out(c) be the outcome model estimator for
specificity in the target population provided in the Supplementary Web Appendix, then the outcome
model estimator for the optimal cut-off point is bcout = max
c
( bψsens,out(c) + bψspec,out(c) −1) and the
analogous versions using weighting or doubly robust estimators can also be used. Here, for each
evaluation measure the notation (c) denotes that the evaluation measure is calculated using the
cut-point c.
We use the notation in [16] to define estimators for the AUC in the target population. For a
function k(Xi, Xj), define dout(Oi, Oj; k(Xi, Xj)) = bm(Xi)(1 −bm(Xj))I(Si = 0, Sj = 0)k(Xi, Xj).
The outcome model estimator for the area under the curve in the target population is given by
bψauc,out =
P
i̸=j dout(Oi, Oj; I(h(Xi, bβ) > h(Xj, bβ))
P
i̸=j dout(Oi, Oj; 1)
.
(7)
Similarly, for a function k(Xi, Xj), define dw(Oi, Oj; k(Xi, Xj)) = bw(Xi) bw(Xj)I(Yi = 1, Yj =
0, Ri = 1, Rj = 1)k(Xi, Xj). The weighting-based estimator for the AUC in the target popula-
tion is given by
bψauc,w =
P
i̸=j dw(Oi, Oj; I(h(Xi, bβ) > h(Xj, bβ))
P
i̸=j dw(Oi, Oj; 1)
.
(8)
Lastly, we define the doubly robust estimator for the AUC in the target population as
bψauc,dr =
P
i̸=j ddr(Oi, Oj; k(Xi, Xj) = I(h(Xi, bβ) > h(Xj, bβ))
P
i̸=j ddr(Oi, Oj; k(Xi, Xj) = 1)
,
(9)
9
where
ddr(Oi, Oj; k(Xi, Xj)) = dw(Oi, Oj; k(Xi, Xj)) + dout(Oi, Oj; k(Xi, Xj))−
bw(Xi) bw(Xj) bm(Xi)(1 −bm(Xj))I(Ri = 1, Rj = 1)k(Xi, Xj).
(10)
The following theorem shows that the doubly robust estimator for the AUC in the target population
is doubly robust and a proof is given in the Supplementary Web Appendix.
Theorem 4. For a random variable W define Gn(W) = √n
  1
n
Pn
i=1 Wi −E[W]

. We assume
that the models bm(X) and bw(X) are parametric and indexed by parameters θ1 and θ2, respectively,
and that {Gn(m(X; θ1)) : θ1 ∈Θ1} and {Gn(m(X; θ2)) : θ2 ∈Θ2} are stochastically equicontinuous
where Θj is the parameter space for θj, j = 1, 2.
If either bm(X)
P
−→Pr[Y = 1|X, R = 1] or
bw(X)
P
−→Pr[R=0|X]
Pr[R=1|X], then bψauc,dr is consistent (i.e., bψauc,dr
P
−→ψauc).
6
Relaxing the conditional exchangeability assumption using knowl-
edge of the marginal prevalence rate in the target population
So far we have assumed that the conditional exchangeability assumption Y ⊥⊥R|X holds. Now
assume that this assumption is violated (Y ⊥̸⊥R|X) and therefore for at least one s′ ∈{1, . . . , K}
we have fY |X,S(y|x, s = 0) ̸= fY |X,S(y|x, s = s′). To relax that assumption we assume for each
study that the relationship between the population underlying the study sample and the target
population can be expressed through an exponential tilt model [26–29]
fY |X,S(y|x, s = 0) ∝eγs′yfY |X,S(y|x, s = s′), s′ ∈{1, . . . , K}
(11)
for some sensitivity parameter γs′ ∈R, for s′ ∈{1, . . . , K}. As outcome information is unavailable
in the target population, γs′ cannot be estimated using the observed data and hence needs to be
specified a priori. If γs′ = 0 for all s′ ∈{1, . . . , K}, then it can be shown that the conditional
exchangeability assumption Y ⊥⊥R|X holds.
10
As fY |X,S(y|x, s = 0) is a density, it follows that for all s′ ∈{1, . . . , K}
fY |X,S(y|x, 0) =
eγs′yfY |X,S(y|x, s′)
E[eγs′y|X = x, S = s′]
which implies
eγ1yfY |X,S(y|x, 1)
E[eγ1y|X = x, S = 1] =
eγ2yfY |X,S(y|x, 2)
E[eγ2y|X = x, S = 2] = . . . =
eγKyfY |X,S(y|x, K)
E[eγKy|X = x, S = K].
(12)
As outcome information is available in all the studies, all quantities appearing in the equation above
only rely on the observed data and hence is testable (e.g., using test of equality of distributions [30]).
However, rejecting the null hypothesis that all the densities in equation (12) are equal does not
indicate which, if any, of the studies satisfies equation (11). And, if the test of equality of densities
in Equation (12) does not provide evidence against the equality of densities in equation (12), and
we believe that Equation (12) holds, that does not imply that assumption of the exponential tilt
model (11) is satisfied.
In Supplementary Web Appendix E we proof the following theorem.
Theorem 5. Under the exponential tilt model, the sensitivity in the target population when trans-
porting from study s′ is identifiable using the observed data functional
ψsens,out(γs′) =
E
"
E[I(h(X,bβ)>c,Y =1)eγs′ y|X,S=s′]
E[eγs′ y|X,S=s′]
S = 0
#
E
"
E[I(Y =1)eγs′ y|X,S=s′]
E[eγs′ y|X,S=s′]
S = 0
#
.
(13)
Expression (13) suggests the following outcome model estimator for the sensitivity in the target
population
bψsens,out(γs′) =
Pn
i=1 I(Si = 0)bb1
s′(Xi)
Pn
i=1 I(Si = 0)bb0
s′(Xi)
,
(14)
where bbj
s′(X) is an estimator for E[I(h(X,bβ)>c)jI(Y =1)eγs′ y|X,S=s′]
E[eγs′ y|X,S=s′]
that can be implemented by bbj
s′(X) =
I(h(X, bβ) > c)jeγ bms′(X)
1 + bms′(X)(eγ −1)
for j = {0, 1}, where bms′(X) is an estimator for Pr[Y = 1|X, S = s′].
To implement bψsens,out(γs′) the sensitivity analysis parameter (γs′) needs to be selected and as
11
outcome information is unavailable in the target population it cannot be estimated using the data.
However if information on the marginal prevalence rate in the target population E[Y |S = 0] is
available, then under the exponential tilt model
Z Z
y
eγs′yfY |X,S(y|x, s′)
E[eγs′y|X = x, S = s′]fX|S(x|0)dydx −E[Y |S = 0] = 0
(15)
and γs′ can be estimated as a solution to the sample analog of equation (15).
The estimators bψsens,out(γs′), s′ ∈{1, . . . , K} transport sensitivity at the individual study level
to the same target population and are therefore estimating the same target parameter, provided
that all relevant assumptions hold. Incompatibility of the data with the asymptotic equality of all
bψsens,out(γs′) suggests that at least one assumption is violated (i.e., at least one of the estimators
bψsens,out(γk) is biased but we cannot from the data determine which it is). If the investigator be-
lieves that all assumptions hold and the data does not provide evidence to the contrary, a natural
question is how to combine bψsens,out(γs′), s′ ∈{1, . . . , K} to improve efficiency. Any linear com-
bination PK
i=1 bak bψsens,out(γk) is a consistent estimator for the sensitivity in the target population
as long as the weights bak, k = 1, . . . , K sum to one (here, the notation bak is used to denote that
the weights can be data dependent). Hence, the main consideration when choosing the weights is
efficiency. In standard meta analysis, selecting the weights bak proportional to the inverse variance
of each estimator bψsens,out(γk) minimizes asymptotic variance [31]. However, this result does not
hold when combining bψsens,out(γk) as they all use the same target population data and are there-
fore not independent [32]. For each s′ ∈{1, . . . , K}, equation (14) puts restrictions on the joint
distribution of (X, S, S × Y ) and as bψsens,out(γk) are estimated using different parts of the data
there is no guarantee that in finite samples there exists a joint distribution that is compatible with
all the estimators. However if all the assumptions hold and all the nuisance functions are correctly
specified, then asymptotically the estimators are compatible [29,33].
12
7
Simulations
To evaluate the finite sample performance of the estimators, we performed simulations comparing
the outcome model estimator, the weighting estimator, and an estimator that estimates model
performance using pooled data from the source studies, referred to as the source estimator.
We simulated the covariate vector from a five dimensional multivariate normal distribution with
mean zero and a covariance matrix where element (i, j) is equal to 0.6|i−j|. The selection into any
study (R) was simulated from a logistic regression model R ∼Ber(Pr[R = 1|X]) where
Pr[R = 1|X] = expit(1 + 0.5X1 + 0.5X2 + 0.3X3 + 0.3X2
1 + 0.3X2
2 + 0.3X2
3),
where expit(x) =
ex
1+ex . The covariate dependent selection into the target population ensures that
there are differences between the covariate distributions in the target population and the population
underlying the pooled data from all the studies (R = 1). We considered a setting where there are
three studies (K = 3) and study participants were selected into one of the three studies by simulat-
ing from a multinomial logistic regression model S|X, R = 1 ∼Multinomial((p1, p2, p3), Pn
i=1 Ri),
where p1 =
β
1+β+η, p2 =
η
1+β+η, p3 = 1−p1−p3, with β = exp(log(1.3)X1+log(1.3)X2+log(1.3)X3)
and η = exp(log(0.8)X1 + log(0.8)X2 + log(0.8)X3). The covariate dependent selection into each
study ensures that the populations underlying each study have different covariate distributions.
The outcome was simulated from a logistic regression model Y ∼Ber(Pr[Y = 1|X]) where
Pr[Y = 1|X] = expit(1 + 0.5X1 + 0.2X2 + 0.3X2
1 + 0.3X2
2).
The model we evaluate the performance of was the asymptotic limit (estimated numerically) of a
logistic regression model in the source population that used linear main affects of all five covariates.
As that model does not include X2
1 and X2
2, it is misspecified. To evaluate the performance of the
model in the target population we used sensitivity, specificity, negative predictive value, positive
predictive value, the Brier score, and the area under the curve. The cut-point required to define
sensitivity, specificity, negative and positive predictive value was selected using the Youden index
13
(maximizing the sum of sensitivity and specificity) from the observations with R = 1.
We ran 1000 simulations where the total sample size was n = 2000. Using this set-up, the
prevalence rate of the outcome is approximately 75% in the target population and 82% in the
collection of the study data. The average sample size in the data from the target population is 366,
565 in study one, 573 in study two, and 496 in study three.
The simulation results are presented in Figure 1. The results show that the outcome model,
doubly robust, and the weighting estimators were nearly unbiased for all measures of model per-
formance. The source estimator is biased for all the measures (6 −200% relative bias) as it fails
to account for the differences between the target population and the population underlying the
pooled data from all the studies. In Supplementary Web Appendix F we present simulation results
under correctly specified models and for cases where the outcome model and the model for study
participation were estimated using a generalized additive models. The results from these additiona
simulation studies show the same trends to those observed in Figure 1.
8
Analysis using data on lung cancer screening
In this section we apply the estimators developed to data on lung cancer screening. We use data
from two large lung cancer screening trials, the National Lung Screening Trial (NLST) [34] and the
Prostate, Lung, Colorectal, and Ovarian (PLCO) Cancer Screening Trial [35]. We are interested in
evaluating the performance of a model for estimating the risk of being diagnosed with lung cancer
within six years from study entry.
NLST randomized participants to either screening with chest X-ray or screening with low-dose
computed tomography. Participants enrolled to PLCO were randomized to either an usual care
arm or an arm where participants received screening for various cancers including chest X-ray
screening for lung cancer. As both trials include screening with chest X-ray we focus on the subset
of participants that were randomized to receive chest X-ray screening for lung cancer. The outcome
of interest is whether a participant was diagnosed with lung cancer within six years from study
enrollment (binary outcome).
A natural target population for lung cancer screening is everyone in the US who is eligible for
14
0.1
0.2
0.3
0.4
OM
W
DR Source
Method
Sensitivity
1)
0.80
0.85
0.90
0.95
OM
W
DR Source
Method
Specificity
2)
0.80
0.85
0.90
0.95
OM
W
DR Source
Method
PPV
3)
0.200
0.225
0.250
0.275
0.300
OM
W
DR Source
Method
NPV
4)
0.14
0.16
0.18
0.20
OM
W
DR Source
Method
Brier
5)
0.50
0.55
0.60
0.65
OM
W
DR Source
Method
AUC
6)
Figure 1: Simulation results for estimating model performance in the target population estimated
using the outcome model (OM) estimator, weighting (W) estimator, doubly robust (DR) and an
estimator that uses only data from the collection of studies (Source).
The measures of model
performance evaluated are: sensitivity (Plot 1), specificity (Plot 2), positive predictive value (Plot
3), negative predictive value (Plot 4), Brier score (Plot 5), and area under the curve (Plot 6). The
horizontal line is the true measure of model performance (calculated analytically). Here, the model
that is evaluated is correctly specified.
15
lung cancer screening. To avoid violations of the positivity assumption and as the criteria used by
U.S. Preventive Services Task Force to recommend people for lung cancer screening [36] are very
similar to the eligibility criteria for NLST, we define the target population as all people in the
US who meet the eligibility criteria for the NLST (people aged 55 to 74 that had ≥30 pack-year
history who were current smokers or had quit within the past 15 years). To obtain a reasonable
sample from the target population we used data from the 2003-2004 NHANES survey. NHANES is
a cross-sectional survey constructed to be representative of the non-institutionalized US population.
We used the subset of the NHANES participants that participated in a smoking sub-study and met
the NLST eligibility criteria (data from the smoking sub-study is needed to assess the eligibility
criteria). Each observation in NHANES is associated with a sampling weight that accounts for,
among other things, oversampling of certain subgroups and survey non-respondence. In Section G
in the Supplementary Web Appendix we show how the estimators presented in Section 5 can be
modified to account for sampling weights.
For simplicity, and due to the limited amount of missing data, we focus on the participants that
have complete data on covariates listed in Table 1 and for NLST and PLCO participants that have
six years of follow-up. This resulted in 22, 920 participants used from NLST, 17, 639 from PLCO,
and 219 participants from NHANES (representing approximately 8.5 million participants).
We split the NLST data into equal sized training and test sets. Using the data from the training
set from NLST we built a logistic regression model with linear main effects of all variables listed in
Table 1. To evaluate the performance of that model in the target population, we used data from the
test set of the NLST and PLCO data as the study data and data from NHANES as the sample from
the target population. To select the cut-point (c) used to calculate sensitivity, specificity, NPV,
and PPV we used the Youden index calculated using data from the NLST training set (i.e., the
value that maximizes the sum of sensitivity and specificity). To estimate the nuisance parameters
needed for the implementation of the outcome model and weighting estimators logistic regression,
models with linear main effects of all variables listed in Table 1 were used.
To calculate confidence intervals we used a stratified bootstrap procedure that was consistent
with the NHANES sampling design [37]. We started by resampling at the first primary sampling
16
unit level and within each first primary sampling unit resampled at the level of the secondary
sampling unit. To estimate confidence intervals for the source estimator we used the non-parametric
bootstrap. We note that there is some potential for non-identifiable overlap between the samples
from the NLST, PLCO, and NHANES. But considering the large number of people eligible for lung
cancer screening, substantial overlap between the samples is unlikely.
Table 1 shows summary statistics for the variables used in the analysis stratified by datasource.
The table shows that the summary statistics are relatively similar between the NLST and PLCO
while there are substantial differences between the NHANES and the two trials (e.g., the NHANES
sample has more comorbidities, less education, and is more racially diverse).
Table 1:
Summary of participant characteristics for participants in the National Lung Screening Trial
(NLST), the Prostate, Lung, Colorectal, and Ovarian (PLCO) Cancer Screening Trial, and the NHANES
2003-2004 survey. Continuous variables are summarized using mean (standard deviation) and categorical
variables are summarized by percentages in each category.
The summaries for the NHANES data are
weighted by the NHANES sampling weight. BMI is body max index; Smoke years is the total number of
years the participant smoked cigarettes; Smoke age is the age at smoking onset; Pack years is calculated as
(Total number of years Smoked × Cigarettes Per Day/20).
Variable
NLST
PLCO
NHANES
Age
61.3 (5.0)
62.4 (5.2)
63.1 (5.5)
BMI
27.9 (5.1)
27.6 (4.8)
28.6 (5.6)
Race (White)
90.8%
91.0%
84.5%
Education level
Some college education
55.5%
53.2%
45.7%
High school graduate
38.8%
37.5%
29.1%
Smoke years
39.6 (7.3)
36.1 (9.2)
42.5 (7.4)
Gender (Male)
58.7%
63.8%
63.0%
Marital status (Married)
68.4%
72.8%
64.7%
Pack year
55.5 (23.3)
57.0 (26.2)
60.6 (28.9)
History of diabetes (Yes)
9.3%
8.5%
20.3%
History of emphysema (Yes)
7.3%
6.5%
8.7%
History of heart disease
or heart attack (Yes)
12.2%
13.2%
28.0%
History of hypertension (Yes)
35.2%
35.3%
45.8%
Cigarettes per day categorical
11-20
47.6%
36.5%
53.8%
21-30
27.4%
30.7%
19.2%
31-40
18.0%
19.4%
16.8%
41-60
6.2%
10.9%
9.0%
61-80
0.6%
2.1%
1.1%
> 80
0.1%
0.4%
0%
Table 2 shows estimates and standard errors from the outcome model estimator, the doubly
robust estimator, the weighting estimator, and an estimator that pools data from the NLST test
set and the PLCO trial for AUC, sensitivity, specificity, PPV, NPV, and Brier score. The result
shows that the outcome model, doubly robust, and weighting estimators are similar for all mea-
17
sures suggesting limited impact of the specification of the outcome model and the model for study
participation. The pooled estimator has lower Brier score, lower sensitivity, and higher specificity
compared to the transportability estimators while the AUC and the negative and positive predictive
values are similar to the outcome model and weighting estimators.
Table 2: Estimates and standard errors from the outcome model, weighting, and source population esti-
mators of area under the curve, sensitivity, specificity, positive predictive value (PPV), negative predictive
value (NPV), and Brier risk. Outcome model refers to estimates from the outcome model estimator, Doubly
Robust refers to estimates from the doubly robust estimator, weighting refers to estimates from the weighing
estimator, and source refers to estimates from an estimator that combines data from the NLST and PLCO.
Outcome Model
Weighting
Doubly Robust
Source
Area under the curve
0.704 (0.013)
0.680 (0.011)
0.689 (0.016)
0.700 (0.0064)
Sensitivity
0.842 (0.029)
0.834 (0.024)
0.841 (0.029)
0.613 (0.012)
Specificity
0.409 (0.046)
0.402 (0.034)
0.408 (0.046)
0.673 (0.029)
PPV
0.114 (0.0083)
0.106 (0.0052)
0.111 (0.0078)
0.0971 (0.0029)
NPV
0.966 (0.0026)
0.966 (0.0020)
0.967 (0.0029)
0.968 (0.0013)
Brier risk
0.0835 (0.0051)
0.0719 (0.0038)
0.0824 (0.0049)
0.0543 (0.0012)
9
Discussion
In this manuscript we developed methods for meta analysis of prediction models that can be
interpreted in the context of a target population. We provided identifiability results and estimators
for several measures of model performance. The estimators show good performance in simulations
and are used to analyse data on lung cancer screening. For the lung cancer screening analyses the
data from the target population is associated with a sampling weight and we extend the estimators
to handle sampling weights. All of the developments hold when evaluating the performance of both
correctly specified and misspecified models.
In our set-up, the model that is being evaluated is built on a dataset that is independent of the
data used for model development. This incorporates when an external evaluation is done, when a
split into a training and a test set is used, the use of cross-validated measures of model performance,
and when evaluating the performance of a biomarker.
The methods developed assume that we have access to individual level data on participants
from all studies and individual level data from the target population. Developing methods that
can be used with summary level information would be useful.
Other extensions of interest in-
18
clude extensions to more complex data-structures, systematically-missing data [38], and addressing
measurement error.
Acknowledgements
This work was supported in part by National Library of Medicine (NLM) Award R01LM013616,
and Patient-Centered Outcomes Research Institute (PCORI) awards ME-2019C3-17875, and ME-
2021C2-22365. Statements in this paper do not necessarily represent the views of the PCORI,
its Board of Governors, the Methodology Committee, or the NIH. We thank the National Cancer
Institute (NCI) for access to the National Lung Screening Trial (NLST) and PCLO data. This
paper does not necessarily reflect the opinions or views of NCI, NHLBI, PLCO, or NLST. L.
Wen is supported by the Natural Sciences and Engineering Research Council of Canada (NSERC)
Discovery Grant [RGPIN-2023-03641, DGECR-2023-00455].
References
[1] L. F. Hutchins, J. M. Unger, J. J. Crowley, C. A. Coltman Jr, and K. S. Albain, “Underrepre-
sentation of patients 65 years of age or older in cancer-treatment trials,” New England Journal
of Medicine, vol. 341, no. 27, pp. 2061–2067, 1999.
[2] P. Pinsky, A. Miller, B. Kramer, T. Church, D. Reding, P. Prorok, E. Gelmann, R. Schoen,
S. Buys, R. Hayes, et al., “Evidence of a healthy volunteer effect in the prostate, lung, col-
orectal, and ovarian cancer screening trial,” American journal of epidemiology, vol. 165, no. 8,
pp. 874–881, 2007.
[3] N. A. of Sciences Engineering, Medicine, et al., “Improving representation in clinical trials and
research: building research equity for women and underrepresented groups,” 2022.
[4] T. P. Debray, J. A. Damen, K. I. Snell, J. Ensor, L. Hooft, J. B. Reitsma, R. D. Riley, and K. G.
Moons, “A guide to systematic review and meta-analysis of prediction model performance,”
bmj, vol. 356, 2017.
19
[5] T. P. Debray, J. A. Damen, R. D. Riley, K. Snell, J. B. Reitsma, L. Hooft, G. S. Collins, and
K. G. Moons, “A framework for meta-analysis of prediction model studies with binary and
time-to-event outcomes,” Statistical methods in medical research, vol. 28, no. 9, pp. 2768–2786,
2019.
[6] J. A. Steingrimsson, C. Gatsonis, and I. J. Dahabreh, “Transporting a prediction model for
use in a new target population,” arXiv preprint arXiv:2101.11182, 2021.
[7] I. J. Dahabreh, L. C. Petito, S. E. Robertson, M. A. Hern´an, and J. A. Steingrimsson, “Toward
causally interpretable meta-analysis: Transporting inferences from multiple randomized trials
to a new target population,” Epidemiology, vol. 31, no. 3, pp. 334–344, 2020.
[8] I. J. Dahabreh, S. E. Robertson, L. C. Petito, M. A. Hern´an, and J. A. Steingrimsson, “Efficient
and robust methods for causally interpretable meta-analysis: Transporting inferences from
multiple randomized trials to a target population,” Biometrics, vol. 79, no. 2, pp. 1057–1072,
2023.
[9] H. Shimodaira, “Improving predictive inference under covariate shift by weighting the log-
likelihood function,” Journal of statistical planning and inference, vol. 90, no. 2, pp. 227–244,
2000.
[10] M. Sugiyama, M. Krauledat, and K.-R. M˜Aˇzller, “Covariate shift adaptation by importance
weighted cross validation,” Journal of Machine Learning Research, vol. 8, no. May, pp. 985–
1005, 2007.
[11] M. Sugiyama and M. Kawanabe, Machine learning in non-stationary environments: Introduc-
tion to covariate shift adaptation. MIT press, 2012.
[12] S. Morrison, C. Gatsonis, I. J. Dahabreh, B. Li, and J. A. Steingrimsson, “Robust estimation
of loss-based measures of model performance under covariate shift,” Canadian Journal of
Statistics, 2023.
[13] R. Sahoo,
L. Lei,
and S. Wager,
“Learning from a biased sample,” arXiv preprint
arXiv:2209.01754, 2022.
20
[14] A. N. Angelopoulos, S. Bates, C. Fannjiang, M. I. Jordan, and T. Zrnic, “Prediction-powered
inference,” Science, vol. 382, no. 6671, pp. 669–674, 2023.
[15] J. Ge, S. Tang, J. Fan, C. Ma, and C. Jin, “Maximum likelihood estimation is all you need for
well-specified covariate shift,” arXiv preprint arXiv:2311.15961, 2023.
[16] B. Li, C. Gatsonis, I. J. Dahabreh, , and J. A. Steingrimsson, “Estimating the area under the
roc curve when transporting a prediction model to a target population,” Biometrics, 2022.
[17] K. Zhang, M. Gong, and B. Sch¨olkopf, “Multi-source domain adaptation: A causal view,” in
Twenty-ninth AAAI conference on artificial intelligence, 2015.
[18] S. Sun, H. Shi, and Y. Wu, “A survey of multi-source domain adaptation,” Information Fusion,
vol. 24, pp. 84–92, 2015.
[19] S. Zhao, B. Li, P. Xu, and K. Keutzer, “Multi-source domain adaptation in the deep learning
era: A systematic survey,” arXiv preprint arXiv:2002.12169, 2020.
[20] M. Nomura and Y. Saito, “Efficient hyperparameter optimization under multi-source covariate
shift,” in Proceedings of the 30th ACM International Conference on Information & Knowledge
Management, pp. 1376–1385, 2021.
[21] Y. Mansour, M. Mohri, and A. Rostamizadeh, “Domain adaptation with multiple sources,”
Advances in neural information processing systems, vol. 21, 2008.
[22] H. Qiu, E. T. Tchetgen, and E. Dobriban, “Efficient and multiply robust risk estimation under
general forms of dataset shift,” arXiv preprint arXiv:2306.16406, 2023.
[23] G. W. Brier, “Verification of forecasts expressed in terms of probability,” Monthly weather
review, vol. 78, no. 1, pp. 1–3, 1950.
[24] J. Robins, “A new approach to causal inference in mortality studies with a sustained exposure
period—application to control of the healthy worker survivor effect,” Mathematical modelling,
vol. 7, no. 9-12, pp. 1393–1512, 1986.
21
[25] W. J. Youden, “Index for rating diagnostic tests,” Cancer, vol. 3, no. 1, pp. 32–35, 1950.
[26] D. Scharfstein, A. McDermott, I. D´ıaz, M. Carone, N. Lunardon, and I. Turkoz, “Global sen-
sitivity analysis for repeated measures studies with informative drop-out: A semi-parametric
approach,” Biometrics, vol. 74, no. 1, pp. 207–219, 2018.
[27] D. O. Scharfstein and A. McDermott, “Global sensitivity analysis of clinical trials with missing
patient-reported outcomes,” Statistical Methods in Medical Research, vol. 28, no. 5, pp. 1439–
1456, 2018.
[28] D. O. Scharfstein, J. Steingrimsson, A. McDermott, C. Wang, S. Ray, A. Campbell, E. Nunes,
and A. Matthews, “Global sensitivity analysis of randomized trials with nonmonotone missing
binary outcomes: Application to studies of substance use disorders,” Biometrics, 2021.
[29] I. J. Dahabreh, J. M. Robins, S. J. Haneuse, S. E. Robertson, J. A. Steingrimsson, and M. A.
Hern´an, “Global sensitivity analysis for studies extending inferences from a randomized trial
to a target population,” arXiv e-prints, pp. arXiv–2207, 2022.
[30] A. Luedtke, M. Carone, and M. J. van der Laan, “An omnibus non-parametric test of equality
in distribution for unknown functions,” Journal of the Royal Statistical Society: Series B
(Statistical Methodology), vol. 81, no. 1, pp. 75–99, 2019.
[31] D. Zeng and D. Lin, “On random-effects meta-analysis,” Biometrika, vol. 102, no. 2, pp. 281–
294, 2015.
[32] J. A. Steingrimsson, D. H. Barker, R. Bie, and I. J. Dahabreh, “Systematically missing data
in causally interpretable meta-analysis,” Biostatistics, 2023.
[33] J. M. Robins, A. Rotnitzky, and D. O. Scharfstein, “Sensitivity analysis for selection bias and
unmeasured confounding in missing data and causal inference models,” in Statistical models
in epidemiology, the environment, and clinical trials, pp. 1–94, Springer, 2000.
[34] N. L. S. T. R. Team, “Reduced lung-cancer mortality with low-dose computed tomographic
screening,” New England Journal of Medicine, vol. 365, no. 5, pp. 395–409, 2011.
22
[35] M. M. Oken, W. G. Hocking, P. A. Kvale, G. L. Andriole, S. S. Buys, T. R. Church, E. D.
Crawford, M. N. Fouad, C. Isaacs, D. J. Reding, et al., “Screening by chest radiograph and
lung cancer mortality: the prostate, lung, colorectal, and ovarian (plco) randomized trial,”
JAMA, vol. 306, no. 17, pp. 1865–1873, 2011.
[36] A. H. Krist, K. W. Davidson, C. M. Mangione, M. J. Barry, M. Cabana, A. B. Caughey, et al.,
“Screening for lung cancer: Us preventive services task force recommendation statement,”
JAMA, vol. 325, no. 10, pp. 962–970, 2021.
[37] J. Shao, “Impact of the bootstrap on sample surveys,” Statistical Science, vol. 18, no. 2,
pp. 191–198, 2003.
[38] J. A. Steingrimsson, D. H. Barker, R. Bie, and I. J. Dahabreh, “Systematically missing data
in causally interpretable meta-analysis,” arXiv preprint arXiv:2205.00610, 2022.
23
Appendix A
Proofs
Proof of theorem 1: For the outcome model representation
E[I(h(X, bβ) > c)|Y = 1, S = 0] = E[I(h(X, bβ) > c, Y = 1)|S = 0]
E[I(Y = 1)|S = 0]
= E[E[I(h(X, bβ) > c, Y = 1)|X, S = 0]|S = 0]
E[E[I(Y = 1)|X, S = 0]|S = 0]
= E[E[I(h(X, bβ) > c, Y = 1)|X, S = 0]|S = 0]
E[E[I(Y = 1)|X, R = 1]|S = 0]
= E[I(h(X, bβ) > c) E[I(Y = 1)|X, S = 0]|S = 0]
E[E[I(Y = 1)|X, R = 1]|S = 0]
= E[I(h(X, bβ) > c) Pr[Y = 1|X, R = 1]|S = 0]
E[Pr[Y = 1|X, R = 1]|S = 0]
.
For the inverse-odds weighting we have
E[I(h(X, bβ) > c)|Y = 1, S = 0] = E[I(h(X, bβ) > c, Y = 1)|S = 0]
E[I(Y = 1)|S = 0]
= E[E[I(h(X, bβ) > c, Y = 1)|X, S = 0]|S = 0]
E[E[I(Y = 1)|X, S = 0]|S = 0]
= E[I(S = 0)I(h(X, bβ) > c) Pr[Y = 1|X, S = 0]]
E[I(S = 0) Pr[Y = 1|X, S = 0]]
= E[I(S = 0)I(h(X, bβ) > c) Pr[Y = 1|X, R = 1]]
E[I(S = 0) Pr[Y = 1|X, R = 1]]
=
E
h
I(S = 0)I(h(X, bβ) > c) Pr[Y =1,R=1|X]
Pr[R=1|X]
i
E
h
I(S = 0) Pr[Y =1,R=1|X]
Pr[R=1|X]
i
=
E
h
E
h
I(S = 0)I(h(X, bβ) > c) Pr[Y =1,R=1|X]
Pr[R=1|X]
X
ii
E
h
E
h
I(S = 0) Pr[Y =1,R=1|X]
Pr[R=1|X]
X
ii
=
E
h
E
h
Pr[R=0|X]
Pr[R=1|X]I(h(X, bβ) > c) Pr[Y = 1, R = 1|X]
X
ii
E
h
E
h
Pr[S=0|X]
Pr[R=1|X] Pr[Y = 1, R = 1|X]
X
ii
=
E
h
E
h
Pr[R=0|X]
Pr[R=1|X]I(h(X, bβ) > c, Y = 1, R = 1)
X
ii
E
h
E
h
Pr[S=0|X]
Pr[R=1|X]I(Y = 1, R = 1)
X
ii
=
E
h
Pr[S=0|X]
Pr[R=1|X]I(h(X, bβ) > c, Y = 1, R = 1)
i
E
h
Pr[S=0|X]
Pr[R=1|X]I(Y = 1, R = 1)
i
24
Proof of theorem 2: Let l denote a random observation from the target population with the
outcome (Y = 1) and k denote a random observation from the target population without the
outcome (Y = 0). Following [16] we have that the AUC in the target population can be rewritten
as
E[I(h(Xl, bβ) > h(Xk, bβ))|Yl = 1, Yk = 0, Sl = 0, Sk = 0]
=E[I(h(Xl, bβ) > h(Xk, bβ), Yl = 1, Yk = 0)|Sl = 0, Sk = 0]
Pr[Yl = 1, Yk = 0|Sl = 0, Sk = 0]
=E[E[I(h(Xl, bβ) > h(Xk, bβ), Yl = 1, Yk = 0)|Xl, Xk, Sl = 0, Sk = 0]|Sl = 0, Sk = 0]
E[Pr[Yl = 1, Yk = 0|Xl, Xk, Sl = 0, Sk = 0]|Sl = 0, Sk = 0]
=E[I(Sl = 0, Sk = 0, h(Xl, bβ) > h(Xk, bβ)) Pr[Yl = 1, Yk = 0|Xl, Xk, Sl = 0, Sk = 0]]
E[I(Sl = 0, Sk = 0) Pr[Yl = 1, Yk = 0|Xl, Xk, Sl = 0, Sk = 0]]
=E[I(Sl = 0, Sk = 0, h(Xl, bβ) > h(Xk, bβ)) Pr[Yl = 1, Yk = 0|Xl, Xk, Rl = 1, Rk = 1]]
E[I(Sl = 0, Sk = 0) Pr[Yl = 1, Yk = 0|Xl, Xk, Rl = 1, Rk = 1]]
=E[I(Sl = 0, Sk = 0, h(Xl, bβ) > h(Xk, bβ)) Pr[Yl = 1|Xl, Rl = 1] Pr[Yk = 0|Xk, Rk = 1]]
E[I(Sl = 0, Sk = 0) Pr[Yl = 1|Xl, Rl = 1] Pr[Yk = 0|Rk = 1, Xk]]
=E[I(h(Xl, bβ) > h(Xk, bβ)) Pr[Yl = 1|Xl, Rl = 1] Pr[Yk = 0|Xk, Rk = 1]|Sl = 0, Sk = 0]
E[Pr[Yl = 1|Xl, Rl = 1] Pr[Yk = 0|Rk = 1, Xk]|Sl = 0, Sk = 0]
.
Now we prove the weighting-based identifiability result given by expression (4)
E[I(h(Xl, bβ) > h(Xk, bβ))|Yl = 1, Yk = 0, Sl = 0, Sk = 0]
=E[I(h(Xl, bβ) > h(Xk, bβ), Yl = 1, Yk = 0)|Sl = 0, Sk = 0]
Pr[Yl = 1, Yk = 0|Sl = 0, Sk = 0]
=E[E[I(h(Xl, bβ) > h(Xk, bβ), Yl = 1, Yk = 0)|Xl, Xk, Sl = 0, Sk = 0]|Sl = 0, Sk = 0]
E[Pr[Yl = 1, Yk = 0|Xl, Xk, Sk = 0, Sk = 0]|Sl = 0, Sk = 0]
=E[I(Sl = 0, Sk = 0)I(h(Xl, bβ) > h(Xk, bβ)) Pr[Yl = 1, Yk = 0|Xl, Xk, Sl = 0, Sk = 0]]
E[I(Sl = 0, Sk = 0) Pr[Yl = 1, Yk = 0|Xl, Xk, Sk = 0, Sk = 0]]
=E[I(Sl = 0, Sk = 0)I(h(Xl, bβ) > h(Xk, bβ)) Pr[Yl = 1, Yk = 0|Xl, Xk, Rl = 1, Rk = 1]]
E[I(Sl = 0, Sk = 0) Pr[Yl = 1, Yk = 0|Xl, Xk, Rl = 1, Rk = 1]]
=
E
h
I(Sl = 0, Sk = 0)I(h(Xl, bβ) > h(Xk, bβ)) Pr[Yl=1,Yk=0,Rl=1,Rk=1|Xl,Xk]
Pr[Rl=1,Rk=1|Xl,Xk]
i
E
h
I(Sl = 0, Sk = 0) Pr[Yl=1,Yk=0,Rl=1,Rk=1|Xl,Xk]]
Pr[Rl=1,Rk=1|Xl,Xk]
i
=
E
h
E
h
I(Sl = 0, Sk = 0)I(h(Xl, bβ) > h(Xk, bβ)) Pr[Yl=1,Yk=0,Rl=1,Rk=1|Xl,Xk]
Pr[Rl=1,Rk=1|Xl,Xk]
Xl, Xk
ii
E
h
E
h
I(Sl = 0, Sk = 0) Pr[Yl=1,Yk=0,Rl=1,Rk=1|Xl,Xk]]
Pr[Rl=1,Rk=1|Xl,Xk]
Xl, Xk
ii
25
=
E
h
Pr[S=0|Xl] Pr[S=0|Xk]
Pr[R=1|Xl] Pr[R=1|Xk]I(h(Xl, bβ) > h(Xk, bβ)) Pr[Yl = 1, Yk = 0, Rl = 1, Rk = 1|Xl, Xk]
i
E
h
Pr[S=0|Xl] Pr[S=0|Xk]
Pr[R=1|Xl] Pr[R=1|Xk] Pr[Yl = 1, Yk = 0, Rl = 1, Rk = 1|Xl, Xk]
i
=
E
h
Pr[S=0|Xl] Pr[S=0|Xk]
Pr[R=1|Xl] Pr[R=1|Xk]I(h(Xl, bβ) > h(Xk, bβ), Yl = 1, Yk = 0, Rl = 1, Rk = 1)
i
E
h
Pr[S=0|Xl] Pr[S=0|Xk]
Pr[R=1|Xl] Pr[R=1|Xk]I(Yl = 1, Yk = 0, Rl = 1, Rk = 1)
i
Appendix B
Influence function for sensitivity
We start by finding the non-parametric influence function for the denominator and numerator in
the outcome formulation for sensitivity
E[E[I(h(X, bβ) > c)I(Y = 1)|X, R = 1]|S = 0]
E[E[Y = 1|X, R = 1]|S = 0]
=: α1
α0
Following the same steps as in the proof of theorem 3 in [12] we get the non-parametric influence
function for the numerator is
α1
1,p0 = I(S = 0)
Pr[S = 0]

E[I(h(X, bβ) > c, Y = 1)|X, R = 1] −α1
	
+ Pr[S = 0|X]I(R = 1)
Pr[S = 0] Pr[R = 1|X]

I(h(X, bβ) > c, Y = 1) −E[I(h(X, bβ) > c)I(Y = 1)|X, R = 1]
	
= I(S = 0)
Pr[S = 0]

I(h(X, bβ) > c)E[I(Y = 1)|X, R = 1] −α1
	
+ I(h(X, bβ) > c) Pr[S = 0|X]I(R = 1)
Pr[S = 0] Pr[R = 1|X]

I(Y = 1) −E[I(Y = 1)|X, R = 1]
	
and the non-parametric influence function for the denominator is
α1
0,p0 = I(S = 0)
Pr[S = 0]

E[I(Y = 1)|X, R = 1] −α0
	
+ Pr[S = 0|X]I(R = 1)
Pr[S = 0] Pr[R = 1|X]

I(Y = 1) −E[I(Y = 1)|X, R = 1]
	
The influence function α1
1,p0 leads to the non-parametric estimator for the numerator
1
n0
n
X
i=1

I(Si = 0)I(h(Xi, bβ) > c) bm(Xi) + bw(Xi)I(Ri = 1)I(h(Xi, bβ) > c)

I(Yi = 1) −bm(Xi)
	
, .
26
And, The influence function α1
0,p0 leads to the non-parametric estimator for the denominator
1
n0
n
X
i=1
 I(Si = 0) bm(Xi) + bw(Xi)I(Ri = 1)

I(Yi = 1) −bm(Xi)
	
Hence, a natural estimator for the sensitivity in the target population is
bψsens,dr =
Pn
i=1

I(Si = 0)I(h(Xi, bβ) > c) bm(Xi) + bw(Xi)I(Ri = 1)I(h(Xi, bβ) > c)

I(Yi = 1) −bm(Xi)
	
Pn
i=1
 I(Si = 0) bm(Xi) + bw(Xi)I(Ri = 1)

I(Yi = 1) −bm(Xi)
	
The non-parametric influence function for the sensitivity in the target population is
α1
1,p0
α0
−α1α1
0,p0
α2
0
= 1
α0
 α1
1,p0 −ψsensα1
0,p0

Now
−I(S = 0)
Pr[S = 0]α1 + ψsens
I(S = 0)
Pr[S = 0]α0 = 0
So
α1
1,p0 −ψsensα1
0,p0 = A −B,
where
A = I(S = 0)
Pr[S = 0]

I(h(X, bβ) > c)E[I(Y = 1)|X, R = 1]
	
+ I(h(X, bβ) > c) Pr[S = 0|X]I(R = 1)
Pr[S = 0] Pr[R = 1|X]

I(Y = 1) −E[I(Y = 1)|X, R = 1]
	
= I(h(X, bβ) > c)
 I(S = 0)
Pr[S = 0]E[I(Y = 1)|X, R = 1]
+ Pr[S = 0|X]I(R = 1)
Pr[S = 0] Pr[R = 1|X]

I(Y = 1) −E[I(Y = 1)|X, R = 1]
	
B = ψsens
 I(S = 0)
Pr[S = 0]E[I(Y = 1)|X, R = 1] + Pr[S = 0|X]I(R = 1)
Pr[S = 0] Pr[R = 1|X]

I(Y = 1) −E[I(Y = 1)|X, R = 1]
	
27
Hence,
α1
1,p0 −ψsensα1
0,p0 = (I(h(X, bβ) > c) −ψsens)×
 I(S = 0)
Pr[S = 0]E[I(Y = 1)|X, R = 1] + Pr[S = 0|X]I(R = 1)
Pr[S = 0] Pr[R = 1|X]

I(Y = 1) −E[I(Y = 1)|X, R = 1]
	
.
And the non-parametric influence function for sensitivity is
(I(h(X, bβ) > c) −ψsens)

I(S=0)
Pr[S=0]E[I(Y = 1)|X, R = 1] + Pr[S=0|X]I(R=1)
Pr[S=0] Pr[R=1|X]

I(Y = 1) −E[I(Y = 1)|X, R = 1]
	
E[E[Y = 1|X, R = 1]|S = 0]
Appendix C
Consistency
Now we prove Theorem 3 for the consistency of the doubly robust estimator for sensitivity in the
target population.
Proof: The doubly robust estimator for sensitivity is
bψsens,dr =
Pn
i=1

I(Si = 0)I(h(Xi, bβ) > c) bm(Xi) + bw(Xi)I(Ri = 1)I(h(Xi, bβ) > c)

I(Yi = 1) −bm(Xi)
	
Pn
i=1
 I(Si = 0) bm(Xi) + bw(Xi)I(Ri = 1)

I(Yi = 1) −bm(Xi)
	
Let m∗(X) be the asymptotic limit of bm(X) and w∗(X) be the asymptotic limit of bw(X). As
n −→∞the doubly robust estimator for sensitivity bψsens,dr converges by the continuous mapping
theorem to
Pr[S = 0]−1 E
h
I(S = 0)I(h(X, bβ) > c)m∗(X) + w∗(X)I(R = 1)I(h(X, bβ) > c)

I(Y = 1) −m∗(X)
	i
Pr[S = 0]−1 E

I(S = 0)m∗(X) + w∗(X)I(R = 1)

I(Y = 1) −m∗(X)
	
.
First assume that m∗(X) = Pr[Y = 1|X, R = 1] but we do not assume that p∗(X) = Pr[R = 1|X].
Under that assumption
Pr[S = 0]−1 E
h
I(S = 0)I(h(X, bβ) > c)m∗(X)
i
= Pr[S = 0]−1 E
h
I(S = 0)I(h(X, bβ) > c) Pr[Y = 1|X, R = 1]
i
= E
h
I(h(X, bβ) > c) Pr[Y = 1|X, R = 1]
S = 0
i
28
and
E
h
w∗(X)I(R = 1)I(h(X, bβ) > c)

I(Y = 1) −m∗(X)
	i
= E
h
E
h
w∗(X)I(R = 1)I(h(X, bβ) > c)

I(Y = 1) −Pr[Y = 1|X, R = 1]
	X
ii
= E
h
w∗(X)I(h(X, bβ) > c) E

I(R = 1)

I(Y = 1) −Pr[Y = 1|X, R = 1]
	X
i
= E
h
w∗(X)I(h(X, bβ) > c) Pr[R = 1|X] E

I(Y = 1) −Pr[Y = 1|X, R = 1]
	X, R = 1
i
= 0
Combining this gives
Pr[S = 0]−1 E
h
I(S = 0)I(h(X, bβ) > c)m∗(X) + w∗(X)I(R = 1)I(h(X, bβ) > c)

I(Y = 1) −m∗(X)
	i
= E
h
I(h(X, bβ) > c) Pr[Y = 1|X, R = 1]
S = 0
i
.
The same arguments give
Pr[S = 0]−1 E

I(S = 0)m∗(X) + w∗(X)I(R = 1)

I(Y = 1) −m∗(X)
	
= E

Pr[Y = 1|X, R = 1]
S = 0

.
And it follows from the identifiability results of the sensitivity in the target population that
bψsens,dr −→E[I(h(X, bβ) > c)|Y = 1, S = 0]
in probability.
Now assume that p∗(X) = Pr[R = 1|X] but we do not assume that m∗(X) = Pr[Y = 1|X, R = 1].
Under that assumption
Pr[S = 0]−1 E
"
(1 −Pr[R = 1|X])I(R = 1)I(h(X, bβ) > c)
Pr[R = 1|X]
I(Y = 1)
	
#
29
= E[I(h(X, bβ) > c, Y = 1)|S = 0]
by the results in the proof of Theorem 1. Now
E
"
I(S = 0)I(h(X, bβ) > c)m∗(X) −(1 −Pr[R = 1|X])I(R = 1)I(h(X, bβ) > c)
Pr[R = 1|X]
m∗(X)
	
#
= E
"
E
"
I(S = 0)I(h(X, bβ) > c)m∗(X) −(1 −Pr[R = 1|X])I(R = 1)I(h(X, bβ) > c)
Pr[R = 1|X]
m∗(X)
	X
##
= E
"
E[I(S = 0)|X]I(h(X, bβ) > c)m∗(X) −(1 −Pr[R = 1|X])I(h(X, bβ) > c)
Pr[R = 1|X]
m∗(X)E[I(R = 1)|X]
	
#
= 0.
Hence,
Pr[S = 0]−1 E
h
I(S = 0)I(h(X, bβ) > c)m∗(X) + w∗(X)I(R = 1)I(h(X, bβ) > c)

I(Y = 1) −m∗(X)
	i
= E[I(h(X, bβ) > c, Y = 1)|S = 0]
and by similar arguments
Pr[S = 0]−1 E

I(S = 0)m∗(X) + Pr[S = 0|X]I(R = 1)
Pr[R = 1|X]

I(Y = 1) −m∗(X)
	
= E[I(Y = 1)|S = 0].
And it follows from the identifiability results of the sensitivity in the target population that
bψsens,dr −→E[I(h(X, bβ) > c)|Y = 1, S = 0]
in probability.
Now we prove Theorem 4 for the consistency of the doubly robust estimator for AUC in the
target population.
30
Proof: The result follows from the continuous mapping theorem if we can show that
1
n(n −1)
X
i̸=j
ddr(Oi, Oj, I(h(Xi, bβ) > h(Xj, bβ))
and the denominator
1
n(n −1)
X
i̸=j
ddr(Oi, Oj, 1)
are consistent
First, suppose that w∗(X) = Pr[R=0|X]
Pr[R=1|X] but we dont make any assumptions on the asymptotic
limit m∗(X). Minor adaptations of Theorem 1 in [16] show that bψauc,w is consistent when w∗(X) =
Pr[R=0|X]
Pr[R=1|X] so it is enough to show that for k(Xi, Xj) = I(h(Xi, bβ) > h(Xj, bβ) and k(Xi, Xj) = 1
then
1
n(n −1)
X
i̸=j
bm(Xi)(1−bm(Xj))(I(Si = 0, Sj = 0)−I(Ri = 1, Rj = 1) bw(Xi) bw(Xj))k(Xi, Xj)
P
−→0.
Now as k(Xi, Xj) only depends on (Xi, Xj)
E [m∗(Xi)(1 −m∗(Xj))I(Ri = 1, Rj = 1)w∗(Xi)w∗(Xj)k(Xi, Xj)]
= E

E

m∗(Xi)(1 −m∗(Xj))I(Ri = 1, Rj = 1)w∗(Xi)w∗(Xj)k(Xi, Xj)
Xi, Xi

= E

m∗(Xi)(1 −m∗(Xj)) E[I(Ri = 1, Rj = 1)|Xi, Xj]Pr[R = 0|Xi]
Pr[R = 1|Xi]
Pr[R = 0|Xj]
Pr[R = 1|Xj]k(Xi, Xj)

= E [m∗(Xi)(1 −m∗(Xj)) Pr[R = 0|Xi] Pr[R = 0|Xj]k(Xi, Xj)]
and
E[m∗(Xi)(1 −m∗(Xj))I(Si = 0, Sj = 0)k(Xi, Xj)]
= E[E[m∗(Xi)(1 −m∗(Xj))I(Si = 0, Sj = 0)k(Xi, Xj)|Xi, Xj]]
= E[m∗(Xi)(1 −m∗(Xj)) E[I(Si = 0, Sj = 0)|Xi, Xj]k(Xi, Xj)]
= E[m∗(Xi)(1 −m∗(Xj)) Pr[R = 0|Xi] Pr[R = 0|Xj]k(Xi, Xj)].
31
It follows that
E[m∗(Xi)(1 −m∗(Xj))(I(Si = 0, Sj = 0) −I(Ri = 1, Rj = 1)w∗(Xi)w∗(Xj))k(Xi, Xj)] = 0.
By Lemma 2 in [16] bm(Xi)(1 −bm(Xj)) and bm(Xi)(1 −bm(Xj)) bw(Xi) bw(Xj) are stochastically
equicontinuous and the results follows from applying Lemma 1 in [16].
Now, assume that m∗(X) = Pr[Y = 1|X, mR = 1] but we don’t assume that w∗(X) = Pr[R=0|X]
Pr[R=1|X].
Minor adaptations of Theorem 2 in [16] show that bψauc,out is consistent when m∗(X) = Pr[Y =
1|X, mR = 1] so it is enough to show that for k(Xi, Xj) = I(h(Xi, bβ) > h(Xj, bβ) and k(Xi, Xj) = 1
then
1
n(n −1)
X
i̸=j
bw(Xi) bw(Xj)(I(Yi = 1, Yj = 0)−bm(Xi)(1−bm(Xj)))I(Ri = 1, Rj = 1)k(Xi, Xj)
P
−→0.
Now
E[w∗(Xi)w∗(Xj)(I(Yi = 1, Yj = 0)I(Ri = 1, Rj = 1) −m∗(Xi)(1 −m∗(Xj)))k(Xi, Xj)]
= E[E[w∗(Xi)w∗(Xj)(I(Yi = 1, Yj = 0) −m∗(Xi)(1 −m∗(Xj)))I(Ri = 1, Rj = 1)k(Xi, Xj)|Xi, Xi]]
= E[w∗(Xi)w∗(Xj)(E[I(Yi = 1, Yj = 0)|Xi, Xi, Ri = 1, Rj = 1]
−Pr[Yi = 1|Xi, Ri = 1] Pr[Yi = j|Xj, Rj = 1]) Pr[Ri = 1|Xi] Pr[Rj = 1|Xj]k(Xi, Xj)]
= 0
The results follows from applying Lemma 1 in [16].
32
Appendix D
Results for specificity, negative and positive predic-
tive value, and estimators of risk
D.1
Identification
The following theorem shows identifiability of specificity in the target population is given below
and proved in Supplementary Web Appendix A.
Theorem 6. If assumptions A1 and A2 and that E[Pr[Y = 0|X, R = 1]|S = 0] > 0 hold, then the
specificity in the target population is identifiable using the observed data through the observed data
functional
E[I(h(X, bβ) ≤c) Pr[Y = 0|X, R = 1]|R = 0]
E[Pr[Y = 0|X, R = 1]R = 0]
(A.1)
or equivalently using the weighting representation
E
h
Pr[R=0|X]
Pr[R=1|X]I(h(X, bβ) ≤c, Y = 0, R = 1)
i
E
h
Pr[R=0|X]
Pr[R=1|X]I(Y = 0, R = 1)
i
.
(A.2)
Proof: For the outcome model representation
E[I(h(X, bβ) ≤c)|Y = 0, S = 0] = E[I(h(X, bβ) ≤c, Y = 0)|S = 0]
E[I(Y = 0)|S = 0]
= E[E[I(h(X, bβ) ≤c, Y = 0)|X, S = 0]|S = 0]
E[E[I(Y = 1)|X, S = 0]|S = 0]
= E[E[I(h(X, bβ) ≤c, Y = 0)|X, R = 1]|S = 0]
E[E[I(Y = 1)|X, R = 1]|S = 0]
= E[I(h(X, bβ) ≤c) Pr[Y = 0|X, R = 1]|S = 0]
E[Pr[Y = 1|X, R = 1]|S = 0]
.
For the inverse-odds weighting we have
E[I(h(X, bβ) ≤c)|Y = 0, S = 0] = E[I(h(X, bβ) ≤c, Y = 0)|S = 0]
E[I(Y = 0)|S = 0]
= E[E[I(h(X, bβ) ≤c, Y = 0)|X, S = 0]|S = 0]
E[E[I(Y = 0)|X, S = 0]|S = 0]
= E[I(S = 0)I(h(X, bβ) ≤c) Pr[Y = 0|X, S = 0]]
E[I(S = 0) Pr[Y = 0|X, S = 0]]
33
= E[I(S = 0)I(h(X, bβ) ≤c) Pr[Y = 0|X, R = 1]]
E[I(S = 0) Pr[Y = 0|X, R = 1]]
=
E
h
I(S = 0)I(h(X, bβ) ≤c) Pr[Y =0,R=1|X]
Pr[R=1|X]
i
E
h
I(S = 0) Pr[Y =0,R=1|X]
Pr[R=1|X]
i
=
E
h
E
h
I(S = 0)I(h(X, bβ) ≤c) Pr[Y =0,R=1|X]
Pr[R=1|X]
X
ii
E
h
E
h
I(S = 0) Pr[Y =0,R=1|X]
Pr[R=1|X]
X
ii
=
E
h
E
h
Pr[S=0|X]
Pr[R=1|X]I(h(X, bβ) ≤c) Pr[Y = 0, R = 1|X]
X
ii
E
h
E
h
Pr[S=0|X]
Pr[R=1|X] Pr[Y = 0, R = 1|X]
X
ii
=
E
h
E
h
Pr[S=0|X]
Pr[R=1|X]I(h(X, bβ) ≤c, Y = 0, R = 1)
X
ii
E
h
E
h
Pr[S=0|X]
Pr[R=1|X]I(Y = 0, R = 1)
X
ii
=
E
h
Pr[S=0|X]
Pr[R=1|X]I(h(X, bβ) ≤c, Y = 0, R = 1)
i
E
h
Pr[S=0|X]
Pr[R=1|X]I(Y = 0, R = 1)
i
Recall that the positive predicted value in the target population is defined as Pr[Y = 1|I(h(X, bβ) >
c), S = 0] and the negative predicted value in the target population is defined as Pr[Y = 0|I(h(X, bβ) ≤
c), S = 0]. The following two theorems show that the positive predictive value and negative pre-
dictive value are identifiable.
Theorem 7. Under assumptions A1 and A2 and that E[I(h(X, bβ) > c)|S = 0] > 0 the positive
predictive value in the target population is identifiable using the observed data through the observed
data functional
E[I(h(X, bβ) > c) Pr[Y = 1|X, R = 1]|S = 0]
E[I(h(X, bβ) > c)|S = 0]
(A.3)
or equivalently using the weighting representation
E
h
Pr[S=0|X]
Pr[R=1|X]I(h(X, bβ) > c, Y = 1, R = 1)
i
E[I(S = 0)I(h(X, bβ) > c)]
(A.4)
34
Proof: For the outcome model representation
E[Y = 1|I(h(X, bβ) > c), S = 0] = E[I(h(X, bβ) > c, Y = 1)|S = 0]
E[I(h(X, bβ) > c)|S = 0]
= E[E[I(h(X, bβ) > c, Y = 1)|X, S = 0]|S = 0]
E[I(h(X, bβ) > c)|S = 0]
= E[E[I(h(X, bβ) > c, Y = 1)|X, R = 1]|S = 0]
E[I(h(X, bβ) > c)|S = 0]
= E[I(h(X, bβ) > c) Pr[Y = 1|X, R = 1]|S = 0]
E[I(h(X, bβ) > c)|S = 0]
For the inverse-odds weighting we have
E[Y = 1|I(h(X, bβ) > c), S = 0] = E[I(h(X, bβ) > c, Y = 1)|S = 0]
E[I(h(X, bβ) > c)|S = 0]
= E[E[I(h(X, bβ) > c, Y = 1)|X, S = 0]|S = 0]
E[I(h(X, bβ) > c)|S = 0]
= E[I(S = 0)I(h(X, bβ) > c) Pr[Y = 1|X, S = 0]]
E[I(S = 0)I(h(X, bβ) > c)]
= E[I(S = 0)I(h(X, bβ) > c) Pr[Y = 1|X, R = 1]]
E[I(S = 0)I(h(X, bβ) > c)]
=
E
h
I(S = 0)I(h(X, bβ) > c) Pr[Y =1,R=1|X]
Pr[R=1|X]
i
E[I(S = 0)I(h(X, bβ) > c)]
=
E
h
E
h
I(S = 0)I(h(X, bβ) > c) Pr[Y =1,R=1|X]
Pr[R=1|X]
X
ii
E[I(S = 0)I(h(X, bβ) > c)]
=
E
h
E
h
Pr[R=0|X]
Pr[R=1|X]I(h(X, bβ) > c) Pr[Y = 1, R = 1|X]
X
ii
E[I(S = 0)I(h(X, bβ) > c)]
=
E
h
E
h
Pr[R=0|X]
Pr[R=1|X]I(h(X, bβ) > c, Y = 1, R = 1)
X
ii
E[I(S = 0)I(h(X, bβ) > c)]
=
E
h
Pr[S=0|X]
Pr[R=1|X]I(h(X, bβ) > c, Y = 1, R = 1)
i
E[I(S = 0)I(h(X, bβ) > c)]
The following theorem gives the identifiability result for the negative predictive value and the proof
is similar to the proof of Theorem 7.
35
Theorem 8. If assumptions A1, A2 and that E[I(h(X, bβ) ≤c)|S = 0] > 0 hold, then the negative
predictive value in the target population is identifiable using the observed data through the observed
data functional
E[I(h(X, bβ) ≤c) Pr[Y = 0|X, R = 1]|S = 0]
E[I(h(X, bβ) ≤c)|S = 0]
(A.5)
or equivalently using the weighting representation
E
h
Pr[S=0|X]
Pr[R=1|X]I(h(X, bβ) ≤c, Y = 0, R = 1)
i
E[I(S = 0)I(h(X, bβ) ≤c)]
.
(A.6)
D.2
Estimation
For specificity the sample analogs of the identifiability result in Theorem 6 give the outcome model
estimator
bψspec,out =
Pn
i=1 I(Ri = 0)I(h(Xi, bβ) ≤c)(1 −bm(Xi))
Pn
i=1 I(Ri = 0)(1 −bm(Xi))
,
(A.7)
and the weighting estimator
bψspec,w =
Pn
i=1 I(h(Xi, bβ) ≤c, Yi = 0, Ri = 1) bw(Xi)
Pn
i=1 I(Yi = 0, Ri = 1) bw(Xi)
.
(A.8)
Lastly, the doubly robust estimator for specificity bψspec,dr is equal to
Pn
i=1

I(Si = 0)I(h(Xi, bβ) ≤c)(1 −bm(Xi)) + bw(Xi)I(Ri = 1)I(h(Xi, bβ) ≤c)

I(Yi = 0) −(1 −bm(Xi))
	
Pn
i=1
 I(Si = 0)(1 −bm(Xi)) + bw(Xi)I(Ri = 1)

I(Yi = 0) −(1 −bm(Xi))
	
Using the sample analogs of the identifiability expressions in Theorem 7 gives the outcome model
estimator for the positive predictive value in the target population
bψppv,out =
Pn
i=1 I(Ri = 0)I(h(Xi, bβ) > c) bm(Xi)
Pn
i=1 I(Ri = 0)I(h(Xi, bβ) > c)
,
(A.9)
and the weighting estimator
bψppv,w =
Pn
i=1 I(h(Xi, bβ) > c, Yi = 1, Ri = 1) bw(Xi)
Pn
i=1 I(Ri = 1) bw(Xi)I(h(Xi, bβ) > c)
.
(A.10)
36
Similar calculations as for the doubly robust estimators of sensitivity result in the doubly robust
estimator of the positive predictive value bψppv,dr given by the formula
Pn
i=1

I(Si = 0)I(h(Xi, bβ) > c) bm(Xi) + bw(Xi)I(Ri = 1)I(h(Xi, bβ) > c)

I(Yi = 1) −bm(Xi)
	
Pn
i=1 I(Ri = 0)I(h(Xi, bβ) > c)
Similarly we have the outcome model estimator for the negative predictive value in the target
population
bψnpv,out =
Pn
i=1 I(Ri = 0)I(h(Xi, bβ) ≤c)(1 −bm(Xi))
Pn
i=1 I(Ri = 0)I(h(Xi, bβ) ≤c)
,
(A.11)
and the weighting estimator
bψnpv,w =
Pn
i=1 I(h(Xi, bβ) ≤c, Yi = 0, Ri = 1) bw(Xi)
Pn
i=1 I(Ri = 1) bw(Xi)I(h(Xi, bβ) ≤c)
.
(A.12)
The doubly robust estimator for the negative predictive value bψnpv,dr is given by
Pn
i=1

I(Si = 0)I(h(Xi, bβ) ≤c)(1 −bm(Xi)) + bw(Xi)I(Ri = 1)I(h(Xi, bβ) ≤c)

I(Yi = 0) −(1 −bm(Xi))
	
Pn
i=1 I(Ri = 0)I(h(Xi, bβ) ≤c)
The doubly robust estimators of specificity, positive and negative predictive value are consistent if
at least one (but not necessarily both) of bm(X) and bw(X) are correctly specified.
For loss-based measures of model performance, the target parameter is the risk (expected loss)
in the target population
E[L(Y, h(X, bβ))|S = 0],
which is identifiable through the expression
E[L(Y, h(X, bβ))|S = 0] = E[E[L(Y, h(X, bβ))|X, S = 0]|S = 0]
= E[E[L(Y, h(X, bβ))|X, R = 1]|S = 0]
37
and
E[E[L(Y, h(X, bβ))|X, R = 1]|S = 0] =
1
Pr[S = 0] E

I(R = 0) E

I(R = 1)
Pr[R = 1|X]L(Y, h(X, bβ))
X

=
1
Pr[S = 0] E

E
I(R = 1) Pr[R = 0|X]
Pr[R = 1|X]
L(Y, h(X, bβ))
X

=
1
Pr[S = 0] E
I(R = 1) Pr[R = 0|X]
Pr[R = 1|X]
L(Y, h(X, bβ))

.
The sample analogs of the identifibaiblity expressions above are the outcome model estimator
bψloss,out = 1
n0
n
X
i=1
I(Si = 0)bE[L(Y, h(X, bβ))|Xi, Ri = 1]
where bE[L(Y, h(X, bβ))|X, R = 1] is an estimator for E[L(Y, h(X, bβ))|X, R = 1]. We also have the
weighting estimator
bψloss,w = 1
n0
n
X
i=1
I(Ri = 1) bw(Xi)L(Yi, h(Xi, bβ)).
Following the arguments in [12], the doubly robust estimator is defined as
1
n0
n
X
i=1
h
I(Ri = 1) bw(Xi)

L(Y, h(X, bβ)) −bE[L(Y, h(X, bβ))|Xi, R = 1]

+ I(Si = 0)bE[L(Y, h(X, bβ))|Xi, R = 1]
i
.
Appendix E
Additional results under the exponential tilt model
for sensitivity
Under the exponential tilt model we have
fY |X,S(y|x, s = 0) = eγs′yfY |X,S(y|x, s = s′)
E[eγs′y|X = x, S = s′] .
which implies that for a function g(Y, X)
E[g(Y, X)|X, S = 0] =
Z
g(y, X)df(y|X, S = 0)
=
R
g(y, X)eγs′dfY |X,S(y|x, s = s′)
E[eγs′Y |X = x, S = s′]
38
= E[g(Y, X)eγs′Y |X, S = s′]
E[eγs′Y |X, S = s′]
Using this result we have
E[E[I(h(X, bβ) > c, Y = 1)|X, S = 0]|S = 0] = E
"
E[I(h(X, bβ) > c, Y = 1)eγs′Y |X, S = s′]
E[eγs′Y |X, S = s′]
S = 0
#
and
E[E[I(Y = 1)|X, S = 0]|S = 0] = E
"
E[I(Y = 1)eγs′q(Y )|X, S = s′]
E[eγs′Y |X, S = s′]
S = 0
#
Using this results the sensitivity in the target population under the exponential tilt model can be
identified using
E[I(h(X, bβ) > c)|Y = 1, S = 0] = E[I(h(X, bβ) > c, Y = 1)|S = 0]
E[I(Y = 1)|S = 0]
= E[E[I(h(X, bβ) > c, Y = 1)|X, S = 0]|S = 0]
E[E[I(Y = 1)|X, S = 0]|S = 0]
= E[E[I(h(X, bβ) > c, Y = 1)|X, S = 0]|S = 0]
E[E[I(Y = 1)|X, R = 1]|S = 0]
=
E
"
E[I(h(X,bβ)>c,Y =1)eγs′ Y |X,S=s′]
E[eγs′ Y |X,S=s′]
S = 0
#
E
"
E[I(Y =1)eγs′ Y |X,S=s′]
E[eγs′ Y |X,S=s′]
S = 0
#
Appendix F
Additional simulation results
Figure 2 show results from simulations were the model is correct and the relative bias < 2% for
both outcome model and weighting estimator and the estimator calculated using the data from the
source population is biased (4% −163% relative bias).
Figures 3 and 4 shows the results when the outcome model and model for study participation are
estimated using a generalized additive model when the model being estimated is correctly specified
and when it is misspecified, respectively. The generalized additive models where fit using splines
for the main effect of each covariate. The results are similar to when generalized linear models are
used to estimate the outcome model and the model for study participation.
39
0.1
0.2
0.3
0.4
0.5
OM
W
DR Source
Method
Sensitivity
1)
0.7
0.8
0.9
OM
W
DR Source
Method
Specificity
2)
0.80
0.85
0.90
OM
W
DR Source
Method
PPV
3)
0.22
0.24
0.26
0.28
0.30
0.32
OM
W
DR Source
Method
NPV
4)
0.14
0.16
0.18
0.20
OM
W
DR Source
Method
Brier
5)
0.55
0.60
0.65
0.70
OM
W
DR Source
Method
AUC
6)
Figure 2: Simulation results for estimating model performance in the target population estimated
using the outcome model (OM) estimator, weighting (W) estimator, doubly robust (DR) and an
estimator that uses only data from the collection of studies (Source).
The measures of model
performance evaluated are: sensitivity (Plot 1), specificity (Plot 2), positive predictive value (Plot
3), negative predictive value (Plot 4), Brier score (Plot 5), and area under the curve (Plot 6). The
horizontal line is the true measure of model performance (calculated analytically). Here, the model
that is evaluated is correctly specified.
40
Figure 3: Simulation results for estimating model performance in the target population estimated
using the outcome model estimator, weighting estimator, and an estimator that uses only data
from the collection of studies. For both the outcome model and the model for study participation
are estimated using a generalized additive model. The measures of model performance evaluated
are: sensitivity (Plot 1), specificity (Plot 2), positive predictive value (Plot 3), negative predictive
value (Plot 4), Brier score (Plot 5), and area under the curve (Plot 6). The horizontal line is the
true measure of model performance (calculated analytically). Here, the model that is evaluated is
correctly specified.
41
0.1
0.2
0.3
0.4
OM
W
DR Source
Method
Sensitivity
1)
0.80
0.85
0.90
0.95
OM
W
DR Source
Method
Specificity
2)
0.80
0.85
0.90
0.95
OM
W
DR Source
Method
PPV
3)
0.200
0.225
0.250
0.275
0.300
OM
W
DR Source
Method
NPV
4)
0.14
0.16
0.18
0.20
OM
W
DR Source
Method
Brier
5)
0.50
0.55
0.60
0.65
OM
W
DR Source
Method
AUC
6)
Figure 4: Simulation results for estimating model performance in the target population estimated
using the outcome model estimator, weighting estimator, and an estimator that uses only data
from the collection of studies. For both the outcome model and the model for study participation
are estimated using a generalized additive model. The measures of model performance evaluated
are: sensitivity (Plot 1), specificity (Plot 2), positive predictive value (Plot 3), negative predictive
value (Plot 4), Brier score (Plot 5), and area under the curve (Plot 6). The horizontal line is the
true measure of model performance (calculated analytically). Here, the model that is evaluated is
misspecified.
42
Appendix G
Accounting for survey sampling weights in the sam-
ple from the target population
In this section we show how the estimators for model performance in the target population can be
extended to sampling designs where each observation in the target population is associated with a
survey sampling weight w.
The modified outcome model estimator for sensitivity in the target population is
Pn
i=1 I(Ri = 0)wiI(h(Xi, bβ) > c) bm(Xi)
Pn
i=1 I(Ri = 0)wi bm(Xi)
.
As bm(X) is an estimator for Pr[Y = 1|X, R = 1] does not involve target population data it does
not need to be modified.
The weighting estimator is given by
Pn
i=1 I(h(Xi, bβ) > c, Yi = 1, Ri = 1) ˜w(Xi)
Pn
i=1 I(Yi = 1, Ri = 1) ˜w(Xi)
,
where ˜w(X) is an estimator for Pr[R=0|X]
Pr[R=1|X] that incorporates the sampling weights (e.g., through a
weighted logistic regression). The modified doubly robust estimator is
Pn
i=1

wiI(Si = 0)I(h(Xi, bβ) > c) bm(Xi) + ˜w(Xi)I(Ri = 1)I(h(Xi, bβ) > c)

I(Yi = 1) −bm(Xi)
	
Pn
i=1
 wiI(Si = 0) bm(Xi) + ˜w(Xi)I(Ri = 1)

I(Yi = 1) −bm(Xi)
	
.
For specificity the modified outcome model estimator is
Pn
i=1 I(Ri = 0)wiI(h(Xi, bβ) ≤c)(1 −bm(Xi))
Pn
i=1 I(Ri = 0)wi(1 −bm(Xi))
,
and the modified weighting estimator is given by
Pn
i=1 I(h(Xi, bβ) ≤c, Yi = 0, Ri = 1) ˜w(Xi)
Pn
i=1 I(Yi = 1, Ri = 1) ˜w(Xi)
.
43
The modified doubly robust estimator for specificity is given by
Pn
i=1

wiI(Si = 0)I(h(Xi, bβ) ≤c)(1 −bm(Xi)) + ˜w(Xi)I(Ri = 1)I(h(Xi, bβ) ≤c)

I(Yi = 0) −(1 −bm(Xi))
	
Pn
i=1
 wiI(Si = 0)(1 −bm(Xi)) + ˜w(Xi)I(Ri = 1)

I(Yi = 0) −(1 −bm(Xi))
	
The modified outcome model estimator for the area under the curve in the target population is
given by
P
i̸=j wiwj bm(Xi)(1 −bm(Xj))I(h(Xi, bβ) > h(Xj, bβ), Si = 0, Sj = 0)
P
i̸=j wiwj bm(Xi)(1 −bm(Xj))I(Si = 0, Sj = 0)
,
and the modified weighting-based estimator for the AUC in the target population is given by
P
i̸=j ˜w(Xi) ˜w(Xj)I(h(Xi, bβ) > h(Xj, bβ), Yi = 1, Yj = 0, Ri = 1, Rj = 1)
P
i̸=j ˜w(Xi) ˜w(Xj)I(Yi = 1, Yj = 0, Ri = 1, Rj = 1)
.
and the modified doubly robust estimator is given by
ddr,w(Oi, Oj; k(Xi, Xj)) = dw,w(Oi, Oj; k(Xi, Xj)) + dout,w(Oi, Oj; k(Xi, Xj))−
˜w(Xi) bw(Xj) bm(Xi)(1 −bm(Xj))I(Ri = 1, Rj = 1)k(Xi, Xj).
where dw,w(Oi, Oj; k(Xi, Xj)) and dout,w(Oi, Oj; k(Xi, Xj)) are weighted versions of dw(Oi, Oj; k(Xi, Xj))
and dout(Oi, Oj; k(Xi, Xj)). The modified outcome model estimator for the positive predictive value
in the target population is given by
Pn
i=1 I(Ri = 0)wiI(h(Xi, bβ) > c) bm(Xi)
Pn
i=1 I(Ri = 0)wiI(h(Xi, bβ) > c)
,
and the modified weighting estimator is
Pn
i=1 I(h(Xi, bβ) > c, Yi = 1, Ri = 1) ˜w(Xi)
Pn
i=1 I(Ri = 1) ˜w(Xi)I(h(Xi, bβ) > c)
.
The modified doubly robust estimator for the positive predictive value in the target population is
Pn
i=1

wiI(Si = 0)I(h(Xi, bβ) > c) bm(Xi) + ˜w(Xi)I(Ri = 1)I(h(Xi, bβ) > c)

I(Yi = 1) −bm(Xi)
	
Pn
i=1 I(Ri = 0)wiI(h(Xi, bβ) > c)
44
The modified outcome model estimator for the negative predictive value in the target population
is
Pn
i=1 wiI(Ri = 0)I(h(Xi, bβ) ≤c)(1 −bm(Xi))
Pn
i=1 wiI(Ri = 0)I(h(Xi, bβ) ≤c)
,
and the modified weighting estimator is given by
Pn
i=1 I(h(Xi, bβ) ≤c, Yi = 0, Ri = 1) ˜w(Xi)
Pn
i=1 I(Ri = 1) ˜w(Xi)I(h(Xi, bβ) ≤c)
.
The modified doubly robust estimator for the negative predictive value is
Pn
i=1

wiI(Si = 0)I(h(Xi, bβ) ≤c)(1 −bm(Xi)) + ˜w(Xi)I(Ri = 1)I(h(Xi, bβ) ≤c)

I(Yi = 0) −(1 −bm(Xi))
	
Pn
i=1 wiI(Ri = 0)I(h(Xi, bβ) ≤c)
Lastly, the modified outcome model estimator for the Brier risk is given by
1
Pn
i=1 I(Ri = 0)wi
n
X
i=1
I(Ri = 0)wibE[L(Y, h(X, bβ))|Xi, Ri = 1]
and the modified weighting estimator is given by
1
Pn
i=1 I(Ri = 0)wi
n
X
i=1
I(Ri = 1) ˜w(Xi)L(Yi, h(Xi, bβ)).
The modified doubly robust estimator for the target population risk is given by
Pn
i=1
h
I(Ri = 1) ˜w(Xi)

L(Y, h(X, bβ)) −bE[L(Y, h(X, bβ))|Xi, R = 1]

+ wiI(Si = 0)bE[L(Y, h(X, bβ))|Xi, R = 1]
i
Pn
i=1 I(Ri = 0)wi
.
45
